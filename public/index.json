[{"content":" Patrick Hunt and Mahadev Konar\nYahoo! Grid\n{phunt,mahadev}@yahoo-inc.com Flavio P. Junqueira and Benjamin Reed\nYahoo! Research\n{fpj,breed}@yahoo-inc.com 摘要 在本文中，我们描述了Zookeeper，一种用于协调分布式应用程序进程的服务。由于Zookeeper是关键基础设施的一部分，它旨在为客户端构建更复杂的协调原语提供一个简单且高性能的核心。它在一个复制的集中式服务中结合了组消息传递、共享寄存器和分布式锁服务的元素。Zookeeper提供的接口具有共享寄存器的无等待特性，并带有一个类似于分布式文件系统中缓存失效的事件驱动机制，从而提供一个简单而强大的协调服务。\nZookeeper的接口支持高性能服务实现。除了无等待特性外，Zookeeper还为客户机提供了请求的先进先出（FIFO）执行保证，并对所有改变Zookeeper状态的请求提供线性一致性。这些设计决策使得实现高性能处理流水线成为可能，读请求可以由本地服务器满足。我们展示了针对目标工作负载（读写比例为2:1到100:1），Zookeeper每秒能够处理数万到数十万次事务。这种性能允许客户端应用程序广泛使用Zookeeper。\n1 引言 大规模分布式应用程序需要不同形式的协调。配置是最基本的协调形式之一。在其最简单的形式中，配置只是系统进程的操作参数列表，而更复杂的系统则具有动态配置参数。组成员关系和领导者选举在分布式系统中也很常见：通常进程需要知道其他哪些进程是活跃的以及这些进程负责什么。锁是一种强大的协调原语，用于实现对关键资源的互斥访问。\n一种协调的方法是为每种不同的协调需求开发特定的服务。例如，Amazon Simple Queue Service 1 专门针对队列设计。其他服务则专门为领导者选举 2 和配置 3 开发。实现更强大原语的服务可以用来实现功能较弱的原语。例如，Chubby 4 是一个具有强同步保证的锁定服务。然后可以使用锁来实现领导者选举、组成员关系等。\n在设计我们的协调服务时，我们没有选择在服务器端实现特定的原语，而是选择公开一个API，使应用程序开发人员能够实现自己的原语。这种选择导致了协调内核（coordination kernel）的实现，使得无需更改服务核心即可启用新的原语。这种方法允许根据应用的需求适应多种协调形式，而不是限制开发者使用固定的一组原语。\n在设计Zookeeper的API时，我们避开了锁等阻塞原语。协调服务中的阻塞原语可能会导致诸如慢速或故障客户端对更快客户端性能产生负面影响等问题。如果请求处理依赖于其他客户端的响应和故障检测，服务本身的实现也会变得更加复杂。因此，我们的系统Zookeeper实现了一个操作简单无等待（wait-free）数据对象的API，这些数据对象以类似于文件系统的方式进行层次化组织。实际上，Zookeeper的API与其他文件系统的API相似，仅从API签名来看，Zookeeper似乎就是没有锁方法、打开和关闭功能的Chubby。然而，实现无等待数据对象使Zookeeper与基于锁等阻塞原语的系统有显著区别。\n尽管无等待特性对性能和容错至关重要，但对于协调来说，这还不够。我们还需要为操作提供顺序保证。特别是，我们发现保证所有操作的先进先出（FIFO）客户机顺序和写操作的线性一致性，能够实现服务的高效实施，并且足以实现对我们应用程序感兴趣的协调原语。实际上，我们可以使用我们的API为任意数量的进程实现共识，根据Herlihy的层次结构，Zookeeper实现了通用对象5。\nZookeeper服务由一组使用复制技术以实现高可用性和性能的服务器组成。其高性能使得包含大量进程的应用程序能够使用这种协调内核来管理所有方面的协调。我们能够使用一种简单的流水线架构实现Zookeeper，这种架构允许我们在仍有低延迟的情况下处理数百或数千个未完成的请求。这样的流水线自然支持单个客户端操作按FIFO顺序执行。保证FIFO客户机顺序使客户机可以异步提交操作。通过异步操作，客户机能够同时拥有多个未完成的操作。例如，当一个新的客户机成为领导者并且需要相应地操作和更新元数据时，这一特性是理想的。如果没有多未完成操作的可能性，初始化时间可能会达到数秒而不是亚秒级。\n为了保证更新操作满足线性一致性，我们实现了一个基于领导者的原子广播协议6，称为Zab7。然而，一个典型的Zookeeper应用程序工作负载主要由读操作主导，因此需要扩展读吞吐量。在Zookeeper中，服务器本地处理读操作，并且不使用Zab对它们进行全局排序。\n客户端侧缓存数据是提高读性能的重要技术。例如，对于一个进程来说，缓存当前领导者的标识符比每次需要知道领导者信息时都查询Zookeeper要高效得多。Zookeeper使用观察机制使客户端能够在不直接管理客户端缓存的情况下缓存数据。通过这种机制，客户端可以监视给定数据对象的更新，并在发生更新时收到通知。Chubby直接管理客户端缓存，它阻止更新以使所有缓存了正在更改数据的客户端的缓存失效。在这种设计下，如果这些客户端中有任何一个缓慢或出现故障，更新将会被延迟。Chubby使用租约防止故障客户端无限期地阻塞系统。然而，租约仅限制了缓慢或故障客户端的影响，而Zookeeper的观察机制则完全避免了这一问题。\n在本文中，我们讨论 ZooKeeper 的设计和实现。借助 ZooKeeper，我们能够实现应用程序所需的所有协调原语，即使只有写入是可线性化的。为了验证我们的方法，我们展示了如何使用 ZooKeeper 实现一些协调原语。\n总之，本文的主要贡献如下：\n协调内核：我们提出了一种具有宽松一致性保证的无等待协调服务，用于分布式系统中。特别是，我们描述了协调内核的设计与实现，该内核已在许多关键应用中用于实现各种协调技术。\n协调方案：我们展示了如何使用Zookeeper构建更高级别的协调原语，甚至是阻塞和强一致性的原语，这些原语在分布式应用中经常被使用。\n协调经验：我们分享了一些使用Zookeeper的方式，并评估了其性能。通过这些实际应用和性能评估，我们可以更好地理解Zookeeper在真实环境中的表现及其对分布式应用的支持能力。\n2 ZooKeeper 服务 客户通过使用Zookeeper客户端库的客户端API向Zookeeper提交请求。除了通过客户端API暴露Zookeeper服务接口外，客户端库还管理客户端与Zookeeper服务器之间的网络连接。在本节中，我们首先提供Zookeeper服务的高层视图。然后讨论客户端用于与Zookeeper交互的API。\n术语。在本文中，我们使用客户端（client）表示ZooKeeper服务的用户，服务器（server）表示提供ZooKeeper服务的进程，znode表示ZooKeeper数据中的内存数据节点，这些节点在一个分层命名空间中组织，称为数据树（data tree）。我们还使用术语更新和写入来指代任何修改数据树状态的操作。客户端在连接到ZooKeeper并获取会话句柄通过其发出请求时建立会话（session）。\n2.1 服务总览 ZooKeeper为其客户端提供了一组按照分层命名空间组织的数据节点（znodes）的抽象。这个层次结构中的znodes是客户端通过ZooKeeper API进行操作的数据对象。分层命名空间常见于文件系统中，这是一种理想的组织数据对象的方式，因为用户对此抽象非常熟悉，并且它能够更好地组织应用程序元数据。为了引用一个特定的znode，我们使用标准的UNIX文件系统路径表示法。例如，我们使用/A/B/C来表示znode C的路径，其中C的父节点是B，而B的父节点是A。所有znodes都存储数据，并且除了临时znodes外，所有znodes都可以有子节点。\n客户端可以创建两种类型的 znode：\n常规znodes（regular）：客户端通过显式地创建和删除来操作常规znodes。\n临时znodes（ephemeral）：客户端创建此类znodes，它们要么由客户端显式删除，要么在创建它们的会话终止（无论是故意终止还是由于故障）时由系统自动移除。\n此外，当创建一个新的znode时，客户端可以设置一个顺序（sequential）标志。设置了顺序标志的节点会在其名称后附加一个单调递增计数器的值。如果$n$是新的znode，$p$是父znode，则$n$的序列值永远不会小于在$p$下创建的任何其他顺序znode名称中的值。\nZooKeeper实现了监视（watches）机制，允许客户端在不进行轮询的情况下及时接收变化的通知。当客户端发出带有监视标志的读操作时，操作会正常完成，但服务器承诺在返回的信息发生变化时通知客户端。监视是一次性触发器，与一个会话相关联；一旦触发或会话关闭，它们就会被注销。监视仅指示发生了变化，但不会提供具体的变化内容。例如，如果客户端在“/foo”被更改两次之前发出getData(''/foo'', true)，客户端将收到一个监视事件，告知“/foo”的数据已更改。会话事件，如连接丢失事件，也会发送到监视回调中，以便客户端知道监视事件可能会延迟。\n数据模型。 ZooKeeper的数据模型本质上是一个简化了API的文件系统，仅支持全数据读写，或者是一个具有层次键的键/值表。层次命名空间有助于为不同应用的命名空间分配子树，并设置这些子树的访问权限。我们还利用客户端侧的目录概念来构建更高级的原语，如我们在第2.4节中将看到的。与文件系统中的文件不同，znodes并不是为通用数据存储设计的。相反，znodes映射到客户端应用程序的抽象，通常对应于用于协调目的的元数据。\n举例来说，在图1中，我们有两个子树，一个用于应用程序1（/app1），另一个用于应用程序2（/app2）。应用程序1的子树实现了一个简单的组成员协议：每个客户端进程$p_i$在/app1下创建一个znode p_i，只要该进程正在运行，这个znode就会持续存在。\n尽管znodes并未设计用于通用数据存储，ZooKeeper确实允许客户端存储一些可用于分布式计算中的元数据或配置的信息。例如，在基于领导者的应用中，刚开始启动的应用服务器可以利用这种信息了解当前的领导者是哪一台服务器。为了实现这一目标，当前的领导者可以在znode空间中的已知位置写入这些信息。znodes还关联有时间戳和版本计数器等元数据，这使得客户端能够跟踪znodes的变化，并基于znode的版本执行条件更新。\n会话。 客户端连接到ZooKeeper并启动一个会话。会话有一个关联的超时时间。如果ZooKeeper在超过该超时时间内未从会话中收到任何信息，则认为该客户端出现故障。当客户端显式关闭会话句柄或ZooKeeper检测到客户端出现故障时，会话结束。在一个会话中，客户端会观察到一系列状态变化，这些变化反映了其操作的执行情况。会话使得客户端能够在ZooKeeper集群中的服务器之间透明地切换，从而实现在ZooKeeper服务器之间的持久化。\n2.2 Client API 我们下面展示ZooKeeper API的一个相关子集，并讨论每个请求的语义。\ncreate(path, data, flags): 创建一个路径名为path的znode，将data[]存储在其中，并返回新znode的名称。flags使客户端可以选择znode的类型：常规、临时，并设置顺序标志。\ndelete(path, version): 如果znode处于预期版本，则删除路径为path的znode。\nexists(path, watch): 如果路径名为path的znode存在，则返回true，否则返回false。watch标志使客户端能够在znode上设置监视。\ngetData(path, watch): 返回与znode关联的数据和元数据（如版本信息）。watch标志的作用方式与exists()相同，除非znode不存在时ZooKeeper不会设置监视。\nsetData(path, data, version): 如果版本号是znode的当前版本，则将data[]写入路径为path的znode。\ngetChildren(path, watch): 返回一个znode的所有子节点的名称集合。\nsync(path): 等待在操作开始时所有挂起的更新传播到客户端所连接的服务器。路径目前被忽略。\n所有方法在API中都有同步和异步两种版本。当应用程序需要执行单个ZooKeeper操作且没有其他并发任务要执行时，可以使用同步API，它会进行必要的ZooKeeper调用并阻塞。然而，异步API允许应用程序同时有多个未完成的ZooKeeper操作和其他任务并行执行。ZooKeeper客户端保证每个操作对应的回调按顺序被调用。\n请注意，ZooKeeper不使用句柄来访问znodes。每个请求都包含正在操作的znode的完整路径。这一选择不仅简化了API（无需open()或close()方法），还消除了服务器需要维护的额外状态。\n每个更新方法都需要一个预期的版本号，这使得实现条件更新成为可能。如果znode的实际版本号与预期版本号不匹配，则更新会因版本不匹配错误而失败。如果版本号为-1，则不执行版本检查。\n2.3 ZooKeeper保证 ZooKeeper有两个基本的顺序保证：\n线性化写入：所有更新ZooKeeper状态的请求都是可序列化的，并且遵循优先顺序。 FIFO客户端顺序：来自同一客户端的所有请求都按照客户端发送的顺序执行。 注意，我们对线性一致性的定义与Herlihy8最初提出的定义不同，我们称之为A-线性一致性（A-linearizability）（异步线性一致性）。在Herlihy最初的线性一致性定义中，客户端一次只能有一个未完成的操作（即一个客户端相当于一个线程）。而在我们的定义中，我们允许客户端有多个未完成的操作，因此我们可以选择不对同一客户端的未完成操作保证任何特定顺序，或者保证FIFO顺序。我们选择了后者作为我们的属性。重要的是要观察到，所有适用于线性一致对象的结果也适用于A-线性一致对象，因为满足A-线性一致性的系统也满足线性一致性。由于只有更新请求是A-线性一致的，ZooKeeper在每个副本上本地处理读请求。这使得服务能够在添加服务器时线性扩展。\n为了理解这两个保证如何相互作用，考虑以下场景：一个由多个进程组成的系统选举一个领导者来指挥工作进程。当一个新的领导者接管系统时，它必须更改大量的配置参数，并在完成后通知其他进程。这里我们有两个重要的要求：\n当新领导者开始进行更改时，我们不希望其他进程开始使用正在更改的配置； 如果新领导者在配置完全更新之前死亡，我们不希望进程使用这个部分配置。 观察到分布式锁，如Chubby提供的锁，可以帮助满足第一个要求，但对于第二个要求是不够的。使用ZooKeeper，新的领导者可以指定一个路径作为就绪（ready） znode；其他进程只有在该znode存在时才会使用配置。新领导者通过删除就绪znode、更新各种配置znode并重新创建就绪来更改配置。所有这些更改都可以流水线化并异步发出以快速更新配置状态。尽管更改操作的延迟大约为2毫秒，但如果一个接一个地发出请求，新领导者必须更新5000个不同的znode将需要10秒钟；通过异步发出请求，整个过程将花费不到一秒钟。由于顺序保证，如果一个进程看到就绪 znode，它也必须看到新领导者做出的所有配置更改。如果新领导者在就绪 znode创建之前失败，其他进程就知道配置尚未最终确定并不会使用它。\n上述方案仍然有一个问题：如果一个进程在新领导者开始进行更改之前看到就绪znode存在，然后在更改进行过程中开始读取配置，会发生什么？这个问题通过通知的顺序保证来解决：如果客户端正在监视更改，那么在更改完成后，客户端会在看到系统的新状态之前看到通知事件。因此，如果读取就绪znode的进程请求对该znode的更改通知，它将在读取任何新的配置之前看到通知，告知客户端发生了更改。\n另一个问题可能出现在客户端除了使用ZooKeeper之外还有自己的通信渠道时。例如，考虑两个客户端A和B在ZooKeeper中有一个共享配置并通过一个共享通信渠道进行通信。如果A在ZooKeeper中更改了共享配置并通过共享通信渠道通知B，B会在重新读取配置时期望看到该更改。如果B的ZooKeeper副本稍微落后于A的副本，它可能不会立即看到新的配置。利用上述保证，B可以通过在重新读取配置之前发出一个写请求来确保看到最新的信息。为了更高效地处理这种情况，ZooKeeper提供了sync请求：当跟随一个读操作时，构成一个慢读（slow read）。sync会使得服务器在处理读请求之前应用所有挂起的写请求，而无需承担完整写入的开销。这个原语在概念上类似于ISIS 9中的flush原语。\nZooKeeper还具有以下两个活跃性和持久性保证：如果大多数ZooKeeper服务器处于活动状态并且能够相互通信，则服务将可用；如果ZooKeeper服务成功响应了一个更改请求，那么该更改将在任何数量的故障后依然存在，只要最终有足够数量的服务器能够恢复。\n2.4 原语示例 在本节中，我们将展示如何使用ZooKeeper API实现更强大的原语。ZooKeeper服务对这些更强大的原语一无所知，因为它们完全是在客户端使用ZooKeeper客户端API实现的。一些常见的原语，如组成员关系和配置管理，也是无等待的。对于其他原语，如会合（rendezvous），客户端需要等待一个事件。尽管ZooKeeper是无等待的，我们仍然可以使用ZooKeeper实现高效的阻塞原语。ZooKeeper的顺序保证允许对系统状态进行高效推理，而监视机制则允许高效地等待。\n配置管理。ZooKeeper可以用于在分布式应用中实现动态配置。最简单的情况下，配置存储在一个znode，$z_c$中。进程启动时使用$z_c$的完整路径名。启动的进程通过读取$z_c$并设置监视标志为true来获取其配置。如果$z_c$中的配置被更新，进程会收到通知，并再次读取新的配置，同时将监视标志设置为true。\n注意，在此方案中，如同在大多数使用监视的其他方案中一样，监视用于确保进程拥有最新的信息。例如，如果一个正在监视$z_c$的进程收到$z_c$更改的通知，并且在它能够发出对$z_c$的读取请求之前，$z_c$又发生了三次更改，该进程不会收到额外的三个通知事件。这不会影响进程的行为，因为那三个事件只会通知进程它已经知道的事情：它所拥有的$z_c$信息已经过时了。\n会合。在分布式系统中，有时事先并不清楚最终的系统配置会是什么样子。例如，客户端可能想要启动一个主进程和若干个工作进程，但启动这些进程是由调度器完成的，因此客户端事先不知道诸如地址和端口之类的信息，这些信息是工作进程连接到主进程所需要的。我们可以通过ZooKeeper使用一个会合znode，$z_r$来处理这种情况，$z_r$是由客户端创建的一个节点。客户端将$z_r$的完整路径名作为启动参数传递给主进程和工作进程。当主进程启动时，它会在$z_r$中填入其使用的地址和端口信息。当工作进程启动时，它们会读取$z_r$并将监视标志设置为true。如果$z_r$尚未填充，工作进程会等待在$z_r$更新时收到通知。如果$z_r$是一个临时节点，主进程和工作进程可以监视$z_r$是否被删除，并在客户端结束时自行清理。\n组成员关系。我们利用临时节点来实现组成员关系。具体来说，我们利用了这样一个事实，即临时节点允许我们查看创建该节点的会话的状态。我们首先指定一个znode，$z_g$，来代表组。当组中的一个进程启动时，它会在$z_g$下创建一个临时子znode。如果每个进程都有唯一的名称或标识符，则使用该名称作为子znode的名称；否则，进程可以使用SEQUENTIAL标志创建znode以获得唯一的名称分配。进程可以在子znode的数据中放入进程信息，例如使用的地址和端口。\n在$z_g$下创建子znode后，进程正常启动，不需要做其他事情。如果进程失败或结束，其在$z_g$下的znode将被自动移除。\n进程可以通过简单地列出$z_g$的子节点来获取组信息。如果进程希望监视组成员关系的变化，它可以将监视标志设置为true，并在接收到更改通知时刷新组信息（始终将监视标志设置为true）。\n简单锁。尽管ZooKeeper不是一个锁服务，但它可以用来实现锁。使用ZooKeeper的应用程序通常会使用根据其需求定制的同步原语，如上述所示。这里我们将展示如何使用ZooKeeper实现锁，以表明它可以实现各种通用的同步原语。\n最简单的锁实现使用“锁文件”。锁由一个znode表示。要获取锁，客户端尝试使用EPHEMERAL标志创建指定的znode。如果创建成功，客户端就持有了锁。否则，客户端可以读取该znode并将监视标志设置为true，以便在当前持有者失效时收到通知。当客户端失效或显式删除znode时，它会释放锁。其他等待锁的客户端一旦观察到znode被删除，就会再次尝试获取锁。\n虽然这种简单的锁定协议有效，但它确实存在一些问题。首先，它受到herd效应的影响。如果有许多客户端在等待获取锁，当锁释放时，它们都会竞争这个锁，即使最终只有一个客户端能够获得锁。其次，它仅实现了独占锁。接下来的两个原语展示了如何克服这些问题。\n简单锁（无 herd 效应）。我们定义一个锁znode $l$来实现这种锁。直观地说，我们将所有请求锁的客户端排成一行，每个客户端按照请求到达的顺序依次获取锁。因此，希望获取锁的客户端执行以下操作：\nLock\n1 2 3 4 5 6 n = create(l + “/lock-”, EPHEMERAL|SEQUENTIAL) C = getChildren(l, false) if n is lowest znode in C, exit p = znode in C ordered just before n if exists(p, true) wait for watch event goto 2 Unlock\n1 delete(n) 在Lock的第1行中使用SEQUENTIAL标志，按照所有其他尝试的顺序对客户端尝试获取锁进行排序。如果客户端的znode在第3行具有最小的序列号，则该客户端持有锁。否则，客户端等待其znode之前持有锁或将会在该客户端的znode之前获得锁的znode被删除。通过仅监视位于自己znode之前的那个znode，我们避免了herd效应，因为在锁释放或锁请求被放弃时只会唤醒一个进程。一旦客户端正在监视的znode消失，客户端必须检查它现在是否持有锁。（之前的锁请求可能已被放弃，且存在一个序列号更小的znode仍在等待或持有锁。）\n释放锁非常简单，只需删除代表锁请求的znode $n$。通过在创建时使用EPHEMERAL标志，崩溃的进程会自动清理任何锁请求或释放它们可能持有的任何锁。\n总结来说，这种锁定方案具有以下优点：\n删除一个znode只会唤醒一个客户端，因为每个znode仅被另一个客户端监视，因此我们不会遇到herd效应； 不需要轮询或超时； 由于我们实现锁定的方式，通过浏览ZooKeeper数据可以查看锁竞争的程度、中断锁并调试锁定问题。 读/写锁。为了实现读/写锁，我们稍微改变了锁定过程，并具有单独的读锁和写锁过程。解锁过程与全局锁定情况相同。\nWrite Lock\n1 2 3 4 5 6 n = create(l + “/write-”, EPHEMERAL|SEQUENTIAL) C = getChildren(l, false) if n is lowest znode in C, exit p = znode in C ordered just before n if exists(p, true) wait for event goto 2 Read Lock\n1 2 3 4 5 6 n = create(l + “/read-”, EPHEMERAL|SEQUENTIAL) C = getChildren(l, false) if no write znodes lower than n in C, exit p = write znode in C ordered just before n if exists(p, true) wait for event goto 3 这种锁过程与之前的锁略有不同。写锁仅在命名上有所不同。由于读锁可以共享，第3行和第4行稍有不同，因为只有较早的写锁znode会阻止客户端获取读锁。看起来当有多个客户端等待读锁并在序列号较低的“写”znode被删除时收到通知时，我们可能会遇到“herd效应”；实际上，这是一种期望的行为，所有这些等待读锁的客户端都应该被释放，因为它们现在可能已经获得了锁。\n双屏障。双屏障使客户端能够同步计算的开始和结束。当足够多的进程（由屏障阈值定义）加入屏障时，进程开始它们的计算并在完成后离开屏障。我们用znode来表示ZooKeeper中的屏障，称为$b$。每个进程$p$在进入时向$b$注册（通过创建一个znode作为$b$的子节点），并在准备离开时取消注册（删除子节点）。当$b$的子znode数量超过屏障阈值时，进程可以进入屏障。当所有进程都移除了它们的子节点时，进程可以离开屏障。我们使用监视来高效地等待进入和退出条件被满足。要进入屏障，进程会监视$ b $是否存在ready子节点，该子节点将由导致子级数量超过屏障阈值的进程创建。要离开屏障，进程会监视特定子节点的消失，并且仅在该znode被删除后才检查退出条件。\n3 ZooKeeper 应用程序 我们现在描述一些使用ZooKeeper的应用，并简要说明它们是如何使用它的。我们将每个示例中的原语以粗体显示。\n获取服务（Fetching Service）。抓取是搜索引擎的重要组成部分，Yahoo!抓取了数十亿的网页文档。获取服务（Fetching Service, FS）是Yahoo!爬虫的一部分，目前已经在生产环境中使用。本质上，它有主进程指挥页面抓取进程。主进程向抓取器提供配置，抓取器则写回报告它们的状态和健康状况。使用ZooKeeper为FS带来的主要优势包括从主进程故障中恢复、保证在故障情况下依然可用以及将客户端与服务器解耦，使它们只需从ZooKeeper读取状态即可将其请求导向健康的服务器。因此，FS主要使用ZooKeeper来管理配置元数据（configuration metadata），尽管它也使用ZooKeeper来进行主进程选举（领导者选举）（leader election）。\n图2显示了FS在三天期间内使用的ZooKeeper服务器的读取和写入流量。为了生成此图，我们统计了这段时间内每秒的操作数量，每个点对应那一秒内的操作数量。我们观察到，读取流量相比写入流量要高得多。在每秒操作速率高于1,000次的期间，读取与写入的比例在10:1到100:1之间变化。此工作负载中的读取操作按普遍程度递增顺序为：getData()、getChildren() 和 exists()。\nKatta。Katta10 是一个分布式索引器，使用ZooKeeper进行协调，它是非Yahoo!应用的一个例子。Katta通过分片来划分索引工作。主服务器将分片分配给从服务器并跟踪进度。从服务器可能会失败，因此主服务器必须在从服务器加入或离开时重新分配负载。主服务器也可能会失败，因此其他服务器必须准备好在主服务器失败时接管。Katta使用ZooKeeper来跟踪从服务器和主服务器的状态（组成员关系）（group membership），并处理主服务器故障转移（领导者选举）（leader elction）。Katta还使用ZooKeeper来跟踪和传播分片到从服务器的分配（配置管理）（configuration management）。\nYahoo! Message Broker。Yahoo! Message Broker（YMB）是一个分布式发布-订阅系统。该系统管理着成千上万个客户端可以向其发布消息和从中接收消息的主题。这些主题分布在一组服务器上以提供可扩展性。每个主题使用主备方案进行复制，确保消息被复制到两台机器上以保证可靠的消息传递。构成YMB的服务器使用无共享分布式架构，这使得协调对于正确操作至关重要。YMB使用ZooKeeper来管理主题的分布（配置元数据），处理系统中机器的故障（故障检测和组成员关系）（failure detection），以及控制系统操作。\n图3显示了YMB的部分znode数据布局。每个代理域都有一个名为nodes的znode，其中包含构成YMB服务的每个活动服务器的临时znode。每个YMB服务器在nodes下创建一个包含负载和状态信息的临时znode，通过ZooKeeper提供组成员关系和状态信息。诸如shutdown和migration_prohibited之类的节点被构成服务的所有服务器监控，允许对YMB进行集中控制。topics目录为YMB管理的每个主题包含一个子znode。这些主题znode有子znode，指示每个主题的主服务器和备份服务器以及该主题的订阅者。primary服务器和backup服务器的znode不仅允许服务器发现负责某个主题的服务器，还管理领导者选举和服务器崩溃的情况。\n4 ZooKeeper实现 ZooKeeper通过在构成服务的每台服务器上复制ZooKeeper数据来提供高可用性。我们假设服务器通过崩溃失败，且这些故障服务器可能在之后恢复。图4展示了ZooKeeper服务的高层组件。当接收到请求时，服务器准备执行该请求（请求处理器）。如果该请求需要服务器之间的协调（写请求），则它们使用一个协议（原子广播的实现），最后服务器将更改提交到完全复制在所有服务器上的ZooKeeper数据库。对于读请求，服务器只需读取本地数据库的状态并生成对该请求的响应。\n复制的数据库是一个内存（in-memory）数据库，包含整个数据树。树中的每个znode默认存储最多1MB的数据，但这个最大值是一个配置参数，在特定情况下可以更改。为了可恢复性，我们将更新高效地记录到磁盘，并在将写操作应用于内存数据库之前强制将其写入磁盘介质。实际上，像Chubby11一样，我们保持一个已提交操作的重放日志（在我们的情况下是预写日志）并定期生成内存数据库的快照。\n每个ZooKeeper服务器都为客户端提供服务。客户端连接到一个服务器来提交其请求。如前所述，读请求由每个服务器数据库的本地副本服务。更改服务状态的请求（写请求）则通过一个协议进行处理。\n作为协议的一部分，写请求被转发到一个称为领导者（leader）的服务器。其余的ZooKeeper服务器，称为跟随者（followers），从领导者接收包含状态更改的消息提案，并就状态更改达成一致。\n4.1 请求处理器 由于消息层是原子性的，我们保证本地副本永远不会出现分歧，尽管在任何时刻某些服务器可能已经应用了比其他服务器更多的事务。与客户端发送的请求不同，这些事务是幂等的（idempotent）。当领导者接收到一个写请求时，它会计算出当写操作被应用时系统的状态，并将其转换为一个捕获这一新状态的事务。未来状态必须被计算出来，因为可能存在尚未应用于数据库的未完成事务。例如，如果客户端执行了一个条件性的setData操作，并且请求中的版本号与即将更新的znode的未来版本号匹配，服务会生成一个包含新数据、新版本号和更新时间戳的setDataTXN。如果发生错误，例如版本号不匹配或要更新的znode不存在，则会生成一个errorTXN。\n4.2 原子广播 所有更新ZooKeeper状态的请求都会被转发给领导者。领导者执行请求并通过Zab7（一个原子广播协议）将状态更改广播到ZooKeeper状态。接收客户端请求的服务器在交付相应的状态更改时响应客户端。Zab默认使用简单多数派法定人数来决定提案，因此Zab和ZooKeeper只能在大多数服务器正常工作的情况下运行（即，有$2f + 1$台服务器时，可以容忍$f$次故障）。\n为了实现高吞吐量，ZooKeeper尝试保持请求处理管道满载，可能会有数千个请求处于处理管道的不同部分。由于状态更改依赖于之前状态更改的应用，Zab提供了比常规原子广播更强的顺序保证。更具体地说，Zab保证由领导者广播的更改按照发送顺序交付，并且在领导者广播自己的更改之前，所有来自前一个领导者的更改都会交付给该领导者。\n有一些实现细节简化了我们的实现并提供了卓越的性能。我们使用TCP作为传输协议，因此消息顺序由网络维护，这使我们能够简化实现。我们使用Zab选择的领导者作为ZooKeeper的领导者，这样创建事务的同一进程也负责提出这些事务。我们使用日志来跟踪提案，将其作为内存数据库的预写日志，因此我们不需要将消息两次写入磁盘。\n在正常操作期间，Zab确实按顺序且仅传递一次所有消息，但由于Zab不会持久记录每个已传递消息的id，在恢复过程中Zab可能会重新传递某些消息。因为我们使用幂等事务，只要消息按顺序传递，多次传递是可以接受的。实际上，ZooKeeper要求Zab至少重新传递上一个快照开始之后已传递的所有消息。\n4.3 复制数据库 每个副本在内存中都有ZooKeeper状态的一份副本。当ZooKeeper服务器从崩溃中恢复时，它需要恢复此内部状态。重放所有已传递的消息以恢复状态会在服务器运行一段时间后花费过长时间，因此ZooKeeper使用周期性的快照，并仅要求重新传递自快照开始以来的消息。我们将ZooKeeper快照称为模糊快照（fuzzy snapshots），因为我们不会锁定ZooKeeper状态来获取快照；相反，我们对树进行深度优先扫描，原子地读取每个znode的数据和元数据并将它们写入磁盘。由于生成的模糊快照可能应用了在快照生成过程中已传递的状态变化的一部分，结果可能不对应于任何时间点上的ZooKeeper状态。然而，由于状态变化是幂等的，只要按顺序应用状态变化，我们可以多次应用它们。\n例如，假设在ZooKeeper数据树中，两个节点/foo和/goo分别具有值f1和g1，并且当模糊快照开始时两者都处于版本1，并且以下状态更改流到达，其形式为\u0026lt;transactionType, path , value, new-version\u0026gt;:\n1 2 3 \u0026lt;SetDataTXN, /foo, f2, 2\u0026gt; \u0026lt;SetDataTXN, /goo, g2, 2\u0026gt; \u0026lt;SetDataTXN, /foo, f3, 3\u0026gt; 处理这些状态变化后，/foo 和 /goo 的值分别为 f3 和 g2，版本分别为 3 和 2。然而，模糊快照可能记录了/foo 和 /goo 的值为 f3 和 g1，版本分别为 3 和 1，这并不是ZooKeeper数据树的一个有效状态。如果服务器在此快照下崩溃并恢复，并且Zab重新传递这些状态变化，最终的状态将与崩溃前的服务状态相对应。\n4.4 客户端-服务器交互 当服务器处理写请求时，它还会发送并清除与该更新相关的所有通知。服务器按顺序处理写操作，并且不会与其他写或读操作并发执行。这确保了通知的严格顺序。需要注意的是，服务器在本地处理通知。只有客户端所连接的服务器才会跟踪并触发该客户端的通知。\n读请求在每个服务器上本地处理。每个读请求都会被处理并标记一个zxid，该zxid对应于服务器看到的最后一个事务。这个zxid定义了读请求相对于写请求的部分顺序。通过在本地处理读取，我们获得了极佳的读性能，因为这只是本地服务器上的内存操作，没有磁盘活动或需要运行的协议。这一设计选择对于实现我们在读取主导的工作负载下达到卓越性能的目标至关重要。\n使用快速读取的一个缺点是不能保证读操作的优先顺序。也就是说，读操作可能会返回一个过时的值，即使对同一znode的最近更新已经提交。并不是所有的应用程序都需要优先顺序，但对于确实需要这一点的应用程序，我们实现了sync操作。这个原语异步执行，并在所有待处理的写入到其本地副本后由领导者排序。为了保证特定读操作返回最新更新的值，客户端会在读操作前调用sync。客户端操作的FIFO顺序保证加上sync的全局保证，使得读操作的结果能够反映在sync发出之前发生的任何变化。在我们的实现中，我们不需要原子广播sync，因为我们使用的是基于领导者的算法，只需将sync操作放在领导者和执行sync调用的服务器之间的请求队列末尾即可。为了使此机制有效，跟随者必须确保领导者仍然是领导者。如果有未完成的事务正在提交，则服务器不会怀疑领导者的身份。如果待处理队列为空，领导者需要发起一个空事务来提交并将sync操作排在此事务之后。这种做法的好处是，当领导者负载较重时，不会产生额外的广播流量。在我们的实现中，超时时间设置为让领导者在跟随者放弃他们之前意识到自己不再是领导者，因此无需发起空事务。\nZooKeeper服务器按照FIFO顺序处理来自客户端的请求。响应中包含响应所对应的zxid。即使在没有活动的时间间隔内的心跳消息也包括客户端所连接服务器最后看到的zxid。如果客户端连接到一个新的服务器，该新服务器通过检查客户端的最后一个zxid与其自身的最后一个zxid来确保其对ZooKeeper数据的视图至少与客户端一样新。如果客户端的视图比服务器更近，服务器会在追赶上之前不会重新建立与客户端的会话。由于客户端只能看到已被复制到大多数ZooKeeper服务器的更改，因此可以保证客户端能够找到另一个具有系统最近视图的服务器。这种行为对于保证持久性非常重要。\n为了检测客户端会话故障，ZooKeeper使用超时机制。如果在会话超时时间内没有任何服务器收到来自客户端会话的任何消息，领导者将判定发生了故障。如果客户端足够频繁地发送请求，则无需发送其他消息。否则，在活动较少的期间，客户端会发送心跳消息。如果客户端无法与服务器通信以发送请求或心跳，它会连接到不同的ZooKeeper服务器以重新建立其会话。为了避免会话超时，ZooKeeper客户端库会在会话空闲$s/3$毫秒后发送心跳，并且如果在$2s/3$毫秒内未从服务器收到消息，则切换到新的服务器，其中$s$是会话超时时间（以毫秒为单位）。\n5 评估 5.1 吞吐量 为了评估我们的系统，我们对系统饱和时的吞吐量以及各种注入故障对吞吐量的影响进行了基准测试。我们改变了构成ZooKeeper服务的服务器数量，但始终保持客户端数量不变。为了模拟大量客户端，我们使用35台机器模拟250个同时在线的客户端。\n我们有一个ZooKeeper服务器的Java实现，以及Java和C两种客户端（该实现可在 http://hadoop.apache.org/zookeeper 上公开获取）。在这些实验中，我们使用的Java服务器配置为在一个专用磁盘上记录日志，并在另一个磁盘上进行快照。我们的基准客户端使用异步Java客户端API，每个客户端至少有100个未完成的请求。每个请求包含读取或写入1K的数据。我们没有展示其他操作的基准测试结果，因为所有修改状态的操作性能大致相同，不修改状态的操作（除sync外）性能也大致相同。（sync的性能接近于轻量级写操作，因为请求必须发送到领导者，但不需要广播。）客户端每300毫秒发送一次已完成操作的数量统计，我们每6秒采样一次。为了避免内存溢出，服务器会限制系统中的并发请求数。ZooKeeper使用请求节流来防止服务器过载。对于这些实验，我们将ZooKeeper服务器配置为最多处理2000个总请求。\n在图5中，我们展示了当我们改变读请求与写请求的比例时的吞吐量，每条曲线对应提供ZooKeeper服务的不同数量的服务器。表1显示了读负载极端情况下的数据。读取吞吐量高于写入吞吐量，因为读取不使用原子广播。图表还表明，服务器数量对广播协议的性能有负面影响。从这些图表中，我们可以观察到系统中服务器的数量不仅影响服务能够处理的故障数量，还影响服务能够处理的工作负载。请注意，三条服务器的曲线在大约60%处与其他曲线相交。这种情况并非三服务器配置独有，由于本地读取允许的并行性，所有配置都会出现这种情况。然而，在图中的其他配置中并未观察到这一点，因为我们为了可读性限制了最大y轴吞吐量。\n写请求比读请求耗时更长有两个原因。首先，写请求必须通过原子广播，这需要额外的处理并增加请求的延迟。写请求处理时间较长的另一个原因是，服务器必须确保事务在向领导者发送确认之前已记录到非易失性存储中。原则上，这一要求可能显得过度，但为了在我们的生产系统中换取可靠性，我们牺牲了一部分性能，因为ZooKeeper构成了应用的基本事实。我们使用更多的服务器来容忍更多的故障。通过将ZooKeeper数据分区到多个ZooKeeper集群中来提高写入吞吐量。这种复制与分区之间的性能权衡之前已被Gray等人观察到12。\nZooKeeper通过将负载分布在其构成服务的服务器上来实现如此高的吞吐量。由于我们放宽了一致性保证，因此可以进行负载分配。相反，Chubby客户端将所有请求直接发送给领导者。图6展示了如果不利用这种放松一致性保证的方式，并强制客户端仅连接到领导者时会发生什么。如预期的那样，对于读取为主的工作负载，吞吐量明显更低，但即使是写入为主的工作负载，吞吐量也较低。由服务客户端引起的额外CPU和网络负载影响了领导者协调提案广播的能力，进而对整体写入性能产生了负面影响。\n原子广播协议完成了系统中的大部分工作，因此比任何其他组件更限制ZooKeeper的性能。图7显示了原子广播组件的吞吐量。为了对其性能进行基准测试，我们在领导者处直接生成事务来模拟客户端，因此没有客户端连接或客户端请求和响应。在最大吞吐量下，原子广播组件成为CPU受限的。理论上，图7的性能应该与100%写入情况下的ZooKeeper性能相匹配。然而，ZooKeeper的客户端通信、ACL检查以及请求到事务的转换都需要CPU。对CPU的竞争降低了ZooKeeper的整体吞吐量，使其远低于单独的原子广播组件。由于ZooKeeper是一个关键的生产组件，迄今为止我们的开发重点是正确性和鲁棒性。通过消除诸如额外副本、同一对象的多次序列化、更高效的内部数据结构等，有大量机会显著提高性能。\n为了展示在注入故障时系统随时间的行为，我们运行了一个由5台机器组成的ZooKeeper服务。我们运行了与之前相同的饱和基准测试，但这次我们将写入比例保持在一个恒定的30%，这是我们预期工作负载的一个保守比例。周期性地，我们会终止一些服务器进程。图8展示了系统吞吐量随着时间的变化情况。图中标记的事件如下：\n一个跟随者的故障和恢复； 另一个跟随者的故障和恢复； 领导者的故障； 在前两个标记中两个跟随者（a, b）的故障，在第三个标记时恢复（c）； 领导者的故障； 领导者的恢复。 从这个图表中可以得出几个重要的观察结果。首先，如果跟随者快速失败并恢复，那么尽管发生了故障，ZooKeeper仍然能够维持较高的吞吐量。单个跟随者的故障不会阻止服务器形成法定人数，并且仅大致减少了该服务器故障前处理的读请求所占的比例。其次，我们的领导者选举算法能够足够快地恢复，以防止吞吐量大幅下降。根据我们的观察，ZooKeeper选举新领导者所需的时间不到200毫秒。因此，虽然服务器在短暂时间内停止服务请求，但由于我们的采样周期是按秒计算的，我们没有观察到吞吐量降为零的情况。第三，即使跟随者需要更多时间来恢复，一旦它们开始处理请求，ZooKeeper也能够再次提升吞吐量。事件1、2和4之后未能完全恢复到最大吞吐量的原因之一是，客户端只有在其与跟随者的连接中断时才会切换跟随者。因此，在事件4之后，直到事件3和5中的领导者失败，客户端才重新分配自己。实际上，随着客户端的加入和离开，这种不平衡会随着时间自行解决。\n5.2 请求延迟 为了评估请求的延迟，我们创建了一个基于Chubby基准测试的模型进行基准测试4。我们创建了一个工作进程，它简单地发送一个创建请求，等待其完成，然后异步删除新节点，并开始下一个创建请求。我们相应地改变了工作进程的数量，在每次运行中，每个工作进程创建50000个节点。我们通过将完成的创建请求数除以所有工作进程完成总时间来计算吞吐量。\n表2展示了我们的基准测试结果。创建请求包含1K的数据，而不是Chubby基准测试中的5字节，以便更好地符合我们的预期使用情况。即使有这些较大的请求，ZooKeeper的吞吐量仍然比已公布的Chubby吞吐量高出3倍以上。单个ZooKeeper工作进程基准测试的吞吐量表明，对于三台服务器，平均请求延迟为1.2毫秒；对于九台服务器，平均请求延迟为1.4毫秒。\n5.3 屏障的性能 在这个实验中，我们依次执行多个屏障以评估使用ZooKeeper实现的原语的性能。对于给定数量的屏障$b$，每个客户端首先进入所有$b$个屏障，然后依次离开所有$b$个屏障。由于我们使用的是2.4节中的双屏障算法，客户端必须等待所有其他客户端执行完enter()过程后才能进行下一个调用（leave()类似）。\n我们在表3中报告了实验结果。在这个实验中，我们有50、100和200个客户端依次进入数量为b的屏障，$b\\in {200, 400, 800, 1600}$。尽管一个应用可以有数千个ZooKeeper客户端，但在每次协调操作中通常只有较小的一部分客户端参与，因为客户端经常根据应用的具体情况进行分组。\n从这个实验中有两个有趣的观察结果：处理所有屏障所需的时间大致与屏障的数量成线性增长，这表明对数据树同一部分的并发访问没有产生任何意外延迟，并且延迟随着客户端数量的增加而按比例增加。这是因为我们没有使ZooKeeper服务达到饱和状态。实际上，我们观察到即使客户端以同步方式进行操作，屏障操作（进入和离开）的吞吐量在所有情况下仍保持在每秒1,950到3,100次操作之间。在ZooKeeper操作中，这相当于每秒10,700到17,000次操作的吞吐量值。在我们的实现中，读写比为4:1（80%的读操作），因此我们基准代码使用的吞吐量远低于ZooKeeper能够实现的原始吞吐量（根据图5，超过40,000次操作/秒）。这是因为客户端需要等待其他客户端完成操作。\n6 相关工作 ZooKeeper旨在提供一种服务，以缓解分布式应用中进程协调的问题。为了实现这一目标，其设计借鉴了以往的协调服务、容错系统、分布式算法和文件系统的理念。\n我们并不是第一个提出用于协调分布式应用程序系统的团队。一些早期系统提出了针对事务性应用的分布式锁服务13，以及用于计算机集群间信息共享的服务14。最近，Chubby提出了一种为分布式应用程序管理咨询锁的系统4。Chubby与ZooKeeper共享多个目标，它也提供了类似文件系统的接口，并使用一致性协议保证副本的一致性。然而，ZooKeeper不是一个锁服务。它可以被客户端用来实现锁，但其API中没有锁操作。不同于Chubby，ZooKeeper允许客户端连接到任何ZooKeeper服务器，而不仅仅是领导者。由于ZooKeeper的一致性模型比Chubby更为宽松，ZooKeeper客户端可以使用其本地副本提供数据和管理监视。这使得ZooKeeper能够提供比Chubby更高的性能，从而使应用程序能够更广泛地利用ZooKeeper。\n文献中提出了多种容错系统，旨在缓解构建容错分布式应用程序的问题。一个早期的系统是ISIS9，它将抽象类型规范转化为容错分布式对象，从而使容错机制对用户透明。Horus15和Ensemble16是从ISIS发展而来的系统。ZooKeeper采纳了ISIS的虚拟同步概念。Totem在利用局域网硬件广播的架构中保证消息传递的全局顺序17。ZooKeeper适用于各种网络拓扑结构，这促使我们依赖于服务器进程之间的TCP连接，而不假设任何特殊的拓扑结构或硬件特性。我们也不公开ZooKeeper内部使用的任何ensemble通信。\n构建容错服务的一个重要技术是状态机复制18，Paxos19是一种允许异步系统中有效实现复制状态机的算法。我们使用了一种与Paxos共享某些特性的算法，但结合了共识所需的事务日志记录和数据树恢复所需的预写日志记录，以实现高效的实现。关于实用的拜占庭容错复制状态机协议已有若干提议20 21 22 23 24。ZooKeeper不假设服务器可以是拜占庭式的，但我们确实采用了如校验和和合理性检查等机制来捕捉非恶意的拜占庭故障。Clement等人讨论了一种在不修改当前服务器代码库的情况下使ZooKeeper完全拜占庭容错的方法25。到目前为止，我们在生产环境中尚未观察到使用完全拜占庭容错协议可能预防的故障26。\nBoxwood27是一个使用分布式锁服务器的系统，它为应用程序提供更高层次的抽象，并依赖于基于Paxos的分布式锁服务。与Boxwood类似，ZooKeeper是用于构建分布式系统的组件，但ZooKeeper有更高的性能要求，并在客户端应用中得到了更广泛的应用。ZooKeeper暴露了较低级别的原语，应用程序可以使用这些原语来实现更高级别的原语。\n尽管ZooKeeper类似于一个小文件系统，但它只提供了文件系统操作的一小部分，并增加了大多数文件系统不具备的功能，如顺序保证和条件写入。ZooKeeper的监视功能与AFS28中的缓存回调在精神上相似。\nSinfonia29引入了迷你事务，这是一种构建可扩展分布式系统的新范式。Sinfonia被设计用来存储应用数据，而ZooKeeper则存储应用元数据。ZooKeeper将其状态完全复制并保存在内存中，以实现高性能和一致的延迟。我们对类似文件系统操作和顺序的使用使得功能类似于迷你事务。Znode是一个方便的抽象，在其基础上我们添加了监视功能，这是Sinfonia所缺少的。Dynamo30允许客户端在一个分布式的键值存储中获取和放置相对较小（小于1M）的数据量。与ZooKeeper不同的是，Dynamo的键空间不是分层的。Dynamo也不提供对写入的强大持久性和一致性保证，而是通过读取解决冲突。DepSpace31使用一个元组空间来提供拜占庭容错服务。与ZooKeeper一样，DepSpace使用简单的服务器接口在客户端实现强大的同步原语。虽然DepSpace的性能远低于ZooKeeper，但它提供了更强的容错能力和保密性保证。\n7 结论 ZooKeeper通过向客户端暴露无等待对象，采取了一种无等待的方式来解决分布式系统中进程协调的问题。我们发现ZooKeeper不仅对Yahoo!内部的多个应用有用，对外部应用也同样有价值。对于读取为主的工作负载，ZooKeeper通过使用带有监视的快速读取（均由本地副本提供服务）实现了每秒数十万次操作的吞吐量。尽管我们的读取和监视的一致性保证看起来较弱，但我们通过实际用例展示了这种组合允许我们在客户端实现高效且复杂的协调协议，即使读取不具有优先顺序，数据对象的实现也是无等待的。无等待属性对于高性能至关重要。\n虽然我们只描述了少数几个应用案例，但实际中有许多其他应用也在使用ZooKeeper。我们认为其成功主要归因于其简单的接口和通过该接口可以实现的强大抽象。由于ZooKeeper的高吞吐量，应用程序不仅可以使用它来进行粗粒度的锁定，还可以广泛地利用它。\n致谢 我们想要感谢Andrew Kornev和Runping Qi对ZooKeeper的贡献；感谢Zeke Huang和Mark Marchukov提供的宝贵反馈；感谢Brian Cooper和Laurence Ramontianu在ZooKeeper早期开发阶段的贡献；同时感谢Brian Bershad和Geoff Voelker对展示内容提出的重要意见。\n参考文献 Amazon. Amazon simple queue service. http://aws.amazon.com/sqs/, 2008.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nN. Schiper and S. Toueg. A robust and lightweight stable leader election service for dynamic systems. In DSN, 2008.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nA. Sherman, P. A. Lisiecki, A. Berkheimer, and J. Wein. ACMS: The Akamai configuration management system. In NSDI, 2005.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nM. Burrows. The Chubby lock service for loosely-coupled distributed systems. In Proceedings of the 7th ACM/USENIX Symposium on Operating Systems Design and Implementation (OSDI), 2006.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nM. Herlihy. Wait-free synchronization. ACM Transactions on Programming Languages and Systems, 13(1), 1991.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nS. Mullender, editor. Distributed Systems, 2nd edition. ACM Press, New York, NY, USA, 1993.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nB. Reed and F. P. Junqueira. A simple totally ordered broadcast protocol. In LADIS ’08: Proceedings of the 2nd Workshop on Large-Scale Distributed Systems and Middleware, pages 1–6, New York, NY, USA, 2008. ACM.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nM. Herlihy and J. Wing. Linearizability: A correctness condition for concurrent objects. ACM Transactions on Programming Languages and Systems, 12(3), July 1990.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nK. P. Birman. Replication and fault-tolerance in the ISIS system. In SOSP ’85: Proceedings of the 10th ACM symposium on Operating systems principles, New York, USA, 1985. ACM Press.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nKatta. Katta - distribute lucene indexes in a grid. http://katta.wiki.sourceforge.net/, 2008.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nT. Chandra, R. Griesemer, and J. Redstone. Paxos made live: An engineering perspective. In Proceedings of the 26th annual ACM symposium on Principles of distributed computing (PODC), Aug. 2007.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nJ. Gray, P. Helland, P. O’Neil, and D. Shasha. The dangers of replication and a solution. In Proceedings of SIGMOD ’96, pages 173–182, New York, NY, USA, 1996. ACM.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nA. Hastings. Distributed lock management in a transaction processing environment. In Proceedings of IEEE 9th Symposium on Reliable Distributed Systems, Oct. 1990.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nN. P. Kronenberg, H. M. Levy, and W. D. Strecker. Vaxclusters (extended abstract): a closely-coupled distributed system. SIGOPS Oper. Syst. Rev., 19(5), 1985.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nR. van Renesse and K. Birman. Horus, a flexible group communication systems. Communications of the ACM, 39(16), Apr. 1996.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nR. van Renesse, K. Birman, M. Hayden, A. Vaysburd, and D. Karr. Building adaptive systems using ensemble. Software - Practice and Experience, 28(5), July 1998.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nL. Moser, P. Melliar-Smith, D. Agarwal, R. Budhia, C. LingleyPapadopoulos, and T. Archambault. The totem system. In Proceedings of the 25th International Symposium on Fault-Tolerant Computing, June 1995.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nF. B. Schneider. Implementing fault-tolerant services using the state machine approach: A tutorial. ACM Computing Surveys, 22(4), 1990.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nL. Lamport. The part-time parliament. ACM Transactions on Computer Systems, 16(2), May 1998.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nM. Castro and B. Liskov. Practical byzantine fault tolerance and proactive recovery. ACM Transactions on Computer Systems, 20(4), 2002.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nJ. Cowling, D. Myers, B. Liskov, R. Rodrigues, and L. Shira. Hq replication: A hybrid quorum protocol for byzantine fault tolerance. In SOSP ’07: Proceedings of the 21st ACM symposium on Operating systems principles, New York, NY, USA, 2007.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nR. Kotla, L. Alvisi, M. Dahlin, A. Clement, and E. Wong. Zyzzyva: speculative byzantine fault tolerance. SIGOPS Oper. Syst. Rev., 41(6):45–58, 2007.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nM. Abd-El-Malek, G. R. Ganger, G. R. Goodson, M. K. Reiter, and J. J. Wylie. Fault-scalable byzantine fault-tolerant services. In SOSP ’05: Proceedings of the twentieth ACM symposium on Operating systems principles, pages 59–74, New York, NY, USA, 2005. ACM.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nA. Singh, P. Fonseca, P. Kuznetsov, R. Rodrigues, and P. Maniatis. Zeno: eventually consistent byzantine-fault tolerance. In NSDI’09: Proceedings of the 6th USENIX symposium on Networked systems design and implementation, pages 169–184, Berkeley, CA, USA, 2009. USENIX Association.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nA. Clement, M. Kapritsos, S. Lee, Y. Wang, L. Alvisi, M. Dahlin, and T. Riche. UpRight cluster services. In Proceedings of the 22 nd ACM Symposium on Operating Systems Principles (SOSP), Oct. 2009.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nY. J. Song, F. Junqueira, and B. Reed. BFT for the skeptics. http://www.net.t-labs.tu-berlin.de/~petr/BFTW3/abstracts/talk-abstract.pdf.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nJ. MacCormick, N. Murphy, M. Najork, C. A. Thekkath, and L. Zhou. Boxwood: Abstractions as the foundation for storage infrastructure. In Proceedings of the 6th ACM/USENIX Symposium on Operating Systems Design and Implementation (OSDI), 2004.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nJ. H. Howard, M. L. Kazar, S. G. Menees, D. A. Nichols, M. Satyanarayanan, R. N. Sidebotham, and M. J. West. Scale and performance in a distributed file system. ACM Trans. Comput. Syst., 6(1), 1988.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nM. Aguilera, A. Merchant, M. Shah, A. Veitch, and C. Karamanolis. Sinfonia: A new paradigm for building scalable distributed systems. In SOSP ’07: Proceedings of the 21st ACM symposium on Operating systems principles, New York, NY, 2007.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nG. DeCandia, D. Hastorun, M. Jampani, G. Kakulapati, A. Lakshman, A. Pilchin, S. Sivasubramanian, P. Vosshall, and W. Vogels. Dynamo: Amazons highly available key-value store. In SOSP ’07: Proceedings of the 21st ACM symposium on Operating systems principles, New York, NY, USA, 2007. ACM Press.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nA. N. Bessani, E. P. Alchieri, M. Correia, and J. da Silva Fraga. Depspace: A byzantine fault-tolerant coordination service. In Proceedings of the 3rd ACM SIGOPS/EuroSys European Systems Conference - EuroSys 2008, Apr. 2008.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://fireflyyh.top/posts/distributionsystem/zookeeper/","summary":"Patrick Hunt and Mahadev Konar\nYahoo! Grid\n{phunt,mahadev}@yahoo-inc.com Flavio P. Junqueira and Benjamin Reed\nYahoo! Research\n{fpj,breed}@yahoo-inc.com 摘要 在本文中，我们描述了Zookeeper，一种用于协调分布式应用程序进程的服务。由于Zookeeper是关键基础设施的一部分，它旨在为客户端构建更复杂的协调原语提供一个简单且高性能的核心。它在一个复制的集中式服务中结合了组消息传递、共享寄存器和分布式锁服务的元素。Zookeeper提供的接口具有共享寄存器的无等待特性，并带有一个类似于分布式文件系统中缓存失效的事件驱动机制，从而提供一个简单而强大的协调服务。\nZookeeper的接口支持高性能服务实现。除了无等待特性外，Zookeeper还为客户机提供了请求的先进先出（FIFO）执行保证，并对所有改变Zookeeper状态的请求提供线性一致性。这些设计决策使得实现高性能处理流水线成为可能，读请求可以由本地服务器满足。我们展示了针对目标工作负载（读写比例为2:1到100:1），Zookeeper每秒能够处理数万到数十万次事务。这种性能允许客户端应用程序广泛使用Zookeeper。\n1 引言 大规模分布式应用程序需要不同形式的协调。配置是最基本的协调形式之一。在其最简单的形式中，配置只是系统进程的操作参数列表，而更复杂的系统则具有动态配置参数。组成员关系和领导者选举在分布式系统中也很常见：通常进程需要知道其他哪些进程是活跃的以及这些进程负责什么。锁是一种强大的协调原语，用于实现对关键资源的互斥访问。\n一种协调的方法是为每种不同的协调需求开发特定的服务。例如，Amazon Simple Queue Service 1 专门针对队列设计。其他服务则专门为领导者选举 2 和配置 3 开发。实现更强大原语的服务可以用来实现功能较弱的原语。例如，Chubby 4 是一个具有强同步保证的锁定服务。然后可以使用锁来实现领导者选举、组成员关系等。\n在设计我们的协调服务时，我们没有选择在服务器端实现特定的原语，而是选择公开一个API，使应用程序开发人员能够实现自己的原语。这种选择导致了协调内核（coordination kernel）的实现，使得无需更改服务核心即可启用新的原语。这种方法允许根据应用的需求适应多种协调形式，而不是限制开发者使用固定的一组原语。\n在设计Zookeeper的API时，我们避开了锁等阻塞原语。协调服务中的阻塞原语可能会导致诸如慢速或故障客户端对更快客户端性能产生负面影响等问题。如果请求处理依赖于其他客户端的响应和故障检测，服务本身的实现也会变得更加复杂。因此，我们的系统Zookeeper实现了一个操作简单无等待（wait-free）数据对象的API，这些数据对象以类似于文件系统的方式进行层次化组织。实际上，Zookeeper的API与其他文件系统的API相似，仅从API签名来看，Zookeeper似乎就是没有锁方法、打开和关闭功能的Chubby。然而，实现无等待数据对象使Zookeeper与基于锁等阻塞原语的系统有显著区别。\n尽管无等待特性对性能和容错至关重要，但对于协调来说，这还不够。我们还需要为操作提供顺序保证。特别是，我们发现保证所有操作的先进先出（FIFO）客户机顺序和写操作的线性一致性，能够实现服务的高效实施，并且足以实现对我们应用程序感兴趣的协调原语。实际上，我们可以使用我们的API为任意数量的进程实现共识，根据Herlihy的层次结构，Zookeeper实现了通用对象5。\nZookeeper服务由一组使用复制技术以实现高可用性和性能的服务器组成。其高性能使得包含大量进程的应用程序能够使用这种协调内核来管理所有方面的协调。我们能够使用一种简单的流水线架构实现Zookeeper，这种架构允许我们在仍有低延迟的情况下处理数百或数千个未完成的请求。这样的流水线自然支持单个客户端操作按FIFO顺序执行。保证FIFO客户机顺序使客户机可以异步提交操作。通过异步操作，客户机能够同时拥有多个未完成的操作。例如，当一个新的客户机成为领导者并且需要相应地操作和更新元数据时，这一特性是理想的。如果没有多未完成操作的可能性，初始化时间可能会达到数秒而不是亚秒级。\n为了保证更新操作满足线性一致性，我们实现了一个基于领导者的原子广播协议6，称为Zab7。然而，一个典型的Zookeeper应用程序工作负载主要由读操作主导，因此需要扩展读吞吐量。在Zookeeper中，服务器本地处理读操作，并且不使用Zab对它们进行全局排序。\n客户端侧缓存数据是提高读性能的重要技术。例如，对于一个进程来说，缓存当前领导者的标识符比每次需要知道领导者信息时都查询Zookeeper要高效得多。Zookeeper使用观察机制使客户端能够在不直接管理客户端缓存的情况下缓存数据。通过这种机制，客户端可以监视给定数据对象的更新，并在发生更新时收到通知。Chubby直接管理客户端缓存，它阻止更新以使所有缓存了正在更改数据的客户端的缓存失效。在这种设计下，如果这些客户端中有任何一个缓慢或出现故障，更新将会被延迟。Chubby使用租约防止故障客户端无限期地阻塞系统。然而，租约仅限制了缓慢或故障客户端的影响，而Zookeeper的观察机制则完全避免了这一问题。\n在本文中，我们讨论 ZooKeeper 的设计和实现。借助 ZooKeeper，我们能够实现应用程序所需的所有协调原语，即使只有写入是可线性化的。为了验证我们的方法，我们展示了如何使用 ZooKeeper 实现一些协调原语。\n总之，本文的主要贡献如下：\n协调内核：我们提出了一种具有宽松一致性保证的无等待协调服务，用于分布式系统中。特别是，我们描述了协调内核的设计与实现，该内核已在许多关键应用中用于实现各种协调技术。\n协调方案：我们展示了如何使用Zookeeper构建更高级别的协调原语，甚至是阻塞和强一致性的原语，这些原语在分布式应用中经常被使用。\n协调经验：我们分享了一些使用Zookeeper的方式，并评估了其性能。通过这些实际应用和性能评估，我们可以更好地理解Zookeeper在真实环境中的表现及其对分布式应用的支持能力。\n2 ZooKeeper 服务 客户通过使用Zookeeper客户端库的客户端API向Zookeeper提交请求。除了通过客户端API暴露Zookeeper服务接口外，客户端库还管理客户端与Zookeeper服务器之间的网络连接。在本节中，我们首先提供Zookeeper服务的高层视图。然后讨论客户端用于与Zookeeper交互的API。\n术语。在本文中，我们使用客户端（client）表示ZooKeeper服务的用户，服务器（server）表示提供ZooKeeper服务的进程，znode表示ZooKeeper数据中的内存数据节点，这些节点在一个分层命名空间中组织，称为数据树（data tree）。我们还使用术语更新和写入来指代任何修改数据树状态的操作。客户端在连接到ZooKeeper并获取会话句柄通过其发出请求时建立会话（session）。\n2.1 服务总览 ZooKeeper为其客户端提供了一组按照分层命名空间组织的数据节点（znodes）的抽象。这个层次结构中的znodes是客户端通过ZooKeeper API进行操作的数据对象。分层命名空间常见于文件系统中，这是一种理想的组织数据对象的方式，因为用户对此抽象非常熟悉，并且它能够更好地组织应用程序元数据。为了引用一个特定的znode，我们使用标准的UNIX文件系统路径表示法。例如，我们使用/A/B/C来表示znode C的路径，其中C的父节点是B，而B的父节点是A。所有znodes都存储数据，并且除了临时znodes外，所有znodes都可以有子节点。\n客户端可以创建两种类型的 znode：\n常规znodes（regular）：客户端通过显式地创建和删除来操作常规znodes。\n临时znodes（ephemeral）：客户端创建此类znodes，它们要么由客户端显式删除，要么在创建它们的会话终止（无论是故意终止还是由于故障）时由系统自动移除。\n此外，当创建一个新的znode时，客户端可以设置一个顺序（sequential）标志。设置了顺序标志的节点会在其名称后附加一个单调递增计数器的值。如果$n$是新的znode，$p$是父znode，则$n$的序列值永远不会小于在$p$下创建的任何其他顺序znode名称中的值。\nZooKeeper实现了监视（watches）机制，允许客户端在不进行轮询的情况下及时接收变化的通知。当客户端发出带有监视标志的读操作时，操作会正常完成，但服务器承诺在返回的信息发生变化时通知客户端。监视是一次性触发器，与一个会话相关联；一旦触发或会话关闭，它们就会被注销。监视仅指示发生了变化，但不会提供具体的变化内容。例如，如果客户端在“/foo”被更改两次之前发出getData(''/foo'', true)，客户端将收到一个监视事件，告知“/foo”的数据已更改。会话事件，如连接丢失事件，也会发送到监视回调中，以便客户端知道监视事件可能会延迟。","title":"[论文翻译]ZooKeeper: Wait-free coordination for Internet-scale systems"},{"content":"软件概述 基本定义 (1) 程序与软件的定义\n程序是由程序设计语言所描述的、能为计算机所理解和处理的一组语句序列。其用程序设计语言（Programming Language）来描述的。程序严格遵循程序设计语言的各项语法和语义规定，应确保程序代码能为程序设计语言的编译器所理解，进而编译生成相应的可运行代码。\n软件是指在计算机系统的支持下，能够完成特定功能与性能的程序、数据和相关文档。文档是记录软件开发活动和阶段性成果、软件配置及变更的阐述性资料。\n(2) 软件的性质\n复杂性 一致性：软件不能独立存在，需要依附于一定的环境（硬件网络等），软件必须遵从人为的惯例并适应已有的技术和系统，软件需要随接口不同而改变，随时间推移而变化，而这些变化是不同人设计的结果 可变性：人们总认为软件是容易修改的，但忽视了修改带来的副作用，不断的修改最终导致软件的退化，从而结束其生命周期 不可见性：软件是一种看不见、摸不着的逻辑实体，不具有空间的形体特征，开发人员可以直接看到程序代码，但源代码并不是软件本身，软件以机器代码的形式运行，开发人员无法看到源代码如何执行的。 (3) 软件的分类\n类别 服务对象 软件的功能 发挥的作用 应用软件 行业和领域应用的用户 为特定行业和领域问题解决提供基于软件解决方案，创新应用领域的问题解决模式 提供更为便捷、快速、高效的服务 系统软件 各类应用软件 为应用软件运行和维护提供基础设施和服务，如加载、通讯、互操作、管理等 作为应用软件的运行环境 支撑软件 软件开发者和维护者 为软件系统的开发和维护提供自动和半自动的支持 提高软件开发效率和质量 (4) 开源许可证\n软件工程概述 (1) 软件开发需要解决的问题\n开发过程：基于什么样的步骤来开发软件系统 开发方法：采用怎样的方法来指导各项软件开发活动 开发管理：如何组织开发人员和管理软件产品 质量保证：如何保证软件开发活动和制品的质量 (2) 软件开发的特殊性\n软件开发技术更新速度快、软件开发需求变更频繁、软件开发复杂度高、软件开发需要团队协作完成、软件开发成果需要长期维护、软件开发保证软件质量、软件开发需要评估和控制风险\n(3) 软件工程的定义\n软件工程是一门研究如何用系统化、规范化、可量化等工程原则和方法进行软件开发和维护的学科。系统化：提供完整和全面的解决方法，包括目标、原则、过程模型、开发活动、开发方法和技术等；规范化：支持各类软件系统的开发，包括语言标准、质量标准、编程标准、方法标准、能力极其改进标准等；可量化：工作量、成本、进度、质量等要素可以量化。 其目标是创造“足够好”的软件，对于好的软件的定义：低成本、高质量、按时交付 其内容包括市场调研、正式立项、需求分析、项目策划、概要设计、详细设计、编程、测试、试运行、产品发布、用户培训、产品复制、销售、实施、系统维护和版本升级等。 (4) 软件工程的三要素\n视角 描述 目的 过程 从管理的视角，回答软件开发、运行和维护需要开展哪些工作、按照什么样的步骤和次序来开展工作 对软件开发过程所涉及的人、制品、质量、成本、计划等进行有效和可量化的管理 方法学 从技术的视角，回答软件开发、运行和维护如何做的问题 为软件开发过程中的各项开发和维护活动提供系统性、规范性的技术支持 工具 从工具辅助的视角，主要回答如何借助工具来辅助软件开发、运行和维护的问题 帮助软件开发人员更为高效地运用软件开发方法学来完成软件开发过程中的各项工作，提高软件开发效率和质量，加快软件交付进度 计算机辅助软件工程 (1) 基本概念\n全称为Computer Aided Software Engineering（CASE）。起源于20世纪80年代，最初是指在信息管理系统开发过程中由各种计算机辅助软件和工具组成的软件开发环境。随着软件工程技术、工具和开发理念的不断发展，CASE逐步演进成为辅助软件工程全生命周期的开发工具和方法集合。CASE旨在帮助软件工程从业者们进行软件开发和维护，提高软件开发和运维效率，提升软件质量，为实现软件开发全生命周期的工程化、自动化和智能化提供基础支撑。\n(2) CASE工具分类\n工具分类 功能 利益相关方 系统分析与设计工具 可视化建模，需求分析 需求分析人员，软件设计人员 程序设计工具 代码编写，代码补全，程序调试 编程人员，维护人员 软件测试与质量保证工具 单元测试，集成测试，性能测试 编程人员，测试人员 项目管理工具 代码和文件托管，团队协作 开发人员，管理人员 软件运维工具 应用程序部署，管理，监控 开发人员，维护人员 一体化集成开发环境 全生命周期管理 软件开发团队全体成员 过程模型 传统软件过程 需求开发：可行性研究之后，分析、整理和提炼所收集到的用户需求，建立完成的需求分析模型，编写软件需求规格说明\n软件设计：根据需求规格说明，确定软件体系结构，进一步设计每个系统部件的实现算法、数据结构及其接口等。\n软件构造：概括地说是将软件设计转换成程序代码，这是一个复杂而迭代的过程，要求根据设计模型进行程序以及正确而高效地编写和测试代码\n软件测试：检查和验证所开发的系统是否符合用户期望，主要包括单元测试、子系统测试、集成测试和验收测试等活动\n软件维护：系统投入使用后对其进行改进，以适应不断变化的需求。完全从头开发的系统很少，将软件系统的开发和维护堪称一个连续过程更有意义。\n软件项目管理：为了使软件项目能够按照预定的成本、进度、质量顺利完成，而对成本、人员、进度、质量和风险进行控制和管理的活动。\n软件配置管理：通过执行版本控制、变更控制的规程，并且使用合适的配置管理软件，保证所有产品配置项的完整性和可跟踪性。\n(1) 瀑布模型\n步骤 活动 方法 产出 需求分析(Requirement Analysis) 任务：定义软件需求，包括功能、非功能需求关注点：要做什么？(What, Problem)层次和视角：用户角度，仅描述问题和需求 依据：用户的期望和要求不断与用户进行交流和商讨，抽象、问题分解、多视点等技术 软件需求模型、软件需求文档、软件确认测试计划文档类的软件制品 概要设计(Architecture Design) 任务：建立软件总体架构、制定集成测试计划关注点：软件高层设计？ (How, Solution)层次和视角：宏观、全局、整体、战略性 依据：软件需求文档自顶向下, 逐步求精, 抽象, 模块化, 局部化，信息隐藏 …\u0026hellip; 软件概要设计模型、软件概要设计文档、软件集成测试计划文档类的软件制品 详细设计(Detailed Design) 任务：设计模块内部细节(算法、数据结构)，制订单元测试计划关注点：详细设计？ (How，Solution)层次和视角：微观、局部、细节性 依据：概要设计文档、软件需求文档高质量的软件设计原则，如单入口单出口 软件详细设计模型、软件详细设计文档、单元测试计划文档类的软件制品 编程实现(Implementation) 任务：编写程序代码并进行单元测试和调试关注点：如何最终做出这个东⻄? (How，Code)层次和视角：最终的实现代码 依据：软件概要和详细设计文档、单元测试计划采用某种程序设计语言(如C、C++、Java) 经过单元测试的源程序代码程序类的软件制品 集成测试(Integration Test) 任务：组装软件模块并进行测试以发现问题关注点：集成后软件中的缺陷（Bug）层次和视角：自底向上组装、全局 依据：软件概要设计文档、软件集成测试计划软件集成测试工具 经过集成测试、修复缺陷的源程序代码，集成测试报告数据、文档和代码类的软件制品 确认测试(Validation Test) 任务：测试软件是否满足用户需求关注点：软件在满足用户需求方面是否存在缺陷层次和视角：从用户角度，聚焦需求是否得以正确实现 依据：软件确认测试计划、软件需求文档软件测试支撑工具 经过确认测试、修复缺陷后的代码，软件确认测试报告数据、文档和代码类的软件制品 软件需求具有易变、多变的特点，而瀑布模型需求确定，过于理想化，缺乏变通，难应对变化。将其改进，可以得到带反馈和回溯的瀑布模型：\n(2) 增量模型\n(3) 迭代模型\n增亮模型和迭代模型的区别\n(4) 原型模型\n(5) 螺旋模型\n(6) 不同模型对比\n模型名称 指导思想 关注点 适合软件 管理难度 瀑布模型 提供系统性指导 与软件生命周期相一致 需求变动不大、较为明确、可预先定义的应用 易 原型模型 以原型为媒介指导用角户的需求导出和评价 需求获取、导出和确角认 理解需求难以表述清楚、角不易导出和获取的应用 易 增量模型 快速交付和并行开发 软件详细设计、编码角和测试的增量式完成 需求变动不大、较为明确、角可预先定义的应用 易 迭代模型 多次迭代，每次仅针角对部分明确软件需求 分多次迭代来开发软角件，每次仅关注部分角需求 需求变动大、难以一次性角说清楚的应用 中等 螺旋模型 集成迭代模型和原型角模型，引入风险分析 软件计划制定和实施，软件风险管理，基于角原型的迭代式开发 开发风险大，需求难以确角定的应用 难 敏捷方法 (1) 传统软件过程模型的特点和不足\n软件开发和运维的大量工作用于撰写软件文档，而非去编写程序代码\n软件开发过程中会花费大量时间和精力用于软件文档的评审，以确保软件质量\n一旦软件需求发生变化，开发人员需要修改软件需求文档，并据此来调整其他的一系列文档，最后再修改程序代码\n等较长时间才能得到可运行软件系统\n软件开发和运维的大量工作用于撰写软件文档，而非去编写程序代码\n软件开发过程中会花费大量时间和精力用于软件文档的评审，以确保软件质量\n一旦软件需求发生变化，开发人员需要修改软件需求文档，并据此来调整其他的一系列文档，最后再修改程序代码\n等较长时间才能得到可运行软件系统\n(2) 概念\n是一种轻量级软件开发方法，主张软件开发要以代码为中心，快速、轻巧和主动应对需求变化，持续、及时交付可运行的软件系统，提供了一组思想和策略，指导快速响应用户需求的变化，快速交付可运行的软件制品\n(3) 敏捷准则\n尽早和持续地交付有价值的软件，以使用户满意 即使到了软件开发后期，也欢迎用户需求的变化 不断交付可运行的软件系统，交付周期可以从几周到几个月 在整个软件项目开发期间，用户和开发人员最好能每天一起工作 由积极主动的人来承担项目开发，给他们提供所需环境和支持，信任他们的能力 团队内部最有效的信息传递方式是面对面的交谈 将可运行软件作为衡量软件开发进度的首要标准 可持续性的开发，出资方、开发方和用户方应当保持⻓期、恒定的开发速度 关注优秀的技能和良好的设计会增强敏捷性 简单化 最好的架构、需求和设计出自于自组织的团队 软件开发团队应定期就如何提高工作效率的问题进行反思，并进行相应的调整 (4) 突出代表\n极限编程 (1) 四条核心思想\n交流，强调基于口头（而非文档、报表和计划）的交流 反馈，通过持续、明确反馈来获得软件状态 简单，用最简单的技术来解决问题 勇气，快速开发并在必要时具有重新进行开发的信心 (2) 五条指导原则\n快速反馈： 从用户处迅速得到有关软件的反馈，确认开发是否满足用户需求，通过自动化测试迅速了解软件运行状况 简单性假设： 开发人员只考虑当前迭代所面临问题，无需考虑下一次迭代的问题，用简单方法和技术来解决问题。 逐步更改： 通过一系列修改来逐步解决问题和完善系统，不要期望一次迭代就开发出完整的软件系统。 支持变化： 欢迎用户改变需求，支持用户需求动态变化。 高量的工作： 采用诸如测试驱动开发等技术高质量地开展工作，确保软件质量。 (3) 十二条核心准则\n计划游戏： 软件开发团队快速制定下一次迭代的软件开发计划 隐喻： 使用业务相关术语来描述需求，促使开发人员和业务人员对系统达成共同和一致的理解 小型发布： 经常性发布可运行软件系统，每次发布的软件系统仅提供少量功能 简单设计： 只为当前的需求做设计，程序能运行所有测试、没有重复逻辑、包含尽可能少的类和方法 测试： 测试应在编写代码之前进行 重构： 在不改变程序代码功能的前提下，改进程序代码的设计，使程序代码更加简单，更易于扩展 结对编程： 两名程序员同时在一台计算机上共同开展编程工作 代码集体拥有： 开发小组的任何成员都可以查看并修改任何部分的代码 持续集成： 经常性地进行集成 每周工作40小时： 倡导质量优先 现场用户： 用户代表在现场办公，参与开发全过程，确保能及时得到反馈 编码标准： 遵循统一编码标准，以提高软件系统的可理解性和可维护性 Scrum方法 (1) 大致流程\n首先，产品拥有者需创建软件产品订单库即“Backblog”。描述软件产品需提供的功能需求以及它们的优先级排序 其次，筛选出最应该实现的软件需求。Scrum主人基于“Backblog”中各项软件需求及其优先级，形成待实现的软件产品冲刺订单库，即“SprintLog” 然后，软件开发将进入冲刺“Sprint”周期。以实现选定软件订单，每个冲刺就是一次增量开发，一般持续1到4周 最后，共同开展Scrum评审。一次冲刺完成后，每个团队成员演示自己的开发成果，大家共同审查成果是否高质量地实现了既定功能，并就其中的问题进行反思，以指导和改进下一次冲刺 (2) 迭代开发的要点\n每一次迭代都建立在稳定的质量基础上，并做为下一轮迭代的基线，整个系统的功能随着迭代稳定地增长和不断完善。 每次迭代要邀请用户代表验收，提供需求是否满足的反馈。 在一次迭代中，一旦团队作出承诺，就不允许变更交付件和交付日期；如果发生重大变化，产品负责人可以中止当次选代。 在迭代中可能会出现“分解”和“澄清”，但是不允许添加新工作或者对现有的工作进行“实质变更”。 对于“分解”和“澄清”，如果存在争议，那么将其认定为变更，放到产品订单中下一次迭代再考虑。 群体化软件开发方法 (1) 概念\n群体话软件开发方法一方面基于结对和团队的软件项目组织和开发方法，即依靠结对和团队的力量和不同人员间的交流与协作来进行软件开发、任务分工、达成共识、成果分享等，是当前软件开发的一种常见方法。另一方面源自开源软件开发的一种全新软件开发方法-群体化开发，具有新的理念、思想，采用新的技术和手段。\n此方法是一种依托互联网平台来吸引、汇聚、组织和管理互联网上的大规模软件开发人员，通过竞争、合作、协商等多种自主协同方式，让他们参与软件开发、分享软件开发知识和成果、贡献智慧和力量的一种新颖软件开发方法。\n(2) 与团队软件开发方法对比\n基于团队软件开发方法 基于社区群体化开发方法 项目组织方式 开发团队边界封闭 软件开发边界开放 开发成员组成 域外人员无法参与 互联网大众自由参与 程序代码开放 人员确定资源有限 利用海量的大众资源 依托平台协同 项目的成果不共享 共享源程序代码 关注创作和生产 集中化的管理模式 兼顾软件创作和生产 可用资源情况 关注生产而非创作 依托互联网平台 软件需求基础 基本概念 (1) 定义\n从软件本⾝的角度，软件需求是指软件用于解决现实世界问题时所表现出的功能和性能等方面的要求 从软件利益相关方的角度，软件需求是指软件系统的利益相关方对软件系统的功能和质量，以及软件运行环境、交付进度等方面提出的期望和要求 软件需求刻画了软件系统能做什么（What to do），应表现出怎样的行为，需满足哪些方面的条件和约束等要求 (2) 组成部分\n软件功能性需求(Functional)：能够完成的功能及在某些场景下可展现的外部可见行为或效果 软件质量方面的需求(Quality)：包含外部质量属性，如外部可展现的，用户、客户等会非常关心，如运行性能、可靠性、易用性等；内部质量属性，隐藏在内部的，软件开发工程师会非常关心，如可扩展性、可维护性、可理解性 软件开发约束性需求(Constraint)：开发成本、交付进度、技术选型、遵循标准等方面提出的要求 (3) 特点\n隐式性：来自于利益相关方，它隐式存在，很难辨别，甚至会遗漏掉\n隐晦性：在利益相关方的潜意识之中，不易于表达出来，难以获取，所表达的软件需求存在模糊性、歧义性、二义性\n多源性：存在多个的利益相关方，且可能存在相冲突和不一致的软件需求\n易变性：用户对软件的期望和要求也会经常性地发生变化，甚至在整个生命周期都会发生变化\n领域知识的相关性：软件需求的内涵与软件所在领域的知识息息相关，例如“12306”与铁路旅客服务领域相关\n价值不均性：不同的软件需求对于客户或用户而言所体现的价值是不一样的，可以细分为：主要和次要、核心和外围需求\n(4) 质量要求\n有价值（Valuable）：基于计算机软件的解决方案，有效提高问题解决的效率和质量，促进相关领域的业务创新 正确（Right）：反映利益相关方的期望，不能曲解或误解他们的要求 完整（Complete）：不能有遗漏或丢失 无二义（Unambiguous）：软件需求的描述应该是清晰和准确的 可行（Feasible）：在技术、经济等方面应该是可行的 一致（Consistent）：不应存在冲突 可追踪（Traceable）：可追踪到其源头 可验证（Verifiable）：可找到某种方式来检验软件需求是否在软件系统中得到实现 UML的多视点建模 视点名称 描述 UML图示及用途 结构视点（Structural View） 用于描述系统的构成 包图（Package Diagram）：展示系统的分组结构，如子系统或模块。\n类图（Class Diagram）：表示系统中的类、接口及其关系，是系统静态结构的核心表达。\n对象图（Object Diagram）：显示特定时间点的对象和它们之间的连接，是对类图的具体实例化。\n构件图（Component Diagram）：描绘了系统的组成部分以及这些部分之间的依赖关系，反映了系统的物理结构。 行为视点（Behavioral View） 刻画系统的行为 交互图（Interaction Diagram）：包括序列图（Sequence Diagram）和通信图（Communication Diagram），用以展示对象间的交互过程。\n状态图（Statechart Diagram）：描绘一个实体基于事件反应的动态行为，通过状态和转移来体现。\n活动图（Activity Diagram）：展示了系统的流程，强调的是操作的顺序和条件分支，可以用来表现并发处理。 部署视点（Deployment View） 刻画目标软件系统的软件制品及其运行环境 部署图（Deployment Diagram）：描述了硬件节点及其上的软件组件部署情况，反映了系统的物理拓扑结构和分布特性。 用例视点（Use Case View） 刻画系统的功能 用例图（Use Case Diagram）：用于捕捉系统的功能需求，即系统应该做什么，它描述了用户（执行者）与系统之间的交互作用。 导出和构思软件需求 (1) 识别利益相关方\n软件需求来自于软件的利益相关方，要获取软件需求，首先要搞清楚软件系统有哪些利益相关方。软件系统的利益相关方可以表现为特定的人群和组织，也可以是一类系统。不仅软件用户或客户可以是软件的利益相关方，软件的开发者也可以成为软件的利益相关方。\n(2) 导出和构思软件的功能性需求\n一方面需求工程师可以通过与利益相关方的交互，听取他们对软件的期望和要求，从他们那里导出软件需求，可以采用多种方法来导出软件需求：包括与用户或客户的面谈、分析业务资料、观察业务流程、进行问卷调查、软件原型等。另一方面需求工程师需要充当软件利益相关方的角色，站在他们的视角，来构思软件需求。针对软件需求开展创作，结合软件解决方案，提出可有效促进问题解决的软件需求。需求工程师可以采用大脑风暴构思、群体化方法、问卷调查、软件原型等多种方式来开展需求构思工作。\n(3) 导出和构思软件的非功能性需求\n非功能性需求包括软件质量要求和软件开发的约束性要求。质量要求又可以分为外部和内部。软件运行性能、可靠性、易用性、安全性、私密性等属于外部质量要求，软件可扩展性、可维护性、可互操作性、可移植性等属于内部质量要求。约束性要求，包括了开发进度要求、成本要求、技术选型等要求。软件的非功能性需求变得越来越重要，在某些情况下它们直接决定了软件是否能用和可用、是否好用和易用、是否高效和可靠运行、是否便于维护和演化等。\n用例图 (1) 概念\n用例图描述软件系统的边界以及软件外部使用者所观察到的系统功能，“观察到”是指外部使用者与系统存在交互，即信息输入和输出。用例图由三部分构成：执行者、用例、边。\n(2) 执行者\n执行者是系统之外的实体，他们使用软件系统功能、与软件系统交换信息，可以是一类用户，也可以是其他软件系统或物理设备。具体提来说，是UML中的类，代表一类用户或者外部实体，而非具体的对象实例。执行者通常对应于软件系统的利益相关方。\n(3) 用例\n用例是执行者为达成一项相对独立、完整的业务目标而要求软件系统完成的功能。通常表现为执行者与系统之间的业务交互动作的序列。对于执行者而言，交互目的或者效果在于达成其业务目标。对于待开发系统而言，交互的过程即是某项相对独立、完整的外部可见功能的实现过程。\n(4) 执行者与用例间的关系\n执行者与用例之间存在交互：执行者触发用例执行，向用例提供信息或从用例获取信息。触发用例执行的执行者称为主动执行者，仅从用例获取信息的执行者称为被动执行者。在用例图中，执行者与用例间的边通常为无向边。\n(5) 用例间的关系\n1. 包含关系\n如果用例B是用例A的某项子功能，则称用例A包含用例B\n包含关系用于提取多个用例中的公共子功能，以避免重复和冗余 体现了功能分解和组织的思想 2. 扩展关系\n如果用例A与B相似，但A的功能较B多，A的动作序列是在B的动作序列中的某些执行点上插入附加动作序列而构成的，则称用例A扩展用例B\n==包含和扩展的关系==\n扩展关系（Extend）：当某个新用例在原来的用例基础上增加了新的步骤序列，则原来用例被称为基用例，这种关系称为扩展关系，可以这样理解这里的基用例是一个完整的用例，即使没有子用例的参与，也可以完成一个完整的功能，只有当扩展点被激活时，子用例才会被执行。由子用例指向基用例，比如说充值金额查询用例中有导出Excel子用例，离开子用例不影响充值金额查询的功能，这就是扩展关系。\n包含关系（include）：几个用例可以提取他们共用的用例作为子用例，使其成为自己行为的一部分，因为子用例被提出，基用例并非一个完整的用例，所以include关系中的基用例必须和子用例一起使用才够完整，子用例也必然被执行。由基用例指向子用例，比如几个用例都要用到登录子用例，登录作为子用例没有它的参与，其他用例也无法执行，这就是包含关系。\n比较：容易混淆的原因在于不理解扩展和包含的含义，所谓扩展是从基用例的基础上扩展出新的功能（子用例），子用例不影响基用例，基用例本身是完整的，没有子用例的参与也可以完成自己的功能，而包含关系是提取出来的用例是基用例的一部分基用例和子用例必须一起使用才完整。二者的关键在于离开子用例，基用例是否可以完成一个完整的功能。\n原文链接：https://blog.csdn.net/kdongyi/article/details/89924780\n3. 继承关系\n如果A与B相似，但A的动作序列是通过改写B的部分动作或者扩展B的动作而获得的，则称用例A继承用例B\n4. 边界框\n表示整个软件系统或子系统的边界\n边界框内的用例构成了系统或子系统的内容，如用例 外面的是系统之外的执行者 5. 详细描述\n用例名：用户登录 用例标识： UC-UserLogin 主要执行者：家属、医生 目标：通过合法身份登录系统以获得操作权限 范围：空巢老人看护软件 前置条件：使用App软件之时 交互动作： 用户输入账号和密码 系统验证用户账号和密码的正确性和合法性 验证正确和合法则意味着登录成功 软件需求分析 基本概念 (1) 任务\n基于初步软件需求，进一步精化和分析软件需求，确定软件需求优先级，建立软件需求模型，发现和解决软件需求缺陷，形成高质量的软件需求模型和软件需求规格说明书\n(2) 不同视角表示\n视点名称 描述 UML图示及用途 用例视点（Use Case View） 具有哪些功能、功能间有何关系、功能与利益相关方有何关系 用例图（Use Case Diagram）：分析和描述用例视角的软件需求模型，捕捉系统的功能需求，描述用户（执行者）与系统之间的交互作用。 行为视点（Behavioral View） 用例是如何通过业务领域中一组对象以及它们间的交互来达成的 交互图（Interaction Diagram）、状态图（Statechart Diagram）：描述行为视角的软件需求模型，展示对象间的交互过程和实体基于事件反应的动态行为。 结构视点（Structural View） 业务领域有哪些重要的领域概念以及它们之间具有什么样的关系 类图（Class Diagram）：描述和分析业务领域的概念模型，表示系统中的类、接口及其关系，是系统静态结构的核心表达。 相关的UML图 交互图 用于刻画对象间的消息传递，分析如何通过交互协作完成功能，主要可以表示用例的功能实现方式、软件系统在某种使用场景下对象间的交互协作流程、软件系统的某个复杂操作的逻辑实现模型。交互图可以分为和顺序图(Sequence Diagram)和通信图(Communication Diagram)，前者强调消息传递的时间序，后者突出对象间的合作。两种交互图表达能力相同，可相互转换。\n顺序图 (1) 形状\n描述对象间的消息交互序列\n纵向：时间轴，对象及其生命线(虚线)，活跃期(⻓条矩形) 横向：对象间的消息传递 (2) 表示方式\n对象 “[对象名] : [类名] 示例：“Tom：Student”或“Student” 消息传递 对象生命线间的有向边 “[*][监护条件] [返回值:=]消息名[(参数表)]” “*”为迭代标记表示同一消息对同一类的多个对象发送 (3) 对象间的消息传递\n同步消息：发送者等待接收者将消息处理完后再继续 异步消息：发送者在发送完消息后不等待接收方即继续自己的处理 自消息：一个对象发送给自身的消息 返回消息：某条消息处理已经完成，处理结果沿返回消息传回 创建消息和销毁消息：消息传递目标对象的创建和删除 (4) 示例\n通信图 主要特点：节点表示对象、对象间连接称为连接器、连接器上可标示一到多条消息、消息传递方向用靠近消息小箭头表示、消息序号采用多层标号。\n视点 图 (diagram) 说明 结构 包图（package diagram） 从包层面描述系统的静态结构 类图（class diagram） 从类层面描述系统的静态结构 对象图（object diagram） 从对象层面描述系统的静态结构 构件图(component diagram) 描述系统中构件及其依赖关系 行为 状态图(statechart diagram ) 描述状态的变迁 活动图(activity diagram) 描述系统活动的实施 通信图(communication diagram) 描述对象间的消息传递与协作 顺序图(sequence diagram) 描述对象间的消息传递与协作 部署 部署图（deployment diagram） 描述系统中工件在物理运行环境中的部署情况 用例 用例图（use case diagram） 从外部用户角度描述系统功能 类图 (1) 图的构成\n结点：表示系统中的类（或接口）及其属性和操作\n边：类之间的关系\n(2) UML表示\n(3) 属性的表示\n[可见性] 名称 [: 类型] [多重性] [= 初值] [{约束特性}] 可见性 公开(+): 所有对象均可访问 保护(#): 所在类及子类对象均可访问 私有(-): 仅所在类的对象才可访问 多重性：属性取值数量, 如1，0..1，0..* ，1..， 约束特性 可更改性：{readOnly}表示只读，缺省为{changeable} 顺序性： {ordered}表示属性取值是有序的，缺省为{unordered} 唯一性： 缺省为{bag}表示属性取值元素允许出现重复元素 静态性：{static}表示静态属性，属性值由类所有实例对象共享 (4) 方法的表示\n[可见性] 名称[(参数表)] [: 返回类型] [{约束特性}] 约束特性 查询操作： {isQuery = true}表示查询操作，{ isQuery = false}表示修改操作，缺省为修改操作。 多态性：{isPolymorphic = true}表示本操作允许多态，即可被子类中相同定义形式的操作所覆盖。 并发性：{concurrency = sequential} 任一时刻只有一个对象调用可执行。{concurrency = guarded} 并行线程可同时调用多个对象的本操作，但同一时刻只允许一个调用执行。{concurrency = concurrent} 并行线程可以同时调用多个对象的本操作且这些调用可并发执行 异常：操作在执行过程中可能引发异常 (5) 接口\n接口是一种不包含操作实现部分的特殊类，形式分为：\n供给接口: 对外提供的接口\n需求接口: 需要使用的接口\n(6) 类间关系\n1. 关联\n表示类间的逻辑联系\n多重性：位于关联端的类可以有多少个实例对象与另一端的类的单个实例对象相联系 角色名：参与关联的类对象在关联关系中扮演的角⾊或发挥的作用 约束特性：针对参与关联的对象或对象集的逻辑约束 2. 聚合与组合\n聚合关系(Aggregation)：部分类对象是多个整体类对象的组成，例如一名学生可同时参与多个兴趣小组 组合关系(Composition)：部分类对象只能位于一个整体类对象中，一旦整体类对象消亡，部分类对象也不能苟活 3. 依赖\n有语义上关系且一个类对象变化会导致另一类对象作相应修改，形式有以下几类：\n使用：A类使用B类的某项服务 追踪：B类的变化导致A类的变化 精化：A类是在B类基础上引进设计、决策等形成 实现：A类给出了B类元素的实现 派生：A类可通过B类推导或计算出 4. 实现\n表示一个类实现了另一个类中定义的对外接口，是一种特殊依赖关系。典型应用为：一个具体类实现一个接口\n5. 继承\n子类继承父类所有可继承的特性，且可通过添加新特性或覆盖（override）父类中的原有特性。父类抽象多个子类中公共特性，从而避免冗余、简化操作。\n对象图 **对象图是系统中的对象在运行过程中的静态瞬时快照，是类图在系统的运行过程中某个时刻点上或某一时间段内的实例化样本。**结点表示对象，边表示对象间的链接，例如类图中的一个类在对象图中可表现为多个活跃的对象实例；对象图的链接边是类图中关联边的实例化；类图中的其他边，如继承、依赖等在对象图中则无从表现。\n状态图 (1) 功能\n描述实体（对象、系统）在事件刺激下的反应式动态行为及其导致的状态变化，并刻画了实体的可能状态、每个状态下可响应事件、响应动作、状态迁移。\n(2) 构成\n状态：对象属性取值构成的一个约束条件，不同状态下对象对事件的响应行为完全一样\n事件：某时刻点发生、需要关注的瞬时刺激或触动\n消息型事件(同步)：其他对象发来消息 信号型事件(异步)：其他对象传来异步信号 时间型事件：到达特定时间点 条件型事件：对象属性取值满足特定条件 动作(action)：计算过程，位于迁移边上，简单，执行时间短\n活动(activity)：计算过程，位于状态中，复杂、执行时间长\n需求分析过程 分析和确定软件需求优先级 (1) 软件需求重要性\n分为核心软件需求和外围软件需求：\n核心软件需求在解决问题方面起到举足轻重的作用，提供了软件系统所特有的功能和服务，体现了软件系统的特⾊和优势。外围软件需求提供了次要、辅助性的功能和服务。\n(2) 软件需求优先级\n有些软件需求需要优先实现，尽早交付给用户使用，以发挥其价值；有些软件需求可以滞后实现，晚点交付使用。在设置优先级时，应考虑以下的因素：\n结合软件项目开发的具体约束，考虑不同软件需求的重要性，确定软件需求的实现优先级，确保在整个迭代开发中有计划、有重点地实现软件需求。 按照软件需求的重要性来确定其优先级。 按照用户的实际需要来确定软件需求的优先级。 (3) 用例分析和实现的次序\n确保有序地开展需求分析、软件设计和实现工作，使得每次迭代开发有其明确的软件需求集，每次迭代开发结束之后可向用户交付他们所急需的软件功能和服务。应考虑：\n结合软件开发的迭代次数、每次迭代的持续时间、可以投入的人力资源等具体情况 充分考虑相关软件需求项的开发工作量和技术难度等因素，确定需求用例分析和实现的先后次序 用例名称 用例标识 重要性 优先级 迭代次序 监视老人 UC-MonitorElder 核心 高 第一次迭代 获取老人信息 UC-GetElderInfo 核心 高 检测异常状况 UC-CheckEmergency 核心 高 通知异常状况 UC-NotifyEmergency 核心 高 第二次迭代 自主跟随老人 UC-FollowElder 核心 高 视频/语音交互 UC-A\u0026VInteraction 外围 中 第三次迭代 控制机器人 UC-ControlRobot 外围 低 提醒服务 UC-AlertService 外围 低 第四次迭代 用户登录 UC-UserLogin 外围 低 系统设置 UC-SetSystem 外围 低 分析和建立软件需求模型 分析和建立用例的交互模型 任务：分析和描述用例是如何通过一组对象之间的交互来完成的 步骤：\n分析和确定用例所涉及的对象及其类 分析和确定对象之间的消息传递 绘制用例的交互图 (1) 分析和确定用例所涉及的对象及其类\n软件需求用例的处理通常涉及三种不同类对象：边界类、控制类、实体类。这些类是在用例分析阶段所识别并产生的，通常将它们称为分析类。\n1. 边界类\n每个用例或者由外部执行者触发，或者需要与外部执行者进行某种信息交互，因而用例的业务逻辑处理需要有一个类对象来负责目标软件系统与外部执行者之间的交互。由于这些类对象处于系统的边界，需与系统外的执行者进行交互，因而将这些对象所对应的类称之为边界类。\n边界类用于交互控制，处理外部执行者的输入数据，或者向外部执行者输出数据。也可以作为外部接口，如果外部执行者表现为其他的系统或者设备，那么边界类对象需要与系统之外的其他系统或设备进行信息交互。\n2. 控制类\n控制类对象作为完成用例任务的主要协调者。负责处理边界类对象发来的任务请求，对任务进行适当的分解，并与系统中的其他对象进行协同，以控制他们共同完成用例规定的任务或行为。\n一般而言，控制类并不负责处理具体的任务细节，而是负责分解任务，并通过消息传递将任务分派给其他对象类来完成，协调这些对象之间的信息交互。\n3. 实体类\n用例所对应业务流程中的所有具体功能最终要交由具体的类对象来完成，这些类称之为实体类。\n一般而言，实体类对象负责保存目标软件系统中具有持久意义的信息项，对这些信息进行相关的处理（如查询、修改、保存等），并向其他类提供信息访问的服务。实体类的职责是要落实目标软件系统中的用例功能，提供相应的业务服务。\n(2) 分析和确定对象之间的消息传递\n1. 确定消息名称\n消息名称直接反映了对象间交互的意图（请求、通知），也体现了接收方对象所对应的类需承担的职责和任务，也即发送方对象希望接收方对象提供什么样的功能和服务。一般地，消息名称用动名词来表示，需求工程师应尽可能用应用领域中通俗易懂的术语来表达消息的名称和参数，以便于用户和需求工程师等能直观地理解对象间的交互语义。\n2. 确定消息传递的信息\n对象间的交互除了要表达消息名称和交互意图之外，在许多场合还需要提供必要的交互信息（通知和请求的内容），这些信息通常以消息参数的形式出现，也即一个对象在向另一个对象发送消息的过程中，需要提供必要的参数，以向目标对象提供相应的信息。在构建用例的交互图过程中，如果用例的业务流程能够明确相应的交互信息，那么就需要确定消息需附带的信息。通常，消息参数用名词或名词短语来表示。\n(3) 绘制用例的交互图\n用例的外部执行者应位于图的最左侧，紧邻其右的是用户界面或外部接口的边界类对象，再往右是控制类对象，控制类的右侧应放置实体类对象，它们的右侧是作为外部接口的边界类对象。对象间的消息传递采用自上而下的布局方式，以反映消息交互的时序先后。\n(4) 交互图的工作流程\n外部执行者与边界类对象进行交互以启动用例的执行 边界类对象接收外部执行者提供的信息，将信息从外部形式转换为内部形式，并通过消息传递将相关信息发送给控制类对象 控制类对象根据业务逻辑处理流程，产生和分解任务，与相关的实体类对象进行交互以请求完成相关的任务，或者向实体类对象提供业务信息，或者请求实体类对象持久保存业务逻辑信息，或者请求获得相关的业务信息 实体类对象实施相关的行为后，向控制类对象反馈信息处理结果 控制类对象处理接收到的信息，将处理结果通知边界类对象 边界类对象对接收到的处理结果信息进行必要的分析，将其从内部形式转换为外部形式，通过界面将处理结果展示给外部执行者 sequenceDiagram participant User participant LoginUI as \u0026lt;\u0026lt;boundary\u0026gt;\u0026gt;\u0026lt;br\u0026gt;LoginUI participant LoginManager as \u0026lt;\u0026lt;controller\u0026gt;\u0026gt;\u0026lt;br\u0026gt;Login participant UserLibrary as \u0026lt;\u0026lt;entity\u0026gt;\u0026gt;\u0026lt;br\u0026gt;UserLibrary User-\u0026gt;\u0026gt;LoginUI: goto LoginUI-\u0026gt;\u0026gt;LoginManager: login(account, password) LoginManager-\u0026gt;\u0026gt;UserLibrary: verifyUserValidity(account, password) UserLibrary--\u0026gt;\u0026gt;LoginManager: UserValidity LoginManager--\u0026gt;\u0026gt;LoginUI: LoginResult 分析和建立软件需求的分析类模型 (1) 确定分析类\n用例模型中的外部执行者应该是分析类图中的类。在各个用例的顺序图，如果该图中出现了某个对象，那么该对象所对应的类属于分析类，应出现在分析类图中。可以根据用例图来确定分析类，也可以根据交互图来确定分析类。\n软件需求用例的处理通常涉及三种不同类对象：边界类、控制类、实体类。这些类是在用例分析阶段所识别并产生的，通常将它们称为分析类。\n(2) 确定分析类的职责\n每一个分析类都有其职责，需提供相关的服务。对象接收的消息与其承担的职责之间存在一一对应关系，即如果一个对象能够接收某项消息，它就应当承担与该消息相对应的职责。可用类的方法名来表示分析类的职责，并采用简短的自然语言来详细刻画类的职责。\n(3) 确定分析类的属性\n分析类具有哪些属性取决于该类需要持久保存哪些信息。用例顺序图中的每个对象所发送和接收的消息中往往附带有相关的参数，这意味着发送或接收对象所对应的类可能需要保存和处理与消息参数相对应的信息，因而可能需要与此相对应的属性。\n(4) 确定分析类之间的关系\n类之间的关系有多种形式，包括继承、关联、聚合和组合、依赖等等，具体可以根据以下的策略进行分析：\n在用例的顺序图中，如果存在从类A对象到类B对象的消息传递，那么意味着类A和B间存在关联、依赖、聚合或组合等关系。 如果经过上述步骤所得到的若干个类之间存在一般和特殊的关系，那么可对这些分析类进行层次化组织，标识出它们间的继承关系。 (5) 绘制分析类图\n经过上述的步骤之后，绘制出系统的分析类图，建立分析类模型。直观描述了系统中的分析类、每个分析类的属性和职责、不同分析类之间的关系（如果系列规模较大，分析类的数量多，关系复杂，难以用一张类图来完整和清晰地表示，那么可以分多个子系统来绘制分析类图）。\n分析和建立软件需求的状态模型 用UML的状态图来描述这些对象的状态模型，以刻画对象拥有哪些状态、对象的状态如何受事件的影响而发生变化。注意以下两点：\n状态模型是针对对象而言的，而非针对分析类 需求工程师无需为所有的类对象建立状态模型，只需针对那些具有复杂状态的对象建立状态模型 软件需求文档化及评审 软件需求文档模板 分析软件需求的输出 **软件原型：**以可运行软件的形式，直观地展示了软件的业务工作流程、操作界面、用户的输入和输出等方面的功能性需求信息 **软件需求模型：**以可视化的图形方式，从多个不同的视角，直观地描述了软件的功能性需求，包括用例模型、用例的交互模型、分析类模型、状态模型等 **软件需求文档：**以图文并茂的方式，结合需求模型以及需求的自然语言描述，详尽刻画了软件需求，包括功能性和非功能性软件需求，软件需求的优先级列表等 软件体系结构设计 软件体系结构的设计元素 (1) 构件\n构件是构成体系结构的基本功能部件，是软件系统中的物理模块，具有特定的功能和精确定义的对外接口，外界可通过接口来访问它，其特点为：\n可分离：一个或数个可独立部署执行码文件 可替换：构件实例可被其它任何实现了相同接口的另一构件实例所替换 可配置：可通过配置机制修改构件配置数据，影响构件对外服务的功能或行为 可复用：构件可不经源代码修改，无需重新编译，即可应用于多个软件项目或软件产品 例如.dll文件和.jar文件，不是源程序，而是可运行的二进制代码，是客观物理存在的（即有实际的文件），表示为UML：\n(2) 连接件\n连接件表示软构件之间的连接和交互关系。每个软构件并非孤立，它们之间通过连接进行交互，为了交换数据、获得服务。软构件之间的典型交互方式主要有：过程调用、远程过程调用（Remote Procedure Call，RPC）、消息传递、事件通知和广播、主题订阅等等。构件通过接口对外提供服务，或与其他构件进行交互，构件有两种接口：\n供给接口，是对外提供的接口 需求接口，请求其他构件帮助所需的接口 构件的实现与构件的接口相分离，构件开发者可自由选择实现方法，只要它实现供给接口中的操作及属性。两个构件的实现遵循相同接口定义，它们就可自由替换。构件之间的连接和交互示例图及表示如下：\n(3) 约束\n约束是组件中的元素应满足的条件以及组件经由连接件组装成更大模块时应满足的条件。组件的元素应当满足以下几点：\n高层次软件元素可向低层次软件元素发请求，低层次软件元素完成计算后向高层次发送应答，反之不行 每个软件元素根据其职责位于适当的层次，不可错置，如核心层不能包含界面输入接收职责 每个层次都是可替换的，一个层次可以被实现了同样的对外服务接口的层次所替代 软件体系结构的不同视图 (1) 逻辑视图——包图\n包图模型包含一组具有逻辑关联的UML模型元素。包间关系可以分为：构成关系、依赖关系。包图可描述软件系统的高层结构，包图以结构化、层次化方式组织、管理大型的软件模型，使得分别处理不同包的开发团队之间的相互干扰程度降至最低。\n(2) 逻辑视图——构件图\n构件图可以描述软件系统中构件及构件间的关系，主要用来描述软件系统中构件的接口定义及构件间的依赖关系，以便评估软件变更的影响范围；描述软件系统或其中某个局部的构件化设计，为在后续开发阶段实现构件化的软件模块订立设计规约。\n(3) 开发视图\n开发视图主要包括：各软件要素源代码的程序分包及目录结构，采用的类库、中间件和框架，它们与逻辑视图中各个软件元素之间的映射关系。\n(4) 部署视图\n部署图：软件安装部署的物理机器及其连接，各个件元素在这些机器上的部署位置，表示软件系统可执行工件在运行环境中的分布情况。有两种部署图：逻辑层面的描述性部署图和物理层面的实例性部署图。\n逻辑层面的描述性部署图描述软件的逻辑布局 物理层面的实例性部署图针对具体运行环境和特定的系统配置描述软件系统的物理部署情况 下图分别为描述性部署图和实例性部署图：\n(5) 运行视图\n运行视图描述软件运行时进程、线程的划分，它们之间的并发和同步，它们与逻辑视图和开发视图之间的映射关系，可用UML的活动图、对象图来表示。\n软件设计模式 设计模式根据不同抽象层次可以分为：\n体系结构风格：面向整个软件系统 构件设计模式：面向子系统或者构件 实现设计模式：针对子系统或构件中的某个特定问题 软件体系结构风格 面向整个软件系统，在抽象层次给出软件体系结构的结构化组织方式，提供一些预定义的子系统或者构件，规定其职责，明确它们之间的相互关系、协作方式的规则或指南，需要针对不同的问题采用不同的体系结构模式。\n(0) 需求设计、软件体系结构设计、详细设计三者关联\n软件需求是体系结构设计的基础和驱动因素，体系结构是以软件需求实现为目标的软件设计蓝图 体系结构设计为详细设计提供可操作指导，详细设计是对体系结构设计中设计要素的局部设计 (1) 分层体系结构模式\n1. 基本概念\n该模式将软件系统按照抽象级别逐次递增或递减的顺序，组织为若干层次，每层由一些抽象级别相同构件组成\n典型层次示例：\n顶层：直接面向用户提供软件系统的交互界面 底层：则负责提供基础性、公共性的技术服务，它比较接近于硬件计算环境、操作系统或数据库管理系统 中间层：介乎二者之间，负责具体的业务处理 2. 模式约束\n层次间的关系\n每层为其紧邻上层提供服务，使用紧邻下层所提供的服务 上层向下层发出服务请求，下层为上层反馈服务结果 下层向上层提供事件信息，上层对下层通知做出处理 服务接口的组织方式\n层次中的每个构件分别公开其服务接口 每个层次统一对外提供整合的服务接口 3. 特点\n松耦合：减低整个软件系统的耦合度 可替换：一个层次可以有多个实现实例 可复用：层次和整个系统可重用 标准化：支持体系结构及其层次、接口的标准化 (2) 管道和过滤器模式\n1. 基本概念\n将软件功能实现为一系列处理步骤，每个步骤封装在一个过滤器构件中； 相邻过滤器间以管道连接，一个过滤器的输出数据借助管道流向后续过滤器，作为其输入数据； 软件系统的输入由数据源（数据库、文件、其他软件系统、物理设备等）提供；软件最终输出由源自某个过滤器的管道流向数据汇（data sink） 例如编译器，采用的就是一个典型的管道/过滤器风格：\n2. 模式约束\n过滤器与管道之间的协作方式\n过滤器以循环的方式不断地从管道提取输入数据，并将其输出数据压入管道，称为主动过滤器 管道将输入数据压入到位于其目标端过滤器，过滤器被动地等待数据，称为被动过滤器 管道负责提取位于其源端过滤器的输出数据 设计考虑\n如果管道连接的两端均为主动过滤器，那么管道必须负责它们之间的同步，典型的同步方法是先进先出缓冲器 如果管道的一端为主动过滤器，另一端为被动过滤器，那么管道的数据流转功能可通过前者直接调用后者来实现 3. 特点\n该模式可以自然地解决具有数据流特征的软件需求，且可独立地更新、升级过滤器来实现软件系统的扩展和进化。\n(3) 黑板风格\n1. 基本概念\n将软件系统划分为黑板、知识源和控制器三类构件\n黑板：负责保存问题求解过程中的状态数据，并提供这些数据的读写服务 知识源：负责根据黑板中存储的问题求解状态评价其自身的可应用性，进行部分问题求解工作，并将此工作的结果数据写入黑板 控制器：负责监视黑板中不断更新的状态数据，安排（多个）知识源的活动。 2. 模式约束\n控制构件通过观察黑板中的状态数据来决定哪些知识源对后续的问题求解可能有所贡献，然后调用这些知识源的评价功能以选取参与下一步求解活动的知识源。被选中的知识源基于黑板中的状态数据将问题求解工作向前推进，并根据结果更新黑板中的状态数据。控制构件不断重复上述控制过程，及至问题求解获得满意的结果。\n3. 特点\n该模式可灵活升级和更换知识源和控制构件，知识源的独立性和可重用性好，因为知识源之间没有交互，除此之外软件系统具有较好的容错性和健壮性，知识源的问题求解动作是探索性的，允许失败和纠错。\n(4) MVC风格\n1. 基本概念\n主要分为三个构件：\n模型构件，负责存储业务数据并提供业务逻辑处理功能 视图构件，负责向用户呈现模型中的数据 控制器，在接获模型的业务逻辑处理结果后，负责选择适当的视图作为软件系统对用户的界面动作的响应 2. 模式约束\n创建视图，视图对象从模型中获取数据并呈现用户界面，视图接受界面动作，将其转换为内部事件传递给控制器。所有视图在接获来自模型的业务数据变化通知后向模型查询新的数据，并据此更新视图。 控制器将用户界面事件转换为业务逻辑处理功能的调用。控制器根据模型的处理结果创建新的视图、选择其他视图或维持原有视图 模型进行业务逻辑处理，将处理结果回送给控制器，必要时还需将业务数据变化事件通知给所有视图 (5) SOA风格\n将软件系统的软构件抽象为一个个的服务（Service），每个服务封装了特定的功能并提供了对外可访问的接口。任何一个服务既可以充当服务的提供方，接受其他服务的访问请求；也可充当服务的请求方，请求其他服务为其提供功能。任何服务需要向服务注册中心进行注册登记，描述其可提供的服务以及访问方式，才可对外提供服务。\n(6) 消息总线\n包含了一组软构件和一条称为“消息总线”的连接件来连接各个软构件。消息总线成为软构件之间的通信桥梁，实现各个软构件之间的消息发送、接收、转发、处理等功能。每一个软构件通过接入总线，实现消息的发送和接收功能\n(7) C/S风格\nClient/Server 的简称，客户机/服务器模式。C/S 结构充分利用客户端的硬件设施，将很多的数据处理工作在客户端完成，故数据处理能力比较强大，对一些复杂的业务流程，也容易实现。\n两层C/S：\n三层C/S：\n(8) B/S\n浏览器/服务器（Browser/Server，简称 B/S）风格就是上述三层应用结构的一种实现方式，其具体结构为：浏览器/Web服务器/数据库服务器。\n(9) 总结\n类别 特点 典型应用 管道/过滤器风格 数据驱动的分级处理，处理流程可灵活重组，过滤器可重用 数据驱动的事务处理软件，如编译器、Web服务请求等 层次风格 分层抽象、层次间耦合度低、层次的功能可重用和可替换 绝大部分的应用软件 MVC风格 模型、处理和显示的职责明确构件间的关系局部化，各个软构件可重用 单机软件系统，Web应用软件系统 SOA风格 以服务作为基本的构件，支持异构构件之间的互操作，服务的灵活重用和组装 部署和运行在云平台上的软件系统 消息总线风格 提供统一的消息总线，支持异构构件之间的消息传递和处理 异构构件之间消息通信密集型的软件系统 用户界面设计 软件详细设计 输入软件体系结构设计、用户界面设计、软件需求，进行细化和精化，具体对象为子系统、构件、关键设计类和界面类，最后获得高质量、面向实现的设计模型，该模型直接支持编码和程序设计。\n活动图 (1) 基本概念\n描述实体为完成某项功能而执行的操作序列，其中某些操作或其子序列存在并发和同步\n(2) 构成\n活动点：表示计算过程 决策点：根据条件进行活动决策 边：表示控制流或信息流。控制流：表示一个操作完成后对其后续操作的触发；信息流：刻画操作间的信息交换 并发控制：控制流经此节点后分叉（Fork）成多条可并行执行的控制流，或多条并行控制流经此节点后同步合并（Join）为单条控制流 泳道：将活动图用形如游泳池中的泳道分隔成数个活动分区，每个区域由一个对象或一个控制线程负责，每个活动节点应位于负责执行该活动的对象或线程所在的区域内。带泳道的活动图更清晰地表示了对象或线程的职责、它们之间的分工、协同和同步。 (3) 绘制原则\n从决策点出发的每条边上均应标注条件，且这些条件必须覆盖完整且互不重叠。必须确保分叉和汇合节点之间的匹配性，对任一分叉节点，其导致的并发控制流必须最终经由一个汇合节点进行控制流的同步和合并。一张活动图可以浓缩成另一活动图中的单个活动节点，前者称为子活动图，后者称为父活动图\n用例设计 给出用例的具体实现解决方案，描述用例是如何通过各个设计元素（包括子系统、软构件、设计类等）的交互和协作来完成的。需要产出用例设计的顺序图、设计类图。\n设计用例实现方案 (1) 基本步骤\n基础：\n分析每个用例的UML交互图，它是开展用例设计的依据 考虑体系结构和用户界面设计要素，它们是用例实现参与者 明确各个设计元素（如对象类、构件等）的职责 方法：\n在需求分析阶段用例交互图的基础上，将交互图的分析类转化为用例实现的设计类，同时引入体系结构设计和用户界面设计所生成的设计元素，共同形成关于用例实现的交互模型\n结果：\n生成用例实现的顺序图 引入更多的设计元素，如构件、子系统、类等 精化更多的设计细节，如接口、方法、交互等 (2) 分析类与设计元素间对应关系\n一个分析类的一项职责由一个设计元素的单项操作完整地实现\n一个分析类的一项职责由一个设计元素的多项操作来实现\n一个分析类的一项职责由多个设计元素协同完成\n(3) 示例\n1. “用户登录”用例\n2. “系统设置”用例\n3. “提醒服务”用例\n4. ”远程控制机器人“用例\n构造设计类图 (1) 基本概念\n需要基于用例实现方案给出详细设计模型中的设计类图，类图中的设计元素可以为子系统、构件和UML类，用不同的构造型或者相应图符来表示。\n对UML类图稍作扩充以表示详细设计类图，允许在类图中出现子系统和构件，它们的类别可以采用不同的UML构造型或者不同的图元符号来表示。\n(2) 构造方法\n创建初始的设计类：从分析类图、体系结构图、用例实现的顺序图寻找 确定设计类的职责：每个设计类都有职责，取决于对交互图中消息的响应 确定设计类间的关系：如果A与B有消息，那么它们间有关系：关联、聚合和组合 确定设计类的属性：需要保存哪些数据项、其他对象类信息 形成整体设计类图：模块化、职责和功能单一化原则，调整和优化 另外，需要确保设计类图与（需求）分析类图之间、设计类图与用例设计模型之间的一致性：分析类图中的类在设计类图中有相应的对应物，用例设计模型中的设计元素（主要是指参与用例实现的对象、对象间的消息传递）在设计类图中要有相应的对应物（主要是指设计类及其方法）\n如下图，为根据用例设计的交互图（顺序图）构造出设计类图：\n类设计 给出每个设计类的具体实现细节，包括类的属性定义、方法的实现算法等，使得程序员能够基于类设计给出这些类的实现代码。需要产出详细的类属性方法和类间关系设计的类图、描述类方法实现算法细节的活动图、必要的状态图（可选）。\n确定类的可见范围 “可见范围”的定义为：如果类仅仅被其所在的包所使用，那么该类是“私有的”，否则是“公开的”。应尽量缩小类的可见范围，除非确有必要，否则应将类“隐藏”于包的内部。\npublic: 公开级范围，软件系统中所有包中的类均可见和可访问该类 protected：保护级范围，只对其所在包中的类以及该类的子类可见和访问 private：私有级范围，只对其所在包中的类可见和访问 精化类间关系 类间关系的语义强度从高到低依次是：继承，组合，聚合，（普通）关联，依赖。定义类间关系时，应当遵循以下原则：\n“自然抽象”原则，类间关系应该自然、直观地反映软件需求及其实现模型 “强内聚、松耦合”的原则，尽量采用语义连接强度较小的关系 1:m，即一对多的类间关系：\n精化用户界面类间的关系：\n精化关键设计类间的关系：\n精化类的属性和方法 (1) 精化类属性\n类属性用业务领域的名词或者名词短语来命名。类属性的可见范围可以分为public、protected、private。又是需要结合类关系来精化类属性设计：\n如果类A与类B间存在1:1关联或聚合（非组合）关系，那么在A中设置类型为B的指针或引用（reference）的属性 如果类A到类B间存在1:n关联或聚合（非组合）关系，那么在A中设置一个集合类型（如列表等）的属性，集合元素的类型为B的指针或引用 如果类A与类B间存在1:1的组合关系，那么在A中设置类型为B的属性 如果类A到类B间存在1:n的组合关系，那么在A中设置一个集合类型（如列表等）的属性，集合元素的类型为B 例如精化Robot类属性的设计：\nprivate int velocity：表示机器人的速度 private int angle：表示运动角度 private int distance：表示与老人的距离 private int state：表示运动状态，包括“IDLE”空闲状态、“AUTO”自主跟随状态、“MANNUAL”手工控制状态 (2) 精化类方法\n细化和明确类中各个方法的以下设计信息：方法名称、参数表（含参数的名称和类型）、返回类型、作用范围、功能描述、实现算法、前提条件（pre-condition）、出口断言（post-condition）等。可以用活动图来描述方法的详细设计，下图分别为Login()、detectFallDown()方法的描述：\n构造类对象的状态图 如果一个类的对象具有较为复杂的状态，在其生命周期中需要针对外部和内部事件实施一系列的活动以变迁其状态，那么可以考虑构造和绘制类的状态图。如果某个类在实现其职责过程中需要执行一系列的方法、与其他的对象进行诸多的交互，那么可以考虑构造和绘制针对该类某些职责的活动图。如Robot类对象的状态图：\n数据设计 对软件所涉及的持久数据及其操作进行设计，明确持久数据的存储方式和格式，细化数据操作的实现细节。需要产出描述数据设计的类图、描述数据操作的活动图。\n确定永久数据与确定数据存储和组织方式 (1) 类内内容\n根据对需求的理解来确定哪些数据需要永久保存，如用户的账号和密码、系统设置信息。然后确定将数据存储在何处，如数据文件中、数据库中。若为数据文件，则需要确定数据存储的组织格式，以便将格式化和结构化的数据存放在数据文件之中；若为数据库，则需要设计支持数据存储的数据库表。以数据库表为例，首先确定设计模型中需要持久保存的类的对象及其属性，然后明确面向对象设计模型与关系数据库模型的对应关系、类对应于 “表格”（table）、对象对应于“记录”（record）、属性对应于表格中的“字段”（field），如下：\n(2) 类间关系\n1. 关联关系\n1:1、1:n关联关系的映射：假设类C1、C2对应的表格分别为T_C1、T_C2，只要将T_C1中关键字段纳入T_C2中作为外键，就可表示从T_C1到T_C2间的1:1、1:n关联关系：\nn:m关联关系的映射：在T_C1、T_C2间引进新交叉表格T_Intersection，将T_C1、T_C2关键字段纳入T_Intersection中作为外键，在T_C1与T_Intersection之间、T_C2与T_Intersection之间建立一对多关系：\n2. 继承关系\n假设C1是C2的父类，数据库表设计有两种方法。第一种方法：将T_C1中的所有字段全部引入至T_C2：\n这种方法浪费了持久存储空间，容易因数据冗余而导致数据不一致性。因此可以使用第二种方法：仅将T_C1中关键字字段纳入T_C2中作为外键：\n获取C2对象的全部属性，需要联合T_C2中的记录和对应于外键值的T_C1中的某条记录。这种方法避免了数据冗余，但在读取C2对象时性能不如前种方法。\n设计数据操作 主要有写入、查询、更新和删除四类基本操作以及由它们复合而成的业务，以及数据验证操作，其负责验证数据的完整性、相关性、一致性等等。例如：boolean insertUser(User)、boolean deleteUser(User)、boolean updateUser(User)、User getUserByAccount(account)、boolean verifyUserValidity(account, password)等。\n子系统/构件设计 (1) 子系统设计\n需要确定子系统内部结构，设置包含于其中的更小粒度子系统、构件和设计类，明确它们之间的协作关系，确保它们能够协同实现子系统接口规定的所有功能和行为。在这一步中，需要完成的操作有：\n细化子系统内部的细节，如设计元素、关联和交互 对子系统内部的结构进行建模 对子系统内部各个设计元素之间的协作进行建模 最后需要产出子系统的包图、构件图、顺序图、活动图、类图。\n1. 精化子系统内部设计元素\n需要输出一组描述子系统内部设计元素交互的UML顺序图，例如RobotController”子系统实现“自主跟随老人”功能和职责的顺序图：\n2. 构造子系统的设计类图\n需要输出基于子系统设计的UML交互图，其详细描述了子系统功能和职责的实现方式。另外，要推导出子系统的设计类图，在该设计类图中，显式区分子系统内部的设计元素与位于子系统之外、为子系统提供服务的其他设计元素。例如，“RobotController”子系统的类图：\n3. 构造子系统的状态图和活动图\n如果子系统或其内部设计元素具有明显状态特征，那么绘制和分析其UML状态图。构造子系统及其设计元素的活动图来理解和分析子系统是如何实现的。\n(2) 构件设计\n需要定义构件内部的设计元素及其协作方法，内部设计元素可以是子构件，也可以是粒度更细的类。在这一步中，需要完成的操作有：\n细化构件的内部细节，如子构件、类等 对构件内部的结构进行建模 对构件内部各个设计元素之间的协作进行建模 最后需要输出构件图、类图、顺序图、活动图等。\n若干面向对象的设计模式 设计模式概述 (1) 软件模式的层次分类\n类别 描述 体系结构模式 (Architecture Styles) - 是系统的高层次策略，涉及到大尺度的组件以及整体性质\n- 可作为具体软件体系结构的模板，是开发一个软件系统时的基本设计决策\n- 规定了系统范围结构特性，架构模式的好坏影响到总体布局和框架性结构 设计模式 (Design Patterns) - 是中等尺度的结构策略。实现了一些大尺度组件的行为和它们之间的关系\n- 设计模式定义出子系统或组件的微观结构\n- 模式的好坏不会影响到系统的总体布局和总体框架\n代码模式 (Idioms) - 是特定的范例和与特定语言有关的编程技巧\n- 处理特定设计问题的实现，关注设计和实现方面\n- 模式的好坏会影响中等尺度组件的内部、外部的结构或行为的底层细节 (2) 模式\n设计模式是关于特定场景下解决一般设计问题的类和相互通信的对象的描述，展示了对典型性问题的普遍、独立于领域的解决方案。作为软件模式的一种，设计模式专注于软件开发中的设计层面，而软件模式则涵盖了更广泛的范畴，包括架构模式、分析模式和过程模式等，实际上在软件生存期的每一个阶段都存在一些被认同的模式。软件模式可以视为对软件开发这一特定“问题”的“解法”的统一表示，即在一定条件下出现的问题及其相应的解决方案。\n设计模式通常包含几个基本要素：\n模式名称：概括描述了模式的问题、解决方案和效果 问题：解释何时使用模式及设计问题的背景 解决方案：详细描述设计的组成部分、它们之间的关系及职责 效果：评估模式应用的结果及需权衡的因素 设计模式提供了一个标准的术语系统，且具体到特定的情景。例如，单例设计模式意味着使用单个对象，这样所有熟悉单例设计模式的开发人员都能使用单个对象，并且可以通过这种方式告诉对方，程序使用的是单例模式。设计模式已经经历了很长一段时间的发展，它们提供了软件开发过程中面临的一般问题的最佳解决方案。学习这些模式有助于经验不足的开发人员通过一种简单快捷的方式来学习软件设计。\n根据设计模式的目的和范围（即模式主要是用于处理类之间关系还是处理对象之间的关系），有以下分类：\n范围 目的 创建型 结构型 行为型 类 Factory Method Adapter (类) Interpreter\nTemplate Method 对象 Abstract Factory\nBuilder\nPrototype\nSingleton Adapter (对象)\nBridge\nFilter、Criteria Pattern\nComposite\nDecorator\nFaçade外观\nFlyweight享元\nProxy Chain of Responsibility\nCommand\nIterator\nMediator中介者\nMemento\nObserver\nState\nStrategy\nVisitor 创建型模式 创建型模式关注对象的创建，抽象和封装了对象的实例化过程，分离了对象创建和对象使用，作为客户程序仅仅需要去使用对象，而不再关心创建对象过程中的逻辑。帮助系统独立于创建、组合和表示它的那些对象。创建型模式有两个重要的特点：\n客户不知道对象的具体类是什么（除非看源代码）； 隐藏了对象实例是如何被创建和组织的。 当想要使用new运算符的时候，就可以考虑创建型模式。创建型类模式使用继承机制改变被实例化的类，创建型对象模式则将实例化工作委托给另一个对象来完成。常见的创建型模式有Factory Method ，Abstract Factory，Builder，Prototype，Singleton。\n(1) 工厂方法（Factory Method）\n1. 基本概念\n在工厂方法模式中，工厂父类负责定义创建产品对象的公共接口，而工厂子类则负责生成具体的产品对象，这样做的目的是将产品类的实例化操作延迟到工厂子类中完成，即通过工厂子类来确定究竟应该实例化哪一个具体产品类。\n2. 示例1\n假设正在开发一款物流管理应用。最初版本只能处理卡⻋运输， 因此大部分代码都在位于名为卡车的类中。一段时间后， 这款应用变得极受欢迎。每天都能收到十几次来自海运公司的请求，希望应用能够支持海上物流功能。这可是个好消息。 但是代码问题该如何处理呢？目前， 大部分代码都与卡车类相关。在程序中添加轮船类需要修改全部代码。更糟糕的是，如果以后需要在程序中支持另外一种运输方式，很可能需要再次对这些代码进行大幅修改。最后， 将不得不编写繁复的代码，根据不同的运输对象类， 在应用中进行不同的处理。\n工厂方法模式建议使用特殊的工厂方法代替对于对象构造函数的直接调用 （即使用 new运算符）。不用担心，对象仍将通过 new运算符创建， 只是该运算符改在工厂方法中调用罢了。工厂方法返回的对象通常被称作“产品”。乍看之下， 这种更改可能毫无意义： 只是改变了程序中调用构造函数的位置而已。 但是，仔细想一下， 现在 可以在子类中重写工厂方法， 从而改变其创建产品的类型。有一点需要注意：仅当这些产品具有共同的基类或者接口时， 子类才能返回不同类型的产品，同时基类中的工厂方法还应将其返回类型声明为这一共有接口。\n举例来说， 卡车Truck和 轮船Ship类都必须实现 运输Transport接口， 该接口声明了一个名为 deliver交付的方法。 每个类都将以不同的方式实现该方法： 卡⻋⾛陆路交付货物， 轮船走海路交付货物。 陆路运RoadLogistics类中的工厂方法返回卡⻋对象， 而 海路运输Sea-Logistics类则返回轮船对象。\n3. 示例2\n考虑这样一个系统，一个按钮工厂类可以返回一个具体的按钮实例，如圆形按钮、矩形按钮、菱形按钮等。在这个系统中，如果需要增加一种新类型的按钮，如椭圆形按钮，那么除了增加一个新的具体产品类之外，还需要修改工厂类的代码，这就使得整个设计在一定程度上违反了“开闭原则”。\n现在对该系统进行修改，不再设计一个按钮工厂类来统一负责所有产品的创建，而是将具体按钮的创建过程交给专门的工厂子类去完成，通过先定义一个抽象的按钮工厂类，再定义具体的工厂类来生成圆形按钮、矩形按钮、菱形按钮等，它们实现在抽象按钮工厂类中定义的方法。这种抽象化的结果使这种结构可以在不修改具体工厂类的情况下引进新的产品，如果出现新的按钮类型，只需要为这种新类型的按钮创建一个具体的工厂类就可以获得该新按钮的实例，更加符合“开闭原则”。\n(2) 建造者模式（Builder）\n1. 基本概念\n一种创建型设计模式， 使 能够分步骤创建复杂对象。 该模式允许使用相同的创建代码生成不同类型和形式的对象。假设有这样一个复杂对象， 在对其进行构造时需要对诸多成员变量和嵌套对象进行繁复的初始化工作。 这些初始化代码通常深藏于一个包含众多参数且让人基本看不懂的构造函数中； 甚至还有更糟糕的情况， 那就是这些代码散落在客户端代码的多个位置。\nBuilder：抽象建造者为创建一个产品对象的各个部件指定抽象接口 ConcreteBuilder：具体建造者实现了抽象建造者接口，实现各个部件的构造和装配方法，定义并明确它所创建的复杂对象，也可以提供一个方法返回创建好的复杂产品对象 Director：指挥者负责安排复杂对象的建造次序，指挥者与抽象建造者之间存在关联关系，可以在其construct方法中调用建造者对象的部件构造与装配方法，完成复杂对象的建造 Product：产品角色是被构建的复杂对象，包含多个组成部件。 2. 示例 如何创建一个房屋House对象？ 建造一栋简单的房屋， 首先 需要建造四面墙和地板， 安装房⻔和一套窗户， 然后再建造一个屋顶。 但是如果 想要一栋更宽敞更明亮的房屋， 还要有院子和其他设施 （例如暖气、 排水和供电设备）， 那又该怎么办呢？\n最简单的方法是扩展 房屋基类， 然后创建一系列涵盖所有参数组合的子类。但最终将面对相当数量的子类。 任何新增的参数 （例如⻔廊类型） 都会让这个层次结构更加复杂。\n另一种方法则无需生成子类。 可以在 房屋基类中创建一个包括所有可能参数的超级构造函数， 并用它来控制房屋对象。 这种方法确实可以避免生成子类， 但它却会造成另外一个问题。通常情况下， 绝大部分的参数都没有使用，这使得对于构造函数的调用十分不简洁。例如， 只有很少的房子有游泳池， 因此与游泳池相关的参数十之八九是毫无用处的。\n构建者式建议将对象构造代码从产品类中抽取出来， 并将其放在一个名为构建者的独立对象中。该模式会将对象构造过程划分为一组步骤， ⽐如 buildWalls()创建墙壁和buildDoor()创建房⻔创建房⻔等。 每次创建对象时， 都需要通过建造者对象执行一系列步骤。 重点在于 无需调用所有步骤， 而只需调用创建特定对象配置所需的那些步骤即可。\n主管Director进一步将用于创建产品的一系列建造者步骤调用抽取成为单独的主管类。 主管类可定义创建步骤的执行顺序， 而建造者则提供这些步骤的实现。严格来说， 程序中并不一定需要主管类。 客户端代码可直接以特定顺序调用创建步骤。 不过， 主管类中非常适合放入各种例行构造流程，以便在程序中反复使用。 此外， 对于客户端代码来说， 主管类完全隐藏了产品构造细节。 客户端只需要将一个建造者与主管类关联， 然后使用主管类来构造产品，就能从建造者处获得构造结果了。\n结构模式 涉及到如何组合类和对象以获得更大结构的系统 ，就像搭积⽊，可以通过简单积⽊的组合形成复杂的、功能更为强大的结构。保证不会因应用系统的变化而要修改对象间的连接。结构型类模式采用继承机制来组合接口或实现，如可采用多重继承方法将两个以上的类组合成一个类，该类包含了所有父类的性质。这一模式有助于多个独立开发的类库协同工作。\n结构型对象模式描述如何对一些对象进行组合，从而实现新功能的一些方法。由于可在运行时刻改变对象组合关系，所以对象组合方式具有更大的灵活性，而这种机制用静态类组合是不可能实现的。常见的结构型模式：Adapter（适配器）, Bridge（桥接），Composite（组合），Proxy（代理），Decorator（装饰），Façade（外观），Flyweight（享元）\n(1) 适配器模式（类）\n1. 基本概念\n适配器模式是一种结构型设计模式， 它能使接口不兼容的对象能够相互合作。\n2. 示例\n假如 正在开发一款股票市场监测程序， 它会从不同来源下载 XML 格式的股票数据， 然后向用户呈现出美观的图表。在开发过程中， 决定在程序中整合一个第三方智能分析函数库。 但是遇到了一个问题， 那就是分析函数库只兼容 JSON 格式的数据。可以修改程序库来支持 XML。 但是，这可能需要修改部分依赖该程序库的现有代码。 甚至还有更糟糕的情况， 可能根本没有程序库的源代码， 从而无法对其进行修改。\n解决方案：可以创建一个适配器。 这是一个特殊的对象， 能够转换对象接口， 使其能与其他对象进行交互。\n适配器模式通过封装对象将复杂的转换过程隐藏于幕后。 被封装的对象甚至察觉不到适配器的存在。 例如， 可以使用一个将所有数据转换为英制单位 （如英尺和英里） 的适配器封装运行于米和千米单位制中的对象。适配器不仅可以转换不同格式的数据， 其还有助于采用不同接口的对象之间的合作。 它的运作方式如下：\n适配器实现与其中一个现有对象兼容的接口。 现有对象可以使用该接口安全地调用适配器方法。 适配器方法被调用后将以另一个对象兼容的格式和顺序将请求传递给该对象。 有时 甚至可以创建一个双向适配器来实现双向转换调用。回到股票市场程序。 为了解决数据格式不兼容的问题， 可以为分析函数库中的每个类创建将 XML 转换为 JSON 格式的适配器， 然后让客户端仅通过这些适配器来与函数库进行交流。 当某个适配器被调用时，它会将传入的 XML 数据转换为 JSON 结构， 并将其传递给被封装分析对象的相应方法。\n对于类适配器，通过使用一个具体的Adapter类对Adaptee和Target进行匹配；可以使用多重继承对一个接口与另一个接口进行匹配。\n(2) 装饰模式(Decorator)\n装饰模式是一种结构型设计模式， 允许 通过将对象放入包含行为的特殊封装对象中来为原对象绑定新的行为。\n行为模式 行为型模式涉及到算法和对象间职责的分配。行为模式不仅描述对象或类的模式，还描述它们之间的通信模式（相互作用）。这些模式刻划了在运行时难以跟踪的复杂的控制流，使得设计者可以将注意力集中在对象间的联系方式，而不是控制流。通过行为型模式，可以更加清晰地划分类与对象的职责，并研究系统在运行时实例对象之间的交互。在系统运行时，对象并不是孤立的，它们可以通过相互通信与协作完成某些复杂功能，一个对象在运行时也将影响到其他对象的运行。\n常见的行为型模式：Chain of Responsibility（职责链），Mediator（中介）， Command（命令） ，Iterator （迭代器），Memento（备忘录） ，Observer（观察者），State（状态） ，Strategy（策略） ，Visitor（访问者），Interpret（解释器），Template（模板）\n(1) Strategy模式\n策略模式是一种行为设计模式， 它能让 定义一系列算法， 并将每种算法分别放入独立的类中， 以使算法的对象能够相互替换。\n(2) Observer模式\n观察者模式是一种行为设计模式， 允许 定义一种订阅机制， 可在对象事件发生时通知多个 “观察” 该对象的其他对象。\n软件实现基础和编码 软件实现基础 (1) 软件实现的过程\n(2) 软件实现与软件设计之间的关系\n基于软件设计来开展软件实现：照软件设计模型和文档来进行编码\n根据实现中发现的问题来纠正和完善软件设计：\n设计不够详细，程序员需要进行进一步的软件设计和程序设计，才能编写出程序代码 设计考虑不周全，软件设计时没有认真考虑编码实现的具体情况（如程序设计语言和目标运行环境的选择），导致有些软件设计不能通过程序设计语言加以实现 代码编写 (1) 编写代码的任务\n根据软件设计信息，借助于程序设计语言，编写出目标软件系统的源程序代码，开展程序单元测试、代码审查等质量保证工作\n(2) 编写类代码\n编写实现类的代码：**设计模型（如设计类图）**详细描述了软件系统中类的详细设计信息，包括可见性、类名、属性、方法等等。程序员需要将这些设计信息直接转换为用程序设计语言表示的实现结构和代码。 编写实现类方法的代码：基于类方法的设计描述（UML的活动图表示），程序员可以依此为依据来编写类方法的实现代码。 编写实现类间关联的代码：将类间关联关系的语义信息具体落实到相应类的程序代码中，即综合考虑关联关系的方向性、多重性、角色名和约束特性等信息来编写相关的类程序代码。 编写实现设计类间聚合和组合关系的代码：可以采用类似于实现关联关系的方法来编写实现聚合和组合关系的代码，根据多重性来设计相应类属性的数据结构。 编写实现接口关系的代码：类设计模型可能包含有表征类与接口之间实现关系的语义信息。诸多面向对象程序设计语言（如Java、C++等）提供了专门针对接口实现的语言机制，因而可以直接将接口设计信息转换为相应的程序代码。 编写实现继承关系的程序代码：面向对象程序设计语言（如Java、C++）提供了继承机制以及相应的语言设施。将设计模型中的类间继承关系用程序设计语言提供的语言机制来表示。 编写实现包的代码：用包（package）来组织和管理软件系统中的类。包是对软件系统中模块的逻辑划分，也可以将包视为是一种子系统。面向对象程序设计语言（如Java）提供了对包进行编程的语言机制，每个包对应于代码目录结构中的某个目录。 (2) 编写用户界面代码\n(3) 编写数据设计代码\n数据设计，定义了软件系统中需要持久保存数据及其组织（如数据库的表、字段）和存储（如数据库中的记录）方式设计了相应的类及其方法来读取、保存、更新和查询持久数据。\n编码实现：\n创建相应的数据库关系表格及其内部的各个字段选项等，确保它们满足设计的要求和约束 编写相应的程序代码来操作数据库，如增加、删除、更改、查询数据记录等 软件缺陷和调试 (1) 何为软件缺陷\n软件缺陷是指软件制品中存在不正确的软件描述和实现。存在缺陷的软件制品不仅包括程序代码，而且还包括需求和设计的模型和文档。软件缺陷产生于软件开发全过程，只有有人介入的地方就有可能产生软件缺陷。任何人都有可能在软件开发过程中犯错误，进而引入软件缺陷。无论是高层的需求分析和软件架构缺陷还是底层的详细设计缺陷，它们最终都会反映在程序代码之中，导致程序代码存在缺陷。\n(2) 软件缺陷的描述\n(3) 软件缺陷的应对方法\n1. 预防缺陷 通过运用各种软件工程技术、方法和管理手段，在软件开发过程中预防和避免软件缺陷，减少软件缺陷的数量，降低软件缺陷的严重程度。采用结对编程、严格的过程管理、必要的技术培训、CASE工具的使用等手段，起到预防缺陷的目的。\n2. 容忍缺陷 增强软件的缺陷容忍度，借助于软件容错机制和技术，允许软件出现错误，但是在出现错误时软件仍然能够正常的运行。在高可靠软件系统的开发过程中，软件工程师通常需要提供容错模块和代码。显然这会增加软件开发的复杂度和冗余度。\n3. 发现缺陷 通过有效的技术和管理手段来发现这些软件缺陷。例如，制定和实施软件质量保证计划、开展软件文档和模型的评 审、程序代码的走查、软件测试等工作。它们都可以帮助软件工程师找到潜藏在文档、模型和代码中的软件缺陷\n4. 修复缺陷 通过一系列的手段来修复缺陷。采用程序调试等手段来找到缺陷的原因、定位缺陷的位置，进而修改存在缺陷的程序代码，将软件缺陷从软件制品中移除出去。\n软件测试（精简版） 基本概念 (1) 任务\n软件测试是运行软件或模拟软件的执行，发现软件缺陷的过程。需要注意，软件测试通过运行程序代码的方式来发现程序代码中潜藏的缺陷，这和代码走查、静态分析形成鲜明对比。另外软件测试的目的是为了发现软件中的缺陷。它只负责发现缺陷，不负责修复和纠正缺陷。\n(2) 测试用例\n软件测试需要合适的测试用例，测试用例包含4个元素：\n输入数据：交由待测试程序代码进行处理的数据 前置条件：程序处理输入数据的运行上下文，即要满足前置条件 测试步骤：程序代码对输入数据的处理可能涉及到一系列的步骤，其中的某些步骤需要用户的进一步输入 预期输出：程序代码的预期输出结果 例如，“用户登录”模块单元的测试用例设计：\n输入数据：用户账号=“admin”，用户密码=“1234” 前置条件：用户账号“admin”是一个尚未注册的非法账号，也即“T_User”表中没有名为“admin”的用户账号。 测试步骤：首先清除“T_User”表中名为“admin”的用户账号；其次用户输入“admin”账号和“1234”密码；第三，用户点击界面的确认按钮；最后，系统提示“用户无法登录系统”的信息 预期输出：系统将提示“用户无法登录系统”的提示信息 (3) 活动及流程\n测试类型 测试对象 测试技术 测试内容 设计阶段及依据 单元测试 - 软件基本模块单元\n- 过程、函数、方法、类 大多采用白盒测试技术 - 模块接口测试\n- 模块局部数据结构测试\n- 模块独立执行路径测试\n- 模块错误处理通道测试\n- 模块边界条件测试 详细设计阶段可以设计单元测试用例及计划 集成测试 - 软件模块之间的接口\n- 过程调用、函数调用、消息传递、远程过程调用 采用黑盒测试技术 - 过程调用\n- 函数调用\n- 消息传递\n- 远程过程调用\n- 网络消息 概要设计阶段可以设计集成测试用例及计划 确认测试 - 软件的功能和性能\n- 判断目标软件系统是否满足用户需求 采用黑盒测试技术 - 根据软件需求规格说明书进行测试 需求分析阶段可以设计确认测试用例及计划 (4) 后续工作\n修改程序可能会引入新的错误，原先“正常”的程序现在变得“不正常”，为此引入回归测试。回归测试目的是验证软件新版本是否从正常状态回归/退化到不正常状态。在回归测试中，再次运行所有的测试用例来发现缺陷，单元测试是回归测试的基础。调试技术包括蛮干法/ 测试、回溯法、归纳法、排除法。\n软件测试需要输出：\n软件测试计划 软件测试报告，记录软件测试情况以及发现的缺陷 软件单元测试报告 软件集成测试报告 软件确认测试报告 系统测试报告等 每个报告详细 软件测试技术 测试用例设计 可以根据以下两种思路来进行测试用例的设计：\n穷举设计：\n选择测试：\n白盒测试 (1) 基本概念\n白盒测试需要根据程序单元内部工作流程来设计测试用例。其目的是发现程序单元缺陷，即运行待测试的程序，检验程序是否按内部工作流程来运行的，如果不是则存在缺陷。因此必须了解程序的内部工作流程才能设计测试用例。\n(2) 测试用例设计\n1. 语句覆盖法\n使得程序中的每一个语句至少被遍历一次，例如可以设计用例：$A=2,B=0,X=3$。\n2. 判定覆盖法（分支）\n使得程序中每一个分支至少被遍历一次。例如对于路径ace，设置$A=3,B=0,X=1$；对于路径abd，设置$A=1,B=0,X=0$。\n3. 条件覆盖\n使得每个判定的条件获取各种可能的结果。\n在a点，$A\u0026gt;1, A\\leq1,B=0,B\\neq0$，在b点，$A=2, A\\neq2, X\u0026gt;1, X\\leq1$。例如对于路径ace，设置$A=2,B=0,X=4$；对于路径abd，设置$A=1,B=1,X=1$。\n4. 判定/条件覆盖\n使得判定中的条件取得各种可能的值，并使得每个判定取得各种可能的结果。例如对于路径ace，设置$A=2,B=0,X=4$；对于路径abd，设置$A=1,B=1,X=1$。\n5. 条件组合覆盖\n使得每个判定条件的各种可能组合都至少出现一次，例如，要求\n$ A \u0026gt; 1 , B = 0 $ $ A \u0026gt; 1 , B \\neq 0 $ $ A \\leq 1 , B = 0 $ $ A \\leq 1 , B \\neq 0 $ $ A = 2 , X \u0026gt; 1 $ $ A = 2 , X \\leq 1 $ $ A \\neq 2 , X \u0026gt; 1 $ $ A \\neq 2 , X \\leq 1 $ 则有测试用例\n$ A = 2 , B = 0 , X = 4 $ $ A = 2 , B = 1 , X = 1 $ $ A = 1 , B = 0 , X = 2 $ $ A = 1 , B = 1 , X = 1 $ 6. 路径覆盖\n覆盖程序中所有可能的路径：\nA B X 覆盖路径 2 0 3 a c e 1 0 1 a b d 2 1 1 a b e 3 0 1 a c d 黑盒测试 (1) 基本概念\n黑盒测试需要根据已知的程序功能和性能，不必了解程序内部结构和处理细节，设计测试用例并通过测试检验程序的每个功能和性能是否正常。\n(2) 测试用例设计\n1. 等价类划分法\n该方法把程序的输入数据集合按输入条件划分为若干个等价类，每一个等价类对于输入条件而言为一组有效或无效的输入，为每一个等价类设计一个测试用例。这样可以减少测试次数，同时不丢失发现错误的机会。每个等价类中的数据具有相同的测试特征。该方法遵循着以下的基本原则：\n输入条件为一范围，划分出三个等价类：(1) 有效等价类(在范围内)，(2) 大于输入最大值，(3)小于输入最少值 输入条件为一值，划分为三个等价类：(1) 有效，(2) 大于，(3) 小于 输入条件为集合，划分两个等价类：(1) 有效(在集合内)，(2) 无效(在集合外) 输入条件为一个布尔量，划分两个等价类：(1) 有效(此布尔量)，(2)无效(布尔量的非) 例如对于函数 func(x, y)：\n当 $0 \u0026lt; x \u0026lt; 1024$ 且 $y = 0$ 时，$z = -1$ 否则，$z = x \\cdot \\lg(y)$ 关于 $x$ 的等价类\n$(0, 1024)$ $(-∞, 0]$ $[1024, +∞)$ 关于 $y$ 的等价类\n${0}$ $(-∞, 0)$ $(0, +∞)$ 有测试用例\n$X = 1, y = 0, z = -1$ $X = 1, y = -1, z =**$ $X = 1, y = 1, z = **$ $X = 0, y = 1, z = **$ $X = 0, y = -1, z = **$ $X = 0, y = 1, z = **$ $X = 2000, y = 0, z = **$ $X = 2000, y = -100, z = **$ $X = 2000, y = 200, z = **$ 2. 边界值分析法\n该方法遵循着以下的基本原则：\n若输入条件是一范围(a,b)，则使用a,b以及紧挨a,b左右的值应作为测试用例 输入条件为一组数，选择这组数最大者和最小者，次大和次小者作为测试用例 如果程序的内部数据结构是有界的，应设计测试用例使它能够检查该数据结构的边界 关于 $x$ 的等价类有6个\n-1, 0, 1 1023, 1024, 1025 关于 $y$ 的等价类有3个：-1, 0, 1\n有测试用例：\n$X = 1, y = 0, z = -1$ $X = 1, y = -1, z =**$ $X = 1, y = 1, z = **$ $X = 0, y = 0, z = **$ $X = 0, y = -1, z = **$ $X = 0, y = 1, z = **$ $X = -1, y = 0, z = **$ $X = -1, y = -1, z = **$ $X = -1, y = 1, z = **$ 等等。\n3. 正交数组测试\n当输入参数的数量不多，且每个参数可取的值有明确的界定时使用。例如传真应用系统的send函数参数：P1, P2, P3, P4. 每个参数有3个不同值。如：\nP1 = 1：现在发送 P1 =2：1H后发送 P1=3：半夜12点后发送 P2,P3,P4也分别取1,2,3值。该方法的局限是，这些测试参数不相交。检测一个参数值使得软件出故障的逻辑错误（单模式错误），不能查出相互影响。\n评审技术 (1) 基本概念\n评审是由技术人员对技术人员进行，在软件工程过程中产生的对工作产品的技术评估、软件质量保证机制、训练场地。\n(2) 非正式评审\n非正式评审包括：与同事就软件工程产品进行的简单桌面检查、以评审一个工作产品为目的的临时会议（涉及两个以上）、结对编程评审。结对编程中有两名角色：\nDriver：控制键盘输入，负责实际的代码编写。根据Navigator的指导，实现具体的编程任务，并确保代码的质量和可读性。 Navigator：起到领航、提醒和指导的作用。观察Driver的编码过程，提供即时反馈，帮助Driver避免错误，提出改进建议，确保代码符合设计规范和最佳实践。 在结对编程过程中，Navigator会持续审查Driver编写的代码，确保每一行代码都经过仔细检查。这种即时的复审有助于及时发现问题，减少后期调试的时间和成本。而随着大模型（如Codex、CS50等）的出现，结对编程得到了新的助力。这些大模型可以自动生成代码片段、提供建议、解释复杂的编程概念，甚至帮助解决编程难题。\n(3) 正时技术评审FTR\nFTR实际上是一类评审方式，包括评审会议、走查walkthrough、审查inspection 和轮查Round-robin/pass-round Review。其目标是：\n发现软件的任何一种表示形式中的功能、逻辑或实现上的错误 验证评审中的软件是否满足其需求 保证软件的表现符合预先指定的标准 获得以统一的方式开发的软件 使项目更易于管理 关于评审会议，需要注意，评审会（通常）由3~5人参加（如评审主席、倡导者、生产者、用户代表）。与会人应该提前进行准备，但是占用每人的工作时间应该不超过2小时，且评审会的时间应该少于2小时。FTR关注的是某个工作产品（例如，一部分需求模型、一份详细的构件设计、一个构件的源代码）。\n软件质量保证SQA SQA是贯穿软件过程中每一步的普适性活动。包括，对方法和工具有效应用的规程，对诸如技术评审和软件测试等质量控制活动的监督，变更管理规程，保证符合标准的构成，以及测量和报告机制。统计SQA，负责收集、评估和发布有关软件工程过程的数据，有助于提高产品和软件过程本身的质量。可靠性模型将测量加以扩展，能够收集相关数据推导出失效率和进行可靠性预测。 质量保证的能力标志着工程的程度。\n软件维护与演化 何为软件维护 软件维护是指，在软件在交付使用后，由于应用需求和环境变化以及自身问题，对软件系统进行改造和调整的过程。软件需要通过维护来应对下面几种情况：\n出故障，不可正常工作。潜在的缺陷产生软件错误，需要对这些缺陷进行纠正。 服务变化，需要升级。例如软件需求发生了变化，需要增强软件的功能和服务。 运行环境变化，需要适应，需要改变软件以在新的环境中运行。 软件维护的形式 (1) 纠正性维护\n用户在使用软件过程中一旦发现缺陷，他们会向开发人员提出纠正性维护的请求。纠正性维护需要诊断和改正软件系统中潜藏的缺陷。\n(2) 适应性维护\n软件运行于一定的环境(硬件、OS、网络等)之上，运行环境发展很快，出现了变化。因此需要进行适应性维护以便适应新的运行环境和平台。\n(3) 改善性维护\n在软件系统运行期间，用户可能要求增加新的功能、建议修改已有功能或提出其他改进意见。为了满足用户日益增长的各种需求，需要对软件进行改善性维护，增加新的功能、修改已有的功能。\n(4) 预防性维护\n为进一步改善软件系统的可维护性和可靠性，为以后的软件改进奠定基础的维护活动。需要获取软件结构，重新改善软件结构以便提高软件的可靠性和可维护性等。\n软件逻辑老化 软件在维护和演化的过程中出现的用户满意度降低、质量逐渐下降、变更成本不断上升等现象。这些现象发生在逻辑层面，而非发生在物理层面。\n软件维护的过程与技术 代码重组 在不改变软件功能的前提下，对程序代码进行重新组织，使得重组后的代码具有更好的可维护性，能够有效支持对代码的变更。\n逆向工程 基于低抽象层次软件制品，通过对其进行理解和分析，产生高抽象层次的软件制品\n通过对程序代码进行逆向的分析，产生与代码相一致的设计模型和文档 基于对程序代码和设计模型的理解，逆向分析出软件系统的需求模型和文档 典型应用场景：分析已有程序，寻求比源代码更高层次的抽象形式（如设计甚至需求）\n设计重构 如果一个软件的设计文档缺失，软件文档与程序代码不一致、或者软件设计的内容不详实，那么软件维护工程师可以采用设计重构的手段来获得软件设计方面的文档信息。通过读入程序代码，理解和和分析代码中的变量使用、模块内部的封装、模块之间的调用或消息传递、程序的控制路径等方面的信息，产生用自然语言或图形化信息所描述的软件设计文档。设计重构是逆向工程的一种具体表现形式。\n再工程 通过分析和变更软件的架构，实现更高质量的软件系统的过程。再工程既包括逆向工程也包括正向工程。\n逆向工程、重组、重构和再工程示意图\n软件维护成本 软件维护工作量$M = P + K * e^{(c-d)}$，P为生产性工作量，K为经验常数，C为复杂度(设计好坏和文档完整程度)，D为对欲维护软件的熟悉程度。维护成本不断增加：70年代 ：35％－40％；80年代 ：60％；90年代 ：75%；如今：数据更高，80%。软件维护工作量涉及二方面：\n助动性：用于理解代码功能，结构特征以及性能约束 生产性：用于分析和评价、修改设计和代码 模型表明，如果没有好的软件开发方法或者软件开发人员不能参与维护，那么软件维护工作量会指数上升。\n软件项目管理 软件项目团队的运行模式 模式 描述 一窝蜂模式 - 无组织，一窝蜂，无序和随意\n- 典型例子是小孩子游戏 主治医生模式 - 主治医生主刀，其他人员协助\n- 容易产生一人干活，其余打酱油 社区模式 - 志愿者因为兴趣参加，没有报酬，众人拾柴火焰高\n- 只烤火不拾柴，柴火质量低 功能团队模式 - 具备不同能力的同事平等协作，共同完成功能\n- 一个功能完成之后，这些人又重组织，完成其他功能\n- 人员之间没有管理关系，小组内部交流频繁 官僚模式 - 大领导\u0026ndash;》小领导\u0026ndash;》员工\n- 存在明显的领导和管理关系\n- 跨组织合作变得困难 ","permalink":"https://fireflyyh.top/posts/campus/se20204fall/","summary":"软件概述 基本定义 (1) 程序与软件的定义\n程序是由程序设计语言所描述的、能为计算机所理解和处理的一组语句序列。其用程序设计语言（Programming Language）来描述的。程序严格遵循程序设计语言的各项语法和语义规定，应确保程序代码能为程序设计语言的编译器所理解，进而编译生成相应的可运行代码。\n软件是指在计算机系统的支持下，能够完成特定功能与性能的程序、数据和相关文档。文档是记录软件开发活动和阶段性成果、软件配置及变更的阐述性资料。\n(2) 软件的性质\n复杂性 一致性：软件不能独立存在，需要依附于一定的环境（硬件网络等），软件必须遵从人为的惯例并适应已有的技术和系统，软件需要随接口不同而改变，随时间推移而变化，而这些变化是不同人设计的结果 可变性：人们总认为软件是容易修改的，但忽视了修改带来的副作用，不断的修改最终导致软件的退化，从而结束其生命周期 不可见性：软件是一种看不见、摸不着的逻辑实体，不具有空间的形体特征，开发人员可以直接看到程序代码，但源代码并不是软件本身，软件以机器代码的形式运行，开发人员无法看到源代码如何执行的。 (3) 软件的分类\n类别 服务对象 软件的功能 发挥的作用 应用软件 行业和领域应用的用户 为特定行业和领域问题解决提供基于软件解决方案，创新应用领域的问题解决模式 提供更为便捷、快速、高效的服务 系统软件 各类应用软件 为应用软件运行和维护提供基础设施和服务，如加载、通讯、互操作、管理等 作为应用软件的运行环境 支撑软件 软件开发者和维护者 为软件系统的开发和维护提供自动和半自动的支持 提高软件开发效率和质量 (4) 开源许可证\n软件工程概述 (1) 软件开发需要解决的问题\n开发过程：基于什么样的步骤来开发软件系统 开发方法：采用怎样的方法来指导各项软件开发活动 开发管理：如何组织开发人员和管理软件产品 质量保证：如何保证软件开发活动和制品的质量 (2) 软件开发的特殊性\n软件开发技术更新速度快、软件开发需求变更频繁、软件开发复杂度高、软件开发需要团队协作完成、软件开发成果需要长期维护、软件开发保证软件质量、软件开发需要评估和控制风险\n(3) 软件工程的定义\n软件工程是一门研究如何用系统化、规范化、可量化等工程原则和方法进行软件开发和维护的学科。系统化：提供完整和全面的解决方法，包括目标、原则、过程模型、开发活动、开发方法和技术等；规范化：支持各类软件系统的开发，包括语言标准、质量标准、编程标准、方法标准、能力极其改进标准等；可量化：工作量、成本、进度、质量等要素可以量化。 其目标是创造“足够好”的软件，对于好的软件的定义：低成本、高质量、按时交付 其内容包括市场调研、正式立项、需求分析、项目策划、概要设计、详细设计、编程、测试、试运行、产品发布、用户培训、产品复制、销售、实施、系统维护和版本升级等。 (4) 软件工程的三要素\n视角 描述 目的 过程 从管理的视角，回答软件开发、运行和维护需要开展哪些工作、按照什么样的步骤和次序来开展工作 对软件开发过程所涉及的人、制品、质量、成本、计划等进行有效和可量化的管理 方法学 从技术的视角，回答软件开发、运行和维护如何做的问题 为软件开发过程中的各项开发和维护活动提供系统性、规范性的技术支持 工具 从工具辅助的视角，主要回答如何借助工具来辅助软件开发、运行和维护的问题 帮助软件开发人员更为高效地运用软件开发方法学来完成软件开发过程中的各项工作，提高软件开发效率和质量，加快软件交付进度 计算机辅助软件工程 (1) 基本概念\n全称为Computer Aided Software Engineering（CASE）。起源于20世纪80年代，最初是指在信息管理系统开发过程中由各种计算机辅助软件和工具组成的软件开发环境。随着软件工程技术、工具和开发理念的不断发展，CASE逐步演进成为辅助软件工程全生命周期的开发工具和方法集合。CASE旨在帮助软件工程从业者们进行软件开发和维护，提高软件开发和运维效率，提升软件质量，为实现软件开发全生命周期的工程化、自动化和智能化提供基础支撑。\n(2) CASE工具分类","title":"高级软件工程复习笔记"},{"content":"原理 具体可以看翻译的论文。\n状态转换图 Raft的系统主要包含节点角色、领导者选举和日志复制。Raft算法基于复制状态机模型，将集群中的节点分为领导者（Leader）、追随者（Follower）和候选者（Candidate）三种角色。\n领导者：负责处理所有客户端请求，并将操作同步到其他节点，确保系统在出现故障时仍能保持一致性。\n追随者：响应领导者的请求并保存日志条目，通常处于被动状态。追随者向领导者发送心跳以维持领导地位。\n候选者：在选举过程中，节点可以变为候选者，尝试成为领导者。候选者通过请求投票来获得足够的支持。\n三种状态之间的转换如下：\n任务流程 在不发生特殊情况的前提下，该系统进行领导者选举、日志复制的时序图如下：\nsequenceDiagram participant Node1 as Node 1 (Follower) participant Node2 as Node 2 (Follower) participant Node3 as Node 3 (Follower) participant Node4 as Node 4 (Follower) participant Node5 as Node 5 (Follower) %% Node1 超时，转变为 Candidate 并发起选举 Note over Node1: 超时 Node1-\u0026gt;\u0026gt;Node1: 增加当前任期编号\u0026lt;br\u0026gt;转变为 Candidate Node1-\u0026gt;\u0026gt;Node2: RequestVote RPC (Term, CandidateId, LastLogIndex, LastLogTerm) Node1-\u0026gt;\u0026gt;Node3: RequestVote RPC (Term, CandidateId, LastLogIndex, LastLogTerm) Node1-\u0026gt;\u0026gt;Node4: RequestVote RPC (Term, CandidateId, LastLogIndex, LastLogTerm) Node1-\u0026gt;\u0026gt;Node5: RequestVote RPC (Term, CandidateId, LastLogIndex, LastLogTerm) %% 其他节点响应投票请求 Node2--\u0026gt;\u0026gt;Node1: VoteGranted (true) Node3--\u0026gt;\u0026gt;Node1: VoteGranted (true) Node4--\u0026gt;\u0026gt;Node1: VoteGranted (false) : 日志较新 Node5--\u0026gt;\u0026gt;Node1: VoteGranted (true) %% Node1 成为 Leader Note over Node1: 获得多数票 Node1-\u0026gt;\u0026gt;Node1: 转变为 Leader %% 持续发送心跳 loop 每个周期 Node1-\u0026gt;\u0026gt;Node2: Heartbeat(Term, LeaderID, PrevLogIndex, PrevLogTerm, nil, LeaderCommit) Node1-\u0026gt;\u0026gt;Node3: Heartbeat(Term, LeaderID, PrevLogIndex, PrevLogTerm, nil, LeaderCommit) Node1-\u0026gt;\u0026gt;Node4: Heartbeat(Term, LeaderID, PrevLogIndex, PrevLogTerm, nil, LeaderCommit) Node1-\u0026gt;\u0026gt;Node5: Heartbeat(Term, LeaderID, PrevLogIndex, PrevLogTerm, nil, LeaderCommit) Node2--\u0026gt;\u0026gt; Node1: Success(true) Node3--\u0026gt;\u0026gt; Node1: Success(true) Node4--\u0026gt;\u0026gt; Node1: Success(true) Node5--\u0026gt;\u0026gt; Node1: Success(true) end %% 更新日志 Node1-\u0026gt;\u0026gt;Node2: AppendEntries RPC(Term, LeaderID, PrevLogIndex, PrevLogTerm, LogEntries, LeaderCommit) Node1-\u0026gt;\u0026gt;Node3: AppendEntries RPC(Term, LeaderID, PrevLogIndex, PrevLogTerm, LogEntries, LeaderCommit) Node1-\u0026gt;\u0026gt;Node4: AppendEntries RPC(Term, LeaderID, PrevLogIndex, PrevLogTerm, LogEntries, LeaderCommit) Node1-\u0026gt;\u0026gt;Node5: AppendEntries RPC(Term, LeaderID, PrevLogIndex, PrevLogTerm, LogEntries, LeaderCommit) Node2--\u0026gt;\u0026gt; Node1: Success(true) Node3--\u0026gt;\u0026gt; Node1: Success(false)：日志不匹配 Node4--\u0026gt;\u0026gt; Node1: Success(true) Node5--\u0026gt;\u0026gt; Node1: Success(true) Note over Node1: 多数派复制成功 Node1-\u0026gt;\u0026gt;Node1: 提交日志 其主要可以分为两个部分：领导者选举和日志复制：\n领导者选举 Raft算法通过心跳机制和选举超时时间来触发领导选举，确保分布式系统中的一致性和高可用性：\n领导者定期向所有跟随者发送心跳信息（不携带任何日志条目的AppendEntries RPC），以维持其领导地位并阻止新的选举发生。 如果跟随者在设定的选举超时时间内没有收到领导者的心跳，它会认为当前没有有效的领导者，并转变为候选者状态。为了防止投票决裂，Raft使用了随机的选举超时时间，这样大多数情况下只有单个服务器会超时并赢得选举。一旦发生了决裂，。每个candidate在开始选举时重置其随机选举超时时间的计时器，且它会在下一次选举开始前等待该超时时间流逝，这减少了新的选举中再次发生投票决裂的可能性。 每个任期由单调递增的数字标识，候选者在发起选举时会增加自己的任期号，以确保选举的新鲜性和避免重复选举。候选者会向集群中的其他节点发送请求投票消息，寻求它们的支持。如果候选者在选举超时时间内获得了超过半数节点（法定人数）的投票，它将成为新的领导者。 日志复制 领导者接收客户端请求：当客户端向集群发送一个写操作请求时，领导者会将该请求作为一个新的日志条目追加到其本地日志中。\n领导者将新的日志条目追加到其本地日志中，并为其分配一个递增的索引值。 领导者通过并行地向所有跟随者发送AppendEntries RPC请求来复制日志条目。这些请求不仅包含日志条目本身，还包含前一个日志条目的索引和任期号，以确保一致性。跟随者在收到AppendEntries RPC请求后，会检查请求中的前一个日志条目的索引和任期号是否与自己的日志匹配。如果匹配，它会将新的日志条目追加到自己的日志中，并返回成功响应给领导者。如果不匹配，跟随者会拒绝该请求，并返回失败响应。 为了使追随者的日志和领导者自己的日志一致，领导者必须找到二者的日志中最新的一致的日志条目，删除追随者日志中该点后的所有条目，并将领导者日志中该点后的所有条目发送给追随者。领导者会为每个追随者维护一个nextIndex，它是领导者将发送给该追随者的下一条日志的index。当领导者首次掌权时，它会将所有的nextIndex值初始化为其日志的最后一个条目的下一个index。如果追随者的日志与领导者的不一致，下一次AppendEntries RPC中的一致性检验会失败。当RPC被拒绝后，领导者会减小该nextIndex并重试AppendEntries RPC。 最终，nextIndex会达到领导者和追随者的日志匹配的点。这时，AppendEntries会成功，它会删除追随者日志中任何冲突的条目，并将日志条目从领导者的日志中追加到追随者的日志中。如下图所示： 一旦领导者从大多数跟随者那里收到了对新日志条目的确认，它会将该日志条目标记为已提交，并将其应用到状态机中。然后，领导者会通知所有跟随者提交该日志条目。跟随者在收到提交通知后，会将相应的日志条目应用到它们的状态机中，从而确保整个集群的状态一致。 实验过程 准备 服务器状态 根据论文，对于服务器，相关的属性如下表：\nState 所有服务器上的持久性状态（在响应 RPC 之前更新稳定存储） currentTerm 服务器见过的最新任期（首次启动时初始化为 0，单调增加） votedFor 在当前任期内获得投票的候选者的ID（如果没有则为 null） log[] 日志条目；每个条目包含状态机命令以及领导者收到条目时的任期（第一个索引为 1） 所有服务器上的易失状态 commitIndex 已知已提交的最高日志条目的索引（初始化为 0，单调增加） lastApplied 应用于状态机的最高日志条目的索引（初始化为 0，单调增加） 领导者服务器上的易失状态（选举后重新初始化） nextIndex[] 对于每个服务器，发送到该服务器的下一个日志条目的索引（初始化为领导者最后一个日志索引 + 1） matchIndex[] 对于每个服务器，已知在服务器上复制的最高日志条目的索引（初始化为 0，单调增加） 具体体现在代码中：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 // A Go object implementing a single Raft peer. type Raft struct { mu sync.Mutex // Lock to protect shared access to this peer\u0026#39;s state peers []*labrpc.ClientEnd // RPC end points of all peers persister *Persister // Object to hold this peer\u0026#39;s persisted state me int // this peer\u0026#39;s index into peers[] dead int32 // set by Kill() applyCh chan ApplyMsg // 服务或测试人员希望Raft发送ApplyMsg消息的通道 applyCond *sync.Cond // 用于通知applyCh有新的日志条目需要应用 // 所有服务器上的持久性状态（在响应 RPC 之前更新稳定存储） currentTerm int // 服务器最后一次知道的任期号（初始化为 0，持续递增） votedFor int // 在当前任期内获得投票的候选者的ID（如果没有则为 null） log []LogEntry // 日志条目集；每个条目包含状态机命令以及领导者收到条目时的任期（第一个索引为 1） recvdIndex int // 已知收到的最后一个日志条目的索引，即为日志长度-1，（初始化为 0，单调增加） // 所有服务器上的易失性状态 commitIndex int // 已知已提交的最高日志条目的索引（初始化为 0，单调增加） lastApplied int // 应用于状态机的最高日志条目的索引（初始化为 0，单调增加） state int // 服务器的状态（跟随者、候选者、领导者） updateTime time.Time // 上次收到心跳的时间，或开始选举的时间 electionTimeout time.Duration // 选举超时时间 // 领导者服务器上的易失状态（选举后重新初始化） nextIndex []int // 对于每个服务器，发送到该服务器的下一个日志条目的索引（初始化为领导者最后一个日志索引 + 1） matchIndex []int // 对于每个服务器，已知在服务器上复制的最高日志条目的索引（初始化为 0，单调增加） heartBeatTime time.Duration // 心跳超时时间 } 在程序启动时，需要对节点变量进行初始化：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 func Make(peers []*labrpc.ClientEnd, me int, persister *Persister, applyCh chan ApplyMsg) *Raft { rf := \u0026amp;Raft{} rf.peers = peers rf.persister = persister rf.me = me // 初始化状态 rf.state = Follower // 心跳时间，因测试要求每秒不多于10次/秒 // 选举超时时间，大于论文中的300ms，且需要随机化 rf.heartBeatTime = 120 * time.Millisecond rf.electionTimeout = time.Duration(360+rand.Intn(360)) * time.Millisecond rf.updateTime = time.Now() rf.currentTerm = 0 // 任期号 rf.votedFor = -1 // 未投票 rf.log = make([]LogEntry, 1) // 索引从1开始 rf.log[0] = LogEntry{0, nil} // 第0个日志条目为空 rf.commitIndex = 0 // 已知已提交的最高日志条目的索引 rf.recvdIndex = 0 // 已知收到的最后一个日志条目的索引 rf.nextIndex = make([]int, len(rf.peers)) rf.matchIndex = make([]int, len(rf.peers)) rf.applyCh = applyCh rf.applyCond = sync.NewCond(\u0026amp;rf.mu) rf.readPersist(persister.ReadRaftState()) go rf.ticker() // 开辟一个goroutine，用于处理心跳和选举 go rf.applyLog() // 开辟一个goroutine，用于应用日志 return rf } 服务器规则 Rules for Servers 所有服务器： 如果 commitIndex \u003e lastApplied：增加 lastApplied，将 log[lastApplied] 应用到状态机（§5.3） 如果RPC请求或响应包含的任期 T \u003e currentTerm：设置currentTerm = T，转换为跟随者（§5.1）。 跟随者（§5.2）: 回应候选者和领导者的 RPC 如果选举超时后没有收到来自当前领导者的 AppendEntries RPC 或向候选者授予投票：转换为候选者 候选者（§5.2）: 转换为候选者后，开始选举： 增加 currentTerm 为自己投票 重置选举计时器 向所有其他服务器发送 RequestVote RPC 如果从大多数服务器收到选票：成为领导者 如果从新领导者收到 AppendEntries RPC：转换为跟随者 如果选举超时：开始新的选举 领导者： 当选后：向每个服务器发送初始的空 AppendEntries RPC（心跳）；在空闲期间重复以防止选举超时（§5.2） 如果从客户端收到命令：将条目附加到本地日志，在条目应用到状态机后响应（§5.3） 如果 lastLogIndex ≥ 跟随者的 nextIndex：发送包含从 nextIndex 开始的日志条目的 AppendEntries RPC 如果成功：更新跟随者的 nextIndex 和 matchIndex（§5.3） 如果 AppendEntries 因日志不一致而失败：递减 nextIndex 并重试（§5.3） 如果存在一个 N 使得 N \u003e commitIndex，且大多数 matchIndex[i] ≥ N，并且 log[N].term == currentTerm：设置 commitIndex = N（§5.3，§5.4）。 ticker() 首先，为了让所有节点定期发送心跳，或启动选举，需要设置一个ticker来进行定期检查：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 func (rf *Raft) ticker() { for !rf.killed() { // 无论是何种状态，都先休眠heartBeatTime时间 time.Sleep(rf.heartBeatTime) rf.mu.Lock() // 如果是领导者，则每过一个heartbeat时间发送一次心跳 if rf.state == Leader { rf.entriesToAll() } // 如果是跟随者，则检测距离上次收到心跳的时间是否超过了选举超时时间 // 如果超过了，则启动新选举 if (rf.state == Follower || rf.state == Candidate) \u0026amp;\u0026amp; time.Since(rf.updateTime) \u0026gt; rf.electionTimeout { rf.leaderElection() } rf.mu.Unlock() } } 在ticker中，需要处理两件事：\n如果是领导者，则发送心跳； 如果最近选举超时时间内没有收到心跳，则启动新选举。 领导者选举 原论文所示的领导者选举规则如下：\nRequestVote RPC 由候选者调用来收集选票（§5.2）。 参数： term 候选者的任期 candidateID 正在请求投票的候选者 lastLogIndex 候选者最后一个日志条目的索引（§5.4） lastLogTerm 候选者最后一次日志条目的任期（§5.4） 结果： term currentTerm，供候选者自行更新 voteGranted true 表示候选者获得选票 接收者实现： 如果 term \u003c currentTerm 就返回 false 如果 votedFor 为空或为 candidateId，并且候选者的日志至少和接收者一样新，就投票给候选者（§5.2, §5.4） 据此设计出来的状态图如下：\n数据结构 定义结构体RequestVoteArgs和RequestVoteReply来负责在Candidate和Follower之间传递消息：\n1 2 3 4 5 6 7 8 9 10 11 type RequestVoteArgs struct { Term int // 候选者的任期号 CandidateID int // 请求选票的候选者的ID LastLogIndex int // 候选者的最后日志条目的索引 LastLogTerm int //\t候选者最后一次日志条目的任期（§5.4） } type RequestVoteReply struct { Term int // currentTerm，供候选者自行更新 VoteGranted bool // true 表示候选者获得选票 } 为了控制与记录选举时的投票结果，还需要一个结构体VoteController：\n1 2 3 4 5 6 7 8 type VoteController struct { wg sync.WaitGroup // 用于等待所有的RPC请求完成 receivedCount int // 用于记录已经接收到的数量 voteCount int // 用于记录已经投票成功的数量 voteCh chan bool // 用于通知RPC请求完成 timeout \u0026lt;-chan time.Time // 用于超时控制 term int // 用于记录发出请求时的任期 } 发送方 leaderElection()\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 func (rf *Raft) leaderElection() { // 设置当前节点为自己选举的候选者，并增加任期编号 me := rf.me rf.currentTerm++ rf.votedFor = me rf.state = Candidate rf.resetTime() // 重置选举超时计时器 // 生成RequestVote RPC参数 args := RequestVoteArgs{ Term: rf.currentTerm, // 当前任期 CandidateID: me, LastLogIndex: rf.recvdIndex, LastLogTerm: rf.log[rf.recvdIndex].Term, } // 初始化投票控制结构 voteCtrl := VoteController{ wg: sync.WaitGroup{}, voteCount: 1, voteCh: make(chan bool, len(rf.peers)-1), timeout: time.After(rf.electionTimeout), term: rf.currentTerm, } // 向其他服务器发送RequestVote RPC for i := range rf.peers { if i != me { voteCtrl.wg.Add(1) go rf.voteToSingle(i, \u0026amp;args, \u0026amp;voteCtrl) } } // 开辟一个goroutine，等待所有投票协程完成 go func() { voteCtrl.wg.Wait() close(voteCtrl.voteCh) }() // 开辟一个goroutine，处理投票回复 go rf.waitVoteReply(\u0026amp;voteCtrl) } leaderElection()用于发起领导者选举，上面的代码做了三件事：\n初始化投票请求参数：当前节点将自己设置为候选者，增加任期编号，为自己投票，并重置选举超时计时器；构建投票请求，其中包含了自身的一些信息；初始化投票控制结构，用于管理和同步投票过程。\n并发发送投票请求：遍历所有对等节点，对于每个非自身的节点，启动一个新的协程来调用voteToSingle方法，向该节点发送RequestVote RPC请求；同时，使用voteCtrl.wg.Add(1)来记录待完成的任务数量。\n处理投票结果：启动一个协程，使用voteCtrl.wg.Wait()等待所有投票请求发送完毕后关闭投票通道voteCtrl.voteCh，以通知处理投票回复的协程不再接收新的投票；启动另一个协程，调用waitVoteReply方法来处理从其他服务器接收到的投票回复。这个方法会检查是否有足够的投票使当前节点成为领导者，或者处理其他可能的情况，如任期变化或选举超时。\nvoteToSingle()\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 func (rf *Raft) voteToSingle(server int, args *RequestVoteArgs, voteCtrl *VoteController) { defer voteCtrl.wg.Done() reply := RequestVoteReply{} if rf.sendRequestVote(server, args, \u0026amp;reply) { rf.mu.Lock() defer rf.mu.Unlock() // 如果回复的任期大于当前任期，则更新当前任期 if reply.Term \u0026gt; rf.currentTerm { rf.setNewTerm(reply.Term) rf.resetTime() rf.updateTime = time.Now() voteCtrl.voteCh \u0026lt;- false return } voteCtrl.voteCh \u0026lt;- reply.VoteGranted } else { // 如果发送失败，则认为投票失败 voteCtrl.voteCh \u0026lt;- false } } voteToSingle()负责将投票请求发送给某个跟随者，并且处理单个回复。其运行逻辑有以下规则：\n如果RPC请求包含的任期 T \u0026gt; currentTerm：设置currentTerm = T，转换为跟随者（§5.1）。 如果RPC发送失败：则视为对方未投票给本候选者。 不论结果如何，都算作请求完成。 waitVoteReply\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 func (rf *Raft) waitVoteReply(voteCtrl *VoteController) { for { rf.mu.Lock() state, curTerm := rf.state, rf.currentTerm rf.mu.Unlock() // 如果当前任期已经改变或者不是候选者状态，则不再处理 if state == Candidate \u0026amp;\u0026amp; curTerm == voteCtrl.term { select { // 使用 select 语句来同时监听两个通道： // 投票通道: 接收其他节点的投票回复。 // 超时通道: 检测选举是否超时。 case voteGranted, ok := \u0026lt;-voteCtrl.voteCh: rf.mu.Lock() if rf.currentTerm != voteCtrl.term || rf.state != Candidate { rf.mu.Unlock() return } // 如果投票通道关闭 (!ok)，则将 voteCtrl.voteCh 置为 nil， // 表示不再接收新的投票。 if !ok { voteCtrl.voteCh = nil rf.mu.Unlock() return } else if voteGranted { voteCtrl.voteCount++ } // 如果获得了大多数的投票，则成为领导者 if voteCtrl.voteCount \u0026gt; len(rf.peers)/2 { rf.state = Leader // 向其他服务器发送日志 // 此日志不一定是空的，因为可能领导者和其他服务器之间的日志不一致 for i := range rf.nextIndex { rf.nextIndex[i] = rf.recvdIndex + 1 rf.matchIndex[i] = 0 } rf.recvdIndex = len(rf.log) - 1 rf.entriesToAll() rf.mu.Unlock() return } rf.mu.Unlock() case \u0026lt;-voteCtrl.timeout: // 如果选举超时 rf.mu.Lock() if rf.currentTerm != voteCtrl.term || rf.state != Candidate { rf.mu.Unlock() return } rf.setNewTerm(rf.currentTerm) rf.resetTime() rf.mu.Unlock() return } } else { return } } } 候选者循环等待投票回复，先检查当前节点是否仍处于候选者状态并保持相同任期，后使用 select 语句来同时监听两个通道：\n投票通道: 接收其他节点的投票回复。当接收到投票回复时，一定要先确保当前任期和投票请求时的任期相同，且当前状态为候选者。因为需要考虑到下面两种情况：\n对方的回复超时，而本候选者在收到回复时，已经更新了自己的任期。 本候选者成为了跟随者或领导者，不能违规去处理属于之前候选者状态时应当处理的回复。 然后根据投票结果进行判定，若收到大部分选票，则成为领导者，更新自身状态，并向跟随者发送心跳，在心跳中，需要实现将跟随者的日志与自身的日志达成一致。\n超时通道: 检测选举是否超时。如果选举超时，则说明本次满足并不满足最大票数。在通过限制条件之后，需要将状态转为跟随者，重置更新时间、选举超时时间等信息。后续根据ticker的安排，可能会重新选举。\n接收方 RequestVote()\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 func (rf *Raft) RequestVote(args *RequestVoteArgs, reply *RequestVoteReply) { rf.mu.Lock() defer rf.mu.Unlock() // 如果请求的任期小于当前任期 if args.Term \u0026lt; rf.currentTerm { reply.Term = rf.currentTerm reply.VoteGranted = false return } // 如果请求的任期大于当前任期 if args.Term \u0026gt; rf.currentTerm { rf.setNewTerm(args.Term) } if (rf.votedFor == -1 || rf.votedFor == args.CandidateID) \u0026amp;\u0026amp; (args.LastLogTerm \u0026gt; rf.log[rf.recvdIndex].Term || (args.LastLogTerm == rf.log[rf.recvdIndex].Term \u0026amp;\u0026amp; args.LastLogIndex \u0026gt;= rf.recvdIndex)) { // 如果 votedFor 为空或为 candidateId，并且候选者的日志至少和接收者一样新 reply.VoteGranted = true rf.votedFor = args.CandidateID rf.updateTime = time.Now() } else { reply.VoteGranted = false } reply.Term = rf.currentTerm } 接收方需要满足以下规则：\n如果 term \u0026lt; currentTerm：返回 false 如果 votedFor 为空或为 candidateId，并且候选者的日志至少和接收者一样新，判断本机和对方哪个日志更新。通过比较日志中最后一个条目的索引和任期来确定两个日志中哪个更新。如果日志的最后一个条目具有不同的任期，那么任期较晚的日志更新。如果日志以相同的任期结束，那么较长的日志更新：投票给候选者 如果RPC请求或响应包含的任期 T \u0026gt; currentTerm：设置currentTerm = T，转换为跟随者。 日志复制 原论文所描述的相关RPC数据结构如下：\nAppendEntries RPC 由领导者调用来复制日志条目（§5.3）；也用作心跳（§5.2）。 参数： term 领导者的任期 learderID 这样跟随者就可以重定向客户端 prevLogIndex 紧邻新日志条目之前的日志条目的索引 prevLogTerm prevLogIndex条目的任期 entries[] 要存储的日志条目（心跳为空；为了提高效率，可以发送多个条目） leaderCommit 领导者的 commitIndex 结果： term currentTerm，用于领导者自我更新 success 如果跟随者包含与 prevLogIndex 和 prevLogTerm 匹配的条目，则为 true 接收者实现： 如果 term \u003c currentTerm 就返回 false 如果日志在 prevLogIndex 处不匹配，则返回 false 如果现有条目与新条目冲突（索引相同但任期不同），则删除现有条目及其后的所有条目 附加日志中尚未存在的任何新条目 如果 leaderCommit \u003e commitIndex，将 commitIndex 设置为 leaderCommit 和新条目索引的较小值 据此设计出来的日志复制状态图为：\n更加具体的流程图为：\n数据结构 与领导者选举有些类似，都要定义一些数据结构：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 type AppendEntriesArgs struct { Term int // 领导者的任期号 LeaderID int // 领导者的ID PrevLogIndex int // 新日志条目之前的索引 PrevLogTerm int // 新日志条目之前的任期 Entries []LogEntry // 要附加的日志条目 LeaderCommit int // 领导者的commitIndex } Term, LeaderID, PrevLogIndex, PrevLogTerm, nil, LeaderCommit type AppendEntriesReply struct { Term int // currentTerm，用于领导者自我更新 Success bool // 如果跟随者包含与 prevLogIndex 和 prevLogTerm 匹配的条目，则为 true Conflict bool // 如果跟随者包含与 prevLogIndex 和 prevLogTerm 不匹配的条目，则为 true XTerm int // 冲突条目的任期 XIndex int // 该任期中存储的第一个索引 XLen int // 跟随者的日志长度 } 上面的为日志复制RPC所使用的参数定义，其中XTerm、XIndex、XLen参考了mit6.824课程上，老师的讲解，用于快速找到不匹配的日志点。\n1 2 3 4 5 6 7 8 9 type AppendController struct { wg sync.WaitGroup // 用于等待所有的RPC请求完成 appendCount int // 用于记录已经append成功的数量 appendCh chan bool // 用于通知RPC请求完成 timeout \u0026lt;-chan time.Time // 用于超时控制 term int // 用于记录发出请求时的任期 recvdIndex int // 用于记录当前接收到的最大日志索引 commitIndex int // 用于记录当前已经提交的最大日志索引 } AppendController与之前的VoteController有着类似的作用。\n发送方 Start()\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 func (rf *Raft) Start(command interface{}) (int, int, bool) { rf.mu.Lock() defer rf.mu.Unlock() me := rf.me if rf.state != Leader { return 0, 0, false } curTerm := rf.currentTerm rf.log = append(rf.log, LogEntry{Term: curTerm, Command: command}) rf.recvdIndex++ recvdIndex := rf.recvdIndex rf.nextIndex[me] = recvdIndex + 1 rf.matchIndex[me] = recvdIndex rf.entriesToAll() return recvdIndex, curTerm, true } 根据Test_test.go中的调用方法，客户端添加新的日志的方法为，对每一个peer都调用一次Start()，但是只有领导者才有资格进行日志的添加，因此在该函数中首先要判断自己的身份，如果不是领导者，则直接返回。领导者自身在进行复制之后，需要一些属性进行更改，然后向其他服务器发送日志复制。\nentriesToAll()\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 func (rf *Raft) entriesToAll() { term := rf.currentTerm appendCtrl := AppendController{ wg: sync.WaitGroup{}, appendCount: 1, appendCh: make(chan bool, len(rf.peers)-1), timeout: time.After(rf.heartBeatTime), term: term, recvdIndex: rf.recvdIndex, commitIndex: rf.commitIndex, } for i := range rf.peers { if i != rf.me { appendCtrl.wg.Add(1) var logEntry []LogEntry if rf.nextIndex[i] \u0026gt; rf.recvdIndex { logEntry = nil } else { logEntry = rf.log[rf.nextIndex[i]:] } prevLogIndex := rf.nextIndex[i] - 1 args := AppendEntriesArgs{ Term: rf.currentTerm, LeaderID: rf.me, PrevLogIndex: prevLogIndex, PrevLogTerm: rf.log[prevLogIndex].Term, Entries: logEntry, LeaderCommit: rf.commitIndex, } go rf.entriesToSingle(i, \u0026amp;args, \u0026amp;appendCtrl) } } go func() { appendCtrl.wg.Wait() close(appendCtrl.appendCh) }() go rf.waitAppendReply(\u0026amp;appendCtrl, term) } 本段代码初始化调用参数并将日志复制请求发送至所有其他服务器。需要注意的是，为了将心跳与日志复制请求结合成一段代码。需要在发送日志时判断rf.nextIndex[i]与rf.recvdIndex之间的关系，如果nextIndex[i] \u0026gt; recvdIndex，则说明认为对方的日志已经是最新的了，请求中的Entries仅为空包即可。另外，为了使其他跟随者能够及时与领导者保持日志一致，不能仅在客户端请求追加日志时，才发送不为空的AppendEntries RPC。因此，在每次心跳时，都需要在心跳包中包含对应跟随者所缺少的日志。\n全部发送之后的处理与leaderElection()中一样，都需要开辟新的协程来等待。\nentriesToSingle()\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 func (rf *Raft) entriesToSingle(server int, args *AppendEntriesArgs, appendCtrl *AppendController) { defer appendCtrl.wg.Done() reply := AppendEntriesReply{} if rf.sendAppendEntries(server, args, \u0026amp;reply) { rf.mu.Lock() defer rf.mu.Unlock() if reply.Term \u0026gt; rf.currentTerm { rf.setNewTerm(reply.Term) return } if rf.currentTerm == args.Term { if reply.Success { // 有时候可能会连续重复发送相同的日志，导致nextIndex不断增加，所以需要取最小值 rf.nextIndex[server] = min(rf.recvdIndex+1, rf.nextIndex[server]+len(args.Entries)) rf.matchIndex[server] = rf.nextIndex[server] - 1 appendCtrl.appendCh \u0026lt;- true } else { rf.nextIndex[server] = reply.XIndex appendCtrl.appendCh \u0026lt;- false } } } else { // 如果是因为网络原因导致的失败，则等下次心跳或append时再次尝试 appendCtrl.appendCh \u0026lt;- false } } 本段代码负责向单个服务器发送日志请求并进行结果处理\n如果调用成功，则进一步判断： 若对方的任期比我方的大，则我方更新任期，并转换为跟随者。 若对方的任期和我方一致，则进行下一步判断： 若成功复制，则更新存储的对应的服务器的属性 否则，则是因为冲突，需要更新nextIndex到返回的XIndex 如果调用不成功，则说明，有可能是网络原因造成，本次日志复制记为失败，需要等到下次心跳或日志复制时继续发送。 waitAppendReply()\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 func (rf *Raft) waitAppendReply(appendCtrl *AppendController, term int) { for { curTerm, isLeader := rf.GetState() if curTerm == term \u0026amp;\u0026amp; isLeader { select { case success, ok := \u0026lt;-appendCtrl.appendCh: rf.mu.Lock() if rf.currentTerm != term || rf.state != Leader { rf.mu.Unlock() return } appendCtrl.receivedCount++ if !ok { appendCtrl.appendCh = nil } else if success { appendCtrl.appendCount++ } if appendCtrl.appendCount \u0026gt; len(rf.peers)/2 { // 因为在等待日志提交的过程中，可能有新的日志被leader接收，所以实际上commitIndex应当是旧的recvdIndex preCommitIndex := appendCtrl.commitIndex rf.commitIndex = appendCtrl.recvdIndex if preCommitIndex != rf.commitIndex { rf.applyCondSignal() } rf.mu.Unlock() return } rf.mu.Unlock() case \u0026lt;-appendCtrl.timeout: return } } else { return } } } 与waitVoteReply类似，在循环等待，其他服务器复制日志的结果，首先也需要检查本服务器的任期是否发生变化且是否为领导者。因为不允许，在本任期内去处理早期任期的回复。\n使用select来进行监听：\n日志复制通道：负责接收其他节点的日志复制的回复。当接收到时，要先判断任期及状态，若符合，条件，则进行下一步判断，当结果为成功复制，则将appendCtrl.appendCount加一，紧接着根据有没有多数复制来判断是否追加成功。若追加成功，则将日志应用。 超时通道：在此处，不需要进行类似于waitVoteReply的特殊处理，因为本次复制不成功，例如原因是网络问题，后续可以通过不断地发送心跳来进行追加。 接收方 AppendEntries()\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 func (rf *Raft) AppendEntries(args *AppendEntriesArgs, reply *AppendEntriesReply) { rf.mu.Lock() defer rf.mu.Unlock() me := rf.me reply.Success = false reply.Term = rf.currentTerm if args.Term \u0026gt; rf.currentTerm { rf.setNewTerm(args.Term) rf.votedFor = args.LeaderID } if args.Term \u0026lt; rf.currentTerm { return } if rf.state == Candidate { rf.state = Follower } rf.updateTime = time.Now() // 如果日志在 prevLogIndex 处不匹配，则返回 false if args.PrevLogIndex \u0026gt; rf.recvdIndex || rf.log[args.PrevLogIndex].Term != args.PrevLogTerm { if args.PrevLogIndex \u0026lt;= rf.recvdIndex { // 找到冲突条目的任期和该任期中它存储的第一个索引 reply.XTerm = rf.log[args.PrevLogIndex].Term for i := args.PrevLogIndex; i \u0026gt;= 0; i-- { if rf.log[i].Term != reply.XTerm { reply.XIndex = i + 1 break } } } else { reply.XTerm = rf.currentTerm reply.XIndex = rf.recvdIndex + 1 } reply.Term = rf.currentTerm return } // 如果一个已经存在的条目和新条目在相同的索引位置有相同的任期号和索引值，则复制其后的所有条目 rf.log = rf.log[:args.PrevLogIndex+1] rf.log = append(rf.log, args.Entries...) rf.recvdIndex = len(rf.log) - 1 if args.LeaderCommit \u0026gt; rf.commitIndex { rf.commitIndex = min(args.LeaderCommit, rf.recvdIndex) rf.applyCondSignal() } reply.Term = rf.currentTerm reply.Success = true reply.Conflict = false } 该段代码用于实现接收方在本机上复制日志，\n首先根据规则，要判断发送方的任期是否大于本机任期，然后转换为跟随者，但是此处处理与其他不同，因为在其他地方收到的请求发出者不一定是leader，在这里，收到的请求发出者一定是leader，因为只有leader才会发送附加日志条目的RPC请求，所以可以直接把voteFor设置为发送方。\n然后判断对方任期是否小于本机任期，如果是，则直接返回。\n根据规则，若本机是候选者，则也需要改变状态，然后将投票赋给对方。\n判断本机日志和领导者日志是否匹配。判断的方式为领导者所知道的prevLogIndex大于本机所接收到的最大日志索引下标recvdIndex，或在对应的日志条目上出现任期不相同的情况，具体情况参考原论文：\n如果发生了日志冲突，为了迅速定位到最后一个一致的日志条目，原论文提出了下面的方法：\n如果需要，可以优化协议以减少被拒绝的 AppendEntries RPC 的数量。例如，当拒绝一个 AppendEntries 请求时，跟随者可以包含冲突条目的任期和该任期中它存储的第一个索引。有了这些信息，领导者可以递减 nextIndex 以绕过该任期中的所有冲突条目；对于每个包含冲突条目的任期，只需要一个 AppendEntries RPC，而不是每个条目一个 RPC。实际上，我们怀疑这种优化是否必要，因为故障很少发生，并且不太可能有很多不一致的条目。\n在mit6.824课程上，老师也提到了这个方法，且为了通过Backup2B这个测试，也必须要实现。根据老师的方法，定义了XIndex、XTerm、XLen来分别存储发生最后一致的索引、任期、日志的长度，但是实际执行上，并不需要XLen这个字段。\n如果没有发生上面的日志冲突情况，则直接进行日志复制：找到两个日志最后一致的日志条目，删除跟随者日志中该点之后的任何条目，并将该点之后的所有领导者条目发送给跟随者。作为跟随者，在之后要触发一次提交，且规定如果 leaderCommit \u0026gt; commitIndex，将 commitIndex 设置为 leaderCommit 和已有日志条目索引的较小值。\n应用状态机 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 func (rf *Raft) applyCondSignal() { rf.applyCond.Broadcast() } func (rf *Raft) applyLog() { rf.mu.Lock() defer rf.mu.Unlock() for !rf.killed() { if rf.commitIndex \u0026gt; rf.lastApplied \u0026amp;\u0026amp; len(rf.log)-1 \u0026gt; rf.lastApplied { rf.lastApplied++ applyMsg := ApplyMsg{ CommandValid: true, Command: rf.log[rf.lastApplied].Command, CommandIndex: rf.lastApplied, } rf.mu.Unlock() rf.applyCh \u0026lt;- applyMsg rf.mu.Lock() } else { rf.applyCond.Wait() } } } 如果 commitIndex \u0026gt; lastApplied：增加 lastApplied，将 log[lastApplied] 应用到状态机，区分复制和应用日志条目。例如，日志为set value = 2，则复制的意思是将这个日志条目复制到其他服务器上，只是记录这个操作，而应用的意思是将这个日志条目应用到本地状态机上，例如，实际更改数据库中的value，将这个操作执行。在上面的AppendEntries()操作中，只是实现了日志的复制。\n注意其中的rf.applyCondSignal()，为了能够将日志条目应用，可以通过此方式来通知相关处理函数运行\napplyCondSignal()用于广播条件变量 applyCond，唤醒所有等待该条件变量的协程。当有新的日志条目被提交时，领导者会调用 applyCondSignal 来通知 applyLog 协程，告知它们有新的日志条目可以应用到状态机。 若是没有可以应用的日志条目，在applyLog()中，则会使得当前协程进入等待状态，直到被 applyCondSignal 唤醒。这有助于减少不必要的CPU占用，等待新的日志条目被提交。在被唤醒之后，如果满足应用的条件，则进行应用，将applyMsg放入到设定好的rf.applyCh中，以成功让测试函数检测到。 测试 测试准备 为了能够更加直观地观察执行的步骤，需要编写一些工具，在这里我参考了博客Debugging by Pretty Printing，按照步骤编写了go代码、python代码，由于仅在博客的基础上进行了一点改动，所以就不在此展示代码。主要有两个工具：\ndslogs\n该工具，用于将单个测试执行的过程打印，例如：\ndstest\n该工具，用于批量多线程运行测试程序，并展示测试过程及结果，例如：\n其中./test-2A.sh中的内容为：\n1 2 3 #!/usr/bin/zsh cat test_test.go| grep \u0026#34;2A\u0026#34; | sed \u0026#39;s/(/ /g\u0026#39;|awk \u0026#39;/func/ {printf \u0026#34;%s \u0026#34;,$2;}\u0026#39; | xargs dstest -o .1224_2 -n 100 -p 50 -r 使用 cat 命令读取 test_test.go 文件的内容，通过 grep \u0026quot;2A\u0026quot; 过滤出包含字符串 \u0026quot;2A\u0026quot; 的行。使用 sed 进行文本替换，利用awk 查找包含关键字 func 的行，并打印出这些行中的第二个字段（函数名），每个后面跟一个空格。接着使用 xargs 将上一步得到的函数名作为参数传递给 dstest 执行，这里的dstest就是所编写工具。最终实现的效果为，测试所有含有\u0026quot;2A\u0026quot;的测试函数。\n紧随后面的-o .1224_2 -n 100 -p 50 -r代表，将运行出错的日志文件存放到.1224_2目录下，每一个测试都进行100次，使用50个线程来进行这些测试，且测试过程使用竞态检测。其他的参数如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 def run_tests( tests: List[str], sequential: bool = typer.Option(False, \u0026#39;--sequential\u0026#39;, \u0026#39;-s\u0026#39;, help=\u0026#39;Run all test of each group in order\u0026#39;), workers: int = typer.Option(1, \u0026#39;--workers\u0026#39;, \u0026#39;-p\u0026#39;, help=\u0026#39;Number of parallel tasks\u0026#39;), iterations: int = typer.Option(10, \u0026#39;--iter\u0026#39;, \u0026#39;-n\u0026#39;, help=\u0026#39;Number of iterations to run\u0026#39;), output: Optional[Path] = typer.Option(None, \u0026#39;--output\u0026#39;, \u0026#39;-o\u0026#39;, help=\u0026#39;Output path to use\u0026#39;), verbose: int = typer.Option(0, \u0026#39;--verbose\u0026#39;, \u0026#39;-v\u0026#39;, help=\u0026#39;Verbosity level\u0026#39;, count=True), archive: bool = typer.Option(False, \u0026#39;--archive\u0026#39;, \u0026#39;-a\u0026#39;, help=\u0026#39;Save all logs intead of only failed ones\u0026#39;), race: bool = typer.Option(False, \u0026#39;--race/--no-race\u0026#39;, \u0026#39;-r/-R\u0026#39;, help=\u0026#39;Run with race checker\u0026#39;), loop: bool = typer.Option(False, \u0026#39;--loop\u0026#39;, \u0026#39;-l\u0026#39;, help=\u0026#39;Run continuously\u0026#39;), growth: int = typer.Option(10, \u0026#39;--growth\u0026#39;, \u0026#39;-g\u0026#39;, help=\u0026#39;Growth ratio of iterations when using --loop\u0026#39;), timing: bool = typer.Option(False, \u0026#39;--timing\u0026#39;, \u0026#39;-t\u0026#39;, help=\u0026#39;Report timing, only works on macOS\u0026#39;), # fmt: on ): 实现以上工具所使用的代码文件为：utils.go、dslogs.py、dstest.py，需要将dslogs.py和dstest.py分别使用pyinstaller打包成可执行文件。\n测试结果 在本机上进行了上千次测试，运行截图如下：\n当2A和2B各自测试运行了1000次时，其平均用时及出错率如下：\n各自运行5000次的平均用时及出错率如下：\n结果分析 Backup2B 代码中涉及到访问公有变量的地方，都可以通过mutex机制在一定地方来进行加锁与解锁，从而解决所遇见的因为并发导致的冲突，从而造成最终运行结果出错的问题。但是在进行测试Backup2B时，似乎这个机制无法很好的解决，甚至会导致比较难以理解的出错。在上一步的运行结果中，可以很明显发现在5000次测试中，有数十个错误结果，打开日志，发现出错的原因都为竞态错误：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 Goroutine 7038 (running) created at: MyRaft/raft.(*Raft).entriesToAll() /home/firefly/Codes/go/myraft/raft/append_entries.go:84 +0x713 MyRaft/raft.(*Raft).ticker() /home/firefly/Codes/go/myraft/raft/raft.go:225 +0xa6 MyRaft/raft.Make.gowrap1() /home/firefly/Codes/go/myraft/raft/raft.go:273 +0x33 Goroutine 7051 (finished) created at: MyRaft/labrpc.(*Network).processReq() /home/firefly/Codes/go/myraft/labrpc/labrpc.go:242 +0x28a MyRaft/labrpc.MakeNetwork.func1.gowrap1() /home/firefly/Codes/go/myraft/labrpc/labrpc.go:160 +0x9c --- FAIL: TestBackup2B (20.02s) testing.go:1398: race detected during execution of test FAIL exit status 1 FAIL\tMyRaft/raft\t20.202s 而labrpc.go文件是mit的lab中作为基础而存在的，暂时没有能力修改，也就是说，此错误是和RPC调用过程相关联的，并不好做修改。\n除此之外，在对该部分单独做测试时，发现其出错的比率与总测试个数和进行并行测试的线程数相关，总测试个数越多、并行的线程数越多，出错的比例就越大：\n上图所进行的三组测试，进行测试的总个数及线程数分别为(100, 10)、(500, 20)、(1000, 30)，若是按照第三组的比例，则第二组测试出错一个是合理的，但是五百次测试并未出错。\n上图是对所有2B部分进行5000次测试，很明显的，Backup2B部分出错比例大大增加，为了避免无效的结果，只好将Backup2B进行单独测试。\n另外，无法将并行测试的线程数设置更大，设置了四组测试，分别在线程数设置为100、50、40的情况下进行，结果所有测试均无法进行，都在几秒之后完全卡住，没有一个正确或错误的结果出现。只能通过ctrl+C的方式结束运行。猜测其原因，可能是Backup的开销较大，系统支持这么多个线程同时运行。\n选举时间问题 关于选举超时及心跳时间，在mit6.824课程主页上有描述：\nThe paper\u0026rsquo;s Section 5.2 mentions election timeouts in the range of 150 to 300 milliseconds. Such a range only makes sense if the leader sends heartbeats considerably more often than once per 150 milliseconds. Because the tester limits you to 10 heartbeats per second, you will have to use an election timeout larger than the paper\u0026rsquo;s 150 to 300 milliseconds, but not too large, because then you may fail to elect a leader within five seconds.\n在进行过次测试时发现，超时时间若短了，如设置为150ms~300ms之间，小概率造成：\n1 2 3 4 5 --- FAIL: TestCount2B (1.52s) test_test.go:643: too many or few RPCs (32) to elect initial leader FAIL exit status 1 FAIL\tMyRaft/raft\t1.531s 即选举出一个领导者所花费的RPC数量过多。若长了，如设置为360~720ms之间，小概率报错：\n1 2 3 4 5 --- FAIL: TestReElection2A (9.15s) config.go:459: expected one leader, got none FAIL exit status 1 FAIL\tMyRaft/raft\t9.163s 即，无法在指定时间内选拔出领导者。造成此问题的原因有两个：\n一个是概率问题，虽然采取了随机化选举超时时间的机制，但是总有一定概率，使得每次两个或多个候选者的时间相差不大；\n另一个是ticker()的方法问题，根据代码：\n1 2 3 4 5 6 7 8 9 10 11 12 // 无论是何种状态，都先休眠heartBeatTime时间 time.Sleep(rf.heartBeatTime) // 如果是领导者，则每过一个heartbeat时间发送一次心跳 if rf.state == Leader { rf.entriesToAll() } // 如果是跟随者，则检测距离上次收到心跳的时间是否超过了选举超时时间 // 如果超过了，则启动新选举 if (rf.state == Follower || rf.state == Candidate) \u0026amp;\u0026amp; time.Since(rf.updateTime) \u0026gt; rf.electionTimeout { rf.leaderElection() } 由于heartBeatTime时间固定，且每次都是在heartBeatTime时间之后进行检测，而不能实时监测，例如，当heartBeatTime为120ms时，每次检测的时间点为120、240、360ms，但是实际上服务器发生选举超时，即使选举超时时间不同，例如，一个为440，一个为460，他们都只能在480ms时进行检测，并同时发起领导者选举。从而有可能导致冲突。\n因此按照原论文随机化超时时间的方法并不能从根本上解决这个问题。但是实际上，经过测试，大概每1000次运行，才会出现一次这种错误，属于小概率事件，如果允许更长的时间，或者测试条件更加宽一些，这个问题也并没有很大的影响。\n","permalink":"https://fireflyyh.top/posts/distributionsystem/raft_report/","summary":"原理 具体可以看翻译的论文。\n状态转换图 Raft的系统主要包含节点角色、领导者选举和日志复制。Raft算法基于复制状态机模型，将集群中的节点分为领导者（Leader）、追随者（Follower）和候选者（Candidate）三种角色。\n领导者：负责处理所有客户端请求，并将操作同步到其他节点，确保系统在出现故障时仍能保持一致性。\n追随者：响应领导者的请求并保存日志条目，通常处于被动状态。追随者向领导者发送心跳以维持领导地位。\n候选者：在选举过程中，节点可以变为候选者，尝试成为领导者。候选者通过请求投票来获得足够的支持。\n三种状态之间的转换如下：\n任务流程 在不发生特殊情况的前提下，该系统进行领导者选举、日志复制的时序图如下：\nsequenceDiagram participant Node1 as Node 1 (Follower) participant Node2 as Node 2 (Follower) participant Node3 as Node 3 (Follower) participant Node4 as Node 4 (Follower) participant Node5 as Node 5 (Follower) %% Node1 超时，转变为 Candidate 并发起选举 Note over Node1: 超时 Node1-\u0026gt;\u0026gt;Node1: 增加当前任期编号\u0026lt;br\u0026gt;转变为 Candidate Node1-\u0026gt;\u0026gt;Node2: RequestVote RPC (Term, CandidateId, LastLogIndex, LastLogTerm) Node1-\u0026gt;\u0026gt;Node3: RequestVote RPC (Term, CandidateId, LastLogIndex, LastLogTerm) Node1-\u0026gt;\u0026gt;Node4: RequestVote RPC (Term, CandidateId, LastLogIndex, LastLogTerm) Node1-\u0026gt;\u0026gt;Node5: RequestVote RPC (Term, CandidateId, LastLogIndex, LastLogTerm) %% 其他节点响应投票请求 Node2--\u0026gt;\u0026gt;Node1: VoteGranted (true) Node3--\u0026gt;\u0026gt;Node1: VoteGranted (true) Node4--\u0026gt;\u0026gt;Node1: VoteGranted (false) : 日志较新 Node5--\u0026gt;\u0026gt;Node1: VoteGranted (true) %% Node1 成为 Leader Note over Node1: 获得多数票 Node1-\u0026gt;\u0026gt;Node1: 转变为 Leader %% 持续发送心跳 loop 每个周期 Node1-\u0026gt;\u0026gt;Node2: Heartbeat(Term, LeaderID, PrevLogIndex, PrevLogTerm, nil, LeaderCommit) Node1-\u0026gt;\u0026gt;Node3: Heartbeat(Term, LeaderID, PrevLogIndex, PrevLogTerm, nil, LeaderCommit) Node1-\u0026gt;\u0026gt;Node4: Heartbeat(Term, LeaderID, PrevLogIndex, PrevLogTerm, nil, LeaderCommit) Node1-\u0026gt;\u0026gt;Node5: Heartbeat(Term, LeaderID, PrevLogIndex, PrevLogTerm, nil, LeaderCommit) Node2--\u0026gt;\u0026gt; Node1: Success(true) Node3--\u0026gt;\u0026gt; Node1: Success(true) Node4--\u0026gt;\u0026gt; Node1: Success(true) Node5--\u0026gt;\u0026gt; Node1: Success(true) end %% 更新日志 Node1-\u0026gt;\u0026gt;Node2: AppendEntries RPC(Term, LeaderID, PrevLogIndex, PrevLogTerm, LogEntries, LeaderCommit) Node1-\u0026gt;\u0026gt;Node3: AppendEntries RPC(Term, LeaderID, PrevLogIndex, PrevLogTerm, LogEntries, LeaderCommit) Node1-\u0026gt;\u0026gt;Node4: AppendEntries RPC(Term, LeaderID, PrevLogIndex, PrevLogTerm, LogEntries, LeaderCommit) Node1-\u0026gt;\u0026gt;Node5: AppendEntries RPC(Term, LeaderID, PrevLogIndex, PrevLogTerm, LogEntries, LeaderCommit) Node2--\u0026gt;\u0026gt; Node1: Success(true) Node3--\u0026gt;\u0026gt; Node1: Success(false)：日志不匹配 Node4--\u0026gt;\u0026gt; Node1: Success(true) Node5--\u0026gt;\u0026gt; Node1: Success(true) Note over Node1: 多数派复制成功 Node1-\u0026gt;\u0026gt;Node1: 提交日志 其主要可以分为两个部分：领导者选举和日志复制：","title":"Raft实验报告（2A、2B）"},{"content":"原理 具体可以看翻译的论文\n系统架构 MapReduce的整体系统架构图如上图所示。总体上可以分为三个部分：Client、Master、Worker\n在Client中，编写的MapReduce程序提交到master端，用户可通过Client提供的一些接口查看作业运行状态。\n在Master中，又分为两个部分：\nTask Scheduler负责调度mapreduce作业，它将作业分解为多个Map任务和Reduce任务，然后将这些任务分配给集群中的不同节点来处理。 JobTracker负责它监控任务的执行状态，负责处理来自worker的数据，并负责将数据转发与存储。同时也负责任务的失败处理。 在Worker中，分为了三个部分：\nTaskTracker任务： 分布在集群各个节点上的工作节点，负责执行由JobTracker分配的Map和Reduce任务。每个TaskTracker节点都可以并行执行多个任务。TaskTracker会将任务的执行进度和状态报告给mastre中的JobTracker。\nMap任务： Map任务是MapReduce处理的第一阶段。输入数据被分为多个分片，每个分片被分配给一个Map任务。Map任务处理数据片段，将其转化为键值对\u0026lt;key, value\u0026gt;的形式。然后，它们将这些键值存储到一定位置并告知master，以供后续的Reduce任务使用。\nReduce任务： Reduce任务是MapReduce处理的第二阶段。Reduce任务负责处理由Map任务产生的中间键值对。它将相同键的数据进行汇总和归并处理，然后输出最终的计算结果。通常，Reduce任务会聚合、筛选或合并相同键的数据，实现对Map结果的进一步处理。\n任务流程 流程图如上图所示，关键流程有以下几步：\n用户程序中的MapReduce库首先将输入文件划分为M个分片，通常每个分片为16MB到64MB（用户可通过可选参数控制）。随后，库会在集群中的机器上启动程序的一些副本。 这些程序的副本中，有一份很特殊，它是master副本。其他的副本是被master分配了任务的worker副本。总计要分配 M个map任务和R个reduce任务。master选取闲置的worker并为每个选取的worker分配map或reduce任务。 被分配map任务的worker从输入数据分片中读取内容。其解析输入数据中的键值对，并将每个键值对传给用户定义的map函数。map函数输出的中间键值对在内存中缓存。 内存中缓存的键值对会定期地写入本地磁盘，写入的数据会被分区函数划分为R个区域。这些在磁盘中缓存的键值对的位置会被发送给master，master会将这些位置信息进一步传递给reduce worker。 当master通知reduce worker中间键值对的位置信息后，reduce worker会通过RPC的方式从map worker的本地磁盘中读取缓存的数据。当reduce worker读取完所有中间数据后，它会对中间数据按照键进行排序，以便将所有键相同的键值对分为一组。因为通常来说，需对键不同的数据会被映射到同一个reduce任务中，所以需要对数据排序。如果中间数据总量过大以至于无法放入内存中，则会使用外排序算法。 reduce worker遍历每一个遇到的中间键值对的，它会将键和该键对应的一系列值传递给用户定义的reduce函数。reduce函数的输出会被追加到该reduce分区的最终输出文件中。 当所有的map和reduce任务都执行完毕后，master会唤醒用户程序。此时，调用MapReduce的调应用序会返回到用户代码中。 总览 本次实验最终实现的思路，其时序图如下：\n实验的类图如下：\nclassDiagram class Coordinator { +state: TaskType +tasks: map[TaskType][]Task +mapping: map[int]int +reducing: map[int]int +GetTask(args: GetTaskArgs, reply: *GetTaskReply) error +WorkerComplete(args: *GetTaskArgs, reply: *GetTaskReply) error } class Worker { +doMap(mapf: func(string, string) []KeyValue, reply: *GetTaskReply) bool +doReduce(reducef: func(string, []string) string, reply: *GetTaskReply) bool +merge(taskId: int, mMap: int) []KeyValue +devide(kva: []KeyValue, taskId: int, nReduce: int) bool } class Task { +TaskId: int +TaskType: TaskType +TaskState: TaskState +startTime: time.Time +FileName: string +Content: string +NReduce: int } class KeyValue { +Key: string +Value: string } Coordinator --\u0026gt; Task : 管理 Worker --\u0026gt; Task : 执行 Worker --\u0026gt; KeyValue : 生成/处理 Task --\u0026gt; KeyValue : 包含 实现过程 RPC 为了使得Worker和Master之间进行调用，首先要对他们之间进行沟通的内容进行规定，定义若干结构体于rpc.go文件中。\n1 2 3 4 5 6 7 8 9 10 type GetTaskArgs struct { WorkerId int // Worker ID TaskType Type // Task Type } type GetTaskReply struct { Task Task // 任务 FileName string // 文件名，提供给worker中的mapf和reducef使用 Content string // 文件内容，提供给worker中的mapf和reducef使用 } GetTaskArgs中的WorkerId部分用于标记Worker，在单机系统中，我使用进程号来作为一个WorkerId。GetTaskReply包含三个部分：\nTask是一个结构体，用来存储任务元数据。\nFilename用来记录文件名，在map和reduce任务中，其起到不同的作用。\nContent用来存储文件中的具体内容。在map任务中，Filename用来记录输入文件名，并将文件内容存放到content中。而在reduce任务中，Filename用来记录输出文件名，以供reduce任务将结果存放到指定的文件中。\nWorker 在本实验中，worker.go 文件实现了 MapReduce 框架中的 Worker 组件，负责执行 Map 和 Reduce 任务，并与 Coordinator 进行通信以获取任务和报告完成状态。其主要分为下面几个部分：\n申请任务 当Worker空闲时，需要不断地向Coordinator申请任务，具体的代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 // 初始化请求参数 args := GetTaskArgs{WorkerId: os.Getpid()} reply := GetTaskReply{} // 向Coordinator发送申请 CallGetTask(\u0026amp;args, \u0026amp;reply) taskType := reply.Task.TaskType // 如果接收到的任务类型为Map或Reduce，则说明要进行具体的处理 if taskType == MapType || taskType == ReduceType { var completed bool if taskType == MapType { completed = doMap(mapf, \u0026amp;reply) } else { completed = doReduce(reducef, \u0026amp;reply) } // 如果任务完成，则要向对方发送任务完成的通知，方便后续处理 if completed { args = GetTaskArgs{WorkerId: os.Getpid(), TaskType: taskType} reply = GetTaskReply{} CallWorkerComplete(\u0026amp;args, \u0026amp;reply) } else { // 如果未能完成任务，则表示处理失败 Debug(dError, \u0026#34;failed!\\n\u0026#34;) } } else if taskType == Wait { // 如果master要求本worker执行wait，则等待一段时间后再去请求任务 time.Sleep(1000 * time.Millisecond) } else if taskType == Done { // 如果master要求本worker执行done，则表示所有任务已经完成 Debug(dInfo, \u0026#34;All tasks are completed\\n\u0026#34;) return } 结构体与排序接口 1 2 3 4 5 6 7 8 9 10 type KeyValue struct { Key string Value string } type ByKey []KeyValue func (a ByKey) Len() int { return len(a) } func (a ByKey) Swap(i, j int) { a[i], a[j] = a[j], a[i] } func (a ByKey) Less(i, j int) bool { return a[i].Key \u0026lt; a[j].Key } KeyValue 结构体用于存储键值对，是 Map 和 Reduce 任务之间传递数据的基本单元。Key是一个单词，而Value是其出现的次数，在本实验中，若在一段内容中，一个单词word出现了5次，则建立5个元素，它们的内容都为key = word \u0026amp;\u0026amp; value = 1直至进入到reduce阶段。 而ByKey排序实现了sort.Interface接口，用于对 KeyValue 切片按键进行排序，以便在 Reduce 阶段聚合同一键的值。\n哈希函数 1 2 3 4 5 func ihash(key string) int { h := fnv.New32a() h.Write([]byte(key)) return int(h.Sum32() \u0026amp; 0x7fffffff) } 使用 ihash(key) % NReduce 选择每个 KeyValue由 Map 发出的 Reduce 任务编号。例如，如果 NReduce是 10，那么 ihash(key) 的结果将是 0 到 9 之间的整数。即，将 key 映射到特定的 reduce 桶中，例如，文档可能有 100 个不同的单词，但是只有 10 个 reduce 桶，且确保同一个键总是被分配到相同的 reduce 桶。\nMap任务 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 func devide(kva []KeyValue, taskId int, nReduce int) bool { files := make([]*os.File, nReduce) encoders := make([]*json.Encoder, nReduce) // 创造nReduce个文件 for i := 0; i \u0026lt; nReduce; i++ { mrOutName := fmt.Sprintf(rootPath+\u0026#34;/intermediate/mr-out-%d-%d\u0026#34;, taskId, i) file, err := os.Create(mrOutName) if err != nil { log.Fatalf(\u0026#34;cannot create %v\u0026#34;, mrOutName) return false } files[i] = file encoders[i] = json.NewEncoder(file) } // 将kv对写入JSON文件 for _, kv := range kva { reduceNo := ihash(kv.Key) % nReduce if err := encoders[reduceNo].Encode(\u0026amp;kv); err != nil { log.Fatalf(\u0026#34;cannot encode %v\u0026#34;, kv) return false } } for _, file := range files { file.Close() } return true } func doMap(mapf func(string, string) []KeyValue, reply *GetTaskReply) bool { kva := mapf(reply.FileName, reply.Content) return devide(kva, reply.Task.TaskId, reply.Task.NReduce) } doMap()函数执行 Map 任务，调用用户定义的mapf函数处理输入文件内容，并将生成的键值对分配到 Reduce 桶中。devide函数将 Map 阶段生成的键值对kva分配到nReduce个 Reduce 桶中。具体步骤包括：\n计算每个键的哈希值并确定对应的 Reduce 编号。 根据任务 ID 和 Reduce 编号构建中间文件名，文件名格式为mr-out-taskId-reduceNo（taskId为该map任务的ID，reduceNo为上一步确认的Reduce编号）。 检查中间文件是否存在，若存在则追加写入，否则创建新文件。 处理文件操作中的潜在错误。 %%{init: {\u0026#39;flowchart\u0026#39;: {\u0026#39;curve\u0026#39;: \u0026#39;basis\u0026#39;}}}%% graph LR; A(开始) --\u0026gt; B[/输入原始文件内容/]; B --\u0026gt; C[\u0026#34;调用mapf函数 生成KeyValue列表(kva)\u0026#34;]; C --\u0026gt; E[遍历kva 中的每个KeyValue]; %% devide函数内部逻辑 %% 添加一些额外的说明 subgraph \u0026#34;devide函数\u0026#34; E --\u0026gt; G[\u0026#34;计算reduce桶编号 (reduceNo)\u0026#34;]; G --\u0026gt; K[向文件mr-out-taskId -reduceNo 写入KeyValue对]; end K --\u0026gt; N[返回true, 表示map任务完成]; N --\u0026gt; O(结束); Reduce任务 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 // 将mr-X-Y文件中的内容读取到Intermediate中 func merge(taskId int, mMap int) []KeyValue { var intermediate []KeyValue // 读取所有map任务的输出文件 for i := 0; i \u0026lt; mMap; i++ { mrOutName := fmt.Sprintf(rootPath+\u0026#34;/intermediate/mr-out-%d-%d\u0026#34;, i, taskId) file, err := os.Open(mrOutName) if errors.Is(err, os.ErrNotExist) { continue } if err != nil { log.Fatalf(\u0026#34;cannot open %v\u0026#34;, mrOutName) return nil } // 读取文件内容，解析为KeyValue dec := json.NewDecoder(file) for { var kv KeyValue if err := dec.Decode(\u0026amp;kv); err != nil { break } intermediate = append(intermediate, kv) } file.Close() } return intermediate } func doReduce(reducef func(string, []string) string, reply *GetTaskReply) bool { // 将mr-X-Y文件中的内容读取到Intermediate中 intermediate := merge(reply.Task.TaskId, reply.Task.MMap) // 下面的代码与mrsequential.go中的代码基本一样，只需要修改输出文件 // 对中间数据根据key进行排序 sort.Sort(ByKey(intermediate)) // 创建输出文件 oname := rootPath + \u0026#34;/res/mr-out-\u0026#34; + strconv.Itoa(reply.Task.TaskId) ofile, err := os.Create(oname) if err != nil { log.Fatalf(\u0026#34;cannot create %v\u0026#34;, oname) return false } defer ofile.Close() i := 0 for i \u0026lt; len(intermediate) { j := i + 1 for j \u0026lt; len(intermediate) \u0026amp;\u0026amp; intermediate[j].Key == intermediate[i].Key { j++ } // values是一个字符串切片，存储相同key的所有value values := []string{} for k := i; k \u0026lt; j; k++ { values = append(values, intermediate[k].Value) } // 在此时，values是[\u0026#34;1\u0026#34;, \u0026#34;1\u0026#34;, \u0026#34;1\u0026#34;, ...]，1的个数就是单词出现的次数 output := reducef(intermediate[i].Key, values) fmt.Fprintf(ofile, \u0026#34;%v %v\\n\u0026#34;, intermediate[i].Key, output) i = j } return true } doReduce()函数执行 Reduce 任务，读取并合并中间文件内容，排序后聚合同一键的值，调用用户定义的 reducef函数处理，并将结果写入输出文件。merge()函数用于将多个 Map 任务的中间结果合并为最终的输出。具体实现包括：\n数据读取：遍历所有 Map 任务生成的中间文件，读取其中的键值对。 数据合并：将读取的键值对存储到intermediate切片中，供后续的reduce处理使用。 %%{init: {\u0026#39;flowchart\u0026#39;: {\u0026#39;curve\u0026#39;: \u0026#39;basis\u0026#39;}}}%% graph LR; A(开始) --\u0026gt; B[读取 MMap 个 mr-X-Y文件]; subgraph merge函数 B --\u0026gt; C[解析每行的keyValue 追加到intermediate]; C --\u0026gt; D[结束读取]; end D --\u0026gt; E[对intermediate 中的KeyValue 根据key排序]; E --\u0026gt; F[遍历排序后的intermediate ，收集具有相同key的 所有value]; F --\u0026gt; G[调用reducef函数 处理values]; G --\u0026gt; H[/输出最终文件/] H --\u0026gt; I(结束) 任务完成 任务完成之后，需要通知coordinator进行后续处理，在worker需要执行的代码：\n1 2 3 4 5 6 7 func CallWorkerComplete(args *GetTaskArgs, reply *GetTaskReply) { ok := call(\u0026#34;Coordinator.WorkerComplete\u0026#34;, args, reply) if !ok { fmt.Print(\u0026#34;call failed!\\n\u0026#34;) Debug(dError, \u0026#34;Worker complete failed!\\n\u0026#34;) } } Coordinator 结构体 在本实验中，coordinator.go负责实现管理整个任务过程，包括，初始化任务、给worker分配任务、处理任务完成的后续等等。为了管理任务，需要创建一个数据结构Coodinator，它包含以下变量：\n1 2 3 4 5 6 7 8 9 // coordinator的属性 type Coordinator struct { state Type // coordinator状态，判断当前是在分配map任务还是reduce任务 mMap int // map任务数量上限，取决于输入文件数量 nReduce int // reduce任务数量上限，取决于mrcoordinator.go中的nReduce mapping map[int]int // 正在执行的map任务列表，key为workerId，value为taskId reducing map[int]int // 正在执行的reduce任务列表，key为workerId，value为taskId tasks [][]Task // 将map任务和reduce任务合并成一个二维数组，方便简化代码，防止重复代码 } 初始化 在创建一个coordinator时，需要对以上属性进行赋初值的操作，具体是在MakeCoordinator()中中进行下面的操作：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 mMap := len(files) c := Coordinator{ mMap: mMap, nReduce: nReduce, mapping: make(map[int]int), reducing: make(map[int]int), tasks: make([][]Task, 2), } mapTasks := make([]Task, mMap) reduceTasks := make([]Task, nReduce) for i := 0; i \u0026lt; mMap; i++ { // 初始化map任务列表 // 将任务的状态设置为Idle，表示未分配 // 需要初始化NReduce，因为在Worker中，需要根据NReduce来将结果划分到不同的桶中 mapTasks[i] = Task{ TaskType: MapType, TaskState: Idle, TaskId: i, NReduce: c.nReduce, FileName: files[i], } } for i := 0; i \u0026lt; nReduce; i++ { // 初始化reduce任务列表 // 需要初始化MMap，因为在Worker中，需要根据MMap来读取map任务的结果 reduceTasks[i] = Task{ TaskType: ReduceType, TaskState: Idle, TaskId: i, MMap: c.mMap, } } c.tasks[0] = mapTasks c.tasks[1] = reduceTasks 其中Task结构体如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 type State int type Type int const ( Idle State = iota // 任务未分配 InProgress // 任务进行中 Completed // 任务已完成 ) const ( MapType Type = iota ReduceType Done Wait // 通知worker等待 ) type Task struct { TaskType Type // 任务类型 TaskState State // 任务状态 TaskId int // 任务编号，代表执行的是map或reduce的第几个任务 NReduce int // reduce任务数量 MMap int // map任务数量 startTime time.Time // 任务开始时间 FileName string // 输入/输出文件名 } Task的更新机制如下：\n在MakeCoordinator()（coordinator初始化）时，将所有任务状态设置为Idle，不设置StartTime 在GetTask()（coordinator给worker分配任务）后，将任务状态设置为InProgress，设置StartTime 在WorkerComplete()（检测到任务完成）时，将任务状态设置为Completed，不设置StartTime 在CheckTimeOut()（检测到worker超时）时，将任务状态设置为Idle，以备之后的worker进行申请，且不设置StartTime。 分配任务 当worker空闲并向自己发送任务申请时，coordinator需要根据现在所处的阶段以及剩余任务的状态来进行任务的分配。具体实现如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 func (c *Coordinator) GetTask(args *GetTaskArgs, reply *GetTaskReply) error { mutex.Lock() defer mutex.Unlock() if c.state == MapType || c.state == ReduceType { taskId := 0 // 遍历map任务或reduce任务，找到第一个状态为Idle的任务 for ; taskId \u0026lt; len(c.tasks[c.state]); taskId++ { if c.tasks[c.state][taskId].TaskState == Idle { break } } // 若未找到Idle的任务，则将任务状态设置为Wait，通知worker等待 if taskId == len(c.tasks[c.state]) { reply.Task = Task{TaskType: Wait} return nil } // 如果是map任务，则需要初始化map任务的content if c.state == MapType { reply.FileName = c.tasks[0][taskId].FileName c.initMapContent(reply) c.mapping[args.WorkerId] = taskId } else { c.reducing[args.WorkerId] = taskId } // 将任务状态设置为InProgress，更新StartTime，用以判断任务是否超时 c.tasks[c.state][taskId].TaskState = InProgress c.tasks[c.state][taskId].startTime = time.Now() reply.Task = c.tasks[c.state][taskId] } else if c.state == Done { reply.Task = Task{TaskType: Done} } return nil } 其中，总任务有以下几种状态\n若有map任务闲置，则状态为MapType\n若所有map任务都已完成，则状态为ReduceType\n若正在等待map或reduce任务完成，则状态为InProgress\n若所有reduce任务都已完成，则状态为Done\n下面的流程图可以大致总结上面的代码：\n%%{init: {\u0026#39;flowchart\u0026#39;: {\u0026#39;curve\u0026#39;: \u0026#39;basis\u0026#39;}}}%% flowchart LR; A(开始) --\u0026gt; B{Map 或Reduce?}; B -- 是 --\u0026gt; C{有Idle任务?}; B -- 否 --\u0026gt; Z[返回任务Done]; C -- 是 --\u0026gt; D[设置任务为InProgress]; C -- 否 --\u0026gt; E[返回任务Wait]; D --\u0026gt; F{任务类型 是Map?}; F -- 是 --\u0026gt; G[初始化Map任务内容 记录WorkerId与taskId映射]; F -- 否 --\u0026gt; H[记录WorkerId与taskId映射]; G --\u0026gt; I[返回任务]; H --\u0026gt; I; E --\u0026gt; J(结束); I --\u0026gt; J; Z --\u0026gt; J; 判断任务是否完成 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 // 如果任务类型和当前的状态都匹配，则将任务状态设置为Completed if args.TaskType == c.state { taskId := 0 var taskType string if args.TaskType == MapType { taskId = c.mapping[args.WorkerId] delete(c.mapping, args.WorkerId) taskType = \u0026#34;map\u0026#34; } else { taskId = c.reducing[args.WorkerId] delete(c.reducing, args.WorkerId) taskType = \u0026#34;reduce\u0026#34; } c.tasks[c.state][taskId].TaskState = Completed for _, task := range c.tasks[c.state] { if task.TaskState != Completed { return nil } } // 将状态设置为下一个状态 // MapType的下一个状态是ReduceType，ReduceType的下一个状态是Done Debug(dInfo, \u0026#34;All %s tasks are completed\\n\u0026#34;, taskType) c.state += 1 } return nil 在worker的部分，设置在完成任务之后，需要通过RPC向coordinator来处理后续，因此需要在这里实现，逻辑比较简单：\n在分配任务时，将workerID与taskID对应了起来并放在了c.mapping或c.reducing中，因此在任务结束时，需要将其从c.mapping或c.reducing中移除。但是需要注意的是，并不是每接收到一个调用请求，就进行删除操作，因为可能有一些过时的操作，例如一个worker1未在规定的时间内完成任务，然后coordinator将该任务分配给了其他worker2，当worker1超时完成了任务并发送调用，该调用实际上不应该被执行。 在上述步骤执行之后，需要将c.tasks中对应的任务状态置为Completed。 然后判断本阶段的任务是否都完成，如果都完成，就进入下一个阶段。 将代码总结如下图：\n%%{init: {\u0026#39;flowchart\u0026#39;: {\u0026#39;curve\u0026#39;: \u0026#39;basis\u0026#39;}}}%% graph LR; A(开始) --\u0026gt; B{任务类型和 当前状态匹配?}; B -- 否 --\u0026gt; Z(返回); B -- 是 --\u0026gt; C[删除Worker映射 检查所有任务是否完成]; C --\u0026gt; H{都已完成?}; H -- 否 --\u0026gt; Z; H -- 是 --\u0026gt; I[将Coordinator 设置为下一个状态]; I --\u0026gt; Z; 判断所有任务是否完成 程序需要一个退出条件——所有任务都已经结束。这一段代码比较简单：\n1 2 3 4 5 6 7 8 9 10 11 func (c *Coordinator) Done() bool { // 依次遍历map任务和reduce任务，判断任务状态是否为Completed mutex.Lock() defer mutex.Unlock() for _, task := range append(c.tasks[0], c.tasks[1]...) { if task.TaskState != Completed { return false } } return true } 结果 优化 检测超时 因为执行过程的不确定性，有一些worker可能在执行过程出错，或由于网络问题，worker无法及时将结果返回给coordinator。为了提高效率需要进行超时处理。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 for { time.Sleep(3 * time.Second) mutex.Lock() if c.state == MapType { for workerId, taskId := range c.mapping { if time.Since(c.tasks[0][taskId].startTime) \u0026gt; time.Duration(maxTime)*time.Second { c.tasks[0][taskId].TaskState = Idle delete(c.mapping, workerId) } } } else if c.state == ReduceType { for workerId, taskId := range c.reducing { if time.Since(c.tasks[1][taskId].startTime) \u0026gt; time.Duration(maxTime)*time.Second { c.tasks[1][taskId].TaskState = Idle delete(c.reducing, workerId) } } } mutex.Unlock() } 在任务分配时，本地都会存储任务的开始时间，在判断超时时，只需要将当前时间与starttime进行比较，判断是否超出规定时间。使用一个线程，每隔3秒就执行一轮检查。检查的步骤为：遍历与当前状态相符合的正在进行的任务列表，如果某一个任务超时，则将其从列表中删除，并将其状态重新置为idle以便分配给其他worker。\n为了减少当前主线程的负担，可以选择开辟一个线程来执行上面的操作，可以在main/mrcoordinator.go中m := mr.MakeCoordinator(os.Args[1:], 10)之后添加go m.CheckTimeOut(10)，含义是使用一个线程，不断检测是否有任务超时，且超时时间设置为10s。\n锁 在执行时，需要考虑对共享资源的访问控制，因此，需要对在适当位置添加锁。使用\n1 2 mutex.Lock() defer mutex.Unlock() 来进行加锁与解锁的操作。其次，需要考虑锁的粒度与位置，在worker进程中，不需要进行加锁，因为每个worker只有一个单线程来访问数据文件，将执行的结果存储到相应的文件中。\n但是在coordinator中，考虑到上一步所要执行的操作——开辟线程检测是否超时，该线程可能会与主线程在同一时刻访问资源，因此需要在一切可能引起冲突的地方添加锁。但是由于细粒度的锁（仅在读写语句前后加锁解锁）太复杂，导致代码非常冗长，所以更好的解决方案是，一旦某个函数要访问资源，就在该函数开始处加锁，在函数结束时解锁。虽然可能性能方面不如细粒度锁，因为一个函数可能会执行很长时间，导致其他操作无法及时访问，但是却方便实现很多，正如在mit6.824课上助教所说的，当前的目标是能够实现正确的效果。\n输出文件格式 Worker 的 map 任务代码需要一种方法将中间键/值对存储在文件中，以便在 Reduce 任务期间可以正确读回。一种可能性是使用 Go 的 encoding/json 包。要将 JSON 格式的键/值对写入打开的文件：\n1 2 3 enc := json.NewEncoder(file) for _, kv := ... { err := enc.Encode(\u0026amp;kv) 并读回这样的文件：\n1 2 3 4 5 6 7 8 dec := json.NewDecoder(file) for { var kv KeyValue if err := dec.Decode(\u0026amp;kv); err != nil { break } kva = append(kva, kv) } 因此需要修改相应的代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 func devide(kva []KeyValue, taskId int, nReduce int) bool { files := make([]*os.File, nReduce) encoders := make([]*json.Encoder, nReduce) // 写入JSON for i := 0; i \u0026lt; nReduce; i++ { mrOutName := fmt.Sprintf(rootPath+\u0026#34;/intermediate/mr-out-%d-%d\u0026#34;, taskId, i) file, err := os.Create(mrOutName) if err != nil { log.Fatalf(\u0026#34;cannot create %v\u0026#34;, mrOutName) return false } files[i] = file encoders[i] = json.NewEncoder(file) } for _, kv := range kva { reduceNo := ihash(kv.Key) % nReduce if err := encoders[reduceNo].Encode(\u0026amp;kv); err != nil { log.Fatalf(\u0026#34;cannot encode %v\u0026#34;, kv) return false } } for _, file := range files { file.Close() } return true } func merge(taskId int, mMap int) []KeyValue { var intermediate []KeyValue for i := 0; i \u0026lt; mMap; i++ { mrOutName := fmt.Sprintf(rootPath+\u0026#34;/intermediate/mr-out-%d-%d\u0026#34;, i, taskId) file, err := os.Open(mrOutName) if errors.Is(err, os.ErrNotExist) { continue } if err != nil { log.Fatalf(\u0026#34;cannot open %v\u0026#34;, mrOutName) return nil } // 读取JSON dec := json.NewDecoder(file) for { var kv KeyValue if err := dec.Decode(\u0026amp;kv); err != nil { break } intermediate = append(intermediate, kv) } file.Close() } return intermediate } Combine MapReduce论文中描述：\n在某些情况下，每个 map 任务产生的中间键可能会有很多重复，而且用户定义的 Reduce 函数具有可交换和可结合的特性。一个典型的例子是第 2.1 节中的单词计数案例。由于单词出现的频率通常遵循 Zipf 分布，每个 map 任务可能会生成数百或数千条 \u0026lt;the, 1\u0026gt; 这种格式的记录。所有这些计数结果都会被发送到同一个 reduce 任务，并由 Reduce 函数合并成一个总数。为了优化这个过程，我们允许用户指定一个可选的 Combiner 函数，这个函数可以在数据发送到网络之前对数据进行局部合并。\nCombiner 函数在执行 map 任务的每台机器上运行。通常，相同的代码被用于实现 combiner 函数和 reduce 函数。reduce 函数与 combiner 函数之间的唯一区别在于 MapReduce 库处理函数输出的方式不同。reduce 函数的输出会直接写入最终的输出文件，而 combiner 函数的输出则被写入一个中间文件，该文件随后会被发送到 reduce 任务进行处理。\n局部合并大大加快了一些特定类型的 MapReduce 操作。附录 A 中提供了一个使用 combiner 函数的示例。\n对于wordCount，根据上一步优化中的json格式表示，其每一行都为：{\u0026quot;Key\u0026quot;:\u0026quot;hello\u0026quot;,\u0026quot;Value\u0026quot;:\u0026quot;1\u0026quot;}，其中的hello需要替换为具体出现的单词，若不使用 Combine，则很有可能，经过 Map 阶段之后的某一中间文件（例如mr-out-1-1），其可能包含上百上千行的{\u0026quot;Key\u0026quot;:\u0026quot;hello\u0026quot;,\u0026quot;Value\u0026quot;:\u0026quot;1\u0026quot;}，若传输到网络上，则可能文件过大导致一定的网络拥塞。因此，为了减少此类影响，可以将相同Key的所有行替换为一行，例如将123行{\u0026quot;Key\u0026quot;:\u0026quot;hello\u0026quot;,\u0026quot;Value\u0026quot;:\u0026quot;1\u0026quot;}经过 Combine 替换成{\u0026quot;Key\u0026quot;:\u0026quot;hello\u0026quot;,\u0026quot;Value\u0026quot;:\u0026quot;123\u0026quot;}。以此可以大大减少行数。\n但是经过分析，发现该 Combine 仅适用于特定场景，例如wordCount，而对于题目中给的indexer.go来说，则考虑得更加复杂。其中间输出为：\n1 2 3 4 {\u0026#34;Key\u0026#34;:\u0026#34;success\u0026#34;,\u0026#34;Value\u0026#34;:\u0026#34;../data/pg-being_ernest.txt\u0026#34;} {\u0026#34;Key\u0026#34;:\u0026#34;considerably\u0026#34;,\u0026#34;Value\u0026#34;:\u0026#34;../data/pg-being_ernest.txt\u0026#34;} {\u0026#34;Key\u0026#34;:\u0026#34;seven\u0026#34;,\u0026#34;Value\u0026#34;:\u0026#34;../data/pg-being_ernest.txt\u0026#34;} {\u0026#34;Key\u0026#34;:\u0026#34;returns\u0026#34;,\u0026#34;Value\u0026#34;:\u0026#34;../data/pg-being_ernest.txt\u0026#34;} Key为单词，Value为其出现的文档名。 其最终生成的文件每一行类似于：\n1 2 A 8 ../data/pg-being_ernest.txt,../data/pg-dorian_gray.txt,../data/pg-frankenstein.txt,../data/pg-grimm.txt,../data/pg-huckleberry_finn.txt,../data/pg-metamorphosis.txt,../data/pg-sherlock_holmes.txt,../data/pg-tom_sawyer.txt ABOUT 1 ../data/pg-tom_sawyer.txt 显然，无法通过类似于wordCount的Combine操作来处理indexer。因为实现 Combine 需要考虑到各种不同的任务，因此本实验并没有做 Combine。\n","permalink":"https://fireflyyh.top/posts/distributionsystem/marpreduce_report/","summary":"原理 具体可以看翻译的论文\n系统架构 MapReduce的整体系统架构图如上图所示。总体上可以分为三个部分：Client、Master、Worker\n在Client中，编写的MapReduce程序提交到master端，用户可通过Client提供的一些接口查看作业运行状态。\n在Master中，又分为两个部分：\nTask Scheduler负责调度mapreduce作业，它将作业分解为多个Map任务和Reduce任务，然后将这些任务分配给集群中的不同节点来处理。 JobTracker负责它监控任务的执行状态，负责处理来自worker的数据，并负责将数据转发与存储。同时也负责任务的失败处理。 在Worker中，分为了三个部分：\nTaskTracker任务： 分布在集群各个节点上的工作节点，负责执行由JobTracker分配的Map和Reduce任务。每个TaskTracker节点都可以并行执行多个任务。TaskTracker会将任务的执行进度和状态报告给mastre中的JobTracker。\nMap任务： Map任务是MapReduce处理的第一阶段。输入数据被分为多个分片，每个分片被分配给一个Map任务。Map任务处理数据片段，将其转化为键值对\u0026lt;key, value\u0026gt;的形式。然后，它们将这些键值存储到一定位置并告知master，以供后续的Reduce任务使用。\nReduce任务： Reduce任务是MapReduce处理的第二阶段。Reduce任务负责处理由Map任务产生的中间键值对。它将相同键的数据进行汇总和归并处理，然后输出最终的计算结果。通常，Reduce任务会聚合、筛选或合并相同键的数据，实现对Map结果的进一步处理。\n任务流程 流程图如上图所示，关键流程有以下几步：\n用户程序中的MapReduce库首先将输入文件划分为M个分片，通常每个分片为16MB到64MB（用户可通过可选参数控制）。随后，库会在集群中的机器上启动程序的一些副本。 这些程序的副本中，有一份很特殊，它是master副本。其他的副本是被master分配了任务的worker副本。总计要分配 M个map任务和R个reduce任务。master选取闲置的worker并为每个选取的worker分配map或reduce任务。 被分配map任务的worker从输入数据分片中读取内容。其解析输入数据中的键值对，并将每个键值对传给用户定义的map函数。map函数输出的中间键值对在内存中缓存。 内存中缓存的键值对会定期地写入本地磁盘，写入的数据会被分区函数划分为R个区域。这些在磁盘中缓存的键值对的位置会被发送给master，master会将这些位置信息进一步传递给reduce worker。 当master通知reduce worker中间键值对的位置信息后，reduce worker会通过RPC的方式从map worker的本地磁盘中读取缓存的数据。当reduce worker读取完所有中间数据后，它会对中间数据按照键进行排序，以便将所有键相同的键值对分为一组。因为通常来说，需对键不同的数据会被映射到同一个reduce任务中，所以需要对数据排序。如果中间数据总量过大以至于无法放入内存中，则会使用外排序算法。 reduce worker遍历每一个遇到的中间键值对的，它会将键和该键对应的一系列值传递给用户定义的reduce函数。reduce函数的输出会被追加到该reduce分区的最终输出文件中。 当所有的map和reduce任务都执行完毕后，master会唤醒用户程序。此时，调用MapReduce的调应用序会返回到用户代码中。 总览 本次实验最终实现的思路，其时序图如下：\n实验的类图如下：\nclassDiagram class Coordinator { +state: TaskType +tasks: map[TaskType][]Task +mapping: map[int]int +reducing: map[int]int +GetTask(args: GetTaskArgs, reply: *GetTaskReply) error +WorkerComplete(args: *GetTaskArgs, reply: *GetTaskReply) error } class Worker { +doMap(mapf: func(string, string) []KeyValue, reply: *GetTaskReply) bool +doReduce(reducef: func(string, []string) string, reply: *GetTaskReply) bool +merge(taskId: int, mMap: int) []KeyValue +devide(kva: []KeyValue, taskId: int, nReduce: int) bool } class Task { +TaskId: int +TaskType: TaskType +TaskState: TaskState +startTime: time.","title":"MapReduce实验报告"},{"content":"\rDiego Ongaro and John Ousterhout Stanford University\r摘要 Raft 是一种用于管理复制日志的共识算法。它能够产生与(多)Paxos 相同的结果，并且效率与 Paxos 相当，但其结构与 Paxos 不同。这种结构上的差异使得 Raft 比 Paxos 更容易理解，同时也为构建实际系统提供了更好的基础。为了提升可理解性，Raft 将共识的关键要素进行了分离，如领导者选举、日志复制和安全性保证等，并且强化了一致性要求以减少需要考虑的状态数量。用户研究的结果表明，相比 Paxos，学生们更容易掌握 Raft。此外，Raft 还引入了一种新的集群成员变更机制，该机制通过使用重叠的多数派来保证安全性。\n1 引言 共识算法使得一组机器能够作为一个连贯的整体工作，并且能够在部分成员发生故障时继续运行。正因如此，这类算法在构建可靠的大规模软件系统中发挥着关键作用。在过去的十年里，Paxos1 2主导了关于共识算法的讨论：大多数共识算法的实现要么基于 Paxos，要么受到它的影响，而且 Paxos 已经成为向学生教授共识知识的主要载体。\n不幸的是，尽管已经有许多让它变得更容易理解的尝试，Paxos 仍然非常难以理解。此外，它的架构需要进行复杂的改动才能支持实际系统。因此，系统构建者和学生都在与 Paxos 作斗争。\n在我们自己也经历过与 Paxos 搏斗之后，我们着手寻找一种新的共识算法，希望它能为系统构建和教育提供更好的基础。我们采用了一种不同寻常的方式，即将 可理解性（understandability） 作为首要目标：我们能否定义一个用于实际系统的共识算法，并以一种比 Paxos 容易得多的方式来描述它？此外，我们希望这个算法能够帮助系统构建者形成必要的直观认识。重要的不仅是算法能够工作，更重要的是能够清楚地理解为什么它能工作。\n这项工作的成果就是一个称为 Raft 的共识算法。在设计 Raft 时，我们应用了特定的技术来提高可理解性，包括分解（Raft 将领导者选举、日志复制和安全性分开）和状态空间简化（相比 Paxos，Raft 减少了不确定性的程度以及服务器之间可能产生不一致的方式）。在两所大学进行的涉及 43 名学生的用户研究表明，Raft 比 Paxos 更容易理解:在学习了这两种算法之后，其中 33 名学生对 Raft 的相关问题回答得比 Paxos 的问题要好。\nRaft 在许多方面与现有的共识算法相似（最值得注意的是 Oki 和 Liskov 的 Viewstamped Replication 3 4），但它有几个新颖的特点：\n强领导者：Raft 使用比其他共识算法更强的领导形式。例如，日志条目仅从领导者流向其他服务器。这简化了复制日志的管理，使 Raft 更易理解。 领导者选举：Raft 使用随机定时器来选举领导者。这仅在任何共识算法所需的心跳中增加了少量机制，同时简单快速地解决冲突。 成员变更：Raft 改变集群中服务器集合的机制使用了一种新的 联合共识（joint consensus） 方法，在转换期间两个不同配置的多数重叠。这允许集群在配置更改期间正常运行。 我们相信 Raft 比 Paxos 和其他共识算法更优，无论是用于教育目的还是作为实现的基础。它比其他算法更简单、更易理解；它的描述足够完整，可以满足实际系统的需求；它有多个开源实现，并被多家公司使用；它的安全性已被正式指定和证明；其效率与其他算法相当。\n本文的其余部分介绍了复制状态机问题（第2节），讨论了 Paxos 的优缺点（第3节），描述了我们对可理解性的一般方法（第4节），介绍了 Raft 共识算法（第5-8节），评估了 Raft（第9节），并讨论了相关工作（第10节）。\n2 复制状态机 共识算法通常出现在 复制状态机（replicated state machines） 的背景下5。在这种方法中，一组服务器上的状态机计算相同状态的相同副本，即使某些服务器宕机也能继续运行。复制状态机用于解决分布式系统中的各种容错问题。例如，具有单个集群领导者的大规模系统，如 GFS6、HDFS7 和 RAMCloud8，通常使用单独的复制状态机来管理领导者选举并存储必须在领导者崩溃时存活的配置信息。复制状态机的例子包括 Chubby9 和 ZooKeeper10。\n复制状态机通常通过复制日志来实现，如图1所示。每个服务器存储一个包含一系列命令的日志，其状态机会按顺序执行这些命令。每个日志包含相同顺序的相同命令，因此每个状态机处理相同的命令序列。由于状态机是确定性的，每个状态机计算相同的状态和相同的输出序列。\n保持复制日志一致是共识算法的任务。服务器上的共识模块从客户端接收命令并将其添加到日志中。它与其他服务器上的共识模块通信，以确保每个日志最终包含相同顺序的相同请求，即使某些服务器发生故障。一旦命令被正确复制，每个服务器的状态机按日志顺序处理它们，并将输出返回给客户端。因此，服务器看起来像是形成了一个高度可靠的状态机。\n实际系统的共识算法通常具有以下属性：\n它们在所有非拜占庭条件下（包括网络延迟、分区、数据包丢失、重复和重新排序）确保 安全性（safety）（从不返回错误结果）。 只要大多数服务器正常运行并且能够相互通信以及与客户端通信，它们就能完全正常工作（可用（available））。因此，一个典型的五台服务器集群可以容忍任意两台服务器的故障。假设服务器通过停止来故障；它们可以稍后从稳定存储中的状态恢复并重新加入集群。 它们不依赖于时间来确保日志的一致性：故障时钟和极端消息延迟最多会导致可用性问题。 在常见情况下，一旦集群的大多数响应了单轮远程过程调用，命令就可以完成；少数慢速服务器不会影响整体系统性能。 3 Paxos有什么问题？ 在过去的十年中，Leslie Lamport 的 Paxos 协议几乎成了共识的代名词：它是课程中最常教授的协议1，大多数共识实现也以它为起点。Paxos 首先定义了一个能够就单一决策（如单个复制日志条目）达成一致的协议，我们称之为 单一决策 Paxos（single-decree Paxos）。然后，Paxos 结合该协议的多个实例来促进一系列决策，如日志（多决策 Paxos（multi-Paxos））。Paxos 确保了安全性和活性，并支持集群成员的变更。其正确性已被证明，在正常情况下也很高效。\n不幸的是，Paxos 有两个显著的缺点。第一个缺点是 Paxos 极其难以理解。完整的解释1非常晦涩，极少有人能理解它，而且需要付出极大的努力。因此，有几次尝试用更简单的术语2 11 12来解释 Paxos，但这些解释仍然具有挑战性。在 2012 年 NSDI 会议的非正式调查中，我们发现即使在经验丰富的研究人员中，也很少有人对 Paxos 感到舒适。我们自己也在与 Paxos 斗争；直到阅读了几篇简化的解释并设计了我们自己的替代协议后，我们才理解了完整的协议，这个过程花费了将近一年的时间。\n我们假设 Paxos 的晦涩难懂源于其选择了单一决策子集作为基础。单一决策 Paxos 非常密集且微妙：它分为两个阶段，这两个阶段没有简单直观的解释，且不能独立理解。因此，很难形成关于为什么单一决策协议有效的直觉。多决策 Paxos 的组合规则显著增加了额外的复杂性和微妙性。我们认为，达成多个决策共识的整体问题（即日志而不是单个条目）可以通过其他更直接和明显的方式来分解。\nPaxos 的第二个问题是它没有为构建实际实现提供良好的基础。一个原因是没有广泛认可的多决策 Paxos 算法。Lamport 的描述主要是关于单一决策 Paxos；他勾画了多决策 Paxos 的可能方法，但缺少许多细节。有几次尝试充实和优化 Paxos，例如13，14和15，但这些尝试彼此之间以及与 Lamport 的草图都有所不同。像 Chubby16 这样的系统实现了类似 Paxos 的算法，但在大多数情况下，它们的细节没有被公布。\n此外，Paxos 架构对于构建实际系统来说是一个糟糕的选择；这是单一决策分解的另一个后果。例如，独立选择一组日志条目然后将它们合并成一个顺序日志几乎没有什么好处；这只会增加复杂性。围绕一个日志设计系统更简单且更高效，其中新条目按顺序依次追加。另一个问题是，Paxos 在其核心使用对等对称的方法（尽管它最终建议了一种弱形式的领导作为性能优化）。这在一个只做出一个决策的简化世界中是有意义的，但很少有实际系统使用这种方法。如果必须做出一系列决策，首先选举一个领导者，然后由领导者协调决策会更简单和更快。\n因此，实际系统与 Paxos 几乎没有相似之处。每个实现都从 Paxos 开始，发现实现它的困难，然后开发出一个显著不同的架构。这既耗时又容易出错，而理解 Paxos 的困难加剧了这个问题。Paxos 的形式化可能是一个证明其正确性的好方法，但实际实现与 Paxos 相差甚远，以至于这些证明几乎没有价值。以下是 Chubby 实现者的典型评论：\nPaxos 算法的描述与实际系统的需求之间存在重大差距\u0026hellip;最终系统将基于未经证实的协议 16。\n由于这些问题，我们得出结论，Paxos 没有为系统建设或教育提供良好的基础。鉴于共识在大规模软件系统中的重要性，我们决定看看是否可以设计一种比 Paxos 具有更好特性的替代共识算法。Raft 是该实验的结果。\n4 为可理解性而设计 我们在设计 Raft 时有几个目标：它必须为系统构建提供一个完整且实用的基础，从而显著减少开发人员所需的设计工作量；它必须在所有条件下都是安全的，并且在典型的操作条件下是可用的；它必须对常见操作高效。但我们最重要的目标——也是最困难的挑战——是 可理解性（understandability）。必须让广大受众能够轻松理解该算法。此外，必须能够对该算法形成直觉，以便系统构建者在实际实现中进行不可避免的扩展。\n在 Raft 的设计中，我们不得不在多种替代方法之间进行选择。在这些情况下，我们基于可理解性来评估替代方案：解释每种替代方案有多难（例如，其状态空间有多复杂，是否有微妙的影响？），以及读者完全理解该方法及其影响有多容易？\n我们认识到这种分析具有高度的主观性；尽管如此，我们使用了两种普遍适用的技术。第一种技术是众所周知的问题分解方法：在可能的情况下，我们将问题分解成可以相对独立地解决、解释和理解的部分。例如，在 Raft 中，我们将领导者选举、日志复制、安全性和成员变更分开。\n我们的第二种方法是通过减少需要考虑的状态数量来简化状态空间，使系统更加一致，并尽可能消除不确定性。具体来说，不允许日志有空洞，并且 Raft 限制了日志之间变得不一致的方式。尽管在大多数情况下我们试图消除不确定性，但在某些情况下，不确定性实际上提高了可理解性。特别是，随机化方法引入了不确定性，但它们倾向于通过以类似方式处理所有可能的选择来减少状态空间（“选择任何一个；这无关紧要”）。我们使用随机化来简化 Raft 的领导者选举算法。\n5 Raft 共识算法 图 2：Raft 共识算法的精简摘要（不包括成员资格更改和日志压缩）。左上角框中的服务器行为描述为一组独立且重复触发的规则。节编号（如 §5.2）表示讨论特定功能的位置。正式规范 [^31] 更精确地描述了该算法。 State\r所有服务器上的持久性状态（在响应 RPC 之前更新稳定存储）\rcurrentTerm\r服务器见过的最新任期（首次启动时初始化为 0，单调增加）\rvotedFor\r在当前任期内获得投票的候选者的ID（如果没有则为 null）\rlog[]\r日志条目；每个条目包含状态机命令以及领导者收到条目时的任期（第一个索引为 1）\r所有服务器上的易失状态\rcommitIndex\r已知已提交的最高日志条目的索引（初始化为 0，单调增加）\rlastApplied\r应用于状态机的最高日志条目的索引（初始化为 0，单调增加）\r领导者服务器上的易失状态（选举后重新初始化）\rnextIndex[]\r对于每个服务器，发送到该服务器的下一个日志条目的索引（初始化为领导者最后一个日志索引 + 1）\rmatchIndex[]\r对于每个服务器，已知在服务器上复制的最高日志条目的索引（初始化为 0，单调增加）\rAppendEntries RPC\r由领导者调用来复制日志条目（§5.3）；也用作心跳（§5.2）。\r参数：\rterm\r领导者的任期\rlearderID\r这样跟随者就可以重定向客户端\rprevLogIndex\r紧邻新日志条目之前的日志条目的索引\rprevLogTerm\rprevLogIndex条目的任期\rentries[]\r要存储的日志条目（心跳为空；为了提高效率，可以发送多个条目）\rleaderCommit\r领导者的 commitIndex\r结果：\rterm\rcurrentTerm，用于领导者自我更新\rsuccess\r如果跟随者包含与 prevLogIndex 和 prevLogTerm 匹配的条目，则为 true\r接收者实现：\r如果 term \u003c currentTerm 就返回 false\r如果日志在 prevLogIndex 处不匹配，则返回 false\r如果现有条目与新条目冲突（索引相同但任期不同），则删除现有条目及其后的所有条目\r附加日志中尚未存在的任何新条目\r如果 leaderCommit \u003e commitIndex，将 commitIndex 设置为 leaderCommit 和新条目索引的较小值\rRequestVote RPC\r由候选者调用来收集选票（§5.2）。\r参数：\rterm\r候选者的任期\rcandidateID\r正在请求投票的候选者\rlastLogIndex\r候选者最后一个日志条目的索引（§5.4）\rlastLogTerm\r候选者最后一次日志条目的任期（§5.4）\r结果：\rterm\rcurrentTerm，供候选者自行更新\rvoteGranted\rtrue 表示候选者获得选票\r接收者实现：\r如果 term \u003c currentTerm 就返回 false\r如果 votedFor 为空或为 candidateId，并且候选者的日志至少和接收者一样新，就投票给候选者（§5.2, §5.4）\rRules for Servers\r所有服务器：\r如果 commitIndex \u003e lastApplied：增加 lastApplied，将 log[lastApplied] 应用到状态机（§5.3）\r如果RPC请求或响应包含的任期 T \u003e currentTerm：设置currentTerm = T，转换为跟随者（§5.1）。\r跟随者（§5.2）:\r回应候选者和领导者的 RPC\r如果选举超时后没有收到来自当前领导者的 AppendEntries RPC 或向候选者授予投票：转换为候选者\r候选者（§5.2）:\r转换为候选者后，开始选举：\r增加 currentTerm\r为自己投票\r重置选举计时器\r向所有其他服务器发送 RequestVote RPC\r如果从大多数服务器收到选票：成为领导者\r如果从新领导者收到 AppendEntries RPC：转换为跟随者\r如果选举超时：开始新的选举\r领导者：\r当选后：向每个服务器发送初始的空 AppendEntries RPC（心跳）；在空闲期间重复以防止选举超时（§5.2）\r如果从客户端收到命令：将条目附加到本地日志，在条目应用到状态机后响应（§5.3）\r如果 lastLogIndex ≥ 跟随者的 nextIndex：发送包含从 nextIndex 开始的日志条目的 AppendEntries RPC\r如果成功：更新跟随者的 nextIndex 和 matchIndex（§5.3）\r如果 AppendEntries 因日志不一致而失败：递减 nextIndex 并重试（§5.3）\r如果存在一个 N 使得 N \u003e commitIndex，且大多数 matchIndex[i] ≥ N，并且 log[N].term == currentTerm：设置 commitIndex\r= N（§5.3，§5.4）。\r选举安全性\r在给定任期内最多只能选举出一个领导者。(§5.2)\r领导者仅追加\r领导者从不覆盖或删除其日志中的条目；它只追加新的条目。(§5.3)\r日志匹配\r如果两个日志包含一个具有相同索引和任期的条目，那么这两个日志在该索引之前的所有条目都是相同的。(§5.3)\r领导者完整性\r如果一个日志条目在某个任期内被提交，那么该条目将出现在所有更高任期号的领导者的日志中。(§5.4)\r状态机安全性\r如果某个服务器已经将某个特定索引位置的日志条目应用到其状态机中，那么其他服务器永远不会在相同的索引位置应用不同的日志条目。(§5.4.3)\rRaft 是一种用于管理复制日志的算法，如第2节所述。图2简要总结了该算法以供参考，图3列出了该算法的关键属性；这些图中的元素将在本节的其余部分逐一讨论。\nRaft 通过首先选举出一个特殊的 领导者（leader） 来实现共识，然后赋予领导者完全管理复制日志的责任。领导者从客户端接受日志条目，将它们复制到其他服务器上，并在日志条目可以安全地应用到状态机时通知服务器。拥有一个领导者简化了复制日志的管理。例如，领导者可以在不咨询其他服务器的情况下决定在日志中放置新条目的位置，并且数据以简单的方式从领导者流向其他服务器。领导者可能会失败或与其他服务器断开连接，在这种情况下会选举出一个新的领导者。\n鉴于领导者的方法，Raft 将共识问题分解为三个相对独立的子问题，这些子问题将在以下小节中讨论：\n领导者选举：当现有领导者失效时，必须选择一个新的领导者（第5.2节）。 日志复制：领导者必须接受来自客户端的日志条目并将它们复制到整个集群中，强制其他日志与其自身一致（第5.3节）。 安全性：Raft 的关键安全属性是图3中的状态机安全属性：如果任何服务器已将特定日志条目应用到其状态机，则其他服务器不得为相同的日志索引应用不同的命令。第5.4节描述了 Raft 如何确保这一属性；解决方案涉及对第5.2节中描述的选举机制的额外限制。 在介绍了共识算法之后，本节讨论了可用性问题以及时间在系统中的作用。\n5.1 Raft 基础 图 4：服务器状态。跟随者仅响应来自其他服务器的请求。如果跟随者没有收到任何通信，它将成为候选者并发起选举。获得整个群集中大多数选票的候选者将成为新的领导者。领导者通常会一直工作到失败。 一个 Raft 集群包含多个服务器；五个是一个典型的数量，这允许系统容忍两个故障。在任何给定时间，每个服务器处于三种状态之一：领导者（leader）、跟随者（follower）或候选者（candidate）。在正常操作中，恰好有一个领导者，所有其他服务器都是跟随者。跟随者是被动的：它们不主动发出请求，只是响应来自领导者和候选者的请求。领导者处理所有客户端请求（如果客户端联系跟随者，跟随者会将其重定向到领导者）。第三种状态，候选者，用于选举新领导者，如第5.2节所述。图4显示了状态及其转换；转换将在下文讨论。\n图 5：时间分为多个任期，每个任期都从一次选举开始。选举成功后，单个 leader 将管理集群，直到任期结束。一些选举失败，在这种情况下，任期结束，没有选择领导者。任期之间的转换可能会在不同时间在不同的服务器上观察到。 Raft 将时间划分为任意长度的 任期（term），如图5所示。任期用连续的整数编号。每个任期以 选举（election） 开始，其中一个或多个候选者尝试成为领导者，如第5.2节所述。如果候选者赢得选举，那么它将在剩余的任期内担任领导者。在某些情况下，选举会导致票数平分。在这种情况下，任期将以没有领导者结束；一个新的任期（伴随新的选举）将很快开始。Raft 确保在给定的任期内最多只有一个领导者。\n不同的服务器可能在不同时间观察到任期之间的转换，在某些情况下，服务器可能不会观察到选举甚至整个任期。任期在 Raft 中充当逻辑时钟17，它们允许服务器检测过时的信息，如过期的领导者。每个服务器存储一个 当前任期（current term） 号，该任期号随时间单调递增。每当服务器通信时，当前任期号都会交换；如果一个服务器的当前任期号小于另一个服务器的任期号，它会将其当前任期号更新为较大的值。如果候选者或领导者发现其任期过期，它会立即恢复为跟随者状态。如果服务器收到带有过期任期号的请求，它会拒绝该请求。\nRaft 服务器使用远程过程调用（RPC）进行通信，基本的共识算法只需要两种类型的 RPC。RequestVote RPC 由候选者在选举期间发起（第5.2节），AppendEntries RPC 由领导者发起以复制日志条目并提供心跳（第5.3节）。第7节增加了第三种用于在服务器之间传输快照的 RPC。如果服务器没有及时收到响应，它们会重试 RPC，并且为了最佳性能，它们会并行发出 RPC。\n5.2 领导者选举 Raft 使用心跳机制来触发领导者选举。当服务器启动时，它们首先作为跟随者。只要从领导者或候选者那里接收到有效的 RPC，服务器就会保持在跟随者状态。领导者定期向所有跟随者发送心跳（不携带日志条目的 AppendEntries RPC）以维持其权威。如果跟随者在一段时间内（称为 选举超时（election timeout））没有收到任何通信，它就会假设没有可行的领导者，并开始选举以选择新的领导者。\n要开始选举，跟随者会增加其当前任期并转换为候选者状态。然后，它会为自己投票，并并行向集群中的其他服务器发出 RequestVote RPC。候选者会继续保持在这种状态，直到发生以下三种情况之一：（a）它赢得选举，（b）另一台服务器确立自己为领导者，或（c）经过一段时间没有赢家。以下段落将分别讨论这些结果。\n如果候选者在同一任期内获得了集群中大多数服务器的投票，它就赢得了选举。每个服务器在给定任期内最多会投票给一个候选者，先到先得（注意：第5.4节对投票增加了额外的限制）。多数规则确保在特定任期内最多只有一个候选者能赢得选举（图3中的选举安全属性）。一旦候选者赢得选举，它就成为领导者。然后，它会向所有其他服务器发送心跳消息以确立其权威并防止新的选举。\n在等待投票期间，候选者可能会收到来自另一台服务器的 AppendEntries RPC，该服务器声称自己是领导者。如果领导者的任期（包含在其 RPC 中）至少与候选者的当前任期一样大，那么候选者会承认该领导者的合法性并返回到跟随者状态。如果 RPC 中的任期小于候选者的当前任期，那么候选者会拒绝该 RPC 并继续保持候选者状态。\n第三种可能的结果是候选者既没有赢得也没有输掉选举：如果许多跟随者同时成为候选者，投票可能会分裂，以至于没有候选者获得多数票。当这种情况发生时，每个候选者都会超时并通过增加其任期并启动新一轮的 RequestVote RPC 来开始新的选举。然而，如果没有额外的措施，分裂投票可能会无限期地重复。\nRaft 使用随机化的选举超时来确保分裂投票很少发生并能迅速解决。为了防止分裂投票，选举超时从一个固定的区间（例如 150-300 毫秒）中随机选择。这使得服务器的超时分散开来，在大多数情况下，只有一个服务器会超时；它赢得选举并在其他服务器超时之前发送心跳。相同的机制用于处理分裂投票。每个候选者在选举开始时重新启动其随机化的选举超时，并等待该超时结束后再开始下一次选举；这减少了新选举中再次发生分裂投票的可能性。第9.3节表明这种方法能够快速选出领导者。\n选举是一个例子，说明了可理解性如何指导我们在设计替代方案之间做出选择。最初，我们计划使用一个排名系统：每个候选者被分配一个唯一的排名，用于在竞争候选者之间进行选择。如果一个候选者发现另一个排名更高的候选者，它会返回到跟随者状态，以便排名更高的候选者更容易赢得下一次选举。我们发现这种方法在可用性方面产生了微妙的问题（如果排名较高的服务器失败，排名较低的服务器可能需要超时并再次成为候选者，但如果它太早这样做，可能会重置选举领导者的进程）。我们多次调整了算法，但每次调整后都会出现新的边缘情况。最终，我们得出结论，随机重试的方法更明显且更易理解。\n5.3 日志复制 一旦领导者被选举出来，它就开始处理客户端请求。每个客户端请求包含一个由复制状态机执行的命令。领导者将命令作为新条目附加到其日志中，然后并行向其他每个服务器发出 AppendEntries RPC 以复制该条目。当条目被安全复制后（如下所述），领导者将该条目应用到其状态机，并将执行结果返回给客户端。如果跟随者崩溃或运行缓慢，或者网络数据包丢失，领导者会无限期地重试 AppendEntries RPC（即使在它已经响应客户端之后），直到所有跟随者最终存储所有日志条目。\n日志的组织如图6所示。每个日志条目存储一个状态机命令以及领导者接收该条目时的任期号。日志条目中的任期号用于检测日志之间的不一致性，并确保图3中的某些属性。每个日志条目还有一个整数索引，用于标识其在日志中的位置。\n领导者决定何时将日志条目安全地应用到状态机；这样的条目称为 已提交（commited） 条目。Raft 保证已提交的条目是持久的，并且最终会被所有可用的状态机执行。一个日志条目一旦被创建它的领导者在大多数服务器上复制，就被认为是已提交的（例如，图6中的条目7）。这也会提交领导者日志中的所有前面的条目，包括以前领导者创建的条目。第5.4节讨论了在领导者更换后应用此规则时的一些细微差别，并且还表明这种提交定义是安全的。领导者跟踪它知道的最高已提交索引，并在未来的 AppendEntries RPC（包括心跳）中包含该索引，以便其他服务器最终得知。一旦跟随者得知一个日志条目已提交，它就会将该条目按日志顺序应用到其本地状态机。\n我们设计了 Raft 日志机制，以保持不同服务器上的日志高度一致。这不仅简化了系统的行为并使其更可预测，而且是确保安全的重要组成部分。Raft 保持以下属性，这些属性共同构成了图3中的日志匹配属性：\n如果不同日志中的两个条目具有相同的索引和任期号，那么它们存储相同的命令。 如果不同日志中的两个条目具有相同的索引和任期号，那么这些日志在所有前面的条目中都是相同的。 第一个属性源于这样一个事实：领导者在给定任期内最多创建一个具有给定日志索引的条目，并且日志条目在日志中的位置永远不会改变。第二个属性通过 AppendEntries 执行的简单一致性检查来保证。当发送 AppendEntries RPC 时，领导者会包含其日志中紧接在新条目之前的条目的索引和任期号。如果跟随者在其日志中没有找到具有相同索引和任期号的条目，那么它会拒绝新的条目。这个一致性检查起到了归纳步骤的作用：日志的初始空状态满足日志匹配属性，并且一致性检查在日志扩展时保持日志匹配属性。因此，每当 AppendEntries 成功返回时，领导者知道跟随者的日志与其自身日志在新条目之前是相同的。\n在正常操作期间，领导者和跟随者的日志保持一致，因此 AppendEntries 的一致性检查从未失败。然而，领导者崩溃可能会导致日志不一致（旧领导者可能没有完全复制其日志中的所有条目）。这些不一致可能会在一系列领导者和跟随者崩溃中加剧。图7说明了跟随者的日志可能与新领导者的日志不同的方式。跟随者可能缺少领导者上存在的条目，可能有领导者上不存在的额外条目，或者两者都有。日志中的缺失和多余条目可能跨越多个任期。\n在 Raft 中，领导者通过强制跟随者复制自己（领导者）的日志来处理不一致。这意味着跟随者日志中的冲突条目将被领导者日志中的条目覆盖。第5.4节将展示，当结合一个额外的限制时，这样做是安全的。\n为了使跟随者的日志与其自身一致，领导者必须找到两个日志最后一致的日志条目，删除跟随者日志中该点之后的任何条目，并将该点之后的所有领导者条目发送给跟随者。所有这些操作都是在 AppendEntries RPC 执行的一致性检查响应中发生的。领导者为每个跟随者维护一个 nextIndex，这是领导者将发送给该跟随者的下一个日志条目的索引。当领导者首次上任时，它将所有 nextIndex 值初始化为其日志中最后一个条目之后的索引（图7中的11）。如果跟随者的日志与领导者的不一致，下一次 AppendEntries RPC 中的一致性检查将失败。在拒绝之后，领导者会递减 nextIndex 并重试 AppendEntries RPC。最终，nextIndex 将达到领导者和跟随者日志匹配的点。当这种情况发生时，AppendEntries 将成功，这将删除跟随者日志中的任何冲突条目，并附加领导者日志中的条目（如果有的话）。一旦 AppendEntries 成功，跟随者的日志将与领导者的一致，并且在剩余的任期内将保持这种状态。\n如果需要，可以优化协议以减少被拒绝的 AppendEntries RPC 的数量。例如，当拒绝一个 AppendEntries 请求时，跟随者可以包含冲突条目的任期和该任期中它存储的第一个索引。有了这些信息，领导者可以递减 nextIndex 以绕过该任期中的所有冲突条目；对于每个包含冲突条目的任期，只需要一个 AppendEntries RPC，而不是每个条目一个 RPC。实际上，我们怀疑这种优化是否必要，因为故障很少发生，并且不太可能有很多不一致的条目。\n通过这种机制，领导者在上任时不需要采取任何特殊行动来恢复日志一致性。它只需开始正常操作，日志会自动在 AppendEntries 一致性检查失败时收敛。领导者从不覆盖或删除其自身日志中的条目（图3中的领导者仅追加属性）。\n这种日志复制机制展示了第2节中描述的理想共识属性：只要大多数服务器正常运行，Raft 就可以接受、复制和应用新的日志条目；在正常情况下，一个新条目可以通过对集群大多数服务器进行一轮 RPC 来复制；单个慢速跟随者不会影响性能。\n5.4 安全性 前几节描述了 Raft 如何选举领导者和复制日志条目。然而，到目前为止描述的机制还不足以确保每个状态机以相同的顺序执行完全相同的命令。例如，一个跟随者在领导者提交了几个日志条目时，其可能不可用，然后它可能被选为领导者并用新条目覆盖这些条目；结果，不同的状态机可能会执行不同的命令序列。\n本节通过增加对哪些服务器可以被选为领导者的限制来完成 Raft 算法。该限制确保任何给定任期的领导者包含所有在之前任期中提交的条目（图3中的领导者完整性属性）。在给定选举限制的情况下，我们将提交规则更加精确化。最后，我们提供领导者完整性属性的证明草图，并展示它如何导致复制状态机的正确行为。\n5.4.1 选举限制 在任何基于领导者的共识算法中，领导者最终必须存储所有已提交的日志条目。在一些共识算法中，例如 Viewstamped Replication4，一个领导者即使最初不包含所有已提交的条目也可以被选举出来。这些算法包含额外的机制来识别缺失的条目并在选举过程中或选举后不久将它们传输给新领导者。不幸的是，这会导致相当多的额外机制和复杂性。Raft 使用一种更简单的方法，它保证从选举时刻起，每个新领导者都包含之前任期中所有已提交的条目，而无需将这些条目传输给领导者。这意味着日志条目只会从领导者流向跟随者，领导者永远不会覆盖其日志中的现有条目。\nRaft 使用投票过程来防止候选者在其日志不包含所有已提交条目的情况下赢得选举。候选者必须联系集群中的大多数服务器才能当选，这意味着每个已提交的条目必须至少存在于这些服务器中的一个。如果候选者的日志至少和大多数服务器中的任何一个日志一样新（“最新”的定义如下），那么它将包含所有已提交的条目。RequestVote RPC 实现了这一限制：RPC 包含关于候选者日志的信息，如果投票者的日志比候选者的日志更新，它将拒绝投票。\nRaft 通过比较日志中最后一个条目的索引和任期来确定两个日志中哪个更新。如果日志的最后一个条目具有不同的任期，那么任期较晚的日志更新。如果日志以相同的任期结束，那么较长的日志更新。\n5.4.2 提交来自先前任期的条目 图8：一个时间序列，它显示了为什么领导者不能使用旧任期的日志条目来确定提交。在(a)中，S1是领导者，并部分复制了索引2处的日志条目。在(b)中，S1崩溃；S5在第3任期中被选为领导者，获得了S3、S4和自己的投票，并在日志索引2处接受了一个不同的条目。在(c)中，S5崩溃；S1重新启动，被选为领导者，并继续复制。在这一点上，第2任期的日志条目已经在大多数服务器上复制，但它尚未提交。如果S1如(d)中所示崩溃，S5可能会被选为领导者（获得S2、S3和S4的投票）并用其第3任期的条目覆盖该条目。然而，如果S1在崩溃前在大多数服务器上复制了其当前任期的一个条目，如(e)中所示，那么该条目就被提交了（S5无法赢得选举，因为日志不完整）。此时，日志中所有先前的条目也都被提交。 如第5.3节所述，领导者知道一旦其当前任期的条目存储在大多数服务器上，该条目就被提交。如果领导者在提交条目之前崩溃，未来的领导者将尝试完成该条目的复制。然而，领导者不能立即得出结论，认为一旦前一个任期的条目存储在大多数服务器上，该条目就被提交。图8展示了一种情况，其中旧的日志条目存储在大多数服务器上，但仍可能被未来的领导者覆盖。\n为了消除图8中类似的问题，Raft 从不通过计算副本数来提交前一个任期的日志条目。只有领导者当前任期的日志条目通过计算副本数来提交；一旦当前任期的条目以这种方式提交，那么由于日志匹配属性，所有之前的条目也间接提交。有些情况下，领导者可以安全地得出结论，认为旧的日志条目已提交（例如，如果该条目存储在每个服务器上），但为了简化，Raft 采取了更保守的方法。\nRaft 在提交规则中引入了额外的复杂性，因为当领导者复制前一个任期的条目时，日志条目保留其原始的任期号。在其他共识算法中，如果新领导者重新复制前一个“任期”的条目，它必须使用其新的“任期号”来进行复制。Raft 的方法使得推理日志条目更容易，因为它们在时间和日志之间保持相同的任期号。此外，Raft 中的新领导者发送的前一个任期的日志条目比其他算法少（其他算法必须发送冗余的日志条目以重新编号，然后才能提交它们）。\n5.4.3 安全性论证 图 9：如果 S1（任期 T 的领导者）在其任期中提交新的日志条目，并且 S5 被选为后续任期 U 的领导者，则必须至少有一个服务器 （S3） 接受日志条目并投票支持 S5。 给定完整的 Raft 算法，我们现在可以更精确地论证 Leader 完备性属性成立（该论证基于安全性证明；参见第 9.2 节）。我们假设 Leader 完备性属性不成立，然后我们证明矛盾。假设任期 T 的领导者（$leader_T$）提交了其任期内的日志条目，但该日志条目未被某个未来任期的领导者存储。考虑最小任期 U \u0026gt; T，其领导者（$leader_U$）不存储该条目。\n已提交的条目在 $leader_U$ 当选时必须不存在于其日志中（领导者从不删除或覆盖条目）。 $leader_T$ 在集群的大多数服务器上复制了该条目，而 $leader_U$ 获得了集群大多数服务器的投票。因此，至少有一台服务器（“投票者”）既接受了 $leader_T$ 的条目又投票给了 $leader_U$，如图9所示。投票者是得出矛盾的关键。 投票者必须在投票给 $leader_U$ 之前接受了 $leader_T$ 的已提交条目；否则，它会拒绝 $leader_T$ 的 AppendEntries 请求（其当前任期会高于 T）。 投票者在投票给 $leader_U$ 时仍然存储该条目，因为每个中间领导者都包含该条目（假设如此），领导者从不删除条目，跟随者只有在与领导者冲突时才会删除条目。 投票者将其票投给了 $leader_U$，因此 $leader_U$ 的日志必须与投票者的日志一样新。这导致了两个矛盾之一。 首先，如果投票者和 $leader_U$ 共享相同的最后一个日志任期，那么 $leader_U$ 的日志必须至少与投票者的日志一样长，因此其日志包含投票者日志中的每个条目。这是一个矛盾，因为投票者包含已提交的条目，而假设 $leader_U$ 不包含。 否则，$leader_U$ 的最后一个日志任期必须大于投票者的任期。此外，它大于 T，因为投票者的最后一个日志任期至少是 T（它包含来自 T 任期的已提交条目）。创建 $leader_U$ 最后一个日志条目的早期领导者必须在其日志中包含已提交的条目（假设如此）。然后，根据日志匹配属性，$leader_U$ 的日志也必须包含已提交的条目，这是一个矛盾。 这完成了矛盾。因此，所有大于 T 任期的领导者必须包含 T 任期中提交的所有条目。 日志匹配属性保证未来的领导者也将包含间接提交的条目，例如图8(d)中的索引2。 鉴于领导者完整性属性，我们可以证明图3中的状态机安全性属性，该属性指出，如果服务器在给定索引处将日志条目应用到其状态机，则没有其他服务器会为相同索引应用不同的日志条目。当服务器将日志条目应用到其状态机时，其日志必须与领导者的日志在该条目之前完全相同，并且该条目必须已提交。现在考虑任何服务器在给定日志索引处应用条目的最低任期；日志完整性属性保证所有更高任期的领导者将存储相同的日志条目，因此在后续任期中应用该索引的服务器将应用相同的值。因此，状态机安全性属性成立。\n最后，Raft 要求服务器按日志索引顺序应用条目。结合状态机安全性属性，这意味着所有服务器将以相同的顺序将完全相同的一组日志条目应用到其状态机。\n5.5 跟随者和候选者崩溃 到目前为止，我们一直关注领导者故障。追随者和候选者的崩溃比领导者崩溃更容易处理，而且处理方式相同。如果追随者或候选者崩溃，那么发送给它的未来 RequestVote 和 AppendEntries RPC 将失败。Raft 通过无限期重试来处理这些故障；如果崩溃的服务器重新启动，则 RPC 将成功完成。如果服务器在完成 RPC 后但在响应之前崩溃，则它将在重新启动后再次收到相同的 RPC。Raft RPC 是幂等的，因此不会造成任何损害。例如，如果追随者收到包含其日志中已存在的日志条目的 AppendEntries 请求，它将在新请求中忽略这些条目。\n5.6 时间与可用性 我们对 Raft 的一个要求是安全性不能依赖于时间：系统不能因为某些事件发生得比预期更快或更慢而产生错误结果。然而，可用性（系统及时响应客户端的能力）不可避免地必须依赖于时间。例如，如果消息交换的时间比服务器崩溃之间的典型时间更长，候选者将无法保持足够长的时间来赢得选举；没有稳定的领导者，Raft 无法取得进展。\n领导者选举是 Raft 中时间最关键的方面。只要系统满足以下时间要求，Raft 就能够选举并维持一个稳定的领导者：\n$$ broadcastTime \\ll electionTimeout \\ll MTBF $$\n在这个不等式中，广播时间（broadcastTime） 是服务器并行向集群中的每个服务器发送 RPC 并接收其响应的平均时间；选举超时（electionTimeout） 是第5.2节中描述的选举超时；MTBF 是单个服务器的平均故障间隔时间。广播时间应比选举超时小一个数量级，以便领导者能够可靠地发送心跳消息，防止跟随者启动选举；鉴于选举超时使用的随机化方法，这个不等式也使得分裂投票不太可能发生。选举超时应比 MTBF 小几个数量级，以便系统能够稳步前进。当领导者崩溃时，系统将大约在选举超时期间不可用；我们希望这只占总时间的一小部分。\n广播时间和 MTBF 是底层系统的属性，而选举超时是我们必须选择的。Raft 的 RPC 通常要求接收者将信息持久化到稳定存储，故广播时间可能在 0.5 毫秒到 20 毫秒之间，具体取决于存储技术。因此，选举超时可能在 10 毫秒到 500 毫秒之间。典型的服务器 MTBF 是几个月或更长时间，这很容易满足时间要求。\n6 集群成员身份变化 图 10： 直接从一种配置切换到另一种配置是不安全的，因为不同的服务器会在不同的时间切换。在此示例中，集群从三台服务器增长到五台。不幸的是，在某个时间点，可以选出两个不同的领导者担任同一任期，一个拥有旧配置的多数席位（Cold），另一个拥有新配置的多数席位（Cnew）。 到目前为止，我们一直假设集群配置（configuration）（参与共识算法的服务器集合）是固定不变的。但在实践中，偶尔需要改变配置，例如在服务器发生故障时替换服务器，或者改变副本的数量。虽然可以通过使整个集群离线、更新配置文件、然后重启集群的方式来完成这些改变，但这种方式会导致集群在变更期间不可用。此外，如果存在任何手动步骤，就会有操作员出错的风险。为了避免这些问题，我们决定将配置变更自动化，并将其整合到 Raft 共识算法中。\n对于配置变更机制来说，必须确保在转换过程中的任何时刻都不可能出现在同一任期内选举出两个领导者的情况。不幸的是，任何让服务器直接从旧配置切换到新配置的方法都是不安全的。由于无法让所有服务器同时原子性地切换，在转换过程中集群可能会分裂成两个独立的多数派（如图10所示）。\n为了确保安全性，配置变更必须采用两阶段的方法。实现这两个阶段有多种方式。例如，一些系统（如4）在第一阶段禁用旧配置使其无法处理客户端请求；然后在第二阶段启用新配置。在 Raft 中，集群首先切换到一个称为“联合共识”的过渡配置；一旦联合共识被提交，系统就会转换到新配置。联合共识将新旧配置结合在一起：\n日志条目会复制到两种配置中的所有服务器。 任一配置的任何服务器都可以充当领导者。 在达成一致（包括选举和日志条目提交）时，需要同时获得旧配置和新配置中的多数派同意。 联合共识允许各个服务器在不同时间点进行配置转换，同时不影响安全性。此外，联合共识使集群能够在整个配置变更过程中持续处理客户端请求。\n图 11：配置更改的时间表。虚线表示已创建但未提交的配置条目，实线表示最新提交的配置条目。领导者首先在其日志中创建 Cold,new 配置条目并将其提交给 Cold,new（大部分 Cold 和大部分 Cnew）。然后它创建 Cnew 条目并将其提交给大多数 Cnew。 Cold 和 Cnew 不存在可以同时独立做出决策的时间点。 集群配置通过复制日志中的特殊条目来存储和传输；图11展示了配置变更的过程。当领导者收到将配置从 $C_{old}$ 改变为 $C_{new}$ 的请求时，它会将联合共识的配置（图中的 $C_{old,new}）$作为一个日志条目存储，并使用之前描述的机制复制该条目。一旦某个服务器将新的配置条目添加到其日志中，它就会将该配置用于所有后续的决策（服务器总是使用其日志中最新的配置，无论该条目是否已提交）。这意味着领导者将使用 $C_{old,new}$ 的规则来确定 $C_{old,new}$,new 的日志条目何时被提交。如果领导者崩溃，新的领导者可能根据 $C_{old}$ 或 $C_{old,new}$被选出，这取决于获胜的候选者是否已收到 $C_{old,new}$。在任何情况下，$C_{new}$ 在此期间都不能单方面做出决策。\n一旦 $C_{old,new}$ 被提交，如果没有对方的认可，$C_{old}$ 和 $C_{new}$ 都不能做出决策，并且领导者完整性属性确保只有具有 $C_{old,new}$ 日志条目的服务器才能被选举为领导者。此时，领导者就可以安全地创建描述 $C_{new}$ 的日志条目并将其复制到集群中。同样，这个配置在每个服务器看到时就会立即生效。当新配置在 $C_{new}$ 规则下被提交后，旧配置就变得无关紧要了，不在新配置中的服务器可以被关闭。如图11所示，不存在 $C_{old}$ 和 $C_{new}$ 都能单方面做出决策的时间点；这保证了安全性。\n对于重新配置，还有三个问题需要解决。第一个问题是新服务器最初可能不存储任何日志条目。如果在这种状态下将它们加入集群，它们可能需要相当长的时间才能赶上进度，在此期间可能无法提交新的日志条目。为了避免可用性中断，Raft 在配置变更之前引入了一个额外的阶段，在这个阶段中，新服务器以非投票成员的身份加入集群（领导者会向它们复制日志条目，但不将它们计入多数派）。一旦新服务器赶上了集群的其余部分，就可以按照上述方式进行重新配置。\n第二个问题是集群领导者可能不属于新配置。在这种情况下，一旦领导者提交了 $C_{new}$ 日志条目，就会主动退位（返回追随者状态）。这意味着会有一段时间（在提交 $C_{new}$ 期间）领导者在管理一个不包含自己的集群；它会复制日志条目，但在计算多数派时不将自己计算在内。领导者交接发生在 $C_{new}$ 被提交时，因为这是新配置能够独立运作的第一个时间点（从 $C_{new}$ 中总能选出一个领导者）。在此之前，可能只有来自 $C_{old}$ 的服务器才能被选举为领导者。\n第三个问题是被移除的服务器（不在 $C_{new}$ 中的服务器）可能会扰乱集群。这些服务器将收不到心跳，因此它们会超时并开始新的选举。然后它们会发送带有新任期号的 RequestVote RPC，这将导致当前领导者退回到追随者状态。最终会选出新的领导者，但被移除的服务器会再次超时，这个过程会重复发生，导致可用性降低。\n为了防止这个问题，当服务器认为存在当前领导者时，会忽略 RequestVote RPC。具体来说，如果服务器在最小选举超时时间内收到过当前领导者的消息，那么当它收到 RequestVote RPC 时，既不会更新自己的任期号，也不会投票。这不会影响正常的选举，因为在正常选举中，每个服务器都会至少等待最小选举超时时间才开始选举。然而，这有助于避免被移除服务器的干扰：如果领导者能够向其集群发送心跳，那么它就不会因为更大的任期号而被废黜。\n7 日志压缩 在正常操作过程中，Raft 的日志会不断增长以包含更多的客户端请求，但在实际系统中，它不能无限制地增长。随着日志变得越来越长，它会占用更多的空间并需要更多的时间来重放。如果没有某种机制来丢弃日志中累积的过时信息，最终会导致可用性问题。\n快照是最简单的压缩方法。在快照机制中，整个当前系统状态被写入稳定存储中的 快照（snapshot） 文件，然后该时间点之前的所有日志都可以被丢弃。快照机制在 Chubby 和 ZooKeeper 中都有使用，本节的剩余部分将描述 Raft 中的快照机制。\n增量压缩的方法也是可行的，比如日志清理18和日志结构合并树19 20。这些方法每次只处理部分数据，因此可以将压缩的负载更均匀地分散到不同时间点。它们首先选择一个已经累积了许多已删除和被覆盖对象的数据区域，然后更紧凑地重写该区域中的活跃对象，并释放该区域的空间。与快照相比，这需要大量额外的机制和复杂性，而快照通过始终对整个数据集进行操作来简化问题。虽然日志清理需要对 Raft 进行修改，但状态机可以使用与快照相同的接口来实现 LSM 树。\n图 12：服务器用新快照替换其日志中已提交的条目（索引 1 到 5），新快照仅存储当前状态（本例中的变量 x 和 y）。快照最后包含的索引和任期用于将快照定位在日志中条目 6 之前。 图12展示了Raft中快照的基本概念。每个服务器独立地进行快照，只覆盖其日志中的已提交条目。大部分工作由状态机将其当前状态写入快照中完成。Raft还在快照中包含少量元数据：最后包含的索引（last included index） 是快照替换的日志中最后一个条目的索引（状态机已应用的最后一个条目），最后包含的任期（last included term） 是该条目的任期。这些数据被保留以支持快照后第一个日志条目的AppendEntries一致性检查，因为该条目需要前一个日志索引和任期。为了支持集群成员变更（第6节），快照还包括截至最后包含索引的最新配置。一旦服务器完成快照写入，它可以删除所有通过最后包含索引的日志条目以及任何先前的快照。\n虽然服务器通常独立进行快照，但领导者有时必须向落后的追随者发送快照。当领导者已经丢弃了需要发送给追随者的下一个日志条目时，就会发生这种情况。幸运的是，这种情况在正常操作中不太可能发生：一个跟上领导者的追随者已经拥有这个条目。然而，一个异常缓慢的追随者或一个新加入集群的服务器（第6节）则不会。使这样的追随者更新的方法是领导者通过网络向其发送快照。\n图 13：InstallSnapshot RPC 的总结。快照被分割成块进行传输；这为追随者提供了每个块的生命迹象，因此它可以重置其选举计时器。 InstallSnapshot RPC\r由领导者调用以将快照块发送给追随者。领导者总是按顺序发送块。\r参数：\rterm\r领导者的任期\rleaderID\r正在请求投票的候选者\rlastIncludedIndex\r快照将替换该索引之前的所有条目（包括该索引）\rlastIncludedTerm\rlastIncludedIndex的任期\roffset\r快照文件中块所在的字节偏移量\rdata[]\r快照块的原始字节，从偏移量开始\rdone\r如果这是最后一个块则为 true\r结果：\rterm\rcurrentTerm，供领导者自我更新\rvoteGranted\rtrue 表示候选者获得选票\r接收者实现：\r如果 term \u003c currentTerm 则立即回复\r如果是第一个块（偏移量为 0）则创建新的快照文件\r将数据写入给定偏移量的快照文件\r如果 done 为 false，则回复并等待更多数据块\r保存快照文件，丢弃任何现有的或索引较小的部分快照\r如果现有日志条目与快照最后包含的条目具有相同的索引和任期，则保留其后面的日志条目并回复\r丢弃整个日志\r使用快照内容重置状态机（并加载快照的集群配置）\r领导者使用一个称为InstallSnapshot的新RPC来向落后太多的跟随者发送快照，如图13所示。当跟随者通过这个RPC接收到快照时，它必须决定如何处理其现有的日志条目。通常情况下，快照会包含接收者日志中尚未存在的新信息。在这种情况下，跟随者会丢弃其全部日志，因为这些日志都被快照取代了，并且可能包含与快照相冲突的未提交条目。如果跟随者接收到的快照描述的是其日志的前缀部分（由于重传或错误导致），那么被快照覆盖的日志条目会被删除，但快照之后的条目仍然有效且必须保留。\n这种快照方法偏离了Raft的强领导原则，因为追随者可以在领导者不知情的情况下进行快照。然而，我们认为这种偏离是合理的。虽然拥有一个领导者有助于避免在达成共识时出现冲突决策，但在进行快照时共识已经达成，因此不会有决策冲突。数据仍然只从领导者流向追随者，只是追随者现在可以重新组织他们的数据。\n我们考虑了一种基于领导者的替代方法，即只有领导者创建快照，然后将此快照发送给每个追随者。然而，这有两个缺点。首先，将快照发送给每个追随者会浪费网络带宽并减慢快照过程。每个追随者已经拥有生成其自身快照所需的信息，通常服务器从其本地状态生成快照比通过网络发送和接收快照所消耗的代价小得多。其次，领导者的实现会更加复杂。例如，领导者需要在向追随者复制新的日志条目的同时并行发送快照，以免阻塞新的客户端请求。\n还有两个问题会影响快照性能。首先，服务器必须决定何时进行快照。如果服务器快照过于频繁，会浪费磁盘带宽和能源；如果快照过于不频繁，则有耗尽存储容量的风险，并且在重启时重放日志所需的时间会增加。一种简单的策略是在日志达到固定字节大小时进行快照。如果这个大小设置得明显大于预期的快照大小，那么快照的磁盘带宽开销将很小。\n第二个性能问题是写入快照可能需要相当长的时间，我们不希望这会延迟正常操作。解决方案是使用写时复制技术，以便在不影响正在写入的快照的情况下接受新的更新。例如，用函数式数据结构构建的状态机自然支持这一点。或者，可以使用操作系统的写时复制支持（例如，Linux上的fork）来创建整个状态机的内存快照（我们的实现使用这种方法）。\n8 客户端交互 本节描述了客户端如何与Raft交互，包括客户端如何找到集群领导者以及Raft如何支持线性化语义21。这些问题适用于所有基于共识的系统，Raft的解决方案与其他系统类似。\nRaft的客户端将所有请求发送给领导者。当客户端首次启动时，它会连接到一个随机选择的服务器。如果客户端的第一个选择不是领导者，该服务器将拒绝客户端的请求并提供其所知的最近领导者的信息（AppendEntries请求包括领导者的网络地址）。如果领导者崩溃，客户端请求将超时；客户端然后尝试与随机选择的服务器重新连接。\n我们对Raft的目标是实现线性化语义（每个操作看起来像是在其调用和响应之间的某个点瞬时执行且仅执行一次）。然而，如前所述，Raft可能会多次执行一个命令：例如，如果领导者在提交日志条目后但在响应客户端之前崩溃，客户端将会重试该命令并与新的领导者联系，导致该命令被再次执行。解决方案是客户端为每个命令分配唯一的序列号。然后，状态机跟踪每个客户端处理的最新序列号及其关联的响应。如果它收到一个序列号已经执行过的命令，它会立即响应而不重新执行该请求。\n只读操作可以在不写入日志的情况下处理。然而，如果没有额外的措施，这将有返回过时数据的风险，因为响应请求的领导者可能已经被一个它不知道的新领导者取代。线性化读取不能返回过时数据，Raft需要两个额外的预防措施来保证这一点而不使用日志。首先，领导者必须拥有最新的已提交条目信息。领导者完整性属性保证了领导者拥有所有已提交的条目，但在其任期开始时，它可能不知道这些条目是什么。为了找出这些条目，它需要提交一个来自其任期的条目。Raft通过在每个领导者任期开始时提交一个空的无操作条目到日志中来处理这一点。其次，领导者在处理只读请求之前必须检查它是否已被罢免（如果选出了一个更新的领导者，它的信息可能已经过时）。Raft通过让领导者在响应只读请求之前与集群的大多数节点交换心跳消息来处理这一点。或者，领导者可以依赖心跳机制提供一种租约形式22，但这将依赖于时间的安全性（假设时钟偏差是有界的）。\n9 实现与评估 我们将 Raft 实现为复制状态机的一部分，该状态机存储 RAMCloud 8 的配置信息并协助 RAMCloud 协调器进行故障转移。 Raft 实现包含大约 2000 行 C++ 代码，不包括测试、注释或空行。源代码可以免费获得23。根据本文的草稿，还有大约 25 个处于不同开发阶段的 Raft 独立第三方开源实现 24。此外，多家公司正在部署基于 Raft 的系统 24。本节的其余部分使用三个标准评估 Raft：可理解性、正确性和性能。\n9.1 可理解性 为了测量Raft相对于Paxos的可理解性，我们在斯坦福大学的高级操作系统课程和加州大学伯克利分校的分布式计算课程中，以高年级本科生和研究生为对象进行了一项实验研究。我们录制了一个关于Raft的视频讲座和一个关于Paxos的视频讲座，并制作了相应的测验。Raft讲座涵盖了本论文的内容（除了日志压缩）；Paxos讲座涵盖了足够多的内容来创建一个等效的复制状态机，包括单决策Paxos、多决策Paxos、重新配置，以及在实践中需要的一些优化（如领导者选举）。这些测验考察了对算法的基本理解，还要求学生对边界情况进行推理。每个学生观看一个视频，完成相应的测验，然后观看第二个视频，完成第二个测验。为了考虑个人表现差异和从研究第一部分获得的经验，大约一半的参与者先学习Paxos部分，另一半先学习Raft部分。我们比较了参与者在每个测验中的得分，以确定参与者是否对Raft表现出更好的理解。\n表 1：研究中对 Paxos 可能存在的偏见的担忧、针对每种偏见采取的措施以及可用的其他材料。 担忧 为减少偏见而采取的措施 供审查的材料 2526 同等的授课质量 两者的讲师相同。 Paxos 讲座基于几所大学使用的现有材料并对其进行了改进。 Paxos 讲座时间延长了 14%。 视频 同等的测验难度 问题按难度分组并在考试中配对。 测验 公平评分 使用的标题。按随机顺序评分，测验之间交替进行。 标题 我们尽量使Paxos和Raft之间的比较尽可能公平。实验在两个方面偏向了Paxos：43名参与者中有15人报告说他们有一些Paxos的先前经验，并且Paxos视频比Raft视频长14%。如表1所示，我们采取了措施来减轻潜在的偏见来源。我们所有的材料都可供审查25 26。\n图 14：比较 43 名参与者在 Raft 和 Paxos 测验中表现的散点图。对角线上方的点 (33) 代表 Raft 得分较高的参与者。 平均而言，参与者在Raft测验中的得分比在Paxos测验中高4.9分（满分60分，Raft的平均得分为25.7分，Paxos的平均得分为20.8分）；图14显示了他们的个人得分。配对t检验表明，在95%的置信水平下，Raft得分的真实分布的均值至少比Paxos得分的真实分布高2.5分。\n我们还创建了一个线性回归模型，根据三个因素预测新学生的测验得分：他们参加的测验、他们的先前Paxos经验程度以及他们学习算法的顺序。该模型预测测验的选择会导致Raft得分高出12.5分。这显著高于观察到的4.9分差异，因为许多实际学生有先前的Paxos经验，这大大帮助了Paxos，而对Raft的帮助稍小一些。有趣的是，该模型还预测已经参加过Paxos测验的人在Raft测验中的得分会低6.3分；虽然我们不知道为什么，但这似乎在统计上显著。\n图 15：使用 5 分制，参与者被问到（左）他们认为哪种算法更容易在功能正常、正确且高效的系统中实现，以及（右）哪种算法更容易向计算机科学研究生解释。 我们还在测验后对参与者进行了调查，了解他们认为哪种算法更容易实现或解释；这些结果如图15所示。绝大多数参与者报告说Raft更容易实现和解释（每个问题41人中有33人）。然而，这些自我报告的感受可能不如参与者的测验得分可靠，并且参与者可能因为知道我们的假设是Raft更容易理解而存在偏见。\n关于Raft用户研究的详细讨论，请参见26。\n9.2 正确性 我们已经开发了一个正式规范和一个关于第5节中描述的共识机制的安全性证明。正式规范26使用TLA+规范语言27使图2中总结的信息完全精确。它大约有400行长，并作为证明的主题。对于任何实现Raft的人来说，它本身也很有用。我们使用TLA证明系统28机械地证明了日志完整性属性。然而，这个证明依赖于尚未机械检查的不变量（例如，我们尚未证明规范的类型安全性）。此外，我们还撰写了一份关于状态机安全性属性的非正式证明26，该证明是完整的（仅依赖于规范）且相对精确（大约3500字长）。\n9.3 性能 Raft的性能与其他共识算法（如Paxos）相似。性能最重要的情况是当一个已建立的领导者正在复制新的日志条目时。Raft通过使用最少数量的消息（从领导者到集群一半节点的单次往返）来实现这一点。还可以进一步提高Raft的性能。例如，它可以轻松支持批处理和流水线请求，以实现更高的吞吐量和更低的延迟。文献中提出了各种针对其他算法的优化；其中许多可以应用于Raft，但我们将其留待未来工作。\n我们使用Raft的实现来测量Raft的领导者选举算法的性能，并回答两个问题。首先，选举过程是否快速收敛？其次，在领导者崩溃后可以实现的最小停机时间是多少？\n图 16：检测和更换崩溃的领导者的时间。上图改变了选举超时的随机性，下图则缩放了最小选举超时。每行代表 1000 次试验（“150-150ms”的 100 次试验除外），并对应于选举超时的特定选择；例如，“150–155ms”表示选举超时在150ms到155ms之间随机且均匀地选择。测量是在由 5 台服务器组成的集群上进行的，广播时间约为 15 毫秒。由九台服务器组成的集群的结果类似。 为了测量领导者选举，我们反复使五个服务器组成的集群的领导者崩溃，并计时检测到崩溃和选举新领导者所需的时间（见图16）。为了生成最坏情况场景，每次测试中的服务器都有不同的日志长度，因此某些候选人没有资格成为领导者。此外，为了促使选票分散，我们的测试脚本在终止领导者进程之前触发了一次同步的心跳RPC广播（这近似于领导者在崩溃前复制新日志条目的行为）。领导者在其心跳间隔内随机均匀地崩溃，该间隔是所有测试中最小选举超时时间的一半。因此，最短可能的停机时间约为最小选举超时时间的一半。\n图16的上部图显示，选举超时时间的少量随机化就足以避免选举中的选票分散。在没有随机性的情况下，由于许多选票分散，我们的测试中领导者选举始终需要超过10秒。仅添加5毫秒的随机性就能显著改善，使中位停机时间降至287毫秒。增加更多随机性可以改善最坏情况下的表现：使用50毫秒的随机性时，最坏情况下的完成时间（超过1000次测试）为513毫秒。\n图16的下部图显示，通过减少选举超时时间可以减少停机时间。当选举超时时间为12-24毫秒时，选举领导者平均只需要35毫秒（最长的测试花费152毫秒）。然而，将超时时间降低到这个点以下会违反Raft的时间要求：领导者在其他服务器开始新的选举之前难以广播心跳。这可能导致不必要的领导者更换并降低整体系统可用性。我们建议使用较为保守的选举超时时间，如150-300毫秒；这样的超时时间不太可能导致不必要的领导者更换，同时仍能提供良好的可用性。\n10 相关工作 有许多关于共识算法的出版物，其中许多可以归入以下几类之一：\nLamport对Paxos的原始描述1，以及试图更清晰地解释它的尝试2 11 12。 对Paxos的详细阐述，填补了缺失的细节并修改了算法，以提供更好的实现基础13 14 15。 实现共识算法的系统，如Chubby9 16、ZooKeeper10 [^12]和Spanner29。虽然Chubby和Spanner的算法没有详细发表，但它们都声称基于Paxos。ZooKeeper的算法已更详细地发表，但它与Paxos有很大不同。 可以应用于Paxos的性能优化30 31 32 33 34 35。 Oki和Liskov的Viewstamped Replication (VR)，这是与Paxos同时期开发的另一种共识方法。原始描述3与分布式事务协议交织在一起，但核心共识协议在最近的更新中已被分离出来4。VR使用了一种基于领导者的方法，与Raft有许多相似之处。 Raft和Paxos之间最大的区别在于Raft的强领导性：Raft将领导者选举作为共识协议的一个基本部分，并尽可能多地将功能集中在领导者身上。这种方法产生了一个更简单且更易于理解的算法。例如，在Paxos中，领导者选举与基本共识协议是正交的：它仅作为性能优化，不是实现共识所必需的。然而，这导致了额外的机制：Paxos包括一个用于基本共识的两阶段协议和一个单独的领导者选举机制。相比之下，Raft将领导者选举直接纳入共识算法，并将其作为共识的两个阶段中的第一个。这导致了比Paxos更少的机制。\n与Raft类似，VR和ZooKeeper也是基于领导者的，因此它们与Raft相比具有许多优势。然而，Raft的机制比VR或ZooKeeper更少，因为它最小化了非领导者的功能。例如，Raft中的日志条目只在一个方向上流动：通过AppendEntries RPC从领导者向外流动。在VR中，日志条目在两个方向上流动（领导者在选举过程中可以接收日志条目）；这导致了额外的机制和复杂性。ZooKeeper的已发布描述也显示日志条目在领导者之间双向传输，但其实现显然更像Raft36。\nRaft的消息类型比我们所知的任何其他基于共识的日志复制算法都要少。例如，我们统计了VR和ZooKeeper用于基本共识和成员变更的消息类型（不包括日志压缩和客户端交互，因为这些几乎与算法无关）。VR和ZooKeeper各定义了10种不同的消息类型，而Raft只有4种消息类型（两个RPC请求及其响应）。Raft的消息比其他算法的消息更密集一些，但总体上更简单。此外，VR和ZooKeeper在领导者变更期间传输整个日志；为了使这些机制实用，还需要额外的消息类型来优化这些机制。\nRaft的强领导方法简化了算法，但它排除了某些性能优化。例如，Egalitarian Paxos (EPaxos)在某些条件下可以通过无领导方法实现更高的性能35。EPaxos利用状态机命令的可交换性。只要并发提出的其他命令与其可交换，任何服务器都可以通过一轮通信提交一个命令。然而，如果并发提出的命令彼此不可交换，EPaxos需要额外一轮通信。由于任何服务器都可以提交命令，EPaxos在服务器之间很好地平衡了负载，并且在广域网环境中能够实现比Raft更低的延迟。然而，这增加了Paxos的复杂性。\n在其他工作中提出或实现了几种不同的集群成员变更方法，包括Lamport的原始提议1、VR4和SMART37。我们为Raft选择了联合共识方法，因为它利用了其余的共识协议，因此成员变更所需的额外机制非常少。Lamport的基于α的方法不适用于Raft，因为它假设可以在没有领导者的情况下达成共识。与VR和SMART相比，Raft的重新配置算法的优势在于成员变更可以在不限制正常请求处理的情况下进行；相反，VR在配置变更期间停止所有正常处理，而SMART对未完成请求的数量施加了类似α的限制。Raft的方法也比VR或SMART增加了更少的机制。\n11 结论 算法通常以正确性、效率和/或简洁性为主要目标进行设计。虽然这些都是值得追求的目标，但我们认为可理解性同样重要。在开发人员将算法转化为实际实现之前，其他目标都无法实现，而这不可避免地会偏离并扩展已发布的形式。除非开发人员对算法有深刻的理解并能形成直觉，否则他们很难在实现中保留其理想特性。\n在本文中，我们解决了分布式共识问题，其中一个广泛接受但难以理解的算法Paxos多年来一直困扰着学生和开发人员。我们开发了一种新算法Raft，并证明它比Paxos更易于理解。我们还认为Raft为系统构建提供了更好的基础。将可理解性作为主要设计目标改变了我们设计Raft的方法；随着设计的进展，我们发现自己反复使用一些技术，例如分解问题和简化状态空间。这些技术不仅提高了Raft的可理解性，还使我们更容易确信其正确性。\n12 致谢 用户研究得到了Ali Ghodsi、David Mazie`res以及伯克利大学CS 294-91课程和斯坦福大学CS 240课程学生的支持，才得以进行。Scott Klemmer帮助我们设计了用户研究，Nelson Ray在统计分析方面提供了建议。用户研究的Paxos幻灯片大量借用了Lorenzo Alvisi最初创建的幻灯片。特别感谢David Mazie`res和Ezra Hoch发现了Raft中的一些微妙错误。许多人对论文和用户研究材料提供了有益的反馈，包括Ed Bugnion、Michael Chan、Hugues Evrard、Daniel Giffin、Arjun Gopalan、Jon Howell、Vimalkumar Jeyakumar、Ankita Kejriwal、Aleksandar Kracun、Amit Levy、Joel Martin、Satoshi Matsushita、Oleg Pesok、David Ramos、Robbert van Renesse、Mendel Rosenblum、Nicolas Schiper、Deian Stefan、Andrew Stone、Ryan Stutsman、David Terei、Stephen Yang、Matei Zaharia、24位匿名会议评审（包括重复），特别是我们的指导人Eddie Kohler。Werner Vogels在推特上分享了早期草稿的链接，使Raft得到了广泛关注。这项工作得到了Gigascale Systems Research Center和Multiscale Systems Center的支持，这两个中心是半导体研究公司项目Focus Center Research Program资助的六个研究中心之一，还得到了由MARCO和DARPA赞助的半导体研究公司项目STARnet的支持，国家科学基金会的资助（资助号0963859），以及来自Facebook、Google、Mellanox、NEC、NetApp、SAP和三星的资助。Diego Ongaro得到了The Junglee Corporation Stanford Graduate Fellowship的支持。\n参考文献 LAMPORT, L. The part-time parliament. ACM Transactions on Computer Systems 16, 2 (May 1998), 133–169.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nLAMPORT, L. Paxos made simple. ACM SIGACT News 32, 4 (Dec. 2001), 18–25.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nOKI, B. M., AND LISKOV, B. H. Viewstamped replication: A new primary copy method to support highly-available distributed systems. In Proc. PODC’88, ACM Symposium on Principles of Distributed Computing (1988), ACM, pp. 8–17.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nLISKOV, B., AND COWLING, J. Viewstamped replication revisited. Tech. Rep. MIT-CSAIL-TR-2012-021, MIT, July 2012.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nSCHNEIDER, F. B. Implementing fault-tolerant services using the state machine approach: a tutorial. ACM Computing Surveys 22, 4 (Dec. 1990), 299–319.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nGHEMAWAT, S., GOBIOFF, H., AND LEUNG, S.-T. The Google file system. In Proc. SOSP’03, ACM Symposium on Operating Systems Principles (2003), ACM, pp. 29–43.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nSHVACHKO, K., KUANG, H., RADIA, S., AND CHANSLER, R. The Hadoop distributed file system. In Proc. MSST’10, Symposium on Mass Storage Systems and Technologies (2010), IEEE Computer Society, pp. 1–10.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nOUSTERHOUT, J., AGRAWAL, P., ERICKSON, D., KOZYRAKIS, C., LEVERICH, J., MAZIE` RES, D., MITRA, S., NARAYANAN, A., ONGARO, D., PARULKAR, G., ROSENBLUM, M., RUMBLE, S. M., STRATMANN, E., AND STUTSMAN, R. The case for RAMCloud. Communications of the ACM 54 (July 2011), 121–130.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nBURROWS, M. The Chubby lock service for looselycoupled distributed systems. In Proc. OSDI’06, Symposium on Operating Systems Design and Implementation (2006), USENIX, pp. 335–350.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nHUNT, P., KONAR, M., JUNQUEIRA, F. P., AND REED, B. ZooKeeper: wait-free coordination for internet-scale systems. In Proc ATC’10, USENIX Annual Technical Conference (2010), USENIX, pp. 145–158.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nLAMPSON, B. W. How to build a highly available system using consensus. In Distributed Algorithms, O. Baboaglu and K. Marzullo, Eds. Springer-Verlag, 1996, pp. 1–17.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nLAMPSON, B. W. The ABCD’s of Paxos. In Proc. PODC’01, ACM Symposium on Principles of Distributed Computing (2001), ACM, pp. 13–13.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMAZIE` RES, D. Paxos made practical. http: //www.scs.stanford.edu/ ̃dm/home/ papers/paxos.pdf, Jan. 2007.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nVAN RENESSE, R. Paxos made moderately complex. Tech. rep., Cornell University, 2012.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nKIRSCH, J., AND AMIR, Y. Paxos for system builders. Tech. Rep. CNDS-2008-2, Johns Hopkins University, 2008.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nCHANDRA, T. D., GRIESEMER, R., AND REDSTONE, J. Paxos made live: an engineering perspective. In Proc. PODC’07, ACM Symposium on Principles of Distributed Computing (2007), ACM, pp. 398–407.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nLAMPORT, L. Time, clocks, and the ordering of events in a distributed system. Commununications of the ACM 21, 7 (July 1978), 558–565.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nROSENBLUM, M., AND OUSTERHOUT, J. K. The design and implementation of a log-structured file system. ACM Trans. Comput. Syst. 10 (February 1992), 26–52.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nO’NEIL, P., CHENG, E., GAWLICK, D., AND ONEIL, E. The log-structured merge-tree (LSM-tree). Acta Informatica 33, 4 (1996), 351–385.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nCHANG, F., DEAN, J., GHEMAWAT, S., HSIEH, W. C., WALLACH, D. A., BURROWS, M., CHANDRA, T., FIKES, A., AND GRUBER, R. E. Bigtable: a distributed storage system for structured data. In Proc. OSDI’06, USENIX Symposium on Operating Systems Design and Implementation (2006), USENIX, pp. 205–218.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nHERLIHY, M. P., AND WING, J. M. Linearizability: a correctness condition for concurrent objects. ACM Transactions on Programming Languages and Systems 12 (July 1990), 463–492.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nGRAY, C., AND CHERITON, D. Leases: An efficient faulttolerant mechanism for distributed file cache consistency. In Proceedings of the 12th ACM Ssymposium on Operating Systems Principles (1989), pp. 202–210.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nLogCabin source code. http://github.com/logcabin/logcabin.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nRaft consensus algorithm website. http://raftconsensus.github.io.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nRaft user study. http://ramcloud.stanford. edu/ ̃ongaro/userstudy/.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nONGARO, D. Consensus: Bridging Theory and Practice. PhD thesis, Stanford University, 2014 (work in progress). http://ramcloud.stanford.edu/ ̃ongaro/ thesis.pdf.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nLAMPORT, L. Specifying Systems, The TLA+ Language and Tools for Hardware and Software Engineers. AddisonWesley, 2002.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nCOUSINEAU, D., DOLIGEZ, D., LAMPORT, L., MERZ, S., RICKETTS, D., AND VANZETTO, H. TLA+ proofs. In Proc. FM’12, Symposium on Formal Methods (2012), D. Giannakopoulou and D. M ́ery, Eds., vol. 7436 of Lecture Notes in Computer Science, Springer, pp. 147–154.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nCORBETT, J. C., DEAN, J., EPSTEIN, M., FIKES, A., FROST, C., FURMAN, J. J., GHEMAWAT, S., GUBAREV, A., HEISER, C., HOCHSCHILD, P., HSIEH, W., KANTHAK, S., KOGAN, E., LI, H., LLOYD, A., MELNIK, S., MWAURA, D., NAGLE, D., QUINLAN, S., RAO, R., ROLIG, L., SAITO, Y., SZYMANIAK, M., TAYLOR, C., WANG, R., AND WOODFORD, D. Spanner: Google’s globally-distributed database. In Proc. OSDI’12, USENIX Conference on Operating Systems Design and Implementation (2012), USENIX, pp. 251–264.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nLAMPORT, L. Generalized consensus and Paxos. Tech. Rep. MSR-TR-2005-33, Microsoft Research, 2005.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nLAMPORT, L. Fast paxos. Distributed Computing 19, 2 (2006), 79–103.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nCAMARGOS, L. J., SCHMIDT, R. M., AND PEDONE, F. Multicoordinated Paxos. In Proc. PODC’07, ACM Symposium on Principles of Distributed Computing (2007), ACM, pp. 316–317.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMAO, Y., JUNQUEIRA, F. P., AND MARZULLO, K. Mencius: building efficient replicated state machines for WANs. In Proc. OSDI’08, USENIX Conference on Operating Systems Design and Implementation (2008), USENIX, pp. 369–384.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nBOLOSKY, W. J., BRADSHAW, D., HAAGENS, R. B., KUSTERS, N. P., AND LI, P. Paxos replicated state machines as the basis of a high-performance data store. In Proc. NSDI’11, USENIX Conference on Networked Systems Design and Implementation (2011), USENIX, pp. 141–154.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMORARU, I., ANDERSEN, D. G., AND KAMINSKY, M. There is more consensus in egalitarian parliaments. In Proc. SOSP’13, ACM Symposium on Operating System Principles (2013), ACM.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nREED, B. Personal communications, May 17, 2013.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nLORCH, J. R., ADYA, A., BOLOSKY, W. J., CHAIKEN, R., DOUCEUR, J. R., AND HOWELL, J. The SMART way to migrate replicated stateful services. In Proc. EuroSys’06, ACM SIGOPS/EuroSys European Conference on Computer Systems (2006), ACM, pp. 103–115.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://fireflyyh.top/posts/distributionsystem/raft/","summary":"Diego Ongaro and John Ousterhout Stanford University\r摘要 Raft 是一种用于管理复制日志的共识算法。它能够产生与(多)Paxos 相同的结果，并且效率与 Paxos 相当，但其结构与 Paxos 不同。这种结构上的差异使得 Raft 比 Paxos 更容易理解，同时也为构建实际系统提供了更好的基础。为了提升可理解性，Raft 将共识的关键要素进行了分离，如领导者选举、日志复制和安全性保证等，并且强化了一致性要求以减少需要考虑的状态数量。用户研究的结果表明，相比 Paxos，学生们更容易掌握 Raft。此外，Raft 还引入了一种新的集群成员变更机制，该机制通过使用重叠的多数派来保证安全性。\n1 引言 共识算法使得一组机器能够作为一个连贯的整体工作，并且能够在部分成员发生故障时继续运行。正因如此，这类算法在构建可靠的大规模软件系统中发挥着关键作用。在过去的十年里，Paxos1 2主导了关于共识算法的讨论：大多数共识算法的实现要么基于 Paxos，要么受到它的影响，而且 Paxos 已经成为向学生教授共识知识的主要载体。\n不幸的是，尽管已经有许多让它变得更容易理解的尝试，Paxos 仍然非常难以理解。此外，它的架构需要进行复杂的改动才能支持实际系统。因此，系统构建者和学生都在与 Paxos 作斗争。\n在我们自己也经历过与 Paxos 搏斗之后，我们着手寻找一种新的共识算法，希望它能为系统构建和教育提供更好的基础。我们采用了一种不同寻常的方式，即将 可理解性（understandability） 作为首要目标：我们能否定义一个用于实际系统的共识算法，并以一种比 Paxos 容易得多的方式来描述它？此外，我们希望这个算法能够帮助系统构建者形成必要的直观认识。重要的不仅是算法能够工作，更重要的是能够清楚地理解为什么它能工作。\n这项工作的成果就是一个称为 Raft 的共识算法。在设计 Raft 时，我们应用了特定的技术来提高可理解性，包括分解（Raft 将领导者选举、日志复制和安全性分开）和状态空间简化（相比 Paxos，Raft 减少了不确定性的程度以及服务器之间可能产生不一致的方式）。在两所大学进行的涉及 43 名学生的用户研究表明，Raft 比 Paxos 更容易理解:在学习了这两种算法之后，其中 33 名学生对 Raft 的相关问题回答得比 Paxos 的问题要好。\nRaft 在许多方面与现有的共识算法相似（最值得注意的是 Oki 和 Liskov 的 Viewstamped Replication 3 4），但它有几个新颖的特点：","title":"[论文翻译]In Search of an Understandable Consensus Algorithm  (Extended Version)"},{"content":"摘要 MapReduce 是一种用于处理和生成大型数据集的编程模型和相关实现。用户指定一个 map 函数来处理键/值对，生成一组中间键/值对，并指定一个 reduce 函数来合并与同一中间键相关的所有中间值。如本文所示，许多现实世界中的任务都可以用这个模型来表达。\n以这种函数式风格编写的程序会自动并行化，并在大型商用机器集群上执行。运行时系统会处理分割输入数据、调度程序在一组机器上的执行、处理机器故障以及管理所需的机器间通信等细节。这样，没有任何并行和分布式系统经验的程序员也能轻松利用大型分布式系统的资源。\n我们的 MapReduce 实现运行在大型商用机器集群上，并且具有高度可扩展性：典型的 MapReduce 计算在数千台机器上处理数 TB 的数据。程序员发现该系统易于使用：数百个 MapReduce 程序已经实现，并且每天在 Google 集群上执行超过一千个 MapReduce 作业。\n1 引言 在过去五年中，本文作者和 Google 的许多其他人已经实现了数百种特殊用途的计算，这些计算处理大量原始数据（例如抓取的文档、Web 请求日志等），以计算各种派生数据（例如倒排索引、Web 文档图形结构的各种表示、每个主机抓取的页面数量摘要、给定一天中最频繁的查询集等）。大多数此类计算在概念上都很简单。但是，输入数据通常很大，并且计算必须分布在数百或数千台机器上才能在合理的时间内完成。如何并行化计算、分发数据和处理故障的问题共同掩盖了原始的简单计算，并使用大量复杂的代码来处理这些问题。\n为了应对这种复杂性，我们设计了一种新的抽象，它允许我们表达我们试图执行的简单计算，但隐藏了库中的并行化、容错、数据分布和负载平衡的复杂细节。我们的抽象受到 Lisp 和许多其他函数式语言中存在的 map 和 Reduce 原语的启发。我们意识到，我们的大多数计算都涉及将 map 操作应用于输入中的每个逻辑“记录”，以计算一组中间键/值对，然后对共享相同键的所有值应用 Reduce 操作，以便适当地组合派生数据。我们使用具有用户指定的 map 和 Reduce 操作的函数模型，使我们能够轻松地并行化大型计算，并使用重新执行作为容错的主要机制。\n这项工作的主要贡献在于提供了一个简单而功能强大的接口，可实现大规模计算的自动并行化和分布式处理，同时还实现了该接口在大型商用 PC 集群上的高性能。\n第 2 节描述了基本编程模型并给出了几个示例。第 3 节描述了针对我们基于集群的计算环境定制的 MapReduce 接口实现。第 4 节描述了我们发现有用的编程模型的几个改进。第 5 节对我们的实现进行了各种任务的性能测量。第 6 节探讨了 MapReduce 在 Google 中的使用情况，包括我们使用它作为重写生产索引系统的基础的经验。第 7 节讨论了相关工作和未来工作。\n2 编程模型 计算接收一组输入键/值对，并产生一组输出键/值对。MapReduce 库的用户将计算表述为两个函数：Map 和 Reduce。\nMap 由用户编写，它接受一个输入对并生成一组中间键/值对。MapReduce 库将与同一中间键 I 相关的所有中间值分组在一起，并将它们传递给 Reduce 函数。\n2.1 示例 考虑一下计算大量文件集中每个单词出现次数的问题。用户可以编写类似于以下伪代码的代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 map(String key, String value): // key: document name // value: document content for each word w in value: EmitIntermediate(w, \u0026#34;1\u0026#34;); reduce(String key, Iterator values): // key: a word // values: a list of counts int result = 0; for each v in values: result += ParseInt(v); Emit(AsString(result)); map 函数输出每个单词以及相关的出现次数（在这个简单的例子中只有\u0026quot;1\u0026quot;）。reduce 函数将针对特定单词发出的所有计数相加。\n此外，用户编写代码以将输入和输出文件的名称以及可选的调整参数填充到 mapreduce 规范对象中。然后，用户调用 MapReduce 函数，将规范对象传递给它。用户的代码与 MapReduce 库（以 C++ 实现）链接在一起。附录 A 包含此示例的完整程序文本。\n2.2 类型 尽管前面的伪代码是用字符串输入和输出编写的，但从概念上讲，用户提供的 map 和 Reduce 函数具有相关类型：\n1 2 3 map (k1,v1) → list(k2,v2) reduce (k2,list(v2)) → list(v2) 也就是说，输入键值与输出键值来自不同的域。此外，中间键值与输出键值来自同一域。\n我们的 C++ 实现将字符串传入和传出用户定义的函数，并让用户代码在字符串和适当类型之间进行转换。\n2.3 更多例子 下面是几个有趣程序的简单示例，它们可以轻松地表示为 MapReduce 计算。\n分布式 Grep：map 函数会在与所提供的模式匹配时输出一行数据。reduce 函数是一个 identify 函数，它只是将提供的中间数据复制到输出中。\nURL 访问频率计数：map 函数处理网页请求日志并输出\u0026lt;URL, 1\u0026gt;。reduce 函数将同一 URL 的所有值相加，输出一对 \u0026lt;URL, total count\u0026gt;。\n反向 Web 链接图：map 函数针对在名为 source 的页面中找到的目标 URL 的每个链接输出 \u0026lt;target, source\u0026gt; 对。reduce 函数连接与给定目标 URL 关联的所有源 URL 列表并发出以下对：\u0026lt;target, list(source)\u0026gt;.\n每主机的术语向量：术语向量将出现在文档或文档集中的最重要单词总结为\u0026lt;word, f requency\u0026gt;对的列表。map函数为每个输入文档发出\u0026lt;hostname, term vector\u0026gt;对（主机名是从文档的 URL 中提取的）。reduce 函数接收给定主机的所有文档术语向量。它将这些术语向量相加，舍弃不常见的术语，然后发出最终的\u0026lt;hostname, term vector\u0026gt;对。\n反向索引：map函数解析每个文档，并输出\u0026lt;word, document ID\u0026gt;对的序列。reduce 函数接受给定词的所有词对，对相应的文档 ID 进行排序，然后输出\u0026lt;word, list(document ID)\u0026gt;词对。所有输出词对的集合构成了一个简单的倒排索引。这种计算方法很容易扩展，以跟踪单词的位置。\n分布式排序：map 函数从每条记录中提取键，并输出\u0026lt;key, record\u0026gt;对。reduce函数会原封不动地输出所有记录对。这种计算依赖于第 4.1 节中描述的分区设施和第 4.2 节中描述的排序属性。\n3 实现 MapReduce 接口有许多不同的实现方式。正确的选择取决于环境。例如，一种实现可能适用于小型共享内存机器，另一种可能适用于大型 NUMA 多处理器，还有一种可能适用于更大规模的联网机器。\n本节介绍针对谷歌广泛使用的计算环境的实施方案：通过交换式以太网连接在一起的大型商用 PC 集群 1。在我们的环境中：\n(1) 机器通常是运行 Linux 的双处理器 x86 处理器，每台机器有 2-4 GB 内存。\n(2) 使用普通网络硬件\u0026ndash;在机器层面通常为 100 Mb/s或 1 Gb/s，但平均整体带宽要低得多。\n(3) 集群由成百上千台机器组成，因此机器故障很常见。\n(4) 存储由直接连接到各个机器的廉价 IDE 磁盘提供。内部开发的分布式文件系统 2 用于管理存储在这些磁盘上的数据。文件系统使用复制来在不可靠的硬件上提供可用性和可靠性。\n(5) 用户向调度系统提交作业。每个作业由一组任务组成，并由调度程序映射到集群内的一组可用机器上。\n3.1 执行概述 Map 调用通过自动将输入数据划分为一组 M 个分片，分布在多台机器上。输入分片可以由不同的机器并行处理。Reduce 调用通过使用分区函数（例如 hash(key) mod R）将中间键空间划分为 R 个部分来分布。分区数 (R) 和分区函数由用户指定。\nFigure 1: Execution overview 图 1 显示了我们实现 MapReduce 操作的整体流程。当用户程序调用 MapReduce 函数时，会发生以下一系列操作（图 1 中的编号标签与下面列表中的编号相对应）：\n用户程序中的 MapReduce 库首先会将输入文件分割成 M 个片段，每个片段通常为 16 MB 至 64 MB（用户可通过可选参数进行控制）。然后，它在机器集群上启动程序的多个副本。 程序中的一个副本是特殊的\u0026ndash;master。其余的是由master分配工作的worker。有 M 个map任务和 R 个reduce任务需要分配。master 会挑选空闲的 worker，为每个worker分配一个map任务或reduce任务。 分配给 Map 任务的 worker 会读取相应输入分片的内容。它从输入数据中解析出键/值对，并将每个键/值对传递给用户定义的 Map 函数。Map 函数生成的中间键/值对在内存中缓冲。 缓冲数据对会定期写入本地磁盘，并由分区函数分割成 R 个区域。本地磁盘上这些缓冲对的位置会传回master，由master负责将这些位置转发给执行 reduce 的worker。 当 master 通知执行 reduce 的worker 这些位置时，它使用远程过程调用从执行 map的worker的本地磁盘读取缓冲数据。当执行 reduce 的worker读取了所有中间数据时，它会按中间键对其进行排序，以便将同一键的所有匹配项组合在一起。排序是必需的，因为通常许多不同的 key 映射到同一个 reduce 任务。如果中间数据量太大而无法放入内存，则使用外部排序。 reduce 工作程序迭代排序的中间数据，对于遇到的每个唯一中间键，它将键和相应的中间值集传递给用户的 Reduce 函数。Reduce 函数的输出将附加到此 reduce 分区的最终输出文件中。 当 map 任务和 reduce 任务全部完成后，master 会唤醒用户程序。 此时，用户程序中的 MapReduce 调用返回给用户代码。 成功完成后，mapreduce 执行的输出可在 R 输出文件中获得（每个 Reduce 任务一个，文件名由用户指定）。通常，用户不需要将这些 R 输出文件合并为一个文件 - 他们经常将这些文件作为输入传递给另一个 MapReduce 调用，或者从能够处理分成多个文件的输入的另一个分布式应用程序中使用它们。\n3.2 Master 数据结构 Master 保存了几个数据结构。对于每个 Map 任务和 Reduce 任务，它存储了状态（空闲、进行中或已完成）和 Worker 机器的标识（对于非空闲任务）。\nmaster是将中间文件区域的位置从 Map 任务传播到 Reduce 任务的管道。因此，对于每个已完成的 Map 任务，master都会存储 Map 任务生成的 R 个中间文件区域的位置和大小。Map 任务完成后，将收到对此位置和大小信息的更新。这些信息将逐步推送到具有正在进行的 Reduce 任务的worker。\n3.3 容错 由于 MapReduce 库旨在帮助使用数百或数千台机器处理大量数据，因此该库必须能够优雅地容忍机器故障。\nWorker 失败 Master 定期对每个 Worker 执行 ping 操作。如果在一定时间内没有收到 Worker 的响应，Master 会将该 Worker 标记为失败。worker 完成的任何map任务都会重置回其初始空闲状态，因此有资格在其他worker 上进行调度。同样，发生故障的worker 上正在进行的任何map任务或reduce任务也会重置为空闲状态，并有资格重新安排。\n已完成的map任务会在发生故障时重新执行，因为它们的输出存储在故障计算机的本地磁盘上，因此无法访问。已完成的reduce任务不需要重新执行，因为它们的输出存储在全局文件系统中。\n当一个map任务先由worker A执行，然后由worker B执行时（因为A失败），所有执行reduce任务的worker都会收到重新执行的通知。任何尚未从worker A读取数据的reduce任务将从worker B读取数据。\nMapReduce 对大规模工作故障具有弹性。 例如，在一次 MapReduce 操作期间，正在运行的集群上的网络维护导致一次 80 台计算机组在几分钟内无法访问。 MapReduce master只是重新执行了无法访问的worker机器完成的工作，并继续向前推进，最终完成MapReduce操作。\nMaster 失败 很容易让 master 写入上述master数据结构的周期性检查点。如果master任务终止，可以从最后一个检查点状态开始一个新的副本。然而，考虑到只有一个master，它发生故障的可能性不大；因此，如果master发生故障，我们当前的实现将中止 MapReduce 计算。客户端可以检查此情况并根据需要重试 MapReduce 操作。\n出现故障时的语义 当用户提供的 map 和 reduce 操作能够根据输入值确定性地计算出结果时，我们的分布式实现将产生与程序在没有故障的情况下顺序执行时相同的输出。\n我们通过原子性地提交 map 和 reduce 任务的输出来确保这一特性。每个正在执行的任务都会将其输出写入临时文件。一个 reduce 任务生成一个这样的文件，而一个 map 任务则为每个 reduce 任务生成一个文件，共 R 个。当一个 map 任务完成后，worker 会向 master 发送一条消息，并附上这 R 个临时文件的名称。如果 master 收到的是一个已经完成的 map 任务的完成消息，它会忽略这条消息。否则，它会在master的数据结构中记录这 R 个文件的名称。\n当一个 reduce 任务完成后，负责该任务的 worker 会将临时输出文件原子性地重命名为最终输出文件。如果这个 reduce 任务在多台机器上同时执行，那么会有多次重命名操作指向同一个最终输出文件。我们依靠文件系统提供的原子性重命名功能来确保最终文件系统中只包含一次 reduce 任务执行所生成的数据。\n我们的 map 和 reduce 操作大多数都是确定性的，这种情况下，我们的语义等同于顺序执行，这让程序员能够更容易地理解程序的运行行为。当 map 和/或 reduce 操作是非确定性的时候，我们提供了一种较弱但仍然合理的语义。在非确定性操作符的情况下，特定 reduce 任务 $R_1$ 的输出与该非确定性程序顺序执行产生的 $R_1$ 输出相同。但是，对于另一个 reduce 任务 $R_2$，其输出可能来自于该非确定性程序的不同顺序执行所产生的 $R_2$ 输出。\n考虑 map 任务 M 和 reduce 任务 $R_1$ 和 $R_2$。设 $e(R_i)$ 为已提交的 Ri 执行实例（每个 $R_i$ 只有一个这样的执行实例）。较弱的语义之所以出现，是因为 e($R_1$) 可能读取了 M 任务某次执行产生的输出，而 e($R_2$) 可能读取了 M 任务另一次执行产生的输出。\n3.4 位置 在我们的计算环境中，网络带宽是一种相对宝贵的资源。我们通过利用输入数据（由 GFS 2 管理）已存储在集群中机器的本地磁盘上的优势，来减少网络带宽的使用。GFS 将每个文件划分为 64 MB 的数据块，并在不同的机器上存储每个块的多个副本（通常是 3 个）。MapReduce master会考虑输入文件的位置信息，并尽可能在一个拥有相应输入数据副本的机器上安排 map 任务。如果不可能，它会尝试在靠近该任务输入数据副本的地方安排 map 任务（例如，在与数据所在机器相同的网络交换机上的 worker 机器上）。当在集群中大量 worker 上运行大型 MapReduce 操作时，大部分输入数据都能在本地读取，从而不占用网络带宽。\n3.5 任务粒度 我们按照上述方法将 map 阶段划分为 M 个小部分，将 reduce 阶段划分为 R 个小部分。理想情况下，M 和 R 应该远大于工作机器的数量。让每台工作机器执行多个不同的任务有助于提升动态负载均衡，同时在工作机器出现故障时也能加快恢复速度：它已完成的众多 map 任务可以分配到其他所有工作机器上去执行。\n在我们的实现中，M 和 R 的数值实际上存在一定的实际限制。这是因为master需要做出 O(M + R) 次调度决策，并且需要在内存中保持 O(M ∗ R) 的状态，如前所述。（不过，内存使用的常数因子相对较小：O(M ∗ R) 部分的状态大约由每个 map 任务/reduce 任务对的一个字节数据组成。）\n此外，R 的值通常受到用户的限制，因为每个 reduce 任务的输出会分别存储在不同的输出文件中。在实际操作中，我们通常设定 M 的值，使得每个任务处理的输入数据大约在 16 MB 到 64 MB 之间（这样可以使上述的局部性优化效果最大化），而 R 则设定为预期使用的工作机器数量的一小倍数。在我们的计算中，常常使用 M = 200,000 和 R = 5,000，并部署 2,000 台工作机器进行 MapReduce 计算。\n3.6 后备任务 MapReduce 操作总耗时增加的一个常见原因是“慢速机器”，也就是在计算的最后阶段，某台机器完成 map 或 reduce 任务所需的时间异常长。慢速机器的出现可能由多种因素引起。例如，一个磁盘出现问题的机器可能会频繁遇到可纠正的错误，这会使其读取性能从每秒 30 MB 降至每秒 1 MB。集群调度系统可能在同一台机器上安排了其他任务，由于 CPU、内存、本地磁盘或网络带宽的竞争，导致 MapReduce 代码执行速度减慢。我们最近遇到的一个问题是机器初始化代码中的一个错误，导致处理器的缓存功能被禁用，这使受影响的机器上的计算速度降低了超过一百倍。\n我们实现了一个通用机制来减轻慢速机器带来的问题。当一个 MapReduce 操作即将完成时，master会安排剩余未完成任务的后备执行。无论原任务还是后备任务先完成，该任务即被视为完成。我们已经对这个机制进行了优化，使得它通常只会使操作使用的计算资源增加几个百分点。我们发现，这种方法显著缩短了完成大型 MapReduce 操作所需的时间。例如，当禁用后备任务机制时，第 5.3 节中描述的排序程序完成时间会延长 44%。\n4 改进 虽然简单编写 Map 和 Reduce 函数提供的基本功能足以满足大多数需求，但我们发现一些有用的扩展。本节对此进行了描述。\n4.1 分区函数 MapReduce 用户可以指定所需的 reduce 任务/输出文件数量 R。数据通过中间键的分区函数分配到这些任务中。系统提供了一个默认的分区函数，它使用哈希（例如，“hash(key) mod R”），这通常能产生相当均衡的数据分区。但在某些情况下，根据键的其他属性来分区数据会更有用。例如，如果输出键是 URL，我们可能希望同一个主机的所有记录都保存在同一个输出文件中。为了应对这类需求，MapReduce 库的用户可以提供一个自定义的分区函数。例如，使用“hash(Hostname(urlkey)) mod R”作为分区函数，就能确保同一个主机的所有 URL 都保存在同一个输出文件中。\n4.2 顺序保证 我们确保在每个数据分区内部，中间键/值对按照键的递增顺序进行处理。这样的顺序保证使得为每个分区生成一个有序的输出文件变得简单，这在需要支持通过键进行高效随机访问查找的输出文件格式中非常有用，或者当输出文件的最终用户发现数据有序排列更方便时也很实用。\n4.3 合并函数 在某些情况下，每个 map 任务产生的中间键可能会有很多重复，而且用户定义的 Reduce 函数具有可交换和可结合的特性。一个典型的例子是第 2.1 节中的单词计数案例。由于单词出现的频率通常遵循 Zipf 分布，每个 map 任务可能会生成数百或数千条 \u0026lt;the, 1\u0026gt; 这种格式的记录。所有这些计数结果都会被发送到同一个 reduce 任务，并由 Reduce 函数合并成一个总数。为了优化这个过程，我们允许用户指定一个可选的 Combiner 函数，这个函数可以在数据发送到网络之前对数据进行局部合并。\nCombiner 函数在执行 map 任务的每台机器上运行。通常，相同的代码被用于实现 combiner 函数和 reduce 函数。reduce 函数与 combiner 函数之间的唯一区别在于 MapReduce 库处理函数输出的方式不同。reduce 函数的输出会直接写入最终的输出文件，而 combiner 函数的输出则被写入一个中间文件，该文件随后会被发送到 reduce 任务进行处理。\n局部合并大大加快了一些特定类型的 MapReduce 操作。附录 A 中提供了一个使用 combiner 函数的示例。\n4.4 输入与输出类型 MapReduce 库提供了支持多种不同格式读取输入数据的功能。例如，在“文本”模式输入中，每行被视为一个键/值对：键是文件中的位置偏移，值是行的内容。另一种常见且受支持的格式是按键排序的键/值对序列。每种输入类型的实现都了解如何将自己分割成有意义的范围，以便作为独立的 map 任务进行处理（例如，文本模式的范围分割确保只在行边界进行分割）。用户可以通过实现一个简单的读取器接口来添加对新输入类型的支持，尽管大多数用户通常只使用少数几个预定义的输入类型之一。\n读取器并不一定非要从文件中读取数据。例如，可以很容易地定义一个从数据库中读取记录的读取器，或者从内存中映射的数据结构中读取记录。\n同样地，我们支持一系列输出类型，用于以不同格式生成数据，用户编写的代码可以轻松地添加对新输出类型的支持。\n4.5 副作用 在某些情况下，MapReduce 的用户发现从他们的 map 和/或 reduce 操作中生成辅助文件作为额外的输出非常方便。我们依赖于应用程序编写者确保这样的副作用操作具有原子性和幂等性。通常，应用程序会写入一个临时文件，并在文件完全生成后原子性地重命名这个文件。我们不支持单个任务生成的多个输出文件的原子性两阶段提交。因此，产生多个输出文件且需要跨文件一致性的任务应该是确定性的。在实际应用中，这个限制从未造成过问题。\n4.6 跳过坏记录 有时用户编写的代码中可能存在导致 Map 或 Reduce 函数在处理特定记录时始终崩溃的 bug。这类 bug 会阻止 MapReduce 操作的完成。通常的解决方法当然是修复这些 bug，但有时这并不可行，比如 bug 出现在一个没有提供源代码的第三方库中。有时候，忽略一些记录是可以接受的，例如在进行大量数据集的统计分析时。为了应对这种情况，我们提供了一个可选的执行模式，MapReduce 库能够检测出哪些记录会导致崩溃，并跳过这些记录，以便继续执行操作。\n每个工作进程都设置了一个信号处理程序，用于捕获段错误和总线错误。在调用用户的 Map 或 Reduce 操作之前，MapReduce 库会将参数的序列号保存在一个全局变量中。如果用户代码触发了信号，信号处理程序会发送一个包含该序列号的“最后努力”UDP 数据包给 MapReduce master。当master发现某个特定记录上出现多次失败时，它会在下一次重新调度相应的 Map 或 Reduce 任务时指示应该跳过这个记录。\n4.7 本地执行 调试 Map 或 Reduce 函数中的问题可能相当复杂，因为实际计算是在一个分布式系统中进行的，通常涉及数千台机器，而工作分配的决策是由master动态做出的。为了帮助简化调试、性能分析和进行小规模测试，我们开发了一个 MapReduce 库的替代版本，它可以在本地机器上顺序执行 MapReduce 操作的所有工作。这个版本为用户提供了控制选项，可以将计算限制在特定的 map 任务上。用户只需在运行程序时添加一个特殊标志，就可以轻松地使用任何他们觉得有用的调试或测试工具（比如 gdb）。\n4.8 状态信息 master运行一个内部 HTTP 服务器，并提供了一系列供人查看的状态页面。这些页面显示了计算的进展情况，例如完成了多少任务，正在进行中的任务数量，输入数据、中间数据和输出数据的字节数，以及处理速率等信息。页面还提供了每个任务生成的标准错误和标准输出文件的链接。用户可以利用这些数据来预测计算所需的时间，并决定是否需要为计算添加更多资源。这些页面还可以帮助确定计算是否远低于预期速度。\n此外，主页面还显示了哪些工作机器出现了故障，以及它们在故障时正在处理的 map 和 reduce 任务。这些信息对于诊断用户代码中的错误非常有用。\n4.9 计数器 MapReduce 库提供了一个计数器功能，用于记录各种事件的发生次数。例如，用户代码可能需要统计处理过的总词数或索引的德语文档数量等。\n要使用这个功能，用户代码需要创建一个具有名称的计数器对象，然后在 Map 和/或 Reduce 函数中根据需要增加计数器的值。例如：\n1 2 3 4 5 6 7 Counter* uppercase; uppercase = GetCounter(\u0026#34;uppercase\u0026#34;); map(String name, String contents): for each word w in contents: if (IsCapitalized(w)): uppercase-\u0026gt;Increment(); EmitIntermediate(w, \u0026#34;1\u0026#34;); 各个工作机器上的计数器值会定期发送到master（随 ping 响应一起发送）。master会汇总成功完成的 map 和 reduce 任务的计数器值，并在 MapReduce 操作完成后返回给用户代码。当前的计数器值也会显示在master的状态页面上，以便人们可以监控计算的实时进展。在汇总计数器值时，master会排除同一 map 或 reduce 任务重复执行的影响，以避免重复计算。（重复执行可能是由我们使用后备任务或因故障而重新执行任务所导致的。）\nMapReduce 库自动记录一些计数器值，如处理的输入键/值对数量和生成的输出键/值对数量。\n用户发现计数器功能对于验证 MapReduce 操作的正确性非常有帮助。例如，在某些 MapReduce 操作中，用户代码可能需要确保生成的输出对数量与处理的输入对数量完全相等，或者处理的德语文档数量占所有处理文档数量的比例在可接受的范围内。\n5 性能 在这节中，我们评估了 MapReduce 在一个大型计算机集群上执行两个计算任务的表现。其中一个任务是在大约一兆字节的数据中寻找特定模式。另一个任务是对大约一兆字节的数据进行排序。\n这两个程序是用户编写的 MapReduce 程序中的典型代表。一类程序负责将数据在不同的表示形式之间进行转换，另一类程序则从大量数据中筛选出有价值的信息。\n5.1 集群配置 所有程序都在一个包含大约 1800 台机器的集群上运行。每台机器都安装有两个 2GHz 的 Intel Xeon 处理器并开启了超线程功能，拥有 4GB 内存，两个 160GB 的 IDE 硬盘，以及千兆以太网连接。这些机器构成了一个两层树状交换网络，其根部的总带宽约为 100-200 Gbps。由于所有机器位于同一托管设施内，任意两台机器之间的往返延迟不到一毫秒。\n在 4GB 内存中，大约有 1-1.5GB 被集群上运行的其他任务占用。程序是在一个周末下午执行的，那时 CPU、硬盘和网络的使用率相对较低。\n5.2 Grep grep 程序检查了 $10^{10}$ 个 100 字节长的记录，寻找一个出现频率较低的三字符模式（该模式在 92337 个记录中出现）。输入数据被划分为大约 64MB 的片段（M = 15000），所有输出结果被保存在一个文件中（R = 1）。\n图 2：随时间变化的数据传输速率 图 2 展示了计算过程随时间的变化。Y 轴表示输入数据的扫描速率。随着更多机器加入到这个 MapReduce 任务中，扫描速率逐渐加快，当分配了 1764 个工作节点时，速率达到峰值，超过 30 GB/s。随着 map 任务的完成，速率开始下降，在大约 80 秒后降至零。整个计算过程大约需要 150 秒，包括大约一分钟的启动时间。启动时间包括了将程序分发到所有工作节点以及与 GFS 交互，打开 1000 个输入文件并获取本地优化所需信息的时间延迟。\n5.3 Sort 图 3：排序程序的不同执行随时间变化的数据传输速率 sort 程序对 $10^{10}$ 个 100 字节的记录（大约 1 TB 的数据）进行排序。该程序以 TeraSort 基准测试 3 为蓝本。\n排序程序的用户代码部分少于 50 行。一个三行的 Map 函数负责从文本行中提取一个 10 字节的排序键，并将这个键和原始文本行作为中间键/值对输出。我们使用了一个内置的 Identity 函数作为 Reduce 操作符，这个函数会将中间键/值对原封不动地作为输出键/值对。排序后的最终输出被写入一组两路复制的 GFS 文件中（也就是说，程序的输出是 2 兆字节的数据）。\n和之前一样，输入数据被划分为 64MB 的片段（M = 15000）。我们将排序后的结果分成 4000 个文件（R = 4000）。分区函数通过检查键的起始字节来确定每个键应该分配到哪一部分。\n在这个基准测试中，我们的分区函数已经预先知道了键的分布情况。在一般的排序程序中，我们会先进行一次 MapReduce 操作来收集键的样本，然后根据这些样本键的分布情况来计算最终排序阶段所需的分割点。\n图 3 (a) 展示了排序程序正常执行的过程。左上角的图表显示了输入数据的读取速度。这个速度在达到大约 13 GB/s 后达到顶峰，然后迅速下降，因为所有的 map 任务在大约 200 秒内完成了。请注意，这个读取速度比 grep 程序的要慢。这是因为排序任务的 map 阶段大约有一半的时间和 I/O 带宽用于将中间结果写入本地磁盘，而 grep 程序的中间结果大小几乎可以忽略不计。\n左中角的图表显示了数据从 map 任务传输到 reduce 任务的速率。这个过程在第一个 map 任务完成后立即开始。图表中的第一个高峰对应于大约 1700 个 reduce 任务的第一批（整个 MapReduce 任务被分配了大约 1700 台机器，每台机器同时最多执行一个 reduce 任务）。在大约 300 秒的计算过程中，一些第一批的 reduce 任务完成了，我们开始为剩下的 reduce 任务传输数据。所有的数据传输在大约 600 秒的计算过程中完成。\n左下角的图表展示了 reduce 任务将排序后的数据写入最终输出文件的速度。在第一次数据洗牌结束和写入开始之间有一个时间差，因为机器正在对中间数据进行排序。写入操作以大约 2-4 GB/s 的速度持续了一段时间。所有的写入在大约 850 秒的计算过程中完成。包括启动时间在内，整个计算过程耗时 891 秒，这与目前 TeraSort 基准测试报告4的最佳结果 1057 秒相近。\n需要关注的几个点是：由于我们的本地优化策略，输入速率高于数据洗牌速率和输出速率——大部分数据是从本地磁盘读取的，绕过了我们相对受限的网络带宽。数据洗牌速率高于输出速率，因为输出阶段需要写入排序数据的两个副本（我们为了确保数据的可靠性和可用性，制作了输出的两个副本）。我们之所以写入两个副本，是因为这是我们底层文件系统提供的确保数据可靠性和可用性的机制。如果底层文件系统使用的是擦除编码 5 而非复制，那么写入数据的网络带宽需求将会降低。\n5.4 备份任务的效果 在图 3 (b) 中，我们展示了当禁用备份任务时排序程序的执行情况。整体执行流程与图 3 (a) 相似，但存在一个明显的长尾阶段，期间几乎没有任何写入活动。在经过 960 秒后，除了 5 个 reduce 任务外，其余所有任务都已结束。然而，这几个剩余的慢任务又花了额外的 300 秒才最终完成。整个计算过程耗时 1283 秒，相比正常执行时间增加了 44%。\n5.5 机器故障 在图 3 (c) 中，我们展示了在计算进行了几分钟之后，故意杀死了 1746 个工作进程中的 200 个的排序程序执行情况。由于只有进程被终止，而机器本身仍然正常工作，底层的集群调度程序迅速在这些机器上重新启动了新的工作进程。\n工作进程的终止在图表上显示为负的输入速率，因为一些已经完成的 map 任务消失（由于相应的 map 工作进程被终止），需要重新执行。这些 map 任务的重新执行相对迅速。整个计算过程包括启动开销在内耗时 933 秒，仅比正常执行时间增加了 5%。\n6 经验 图 4：MapReduce 实例随时间的变化 表 1：2004 年 8 月运行的 MapReduce 作业 我们在 2003 年 2 月开发了 MapReduce 库的第一个版本，并在同年 8 月对其进行了重大升级，增加了本地优化、跨工作计算机任务执行的动态负载平衡等。自那时起，我们惊喜地发现 MapReduce 库在我们处理的各种问题中有着广泛的应用。它已经被 Google 内部的多个领域所采用，包括：\n大规模机器学习问题 Google 新闻和 Froogle 产品的聚类问题 提取用于生成热门查询报告的数据（例如 Google Zeitgeist） 为新实验和产品提取网页的属性（例如，从大量网页语料库中提取地理位置以进行本地化搜索），以及 大规模图计算 图 4 展示了在我们的主要源代码管理系统中，独立 MapReduce 程序的数量随时间急剧增加，从 2003 年初的 0 个增加到 2004 年 9 月底的近 900 个实例。MapReduce 取得巨大成功的原因是它允许开发者编写简单的程序，并在半小时内在成千上万台机器上高效运行，这极大地加快了开发和原型设计的速度。此外，它还让那些没有分布式或并行系统经验的程序员能够轻松地利用大量资源。\n每个作业完成后，MapReduce 库会记录下作业使用的计算资源统计数据。在表 1 中，我们展示了 2004 年 8 月在 Google 运行的一些 MapReduce 作业的统计信息。\n6.1 大规模索引 到目前为止，我们对 MapReduce 最重要的用途之一是完全重写了生产索引系统，该系统生成用于 Google 网络搜索服务的数据结构。索引系统将我们的爬虫系统检索到的大量文档作为输入，这些文档存储为一组 GFS 文件。这些文档的原始内容超过 20 TB 的数据。索引过程以五到十个 MapReduce 操作的序列运行。使用 MapReduce（而不是索引系统先前版本中的临时分布式传递）提供了几个好处：\n索引代码更简单、更小、更易于理解，因为处理容错、分布和并行化的代码隐藏在 MapReduce 库中。例如，使用 MapReduce 表达时，一个计算阶段的大小从大约 3800 行 C++ 代码下降到大约 700 行。 MapReduce 库的性能足够好，因此我们可以将概念上不相关的计算分开，而不是将它们混合在一起，以避免对数据进行额外的传递。这使得更改索引过程变得很容易。例如，在旧索引系统中需要几个月才能完成的一项更改在新系统中仅用了几天就完成了。 索引过程变得更容易操作，因为大多数由机器故障、机器速度慢和网络故障引起的问题都由 MapReduce 库自动处理，无需操作员干预。此外，通过向索引集群添加新机器，可以轻松提高索引过程的性能。 7 相关工作 许多系统通过限制编程模型来自动实现计算的并行化。例如，使用并行前缀计算678，可以在 N 个处理器上以 O(log N) 的时间复杂度计算一个 N 元素数组的所有前缀的关联函数。MapReduce 可以看作是基于我们在大型实际计算中的经验，对这些模型进行简化和提炼的结果。更重要的是，我们提供了一个能够扩展到数千个处理器上的容错实现。与此相反，大多数并行处理系统只在较小的规模上实现，并且将处理机器故障的细节留给程序员去处理。\nBSP（Bulk Synchronous Programming）9 和一些 MPI（Message Passing Interface）原语 10 提供了更高级别的抽象，使程序员更容易编写并行程序。这些系统与 MapReduce 的关键区别在于，MapReduce 通过限制编程模型来自动并行化用户程序，并提供了透明的容错能力。\n我们的本地优化受到了主动磁盘 1112 等技术的启发，这些技术将计算推向靠近本地磁盘的处理元素，以减少跨 I/O 子系统或网络发送的数据量。我们在连接了少量磁盘的普通处理器上运行，而不是直接在磁盘控制处理器上运行，但基本方法类似。\n我们的备份任务机制与 Charlotte 系统中使用的急切调度机制 13 相似。简单急切调度的一个缺点是，如果某个任务不断失败，整个计算将无法完成。我们通过一种机制来跳过导致问题的记录，从而解决了这个问题的一些情况。\nMapReduce 的实现依赖于一个内部的集群管理系统，该系统负责在大量共享机器上分发和运行用户任务。尽管这并非本文的核心内容，但这个集群管理系统在本质上与 Condor 14 等其他系统相似。\nMapReduce 库中的排序功能在操作上与 NOW-Sort 15 类似。源机器（map 工作进程）对要排序的数据进行分区，并将其发送给 R 个 reduce 工作进程之一。每个 reduce 工作进程在其本地对数据进行排序（如果可能，在内存中）。当然，NOW-Sort 不具备用户可定义的 Map 和 Reduce 函数，这赋予了我们的库广泛的应用性。\nRiver16提供了一个编程模型，其中的进程通过在分布式队列上发送数据来相互通信。与 MapReduce 类似，River 系统旨在即使在异构硬件或系统扰动导致的非均匀性存在的情况下，也能提供良好的平均性能。River 通过精心调度磁盘和网络传输来实现任务均衡完成时间。MapReduce 采用了不同的方法。通过限制编程模型，MapReduce 框架能够将问题细分为大量小任务。这些任务在可用的工作节点上动态分配，使得更快的工作节点处理更多任务。受限的编程模型还允许我们在作业即将完成时安排任务的冗余执行，这在存在如慢速或卡住的工作节点等非均匀性的情况下，显著减少了完成时间。\nBAD-FS 17 与 MapReduce 的编程模型有很大不同，且与 MapReduce 不同，BAD-FS 主要面向广域网中作业的执行。然而，两者有两个基本的相似点：(1) 两个系统都使用冗余执行来应对由于故障导致的数据丢失；(2) 两个系统都采用了感知局部性的调度方法，以减少通过拥塞网络链路传输的数据量。\nTACC 18 是一个旨在简化构建高可用网络服务的系统。像 MapReduce 一样，TACC 依赖于重新执行作为实现容错的机制。\n8 结论 MapReduce 编程模型已被 Google 成功应用于多种不同的用途。我们认为其成功有几个原因。首先，这个模型易于使用，即使是没有并行和分布式系统经验的程序员也能轻松上手，因为它隐藏了并行化、容错、局部性优化和负载均衡等细节。其次，许多问题可以很容易地表达为 MapReduce 计算。例如，MapReduce 被用于生成 Google 生产搜索服务的数据、排序、数据挖掘、机器学习以及许多其他系统。第三，我们开发了一个可扩展到大型机器集群的 MapReduce 实现，支持数千台机器。该实现能够高效利用这些机器资源，因此适合用于解决 Google 中遇到的许多大型计算问题。\n从这项工作中，我们学到了几个重要的经验。首先，限制编程模型使得并行化和分布式计算变得更加容易，同时也能更轻松地实现容错。其次，网络带宽是一种稀缺资源。因此，我们系统中的许多优化都旨在减少通过网络传输的数据量：局部性优化使得我们能够从本地磁盘读取数据，而将中间数据写入本地磁盘的单一副本则节省了网络带宽。第三，冗余执行可以用来减少慢速机器的影响，并处理机器故障和数据丢失。\n致谢 Josh Levenberg 凭借自己使用 MapReduce 的经验以及其他人的改进建议，在用户级 MapReduce API 中修改和扩展了许多新功能。MapReduce 从 Google 文件系统 2 读取输入并将输出写入其中。我们要感谢 Mohit Aron、Howard Gobioff、Markus Gutschke、David Kramer、Shun-Tak Leung 和 Josh Redstone 在开发 GFS 方面所做的工作。我们还要感谢 Percy Liang 和 Olcan Sercinoglu 在开发 MapReduce 使用的集群管理系统方面所做的工作。Mike Burrows、Wilson Hsieh、Josh Levenberg、Sharon Perl、Rob Pike 和 Debby Wallach 对本文的早期草稿提出了有益的评论。匿名 OSDI 审阅者和我们的指导者 Eric Brewer 就本文的改进领域提出了许多有用的建议。最后，我们感谢 Google 工程组织内所有 MapReduce 用户提供有用的反馈、建议和错误报告。\n附录A Word Frequency 本节包含一个程序，用于计算命令行指定的一组输入文件中每个唯一单词出现的次数。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 #include \u0026#34;mapreduce/mapreduce.h\u0026#34; // User’s map function class WordCounter : public Mapper { public: virtual void Map(const MapInput \u0026amp;input) { const string \u0026amp;text = input.value(); const int n = text.size(); for (int i = 0; i \u0026lt; n;) { // Skip past leading whitespace while ((i \u0026lt; n) \u0026amp;\u0026amp; isspace(text[i])) i++; // Find word end int start = i; while ((i \u0026lt; n) \u0026amp;\u0026amp; !isspace(text[i])) i++; if (start \u0026lt; i) Emit(text.substr(start, i - start), \u0026#34;1\u0026#34;); } } }; REGISTER_MAPPER(WordCounter); // User’s reduce function class Adder : public Reducer { virtual void Reduce(ReduceInput *input) { // Iterate over all entries with the // same key and add the values int64 value = 0; while (!input-\u0026gt;done()) { value += StringToInt(input-\u0026gt;value()); input-\u0026gt;NextValue(); } // Emit sum for input-\u0026gt;key() Emit(IntToString(value)); } }; REGISTER_REDUCER(Adder); int main(int argc, char **argv) { ParseCommandLineFlags(argc, argv); MapReduceSpecification spec; // Store list of input files into \u0026#34;spec\u0026#34; for (int i = 1; i \u0026lt; argc; i++) { MapReduceInput *input = spec.add_input(); input-\u0026gt;set_format(\u0026#34;text\u0026#34;); input-\u0026gt;set_filepattern(argv[i]); input-\u0026gt;set_mapper_class(\u0026#34;WordCounter\u0026#34;); } // Specify the output files: // /gfs/test/freq-00000-of-00100 // /gfs/test/freq-00001-of-00100 // ... MapReduceOutput *out = spec.output(); out-\u0026gt;set_filebase(\u0026#34;/gfs/test/freq\u0026#34;); out-\u0026gt;set_num_tasks(100); out-\u0026gt;set_format(\u0026#34;text\u0026#34;); out-\u0026gt;set_reducer_class(\u0026#34;Adder\u0026#34;); // Optional: do partial sums within map // tasks to save network bandwidth out-\u0026gt;set_combiner_class(\u0026#34;Adder\u0026#34;); // Tuning parameters: use at most 2000 // machines and 100 MB of memory per task spec.set_machines(2000); spec.set_map_megabytes(100); spec.set_reduce_megabytes(100); // Now run it MapReduceResult result; if (!MapReduce(spec, \u0026amp;result)) abort(); // Done: ’result’ structure contains info // about counters, time taken, number of // machines used, etc. return 0; } 参考文献 Luiz A. Barroso, Jeffrey Dean, and Urs Ho ̈lzle. Web search for a planet: The Google cluster architecture. IEEE Micro, 23(2):22–28, April 2003.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nSanjay Ghemawat, Howard Gobioff, and Shun-Tak Leung. The Google file system. In 19th Symposium on Operating Systems Principles, pages 29–43, Lake George, New York, 2003.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nJim Gray. Sort benchmark home page. http://research.microsoft.com/barc/SortBenchmark/.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nJim Wyllie. Spsort: How to sort a terabyte quickly. http://alme1.almaden.ibm.com/cs/spsort.pdf.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMichael O. Rabin. Efficient dispersal of information for security, load balancing and fault tolerance. Journal of the ACM, 36(2):335–348, 1989.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nGuy E. Blelloch. Scans as primitive parallel operations. IEEE Transactions on Computers, C-38(11), November 1989.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nS. Gorlatch. Systematic efficient parallelization of scan and other list homomorphisms. In L. Bouge, P. Fraigniaud, A. Mignotte, and Y. Robert, editors, Euro-Par’96. Parallel Processing, Lecture Notes in Computer Science 1124, pages 401–408. Springer-Verlag, 1996.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nRichard E. Ladner and Michael J. Fischer. Parallel prefix computation. Journal of the ACM, 27(4):831–838, 1980.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nL. G. Valiant. A bridging model for parallel computation. Communications of the ACM, 33(8):103–111, 1997.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nWilliam Gropp, Ewing Lusk, and Anthony Skjellum. Using MPI: Portable Parallel Programming with the Message-Passing Interface. MIT Press, Cambridge, MA, 1999.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nL. Huston, R. Sukthankar, R. Wickremesinghe, M. Satyanarayanan, G. R. Ganger, E. Riedel, and A. Ailamaki. Diamond: A storage architecture for early discard in interactive search. In Proceedings of the 2004 USENIX File and Storage Technologies FAST Conference, April 2004.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nErik Riedel, Christos Faloutsos, Garth A. Gibson, and David Nagle. Active disks for large-scale data processing. IEEE Computer, pages 68–74, June 2001.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nArash Baratloo, Mehmet Karaul, Zvi Kedem, and Peter Wyckoff. Charlotte: Metacomputing on the web. In Proceedings of the 9th International Conference on Parallel and Distributed Computing Systems, 1996.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nDouglas Thain, Todd Tannenbaum, and Miron Livny. Distributed computing in practice: The Condor experience. Concurrency and Computation: Practice and Experience, 2004.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nAndrea C. Arpaci-Dusseau, Remzi H. Arpaci-Dusseau, David E. Culler, Joseph M. Hellerstein, and David A. Patterson. High-performance sorting on networks of workstations. In Proceedings of the 1997 ACM SIGMOD International Conference on Management of Data, Tucson, Arizona, May 1997.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nRemzi H. Arpaci-Dusseau, Eric Anderson, Noah Treuhaft, David E. Culler, Joseph M. Hellerstein, David Patterson, and Kathy Yelick. Cluster I/O with River: Making the fast case common. In Proceedings of the Sixth Workshop on Input/Output in Parallel and Distributed Systems (IOPADS ’99), pages 10–22, Atlanta, Georgia, May 1999.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nJohn Bent, Douglas Thain, Andrea C.Arpaci-Dusseau, Remzi H. Arpaci-Dusseau, and Miron Livny. Explicit control in a batch-aware distributed file system. In Proceedings of the 1st USENIX Symposium on Networked Systems Design and Implementation NSDI, March 2004.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nArmando Fox, Steven D. Gribble, Yatin Chawathe, Eric A. Brewer, and Paul Gauthier. Cluster-based scalable network services. In Proceedings of the 16th ACM Symposium on Operating System Principles, pages 7891, Saint-Malo, France, 1997.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://fireflyyh.top/posts/distributionsystem/mapreduce/","summary":"摘要 MapReduce 是一种用于处理和生成大型数据集的编程模型和相关实现。用户指定一个 map 函数来处理键/值对，生成一组中间键/值对，并指定一个 reduce 函数来合并与同一中间键相关的所有中间值。如本文所示，许多现实世界中的任务都可以用这个模型来表达。\n以这种函数式风格编写的程序会自动并行化，并在大型商用机器集群上执行。运行时系统会处理分割输入数据、调度程序在一组机器上的执行、处理机器故障以及管理所需的机器间通信等细节。这样，没有任何并行和分布式系统经验的程序员也能轻松利用大型分布式系统的资源。\n我们的 MapReduce 实现运行在大型商用机器集群上，并且具有高度可扩展性：典型的 MapReduce 计算在数千台机器上处理数 TB 的数据。程序员发现该系统易于使用：数百个 MapReduce 程序已经实现，并且每天在 Google 集群上执行超过一千个 MapReduce 作业。\n1 引言 在过去五年中，本文作者和 Google 的许多其他人已经实现了数百种特殊用途的计算，这些计算处理大量原始数据（例如抓取的文档、Web 请求日志等），以计算各种派生数据（例如倒排索引、Web 文档图形结构的各种表示、每个主机抓取的页面数量摘要、给定一天中最频繁的查询集等）。大多数此类计算在概念上都很简单。但是，输入数据通常很大，并且计算必须分布在数百或数千台机器上才能在合理的时间内完成。如何并行化计算、分发数据和处理故障的问题共同掩盖了原始的简单计算，并使用大量复杂的代码来处理这些问题。\n为了应对这种复杂性，我们设计了一种新的抽象，它允许我们表达我们试图执行的简单计算，但隐藏了库中的并行化、容错、数据分布和负载平衡的复杂细节。我们的抽象受到 Lisp 和许多其他函数式语言中存在的 map 和 Reduce 原语的启发。我们意识到，我们的大多数计算都涉及将 map 操作应用于输入中的每个逻辑“记录”，以计算一组中间键/值对，然后对共享相同键的所有值应用 Reduce 操作，以便适当地组合派生数据。我们使用具有用户指定的 map 和 Reduce 操作的函数模型，使我们能够轻松地并行化大型计算，并使用重新执行作为容错的主要机制。\n这项工作的主要贡献在于提供了一个简单而功能强大的接口，可实现大规模计算的自动并行化和分布式处理，同时还实现了该接口在大型商用 PC 集群上的高性能。\n第 2 节描述了基本编程模型并给出了几个示例。第 3 节描述了针对我们基于集群的计算环境定制的 MapReduce 接口实现。第 4 节描述了我们发现有用的编程模型的几个改进。第 5 节对我们的实现进行了各种任务的性能测量。第 6 节探讨了 MapReduce 在 Google 中的使用情况，包括我们使用它作为重写生产索引系统的基础的经验。第 7 节讨论了相关工作和未来工作。\n2 编程模型 计算接收一组输入键/值对，并产生一组输出键/值对。MapReduce 库的用户将计算表述为两个函数：Map 和 Reduce。","title":"[论文翻译]MapReduce: Simplified Data Processing on Large Clusters"},{"content":"摘要 我们设计并实现了谷歌文件系统，这是一个可扩展的分布式文件系统，适用于大型分布式数据密集型应用。该系统可在廉价的商品硬件上运行，同时提供容错功能，并能为大量客户端提供高聚合性能。\n我们的设计目标与之前的分布式文件系统有许多相同之处，但我们对应用工作负载和技术环境（包括当前和预期环境）的观察结果表明，我们的设计明显偏离了之前的一些文件系统假设。这促使我们重新审视传统的选择，探索完全不同的设计要点。\n文件系统成功地满足了我们的存储需求。它在谷歌内部被广泛部署，作为生成和处理我们的服务所使用的数据以及需要大型数据集的研发工作的存储平台。迄今为止，最大的集群在一千多台机器上的数千个磁盘上提供了数百 TB 的存储空间，并被数百个客户端并发访问。\n在本文中，我们介绍了为支持分布式应用而设计的文件系统接口扩展，讨论了我们设计的许多方面，并报告了微基准测试和实际使用的测量结果。\n1. 引言 我们设计并实施了谷歌文件系统（GFS），以满足谷歌快速增长的数据处理需求。GFS 与以前的分布式文件系统有许多相同的目标，如性能、可扩展性、可靠性和可用性。但是，在设计 GFS 时，我们对当前和预期的应用工作负载和技术环境进行了重要观察，这反映出我们明显偏离了之前的一些文件系统设计假设。我们重新审视了传统的选择，并探索了设计空间中完全不同的点。\n首先，组件故障是常态而非例外。文件系统由数百甚至数千台存储机组成，这些存储机都是用廉价的商品部件制造的，并被数量相当的客户机访问。这些组件的数量和质量几乎可以保证，在任何特定时间都会有一些组件无法正常工作，而且有些组件无法从当前故障中恢复。我们见过应用程序错误、操作系统错误、人为错误以及磁盘、内存、连接器、网络和电源故障造成的问题。因此，持续监控、错误检测、容错和自动恢复必须成为系统的组成部分。\n其次，按照传统的标准，文件是巨大的。多 GB 的文件很常见。每个文件通常包含许多应用对象，如网络文档。当我们经常处理由数十亿个对象组成的多 TB 快速增长的数据集时，即使文件系统可以支持，要管理数十亿个约 KB 大小的文件也很不方便。因此，必须重新审视 I/O 操作和块大小等设计假设和参数。\n第三，大多数文件都是通过添加新数据而不是覆盖现有数据来改变的。文件内的随机写入几乎不存在。文件一旦写入，就只能读取，而且通常只能按顺序读取。各种数据都具有这些特征。有些可能是数据分析程序扫描过的大型存储库。有些可能是运行中的应用程序持续生成的数据流。有些可能是档案数据。有些可能是在一台机器上生成并在另一台机器上处理的中间结果，无论是同时处理还是稍后处理。鉴于巨型文件的这种访问模式，追加成为性能优化和原子性保证的重点，而在客户端缓存数据块则失去了吸引力。\n第四，共同设计应用程序和文件系统 API 可以提高我们的灵活性，从而使整个系统受益。例如，我们放宽了 GFS 的一致性模型，大大简化了文件系统，而不会给应用程序带来沉重负担。我们还引入了原子追加操作，使多个客户端可以同时追加文件，而无需额外的同步。本文稍后将详细讨论这些内容。\n目前，为不同目的部署了多个 GFS 集群。最大的集群有超过 1000 个存储节点，超过 300 TB 的磁盘存储空间，数百个客户端在不同的机器上持续大量访问。\n2. 设计概述 2.1 假设 在设计满足我们需求的文件系统时，我们遵循的假设既是挑战也是机遇。我们在前面提到了一些重要的观察结果，现在详细介绍一下我们的假设。\n该系统由许多经常发生故障的廉价商品组件构成。系统必须不断进行自我监控，日常检测、容忍和及时恢复组件故障。 系统存储的大文件数量不多。我们预计会有几百万个文件，每个文件的大小通常为 100 MB 或更大。多 GB 文件是常见情况，应得到有效管理。我们必须支持小文件，但无需对其进行优化。 工作负载主要包括两种读取：大型流式读取和小型随机读取。在大数据流读取中，单个操作通常读取数百 KB，更常见的是 1 MB 或更多。来自同一客户端的连续操作通常会读取文件的连续区域。小型随机读取通常在某个任意偏移位置读取几个 KB 的数据。注重性能的应用程序通常会对小规模读取进行批处理和排序，以稳定地读取文件，而不是来回读取。 这些工作负载中还有许多向文件追加数据的大型连续写入操作。典型的操作大小与读取类似。文件一旦写入，就很少再修改。支持在文件任意位置进行小规模写入，但不一定要高效。 系统必须有效地实现多个客户端同时追加到同一文件的定义明确的语义。我们的文件通常用作生产者-消费者队列或多路合并。数以百计的生产者（每台机器运行一个）将同时追加到一个文件。同步开销最小的原子性至关重要。文件可能会在稍后被读取，或者消费者可能会同时读取文件。 高持续带宽比低延迟更重要。我们的大多数目标应用都非常重视高速批量处理数据，而很少有应用对单个读取或写入的响应时间有严格要求。 2.2 接口 GFS 提供了一个熟悉的文件系统接口，尽管它没有实现标准的 API（如 POSIX）。文件在目录中按层次组织，并用路径名标识。我们支持创建、删除、打开、关闭、读取和写入文件的常规操作。\n此外，GFS 还有快照和记录追加操作。快照以低成本创建文件或目录树的副本。记录追加允许多个客户端同时向同一个文件追加数据，同时保证每个客户端追加的原子性。它适用于实现多向合并结果和生产者-消费者队列，许多客户端可以同时追加数据而无需额外锁定。我们发现，这些类型的文件在构建大型分布式应用时非常有用。快照追加和记录追加将分别在第 3.4 节和第 3.3 节中进一步讨论。\n2.3 架构 如图 1 所示，GFS 集群由一个主服务器和多个分块服务器组成，并由多个客户端访问。每个客户端通常是一台运行用户级服务器进程的商用 Linux 机器。只要机器资源允许，并且可以接受运行可能不稳定的应用程序代码所带来的较低可靠性，在同一台机器上同时运行分块服务器和客户端是很容易的。\nFigure 1: GFS Architecture 文件被分成固定大小的块。每个分块都由主服务器程序在创建分块时分配的不可更改且全球唯一的 64 位分块句柄来标识。分块服务器将分块作为 Linux 文件存储在本地磁盘上，并读取或写入由分块句柄和字节范围指定的分块数据。为了保证可靠性，每个数据块都会在多个数据块服务器上复制。默认情况下，我们会存储三个副本，但用户可以为文件命名空间的不同区域指定不同的复制级别。\n主文件系统维护所有文件系统元数据。其中包括命名空间、访问控制信息、文件到分块的映射以及分块的当前位置。主服务器还控制着全系统的活动，如块租约管理、孤儿块的垃圾回收以及块服务器之间的块迁移。主服务器会定期通过 HeartBeat 消息与每个块服务器进行通信，向其下达指令并收集其状态。\n连接到每个应用程序的 GFS 客户端代码实现文件系统 API，并与主服务器程序和块服务器通信，代表应用程序读取或写入数据。客户端与主服务器交互元数据操作，但所有数据通信都直接与块服务器进行。我们不提供 POSIX API，因此无需连接 Linux vnode 层。\n客户端和分块服务器都不缓存文件数据。客户端缓存的好处不大，因为大多数应用程序都会流式处理大量文件，或者工作集过大而无法缓存。没有缓存可以消除缓存一致性问题，从而简化客户端和整个系统。（但客户端会缓存元数据）。块服务器无需缓存文件数据，因为块是以本地文件的形式存储的，因此 Linux 的缓冲缓存已经将经常访问的数据保存在内存中。\n2.4 单个主服务器 单个主服务器大大简化了我们的设计，并使主服务器能够利用全局知识做出复杂的分块放置和复制决策。不过，我们必须尽量减少主服务器程序对读写的参与，以免其成为瓶颈。客户端从不通过主服务器读写文件数据。相反，客户端会询问主服务器它应该联系哪些分块服务器。客户端会在有限的时间内缓存这些信息，并在随后的许多操作中直接与分块服务器交互。\n让我们参照图 1 来解释一下简单读取的交互过程。首先，客户端使用固定的块大小，将应用程序指定的文件名和字节偏移转化为文件中的块索引。然后，客户端向主服务器程序发送包含文件名和块索引的请求。主服务器会回复相应的块句柄和副本位置。客户端使用文件名和块索引作为密钥缓存这些信息。\n然后，客户端向其中一个副本（很可能是最近的副本）发送请求。该请求指定了数据块句柄和该数据块内的字节范围。在缓存信息过期或文件重新打开之前，对同一数据块的进一步读取不再需要客户端与主服务器端之间的交互。事实上，客户端通常会在同一个请求中请求多个数据块，主服务器程序也可以包含紧随其后的数据块信息。这些额外的信息可以避免今后客户端与主服务器端之间的多次交互，而且几乎没有额外成本。\n2.5 分块大小 块大小是关键设计参数之一。我们选择了 64 MB，这比典型的文件系统块大小大得多。每个块副本都作为普通 Linux 文件存储在块服务器上，并且仅在需要时进行扩展。懒惰空间分配可避免因内部碎片而浪费空间，这可能是对如此大的块大小的最大反对意见。\n大块大小具有几个重要优势。首先，它减少了客户端与主服务器程序交互的需要，因为对同一分块的读写只需向主服务器程序发出一次初始请求，以获取分块位置信息。这对我们的工作负载来说意义尤其重大，因为应用程序大多是顺序读写大文件。即使是小规模的随机读取，客户端也能轻松缓存多 TB 工作集的所有分块定位信息。其次，由于在大块上，客户端更有可能对给定的大块执行许多操作，因此可以通过长时间保持与大块服务器的持久 TCP 连接来减少网络开销。第三，它可以减少存储在主服务器上的元数据的大小。这样我们就能将元数据保存在内存中，从而带来其他优势，我们将在第 2.6.1 节中讨论。\n另一方面，即使使用懒惰空间分配，大块大小也有其缺点。小文件由少量的块组成，也许只有一个。如果有很多客户端访问同一个文件，存储这些分块的分块服务器可能会成为热点。在实际应用中，热点并不是一个大问题，因为我们的应用程序大多是按顺序读取大型多块文件。\n然而，当 GFS 首次用于批处理队列系统时，确实出现了热点：一个可执行文件以单块文件的形式写入 GFS，然后在数百台机器上同时启动。数以百计的同时请求使存储该可执行文件的少数主块服务器不堪重负。我们通过使用更高的复制系数来存储此类可执行文件，并让批队列系统错开应用程序的启动时间，从而解决了这一问题。一个潜在的长期解决方案是允许客户端在这种情况下从其他客户端读取数据。\n2.6 元数据 主服务器存储三种主要类型的元数据：文件和块命名空间、从文件到块的映射以及每个块的副本的位置。所有元数据都保存在主服务器的内存中。前两种类型（命名空间和文件到块的映射）也通过将变化记录到存储在主服务器本地磁盘上的操作日志中并复制到远程机器上来保持持久性。使用日志使我们能够简单、可靠地更新主服务器状态，并且在主服务器崩溃时不会冒不一致的风险。主服务器不会持久存储块位置信息。相反，它会在主服务器启动时以及每当有块服务器加入集群时向每个块服务器询问其块。\n2.6.1 内存数据结构 由于元数据存储在内存中，因此主服务器操作速度很快。此外，主服务器在后台定期扫描其整个状态也非常简单高效。这种周期性扫描被用来实现垃圾块收集、在主块服务器出现故障时进行重新复制以及主块迁移，以平衡主块服务器之间的负载和磁盘空间使用。第4.3节和第4.4节将进一步讨论这些活动。\n这种只使用内存的方法可能存在的一个问题是，分块的数量以及整个系统的容量都受到主服务器内存容量的限制。实际上，这并不是一个严重的限制。主文件会为每个 64 MB 的数据块维护少于 64 字节的元数据。大多数分块都是满的，因为大多数文件包含许多分块，只有最后一个分块可能被部分填满。同样，文件命名空间数据通常每个文件只需要少于 64 字节，因为它使用前缀压缩紧凑地存储了文件名。\n如果有必要支持更大的文件系统，为主文件系统增加额外内存的成本并不高，但却能通过在内存中存储元数据而获得简单性、可靠性、性能和灵活性。\n2.6.2 分块位置 主服务器程序不会持续记录哪些分块服务器拥有某个分块的副本。它只需在启动时轮询各块服务器以获取该信息。由于主服务器控制着所有的分块放置，并通过定期的 HeartBeat 信息监控分块服务器的状态，因此主服务器可以随时更新自己的信息。\n我们最初尝试在主服务器端持久保存块位置信息，但后来发现，在启动时和之后定期从块服务器请求数据要简单得多。这样就解决了主服务器和块服务器在块服务器加入、离开集群、更名、故障、重启等情况下保持同步的问题。在拥有数百台服务器的集群中，这些事件经常发生。\n理解这一设计决定的另一种方法是认识到，对于自己的磁盘上是否有数据块，数据块服务器拥有最终决定权。试图在主服务器上保持对这些信息的一致看法是没有意义的，因为数据块服务器上的错误可能会导致数据块自发消失（例如，磁盘坏掉并被禁用），或者操作员可能会重命名数据块服务器。\n2.6.3 操作日志 操作日志包含关键元数据更改的历史记录。它是 GFS 的核心。它不仅是元数据的唯一持久记录，还是定义并发操作顺序的逻辑时间线。文件和数据块以及它们的版本（见第 4.5 节）都以它们创建的逻辑时间为唯一且永恒的标识。\n由于操作日志至关重要，因此我们必须可靠地存储操作日志，并且在元数据更改持久化之前，不能让客户端看到更改。否则，即使数据块本身存活下来，我们也会丢失整个文件系统或最近的客户端操作。因此，我们将日志复制到多台远程机器上，只有在本地和远程将相应的日志记录刷新到磁盘后，才能响应客户端操作。在刷新之前，主服务器程序会将多条日志记录集中在一起，从而减少刷新和复制对整个系统吞吐量的影响。\n主服务器通过重放操作日志来恢复其文件系统状态。为了最大限度地缩短启动时间，我们必须保持日志较小。每当日志超过一定大小时，主服务器都会检查其状态，以便它可以通过从本地磁盘加载最新的检查点并在此之后仅重放有限数量的日志记录来恢复。检查点采用紧凑的 B 树形式，可以直接映射到内存中并用于命名空间查找，而无需额外解析。这进一步加快了恢复速度并提高了可用性。\n由于创建一个检查点可能需要一段时间，因此主服务器的内部状态结构应能在不耽误接收传入的变更的情况下创建新的检查点。主服务器会切换到新的日志文件，并在单独的线程中创建新的检查点。新的检查点包括切换前的所有变更。对于拥有几百万个文件的集群来说，一分钟左右就能创建完毕。完成后，它将被写入本地和远程磁盘。\n恢复只需要最新的完整检查点和后续日志文件。较早的检查点和日志文件可以随意删除，但我们会保留一些以防万一。检查点过程中的故障不会影响正确性，因为恢复代码会检测并跳过不完整的检查点。\n2.7 一致性模型 GFS 有一个宽松的一致性模型，可以很好地支持我们的高度分布式应用，而且实现起来相对简单高效。我们现在讨论 GFS 的保证及其对应用程序的意义。我们还将重点介绍 GFS 如何维护这些保证，但具体细节将留待本文其他部分讨论。\n2.7.1 GFS的保证 文件命名空间的变更（如文件创建）是原子性的。它们完全由主服务器程序处理：命名空间锁定保证了原子性和正确性（第 4.1 节）；主服务器程序的操作日志定义了这些操作的全局总顺序（第 2.6.3 节）。\n文件区域在数据变更后的状态取决于变更的类型、变更是否成功，以及是否存在并发变更。表1总结了结果。如果所有客户端无论从哪个副本读取数据都始终看到相同的数据，则文件区域是一致的（consistent）。在文件数据变更后，如果区域是一致的，并且客户端能够完整地看到其变更所写入的内容，则该区域是确定的（defined）。当一个变更在没有并发写入者干扰的情况下成功时，受影响的区域则为确定的（包含了一致性）：所有客户端将始终看到变更所写入的内容。并发成功的变更使区域不确定但仍然一致：所有客户端看到相同的数据，但这些数据可能无法反映任何单个变更的内容。通常，这些数据由多个变更的混合片段组成。失败的变更使区域变得不一致（因此也不确定）：不同的客户端可能在不同的时间看到不同的数据。下面我们将描述我们的应用程序如何区分确定与不确定区域。应用程序不需要进一步区分不同类型的不确定区域。\n数据变更可以是写入操作或记录追加操作。写入操作会在应用程序指定的文件偏移位置写入数据。记录追加操作会在存在并发变更的情况下，以原子方式至少追加一次数据（即“记录”），但写入的位置由 GFS 选择（见第3.3节）。（与此相反，\u0026ldquo;常规 \u0026ldquo;追加只是在客户端认为是当前文件末尾的偏移位置进行写入）。偏移量会返回给客户端，并标志着包含记录的确定区域的开始。此外，GFS 还可能在中间插入填充或重复记录。它们占据的区域被认为是不一致的，与用户数据量相比通常相形见绌。\n在一连串成功的变更之后，变更后的文件区域保证是已确定的，并包含最后一次变更所写入的数据。GFS 通过以下方式实现这一目标：(a) 在所有副本上以相同顺序对一个主块进行变异（第 3.1 节）；(b) 使用主块版本号来检测因其主块服务器宕机而错过变异的副本（第 4.5 节）。陈旧副本绝不会参与变更，也不会提供给向主服务器询问主块位置的客户端。它们会尽早被垃圾回收。\n由于客户端会缓存块定位，因此可能会在信息刷新前从陈旧的副本中读取信息。这个窗口会受到缓存条目超时和下一次打开文件的限制，因为下一次打开文件会从缓存中清除该文件的所有分块信息。此外，由于我们的大多数文件都是仅附加的，因此陈旧的副本通常会返回一个过早结束的分块，而不是过时的数据。当阅读器重试并联系主文件时，它将立即获得当前的分块位置。\n当然，在成功变更后的很长一段时间内，组件故障仍有可能损坏或毁坏数据。GFS 通过主服务器与所有主服务器之间的定期握手来识别故障的主服务器，并通过校验和来检测数据损坏（第 5.2 节）。一旦出现问题，就会尽快从有效副本中恢复数据（第 4.3 节）。只有当数据块的所有副本在 GFS 作出反应前丢失（通常在几分钟内），数据块才会不可逆转地丢失。即使在这种情况下，数据块也是不可用的，而不是损坏的：应用程序收到的是明确的错误，而不是损坏的数据。\n2.7.2 对应用的影响 GFS 应用程序可以通过其他用途所需的一些简单技术来适应宽松的一致性模型：依靠追加而不是覆盖、检查点以及写入自验证、自识别记录。\n实际上，我们所有的应用程序都是通过追加而不是覆盖来改变文件的。在一个典型的应用中，写入器从头到尾生成一个文件。在写入所有数据后，它会以原子方式将文件重命名为永久名称，或定期检查已成功写入多少数据。检查点还可能包括应用级校验和。读取器只验证和处理上一个检查点之前的文件区域，因为已知该区域处于确定的状态。无论一致性和并发性问题如何，这种方法都很有效。与随机写入相比，追加的效率要高得多，对应用程序故障的恢复能力也更强。检查点允许写入程序以增量方式重新启动，并防止读取程序处理从应用程序角度来看仍不完整的已成功写入文件数据。\n在另一种典型用途中，许多写入器同时向文件追加合并结果或作为生产者-消费者队列。记录追加的 \u0026ldquo;至少追加一次 \u0026ldquo;语义保留了每个写入器的输出。读取器会按如下方式处理偶尔出现的填充和重复。写入器编写的每条记录都包含校验和等额外信息，以便验证其有效性。阅读器可以使用校验和来识别和丢弃额外的填充和记录片段。如果不能容忍偶尔出现的重复记录（例如，如果重复记录会触发非幂等操作），则可以使用记录中的唯一标识符将其过滤掉。记录 I/O 的这些功能（除重复删除外）都在我们应用程序共享的库代码中，也适用于谷歌的其他文件接口实现。有了这些功能，我们就能始终向记录阅读器提供相同序列的记录，以及极少数的重复记录。\n3. 系统交互 我们在设计系统时尽量减少主服务器对所有操作的参与。有了上述背景，我们现在来介绍客户端、主服务器端和分块服务器是如何交互实现数据变更、原子记录追加和快照的。\n3.1 租约和变更顺序 变更是指更改数据块内容或元数据的操作，例如写入或追加操作。每次变更都会在所有数据块的副本上执行。我们使用租约来维护副本之间一致的变更顺序。主服务器将一个数据块的租约授予其中一个副本，我们称之为主副本。主副本为所有对该数据块的变更选择一个串行顺序。所有副本在应用变更时都遵循这个顺序。因此，全局变更顺序首先由主服务器选择的租约授予顺序定义，而在一个租约内，则由主副本分配的序列号来定义。\n租约机制旨在最小化主服务器的管理开销。租约的初始超时时间为60秒。然而，只要数据块正在被变更，主副本可以向主服务器请求并通常能够获得无限期的租约延长。这些延长请求和授予通过主服务器与所有数据块服务器定期交换的 HeartBeat 消息进行捆绑。当主服务器希望在文件重命名时禁用对该文件的变更时，有时会尝试在租约到期前撤销租约。即使主服务器与主副本失去通信，在旧租约到期后，它也可以安全地将新租约授予另一个副本。\n在图 2 中，我们按照写入的控制流，通过这些编号步骤来说明这一过程。\n客户端向主服务器询问当前哪个数据块服务器持有该数据块的租约，以及其他副本的位置。如果没有副本持有租约，主服务器将向它选择的一个副本授予租约（未显示）。 主服务器会回复主副本的身份和其他（次级）副本的位置。客户端将这些数据缓存以供将来的变更使用。只有在主副本变得不可达或回复称不再持有租约时，客户端才需要再次联系主服务器。 客户端将数据推送到所有副本。客户端可以按照任意顺序进行此操作。每个数据块服务器会在内部的LRU缓存中存储数据，直到数据被使用或过期。通过将数据流与控制流解耦，我们可以根据网络拓扑优化昂贵的数据流调度，而不依赖于哪个数据块服务器是主副本。第3.2节对此进行了进一步讨论。 一旦所有副本确认接收到数据，客户端会向主副本发送写请求。该请求标识了之前推送给所有副本的数据。主副本为接收到的所有变更（可能来自多个客户端）分配连续的序列号，以提供必要的序列化。它按照序列号的顺序将变更应用到其本地状态中。 主副本将写入请求转发给所有次级副本。每个次级副本按照主副本分配的序列号顺序应用变更。 所有次级副本都会回复主副本，表示它们已完成操作。 主副本会向客户端回复。任何在副本处遇到的错误都会报告给客户端。在发生错误的情况下，写操作可能在主副本成功，而在任意数量的次级副本中失败。（如果主副本的写操作失败，它将不会被分配序列号并进行转发。）客户端请求被视为失败，修改区域将处于不一致状态。我们的客户端代码通过重试失败的变更来处理这些错误。它会在步骤（3）到（7）之间进行几次尝试，然后才会回退到从写操作开始重新尝试。 如果应用程序的写操作较大或跨越了数据块边界，GFS客户端代码会将其分解为多个写操作。所有操作都会遵循上述控制流程，但可能与其他客户端的并发操作交错或被覆盖。因此，虽然副本之间的内容会保持一致（因为所有操作在所有副本上都以相同的顺序成功完成），共享文件区域可能最终包含来自不同客户端的片段。正如第2.7节提到的，这会使文件区域处于一致但未确定的状态。\n3.2 数据流 我们将数据流与控制流解耦，以更高效地利用网络资源。控制流从客户端传递到主副本，再从主副本传递到所有次级副本；而数据则以流水线的方式沿着精心选择的链式数据块服务器线性推送。我们的目标是充分利用每台机器的网络带宽，避免网络瓶颈和高延迟连接，并尽量减少推送全部数据的延迟。\n为了充分利用每台机器的网络带宽，数据被沿着一条数据块服务器链线性推送，而不是通过其他拓扑结构（例如树形结构）分发。这样，每台机器的全部出站带宽都用于尽可能快速地传输数据，而不是被分配给多个接收者。\n为了尽可能避免网络瓶颈和高延迟链路（例如，交换机间链路往往同时存在），每台机器都会将数据转发给网络拓扑结构中尚未接收数据的 \u0026ldquo;最近 的\u0026quot;机器。假设客户端正在向分块服务器 S1 至 S4 推送数据。客户端将数据发送到最近的分块服务器，如 S1。S1 将数据转发给离 S1 最近的分块服务器 S2 至 S4，即 S2。同样，S2 将数据转发给离 S2 最近的 S3 或 S4，以此类推。我们的网络结构非常简单，\u0026ldquo;距离 \u0026ldquo;可以通过 IP 地址准确估算。\n为了最大限度地减少延迟，我们通过 TCP 连接进行数据传输的流水线化处理。一旦数据块服务器接收到一部分数据，它就会立即开始转发。流水线机制对我们特别有帮助，因为我们使用的是带有全双工链路的交换网络。立即发送数据不会降低接收速率。在没有网络拥塞的情况下，将 B 字节的数据传输到 R 个副本的理想时间为 B/T + RL，其中 T 是网络吞吐量，L 是两台机器之间传输数据的延迟。我们网络的典型链路速率为 100 Mbps (T)，而L远低于 1 毫秒。因此，1 MB 的数据理想情况下可以在大约 80ms 内分发完成。\n3.3 原子记录追加 GFS 提供了一种称为记录追加的原子追加操作。在传统的写操作中，客户端指定数据写入的偏移量。对于同一区域的并发写操作，无法实现可序列化：该区域可能最终包含来自多个客户端的数据片段。然而，在记录追加操作中，客户端只需指定数据。GFS 会以原子方式（即作为一个连续的字节序列）至少一次将数据追加到文件中，偏移量由 GFS 决定，并将该偏移量返回给客户端。这类似于在 Unix 系统中以 O_APPEND 模式打开文件进行写操作，但避免了多个写入者同时操作时的竞争条件。\n我们的分布式应用程序大量使用记录追加功能，其中不同机器上的许多客户端会同时追加到同一个文件。如果客户端采用传统的写入方式，则需要额外复杂而昂贵的同步，例如通过分布式锁管理器。在我们的工作负载中，此类文件通常用作多生产者/单消费者队列，或包含来自许多不同客户端的合并结果。\n记录追加是一种变更，它遵循第 3.1 节中的控制流，只在主副本有一些额外的逻辑。客户端将数据推送到文件最后一个分块的所有副本中，然后将请求发送给主副本。主副本会检查将记录追加到当前数据块是否会导致数据块超过最大容量（64 MB）。如果会，它就会将分块填充到最大大小，告诉辅助分块也这样做，并回复客户端，说明应在下一个分块上重试操作。（记录追加的大小最多只能是最大分块大小的四分之一，以便将最坏情况下的碎片保持在可接受的水平）。如果记录符合最大大小（这是常见的情况），主副本就会将数据追加到其副本中，并告诉次节点在其确切偏移量处写入数据，最后向客户端回复成功。\n如果任何副本的记录追加失败，客户端会重试操作。因此，同一分块的副本可能包含不同的数据，其中可能包括同一记录的全部或部分副本。GFS 并不保证所有副本在字节上完全相同。它只保证数据作为一个原子单元至少被写入一次。这一特性很容易从简单的观察中得出：要使操作报告成功，数据必须在某个数据块的所有副本上以相同的偏移量写入。此外，在此之后，所有副本的长度至少与记录末尾的长度相同，因此，即使后来不同的副本成为主副本，未来的记录也会被分配到更高的偏移量或不同的分块。就一致性保证而言，成功进行记录追加操作并写入数据的区域是确定的（因此是一致的），而中间区域则是不一致的（因此是未确定的）。正如我们在第 2.7.2 节中所讨论的，我们的应用程序可以处理不一致的区域。\n3.4 快照 快照操作几乎可以瞬间复制文件或目录树（\u0026ldquo;源\u0026rdquo;），同时最大限度地减少对正在进行的变更的干扰。我们的用户用它来快速创建庞大数据集的分支副本（通常是这些副本的递归副本），或者在尝试更改之前对当前状态进行检查，这些更改随后可以很容易地提交或回滚。\n与 AFS [5] 一样，我们使用标准的写时复制技术来实现快照。当主服务器接收到快照请求时，它首先会撤销即将快照文件中的数据块上的所有未完成的租约。这确保了对这些数据块的任何后续写入都需要与主服务器进行交互，以查找租约持有者。这将主服务器就有机会首先创建数据块的新副本。\n租约撤销或过期后，主服务器会将操作记录到磁盘上。然后，它通过复制源文件或目录树的元数据，将此日志记录应用到内存状态。新创建的快照文件指向与源文件相同的块。\n当客户端第一次想要在快照操作之后写入数据块 C 时，它会向主服务器发送请求以查找当前的租约持有者。主服务器注意到数据块 C 的引用计数大于1。它推迟了对客户端请求的回复，而是选择了一个新的数据块句柄 C\u0026rsquo;。然后，主服务器要求每个拥有 C 当前副本的数据块服务器创建一个名为 C\u0026rsquo; 的新数据块。通过在与原始数据块相同的数据块服务器上创建新数据块，我们确保数据可以在本地复制，而不是通过网络复制（我们的磁盘速度约是100 Mb 以太网链接的三倍）。从这一点开始，请求处理与任何数据块的处理没有区别：主服务器将新的数据块 C\u0026rsquo; 的租约授予其中一个副本，并回复客户端，客户端可以正常写入该数据块，而不知道它刚刚是从现有数据块创建的。\n4. 主服务器操作 主服务器执行所有命名空间操作。此外，它还负责管理整个系统中的分块副本：做出放置决定、创建新的分块和副本、协调各种全系统活动以保持分块完全复制、平衡所有分块服务器的负载以及回收未使用的存储空间。下面我们将逐一讨论这些主题。\n4.1 命名空间管理和锁定 许多主服务器操作可能需要较长时间：例如，快照操作必须撤销覆盖快照的所有数据块服务器上的租约。我们不希望在这些操作运行时延迟其他主服务器操作。因此，我们允许多个操作同时进行，并在命名空间的区域上使用锁来确保适当的序列化。\n与许多传统文件系统不同，GFS 没有每个目录的数据显示结构来列出该目录中的所有文件。它也不支持同一个文件或目录的别名（即 Unix 术语中的硬链接或符号链接）。GFS 在逻辑上将其命名空间表示为一个查找表，该表将完整路径名映射到元数据。通过前缀压缩，该表可以高效地在内存中表示。命名空间树中的每个节点（无论是绝对文件名还是绝对目录名）都有一个关联的读写锁。\n每个主操作都会在运行前获取一组锁。通常情况下，如果涉及 /d1/d2/.../dn/leaf，它将获得目录名 /d1、/d1/d2、\u0026hellip;、/d1/d2/.../dn 的读锁，以及完整路径名 /d1/d2/.../dn/leaf 的读锁或写锁。请注意，根据操作的不同，leaf 可以是文件或目录。\n现在，我们将说明这种锁定机制如何防止 /home/user/foo 文件在 /home/user 被快照到 /save/user时被创建。快照操作会获取/home 和 /save 上的读锁，以及 /home/user 和 /save/user 上的写锁。文件创建会获取/home 和 /home/user 上的读锁，以及 /home/user/foo 上的写锁。这两个操作将被正确序列化，因为它们试图获取 /home/user 上的冲突锁。文件创建不需要对父级目录加写锁，因为没有 \u0026ldquo;目录 \u0026ldquo;或类似于 inode 的数据结构需要防止修改。对名称的读取锁足以保护父目录不被删除。\n该锁机制的一个优点是它允许在同一目录中同时进行并发的修改。例如，可以在同一目录中同时执行多个文件创建操作：每个操作都会对目录名称获取读锁，并对文件名称获取写锁。对目录名称的读锁足以防止目录被删除、重命名或快照。而对文件名称的写锁则能序列化（排队）防止两次创建同名文件的尝试。\n由于命名空间可能有很多节点，因此读写锁对象的分配比较懒惰，一旦不使用就会被删除。此外，为防止死锁，获取锁的总顺序是一致的：首先按命名空间树中的层级排序，然后在同一层级内按字典序排序。\n4.2 副本放置 一个 GFS 集群在多个层面上高度分布化。它通常拥有数百个分布在多个机架上的数据块服务器。这些数据块服务器又可能被来自同一机架或不同机架的数百个客户端访问。位于不同机架的两台机器之间的通信可能需要通过一个或多个网络交换机。此外，进入或离开某个机架的带宽可能小于该机架内所有机器的总带宽。多层级的分布化为数据分布带来了独特的挑战，涉及到可扩展性、可靠性和可用性的需求。\n分块副本放置策略有两个目的：最大化数据的可靠性和可用性，以及最大化网络带宽的利用。为此，仅将副本分布在不同机器上是不够的，这样只能防止磁盘或机器故障并充分利用每台机器的网络带宽。我们还必须将块副本分布在不同的机架上。这可以确保即使整个机架发生故障或下线（例如，由于共享资源故障，如网络交换机或电路问题），块的一些副本仍能存活并保持可用性。这也意味着某个块的流量，尤其是读操作，可以利用多个机架的总带宽。然而，写操作的流量需要通过多个机架，这是我们愿意接受的权衡。\n4.3 创建、再复制、再平衡 数据块副本的创建有三个原因：块创建、重新复制和再平衡。\n当主服务器创建一个数据块时，它会选择放置初始空副本的位置，并考虑几个因素：(1) 我们希望将新副本放置在磁盘利用率低于平均水平的块服务器上。随着时间推移，这将使各块服务器的磁盘利用率趋于平衡。(2) 我们希望限制每个块服务器上“最近”创建的副本数量。虽然创建本身成本低，但它能可靠地预测即将到来的大量写入流量，因为数据块是在写入需求时创建的，并且在我们的“一次追加-多次读取”工作负载中，一旦完全写入，它们通常会变成几乎只读。(3) 如上所述，我们希望将数据块的副本分散到不同的机架上。\n主服务器会在可用副本数量低于用户指定目标时立即重新复制数据块。这可能由于多种原因发生：数据块服务器变得不可用、报告其副本可能已损坏、某个磁盘因错误被禁用，或复制目标增加。每个需要重新复制的数据块会根据多个因素进行优先级排序。其中一个因素是它距离复制目标的远近。例如，我们会优先处理失去两个副本的数据块，而不是仅失去一个副本的数据块。此外，我们更倾向于优先重新复制活动文件的数据块，而不是属于最近删除文件的数据块（见第 4.4 节）。最后，为了最小化故障对正在运行的应用程序的影响，我们会提高任何阻塞客户端进展的数据块的优先级。\n主服务器会选择优先级最高的数据块，并通过指示某个数据块服务器直接从现有有效副本复制数据块来“克隆”它。新副本的放置目标与创建时类似：平衡磁盘空间利用率、限制任何单个数据块服务器上的活动克隆操作，以及在机架间分散副本。为了防止克隆流量压倒客户端流量，主服务器限制了集群和每个数据块服务器上的活动克隆操作数量。此外，每个数据块服务器通过限制对源数据块服务器的读取请求，来控制每个克隆操作所使用的带宽。\n最后，主服务器会定期重新平衡副本：它会检查当前的副本分布，并移动副本以实现更好的磁盘空间和负载平衡。在这个过程中，主服务器逐步填充新的数据块服务器，而不是立即用新数据块和随之而来的大量写入流量淹没它。新副本的放置标准与上述讨论的相似。此外，主服务器还必须选择移除哪个现有副本。一般来说，它更倾向于移除那些在磁盘空间低于平均水平的数据块服务器上的副本，以便平衡磁盘空间的使用。\n4.4 垃圾回收 删除文件后，GFS 不会立即回收可用的物理存储空间。它只会在文件和块级的定期垃圾回收过程中懒惰地回收。我们发现，这种方法让系统变得更简单、更可靠。\n4.4.1 机制 当应用程序删除一个文件时，主服务器会立即记录删除操作，就像其他更改一样。然而，主服务器并不会立即回收资源，而是将文件重命名为一个包含删除时间戳的隐藏名称。在主服务器定期扫描文件系统命名空间时，它会移除任何存在超过三天（该时间间隔是可配置的） 的隐藏文件。在此之前，该文件仍可以通过新的特殊名称进行读取，并且可以通过重命名恢复为正常文件。当隐藏文件从命名空间中移除时，其内存中的元数据会被擦除，这有效地切断了与所有数据块的链接。\n在对数据块命名空间进行类似的定期扫描时，主服务器会识别孤立的数据块（即那些无法从任何文件访问的数据块），并擦除这些数据块的元数据。在与主服务器定期交换的心跳消息中，每个数据块服务器会报告它所拥有的一部分数据块，而主服务器则回复所有不再存在于其元数据中的数据块的身份。数据块服务器可以自由地删除这些孤立数据块的副本。\n4.4.2 讨论 尽管分布式垃圾回收在编程语言中是一个难题，需要复杂的解决方案，但在我们的情况下却相对简单。我们可以轻松识别所有对数据块的引用：它们在由主服务器独占维护的文件到数据块的映射中。此外，我们也可以轻松识别所有的数据块副本：它们是每个数据块服务器上指定目录下的Linux文件。任何不被主服务器知晓的副本都可以视为“垃圾”。\n这种垃圾回收的方法在存储回收方面相比于急切删除具有几个优势。首先，在组件故障常见的大规模分布式系统中，它简单且可靠。数据块的创建可能在某些数据块服务器上成功，但在其他服务器上失败，导致主服务器不知道存在的副本。副本删除消息可能会丢失，主服务器需要记住在故障（包括自身和数据块服务器的故障）后重新发送这些消息。垃圾回收提供了一种统一且可靠的方式来清理任何不被认为有用的副本。其次，它将存储回收与主服务器的常规后台活动（如命名空间的定期扫描和与数据块服务器的握手）合并。因此，回收操作是在批处理过程中进行的，成本被摊销。此外，它只在主服务器相对空闲时进行，从而使主服务器能够更迅速地响应需要及时关注的客户端请求。第三，回收存储的延迟提供了一个安全网，防止意外和不可逆的删除。\n根据我们的经验，主要缺点是延迟有时会妨碍用户在存储空间紧张时对使用情况进行微调。反复创建和删除临时文件的应用程序可能无法立即重新使用存储空间。为了解决这些问题，如果删除的文件被再次明确删除，我们就会加快存储空间的回收。我们还允许用户对命名空间的不同部分应用不同的复制和回收策略。例如，用户可以指定某些目录树中的所有文件块都不进行复制存储，任何被删除的文件都会立即从文件系统状态中不可撤销地移除。\n4.5 过时副本检测 如果一个分块服务器发生故障，并在宕机期间错过了对分块的变更，那么分块副本就可能成为过期副本。对于每个数据块，主服务器都会维护一个数据块版本号，以区分最新和过时的副本。\n每当主服务器为某个数据块授予新的租约时，它会增加该数据块的版本号，并通知最新的副本。主服务器和这些副本都会在其持久状态中记录新的版本号。这一过程发生在任何客户端被通知之前，因此在客户端开始写入数据块之前。如果某个副本当前不可用，则该副本的版本号将不会被提升。当该数据块服务器重新启动并报告其数据块及其相关版本号时，主服务器将检测到该数据块服务器拥有一个过时的副本。如果主服务器看到某个版本号高于其记录中的版本号，它会假设在授予租约时发生了故障，因此会将更高的版本视为最新版本。\n主服务器在其定期的垃圾回收过程中会移除过时的副本。在此之前，主服务器在回复客户端关于数据块信息的请求时，实际上会认为过时的副本根本不存在。作为另一种保护措施，主服务器在告知客户端哪个数据块服务器持有某个数据块的租约或在指示某个数据块服务器从另一数据块服务器读取数据块进行克隆操作时，会包含数据块的版本号。客户端或数据块服务器在执行操作时会验证版本号，以确保始终访问最新的数据。\n5. 容错与诊断 我们在设计系统时面临的最大挑战之一就是处理频繁的组件故障。组件的质量和数量使得这些问题变得更加普遍，而不是偶尔出现：我们不能完全信任机器，也不能完全信任磁盘。组件故障可能导致系统不可用，或更糟糕的是，数据损坏。我们讨论如何应对这些挑战，以及我们在系统中内置的工具，用于在问题不可避免地发生时对其进行诊断。\n5.1 高度可用性 5.1.1 快速恢复 无论主服务器和分块服务器是如何终止的，它们都能在数秒内恢复状态并启动。事实上，我们并不区分正常终止和非正常终止；服务器通常只需杀死进程即可关闭。客户端和其他服务器在未处理请求超时、重新连接到重新启动的服务器并重试时，都会经历一个小插曲。第 6.2.2 节报告了观察到的启动时间。\n5.1.2 分块复制 如前所述，每个数据块会在不同机架的多个块服务器上进行复制。用户可以为文件命名空间的不同部分指定不同的复制级别，默认值为三。主服务器根据需要克隆现有副本，以保持每个数据块的完全复制，尤其是在块服务器离线或通过校验和验证检测到副本损坏时（参见第5.2节）。虽然复制技术一直表现良好，但我们正在探索其他形式的跨服务器冗余，如奇偶校验或纠删码，以满足日益增长的只读存储需求。我们预计在我们这种松耦合的系统中实施这些更复杂的冗余方案既具有挑战性又是可管理的，因为我们的流量主要是追加和读取，而不是小规模随机写入。\n主服务器的状态被复制以确保可靠性。其操作日志和检查点会在多个机器上进行复制。只有当状态的日志记录已在本地及所有主服务器副本上刷新到磁盘后，状态的变更才被视为已提交。为了简化管理，只有一个主进程负责所有变更操作以及如垃圾回收等内部系统活动。当主服务器发生故障时，它几乎可以立即重新启动。如果其所在的机器或磁盘故障，GFS之外的监控基础设施会在其他地方启动一个新的主进程，并使用复制的操作日志。客户端只使用主服务器的规范名称（例如 gfs-test），这是一个可以在主服务器迁移到另一台机器时更改的DNS别名。\n此外，“影子”主服务器在基本主服务器宕机时提供只读访问文件系统。它们被称为影子，而非镜像，因为它们可能会稍微滞后于主服务器，通常是几分之一秒。影子主服务器提高了对于未被积极修改的文件的读取可用性，或者对于不介意稍微陈旧结果的应用程序而言，增强了可用性。实际上，由于文件内容是从数据块服务器读取的，应用程序并不会观察到陈旧的文件内容。短时间内可能出现陈旧的，是文件元数据，比如目录内容或访问控制信息。\n为了保持信息更新，影子主服务器读取正在增长的操作日志的副本，并以与主服务器完全相同的顺序将更改应用到其数据结构中。像主服务器一样，它在启动时（以及之后不频繁地）轮询块服务器以定位块副本，并与它们交换频繁的握手消息以监控其状态。影子主服务器仅依赖主服务器提供的副本位置更新，这些更新源于主服务器对副本的创建和删除决策。\n5.2 数据完整性 每个块服务器使用校验和来检测存储数据的损坏。考虑到GFS集群通常有数千个磁盘分布在数百台机器上，它定期会经历磁盘故障，这会导致读写路径上的数据损坏或丢失（见第7节了解一个原因）。我们可以通过其他块副本来恢复损坏的数据，但通过比较块服务器之间的副本来检测损坏是不切实际的。此外，差异副本可能是合法的：GFS变更的语义，特别是之前讨论的原子记录追加，并不保证副本完全相同。因此，每个块服务器必须通过维护校验和独立验证其自身副本的完整性。\n一个数据块被分成 64 KB 的块。每个块都有相应的 32 位校验和。与其他元数据一样，校验和也保存在内存中，并与日志一起持久存储，与用户数据分开。\n对于读取，在向请求者（无论是客户端还是其他分块服务器）返回任何数据之前，分块服务器会验证与读取范围重叠的数据块的校验和。因此，数据块服务器不会将损坏传播给其他机器。如果数据块与记录的校验和不匹配，分块服务器会向请求者返回错误信息，并向主服务器报告不匹配情况。作为回应，请求者将从其他副本中读取，而主服务器将从另一个副本中克隆该块。在有效的新副本就位后，主服务器会指示报告不匹配的分块服务器删除其副本。\n校验和对读取性能影响不大，原因有几个。由于我们的大多数读取至少跨越几个块，因此我们只需要读取和校验相对少量的额外数据以进行验证。GFS 客户端代码通过尝试在校验和块边界处对齐读取来进一步减少这种开销。此外，分块服务器上校验和的查找和比较无需任何 I/O，校验和计算通常可以与 I/O 重叠。\n校验和计算针对附加到块末尾的写入（相对于覆盖现有数据的写入）进行了大量优化，因为它们在我们的工作负载中占主导地位。我们只需增量更新最后一个部分校验和块的校验和，并为附加所填充的全新校验和块计算新的校验和。即使最后一个部分校验和区块已经损坏，并且我们现在没有检测到，新的校验和值也不会与存储的数据匹配，而且在下一次读取该区块时，也会像往常一样检测到损坏。\n相反，如果写入的内容覆盖了数据块的现有范围，我们就必须先读取并校验被覆盖范围的第一个和最后一个数据块，然后执行写入操作，最后计算并记录新的校验和。如果我们在部分覆盖首尾区块之前不对其进行校验，新的校验和可能会掩盖未被覆盖区域中存在的损坏。\n在空闲期间，数据块服务器可以扫描并验证非活动数据块的内容。这样，我们就能检测到很少被读取的数据块的损坏。一旦检测到损坏，主控程序就可以创建一个新的未损坏副本，并删除损坏的副本。这样就能防止不活动但已损坏的数据块副本欺骗主服务器，让它以为自己有足够多的数据块有效副本。\n5.4 诊断工具 广泛而细致的诊断日志在问题隔离、调试和性能分析方面发挥了不可估量的作用，而其成本却非常低。没有日志的话，很难理解机器之间瞬时且不可重复的交互。GFS 服务器生成诊断日志，记录许多重要事件（例如分块服务器的启动和关闭）以及所有的 RPC 请求和回复。这些诊断日志可以随意删除，而不会影响系统的正确性。然而，我们尽量在空间允许的情况下保留这些日志。\n除了正在读取或写入的文件数据外，RPC 日志包括在线路上发送的确切请求和响应。通过匹配请求和回复，并整理不同机器上的 RPC 记录，我们可以重建整个交互历史，从而诊断问题。日志还可作为负载测试和性能分析的跟踪记录。\n日志记录对性能的影响极小（并且其好处远远超过影响），因为这些日志是以顺序和异步方式写入的。最近的事件还保存在内存中，可用于持续的在线监控。\n6. 测量 在本节中，我们将介绍一些微型基准测试，以说明 GFS 架构和实施中固有的瓶颈，以及谷歌实际使用的集群中的一些数据。\n6.1 微基准测试 我们在由一个主服务器、两个主服务器副本、16 个块服务器和 16 个客户端组成的 GFS 集群上测量了性能。请注意，这种配置是为了便于测试而设置的。典型的集群有数百个块服务器和数百个客户端。\n所有机器都配置了双 1.4 GHz PIII 处理器、2 GB 内存、两个 80 GB 5400 rpm 磁盘，以及连接到 HP 2524 交换机的 100 Mbps 全双工以太网。所有 19 台 GFS 服务器连接到一台交换机，所有 16 台客户机连接到另一台交换机。两台交换机通过 1 Gbps 链路连接。\n6.1.1 读 N 个客户端同时从文件系统读取数据。每个客户端从 320 GB 的文件集中随机读取 4 MB 区域。此过程重复 256 次，因此每个客户端最终读取 1 GB 的数据。所有块服务器加起来只有 32 GB 的内存，因此我们预计 Linux 缓冲区缓存的命中率最多为 10%。我们的结果应该接近冷缓存结果。\n图 3(a) 显示了 N 个客户端的总读取速率及其理论极限。当两个交换机之间的 1 Gbps 链路达到饱和时，极限值达到 125 MB/s，或当每个客户端的 100 Mbps 网络接口达到饱和时，极限值达到 12.5 MB/s。当只有一个客户端在读取数据时，观察到的读取速率为 10 MB/s，即每个客户端上限的 80%。16 个读取器的总读取速率达到 94 MB/s，约为 125 MB/s 链路限值的 75%，即每个客户端 6 MB/s。效率从 80% 下降到 75%，是因为随着读取器数量的增加，多个读取器同时从同一个分块服务器读取数据的概率也在增加。\n6.1.2 写 N 个客户端同时向 N 个不同的文件写入数据。每个客户端通过一系列 1 MB 的写入将 1 GB 的数据写入新文件。图 3(b) 显示了总写入速率及其理论极限。极限稳定在 67 MB/s，因为我们需要将每个字节写入 16 个块服务器中的 3 个，每个块服务器的输入连接为 12.5 MB/s。\n一个客户端的写入速率为 6.3 MB/s，约为极限的一半。造成这种情况的主要原因是我们的网络栈。它与我们用于将数据推送到块副本的流水线方案交互效果不佳。将数据从一个副本传播到另一个副本的延迟会降低整体写入速率。16 个客户端的总写入速率达到 35 MB/s（或每个客户端 2.2 MB/s），约为理论极限的一半。与读取的情况一样，随着客户端数量的增加，多个客户端同时写入同一个块服务器的可能性变得更大。此外，由于每次写入涉及三个不同的副本，因此 16 个写入者比 16 个读取者更容易发生冲突。\n写入速度比我们预期的要慢。实际上，这并不是一个大问题，因为即使它增加了单个客户端看到的延迟，也不会显著影响系统向大量客户端提供的总写入带宽。\n6.1.3 记录追加 图 3(c) 显示了记录附加性能。N 个客户端同时附加到单个文件。性能受存储文件最后一块的块服务器的网络带宽限制，与客户端数量无关。对于一个客户端，它从 6.0 MB/s 开始，对于 16 个客户端，它下降到 4.8 MB/s，这主要是由于拥塞和不同客户端看到的网络传输速率差异。\n我们的应用通常会同时生成多个这样的文件。换句话说，N 个客户端会同时附加数据到 M 个共享文件中，N 和 M 的数量可以达到数十甚至上百。因此，在实际应用中，分块服务器的网络拥堵问题并不显著，因为当一个文件的分块服务器繁忙时，客户端仍然可以继续在其他文件上写入数据。\n6.2 真实世界集群 我们现在研究 Google 内部使用的两个集群，它们代表了其他几个类似的集群。集群 A 经常被一百多名工程师用于研究和开发。一个典型的任务由人类用户发起，运行时间长达几个小时。它读取几 MB 到几 TB 的数据，转换或分析数据，并将结果写回集群。集群 B 主要用于生产数据处理。任务持续时间更长，并且持续生成和处理多 TB 数据集，仅偶尔需要人工干预。在这两种情况下，单个“任务”都由多台机器上的许多进程组成，这些进程同时读取和写入许多文件。\n6.2.1 存储 如表2中的前五个条目所示，两个集群都有数百个分块服务器，支持许多 TB 的磁盘空间，而且都相当满，但不是完全满。\u0026ldquo;已用空间 \u0026ldquo;包括所有的分块复制。几乎所有文件都复制了三次。因此，集群分别存储了 18 TB 和 52 TB 的文件数据。\n这两个集群的文件数量相似，但 B 集群的死文件比例更大，即已被删除或被新版本取代但其存储尚未被回收的文件。此外，由于 B 的文件往往较大，因此它的块数也更多。\n6.2.2 元数据 分块服务器总共存储了数十 GB 的元数据，其中大部分是 64 KB 用户数据块的校验和。分块服务器中保存的唯一其他元数据是第 4.5 节中讨论的块版本号。\n主服务器上保存的元数据要小得多，只有几十 MB，平均每个文件大约 100 字节。这符合我们的假设，即主服务器内存的大小实际上不会限制系统的容量。大多数文件元数据是以前缀压缩形式存储的文件名。其他元数据包括文件所有权和权限、从文件到块的映射以及每个块的当前版本。此外，对于每个块，我们存储当前副本位置和引用计数以实现写时复制。\n每个单独的服务器（包括块服务器和主服务器）只有 50 到 100 MB 的元数据。因此恢复速度很快：在服务器能够回答查询之前，只需几秒钟就可以从磁盘读取这些元数据。但是，主服务器在一段时间内会有些不顺畅（通常为 30 到 60 秒），直到它从所有块服务器获取块位置信息。\n6.2.3 读写速率 表 3 显示了不同时间段的读写速率。在进行这些测量时，两个集群都已运行了一周左右。（最近，为了升级到新版 GFS，集群被重新启动）。\n自重启以来，平均写入速率不到 30 MB/s。当我们进行这些测量时，B 正处于写入活动的爆发期，产生了大约每秒 100 MB 的数据，由于写入会传播到三个副本，因此产生了每秒 300 MB 的网络负载。\n读取速率远高于写入速率。正如我们所假设的，总工作负载由更多的读取而不是写入组成。两个集群都处于大量读取活动之中。特别是，A 在前一周一直保持着 580 MB/s 的读取速率。其网络配置可以支持 750 MB/s，因此它正在高效地利用其资源。集群 B 可以支持 1300 MB/s 的峰值读取速率，但其应用程序仅使用了 380 MB/s。\n6.2.4 主服务器负载 表 3 还显示，发送给主服务器的操作速率约为每秒 200 到 500 次操作。主服务器可以轻松跟上这个速率，因此不会成为这些工作负载的瓶颈。 在 GFS 的早期版本中，主服务器偶尔会成为某些工作负载的瓶颈。它大部分时间都在按顺序扫描大型目录（其中包含数十万个文件）以查找特定文件。此后，我们更改了主服务器数据结构，以允许通过命名空间进行高效的二分搜索。它现在可以轻松支持每秒数千次文件访问。如有必要，我们可以通过在命名空间数据结构前面放置名称查找缓存来进一步加快速度。\n6.2.5 恢复时间 在块服务器发生故障后，某些块将变得复制不充分，必须进行克隆才能恢复其复制级别。恢复所有这些块所需的时间取决于资源量。在一次实验中，我们关闭了集群 B 中的单个块服务器。该块服务器有大约 15000 个块，包含 600 GB 的数据。为了限制对正在运行的应用程序的影响并为调度决策提供余地，我们的默认参数将此集群限制为 91 个并发克隆（块服务器数量的 40%），其中每个克隆操作最多允许消耗 6.25 MB/s（50 Mbps）。所有块在 23.2 分钟内恢复，有效复制速率为 440 MB/s。\n在另一个实验中，我们关闭了两个分块服务器，每个服务器大约有 16000 个数据块和 660 GB 的数据。此双重故障导致 266 个数据块仅剩一个副本。这 266 个数据块被优先克隆，并在 2 分钟内全部恢复到至少 2 倍的副本数量，从而使集群恢复到可以容忍另一个分块服务器故障而不会导致数据丢失的状态。\n6.3 工作负载细分 在本节中，我们将详细分析两个 GFS 集群的工作负载，它们与第 6.2 节中的集群类似但不完全相同。集群 X 用于研发，而集群 Y 用于生产数据处理。\n6.3.1 方法与注意事项 这些结果仅包括客户端发起的请求，因此它们反映了我们的应用程序为整个文件系统生成的工作负载。它们不包括执行客户端请求的服务器间请求或内部后台活动，例如转发写入或重新平衡。\n关于 I/O 操作的统计数据基于从 GFS 服务器记录的实际 RPC 请求中通过启发式方法重建的信息。例如，GFS 客户端代码可能会将一次读取分解成多个 RPC，以提高并行性，从中我们可以推断出原始读取。由于我们的访问模式具有高度的固定化特征，因此预期任何误差都微乎其微。应用程序进行显式日志记录可能会提供稍微更准确的数据，但在实际操作中，要重新编译并重启数千个正在运行的客户端并不现实，同时从这么多机器上收集结果也十分繁琐。\n需要注意的是，不应过度泛化我们的工作负载。由于 Google 完全控制 GFS 及其应用程序，因此这些应用程序往往针对 GFS 进行了优化，反过来，GFS 也是为这些应用程序量身设计的。这种相互影响在通用应用程序和文件系统之间也可能存在，但在我们这种情况下，这种影响可能更加明显。\n6.3.2 分块服务器工作负载 表 4 显示了按大小分列的操作分布情况。读取大小呈现双峰分布。小规模读取（64 KB 以下）来自查找密集型客户端，它们在庞大的文件中查找小块数据。大读取（超过 512 KB）来自对整个文件的长时间连续读取。\n在集群 Y 中，大量读取操作没有返回任何数据。我们的应用程序（尤其是生产系统中的应用程序）经常使用文件作为生产者-消费者队列。生产者同时将数据附加到文件，而消费者则读取文件末尾。偶尔，当消费者超过生产者时，不会返回任何数据。集群 X 出现这种情况的频率较低，因为它通常用于短期数据分析任务，而不是长期分布式应用程序。\n写入大小也呈现双峰分布。大写入量（超过 256 KB）通常是写入器内部大量缓冲造成的。写入器缓冲数据较少、检查点或同步频率较高，或仅生成较少数据，则导致写入量较小（64 KB 以下）。\n对于记录追加操作，集群 Y 的大记录追加操作比例比集群 X 高得多，因为我们的生产系统使用集群 Y，并且对 GFS 的优化更加积极。\n表 5 显示了各种大小的操作中传输的数据总量。对于所有类型的操作，较大的操作（超过 256 KB）通常占传输的字节数的大部分。由于随机寻道工作负载，较小的读取（低于 64 KB）确实传输了一小部分但相当可观的读取数据。\n6.3.3 追加与写入 记录追加操作在我们的生产系统中被大量使用。在集群 X 中，按传输字节计算，写操作与记录追加的比率为 108:1，按操作次数计算为 8:1。而在生产系统使用的集群 Y 中，这些比率分别为 3.7:1 和 2.5:1。此外，这些比率表明在两个集群中记录追加操作往往比写操作更大。然而，对于集群 X，在测量期间记录追加的总体使用率相对较低，因此结果可能会因一两个特定选择了特定缓冲区大小的应用程序而有所偏差。\n不出所料，我们的数据变更工作量主要是追加而不是覆盖。我们测量了主副本上被覆盖的数据量。这近似于客户端故意覆盖以前写入的数据而不是追加新数据的情况。对于集群 X，覆盖量占变异字节的 0.0001%，占变异操作的 0.0003%。对于集群 Y，这两个比例都是 0.05%。虽然这个比例很小，但仍然高于我们的预期。事实证明，这些覆盖操作大多来自客户端因错误或超时而进行的重试。它们本身并不是工作量的一部分，而是重试机制的结果。\n6.3.4 主服务器工作负载 Table 6: Master Requests Breakdown by Type (%) 表 6 显示了向主服务器发出的请求类型的明细。大多数请求询问数据块位置（FindLocation）以进行读取，以及租约持有者信息（FindLeaseLocker）以进行数据变更。\n集群 X 和 Y 的删除（Delete）请求数量存在显著差异，因为集群 Y 存储的生产数据集会定期重新生成并替换为新版本。部分差异进一步隐藏在打开请求的差异中，因为文件的旧版本可能会通过从头开始打开进行写入（Unix 打开术语中的模式“w”）而被隐式删除。\nFindMatchingFiles 是一种支持 “ls” 和类似文件系统操作的模式匹配请求。与主服务器的其他请求不同，它可能需要处理命名空间的很大一部分，因此开销可能较大。集群 Y 上这种请求更为常见，因为自动化数据处理任务通常会检查文件系统的部分内容以了解全局应用状态。相比之下，集群 X 的应用更受用户控制，通常提前知道所需文件的名称。\n7. 经历 在建立和部署GFS 的过程中，我们遇到了各种各样的问题，有些是操作问题，有些是技术问题。\n最初，GFS 被设计为我们生产系统的后端文件系统。随着时间的推移，其用途逐渐扩展到研究和开发任务。最初它几乎不支持权限和配额之类的功能，但现在包含了这些功能的基本形式。虽然生产系统管理有序且受控，但用户有时并非如此。需要更多的基础设施来防止用户相互干扰。\n我们遇到的最大问题与磁盘和 Linux 有关。我们的许多磁盘都向 Linux 驱动程序声称它们支持一系列 IDE 协议版本，但实际上它们只对较新的版本做出可靠响应。由于协议版本非常相似，这些驱动器大部分情况下都能正常工作，但偶尔不匹配会导致驱动器和内核对驱动器状态产生分歧。这会由于内核中的问题而悄无声息地损坏数据。这个问题促使我们使用校验和来检测数据损坏，同时我们修改了内核来处理这些协议不匹配。\n之前，我们在使用 Linux 2.2 内核时遇到了一些问题，这是由于 fsync() 的成本所致。其成本与文件大小成正比，而不是与修改部分的大小成正比。这对于我们的大型操作日志来说是一个问题，尤其是在我们实施检查点之前。我们曾一度通过使用同步写入来解决这个问题，并最终迁移到 Linux 2.4。\n另一个 Linux 问题是单一的读写锁。在地址空间内的任一线程从磁盘调入页面时（读锁）或在调用 mmap() 时修改地址空间（写锁），都必须持有此锁。在轻负载下，我们的系统出现了瞬时超时现象，并且我们花了很多精力寻找资源瓶颈或偶发的硬件故障。最终发现，该单一锁阻止了主网络线程将新数据映射到内存中，因为磁盘线程正在调入先前映射的数据。由于我们的瓶颈主要在网络接口，而非内存复制带宽，我们通过用 pread()替换 mmap() 解决了这个问题，代价是增加了一次额外的数据复制。\n尽管偶尔会出现问题，但 Linux 代码的可用性一次又一次地帮助我们探索和理解系统行为。在适当的时候，我们会对内核进行改进，并与开源社区分享这些变化。\n8. 相关工作 与其他大型分布式文件系统（如 AFS 1）类似，GFS 提供了位置无关的命名空间，使得数据可以为负载平衡或容错而透明地移动。与 AFS 不同的是，GFS 将文件的数据分布在多个存储服务器上，这种方式更类似于 xFS 2 和 Swift 3，以实现聚合性能并提高容错能力。\n由于磁盘相对便宜，且复制比更复杂的 RAID 4 方法更简单，GFS 目前仅使用复制来实现冗余，因此比 xFS 或 Swift 消耗更多的原始存储。\n与 AFS、xFS、Frangipani 5 和 Intermezzo 6 等系统相比，GFS 不提供文件系统接口下的任何缓存。我们的目标工作负载在单个应用程序运行中几乎没有重用性，因为它们要么流经大型数据集，要么随机在其中查找并每次读取少量数据。\n一些分布式文件系统，如 Frangipani、xFS、Minnesota 的 GFS7 和 GPFS 8 移除了集中式服务器，并依靠分布式算法来实现一致性和管理。我们选择集中式方法是为了简化设计、提高可靠性并获得灵活性。特别是，集中式主服务器可以更轻松地实现复杂的块放置和复制策略，因为主服务器已经拥有大部分相关信息并控制其更改方式。我们通过保持主服务器状态较小并在其他机器上完全复制来解决容错问题。我们的影子主服务器机制目前提供可扩展性和高可用性（对于读取）。通过附加到预写日志，可以持久保存对主服务器状态的更新。因此，我们可以采用 Harp 9 中的主副本方案，以提供比我们当前方案具有更强一致性保证的高可用性。\n我们正在解决与 Lustre 10 类似的问题，即为大量客户提供总体性能。但是，我们通过专注于应用程序的需求而不是构建符合 POSIX 标准的文件系统，大大简化了这个问题。此外，GFS 假设存在大量不可靠的组件，因此容错是我们设计的核心。\nGFS 最接近 NASD 架构 11。虽然 NASD 架构基于网络连接的磁盘驱动器，但 GFS 使用商用机器作为分块服务器，这与 NASD 原型类似。与 NASD 工作不同的是，GFS 的分块服务器使用懒惰分配的固定大小块，而不是可变长度对象。此外，GFS 实现了生产环境中所需的负载均衡、复制和恢复等功能。\n与 Minnesota 的 GFS 和 NASD 不同，我们并不寻求改变存储设备的模型。我们专注于利用现有的商品组件满足复杂分布式系统的日常数据处理需求。\n由原子记录附加功能启用的生产者-消费者队列解决了与 River 12 中的分布式队列类似的问题。虽然 River 使用分布在机器上的基于内存的队列和谨慎的数据流控制，但 GFS 使用可由许多生产者同时附加的持久文件。River 模型支持 m 对 n 分布式队列，但缺乏持久存储带来的容错能力，而 GFS 仅有效地支持 m 对 1 队列。多个消费者可以读取同一个文件，但他们必须协调以划分传入的负载。\n9. 结论 Google 文件系统展示了在商用硬件上支持大规模数据处理工作负载所必需的品质。虽然一些设计决策特定于我们的独特环境，但许多设计决策可能适用于具有类似规模和成本意识的数据处理任务。\n我们首先根据当前和预期的应用程序工作负载和技术环境重新审视了传统的文件系统假设。我们的观察结果在设计领域中得出了截然不同的观点。我们将组件故障视为常态而非例外，针对大多数情况下追加（可能并发）然后读取（通常顺序）的大型文件进行优化，并扩展和放宽标准文件系统接口以改进整个系统。\n我们的系统通过持续监控、复制关键数据以及快速自动恢复来提供容错能力。块复制使我们能够容忍块服务器故障。这些故障的频率促使我们开发了一种新颖的在线修复机制，该机制定期透明地修复损坏并尽快补偿丢失的副本。此外，我们使用校验和来检测磁盘或 IDE 子系统级别的数据损坏，考虑到系统中的磁盘数量，这种情况变得非常常见。\n我们的设计为执行各种任务的众多并发读取器和写入器提供了很高的整体吞吐量。我们通过将文件系统控制（通过主服务器）与数据传输（直接在块服务器和客户端之间传递）分开来实现这一点。通过较大的块大小和块租借（将数据变更的权限委托给主副本），主服务器对常见操作的参与被最小化。这使得简单、集中的主服务器成为可能，而不会成为瓶颈。我们相信，我们网络栈的改进将解除当前单个客户端看到的写入吞吐量的限制。\nGFS 成功满足了我们的存储需求，在 Google 内部被广泛用作研发和生产数据处理的存储平台。它是我们能够继续创新和攻克整个网络规模问题的重要工具。\n参考文献 John Howard, Michael Kazar, Sherri Menees, David Nichols, Mahadev Satyanarayanan, Robert Sidebotham, and Michael West. Scale and performance in a distributed file system. ACM Transactions on Computer Systems, 6(1):51–81, February 1988.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nThomas Anderson, Michael Dahlin, Jeanna Neefe, David Patterson, Drew Roselli, and Randolph Wang. Serverless network file systems. In Proceedings of the 15th ACM Symposium on Operating System Principles, pages 109–126, Copper Mountain Resort, Colorado, December 1995.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nLuis-Felipe Cabrera and Darrell D. E. Long. Swift: Using distributed diskstriping to provide high I/O data rates. Computer Systems, 4(4):405–436, 1991.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nDavid A. Patterson, Garth A. Gibson, and Randy H. Katz. A case for redundant arrays of inexpensive disks (RAID). In Proceedings of the 1988 ACM SIGMOD International Conference on Management of Data, pages 109–116, Chicago, Illinois, September 1988.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nChandramohan A. Thekkath, Timothy Mann, and Edward K. Lee. Frangipani: A scalable distributed file system. In Proceedings of the 16th ACM Symposium on Operating System Principles, pages 224–237, Saint-Malo, France, October 1997.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nInterMezzo. https://www.inter-mezzo.org, 2003.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nSteven R. Soltis, Thomas M. Ruwart, and Matthew T. O’Keefe. The Gobal File System. In Proceedings of the Fifth NASA Goddard Space Flight Center Conference on Mass Storage Systems and Technologies, College Park, Maryland, September 1996.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nFrankSchmuckand Roger Haskin. GPFS: A shared-diskfile system for large computing clusters. In Proceedings of the First USENIX Conference on File and Storage Technologies, pages 231–244, Monterey, California, January 2002.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nBarbara Liskov, Sanjay Ghemawat, Robert Gruber, Paul Johnson, Liuba Shrira, and Michael Williams. Replication in the Harp file system. In 13th Symposium on Operating System Principles, pages 226–238, Pacific Grove, CA, October 1991.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nLustre. http://www.lustreorg, 2003.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nGarth A. Gibson, David F. Nagle, Khalil Amiri, Jeff Butler, Fay W. Chang, Howard Gobioff, Charles Hardin, ErikRiedel, David Rochberg, and Jim Zelenka. A cost-effective, high-bandwidth storage architecture. In Proceedings of the 8th Architectural Support for Programming Languages and Operating Systems, pages 92–103, San Jose, California, October 1998.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nRemzi H. Arpaci-Dusseau, Eric Anderson, Noah Treuhaft, David E. Culler, Joseph M. Hellerstein, David Patterson, and Kathy Yelick. Cluster I/O with River: Making the fast case common. In Proceedings of the Sixth Workshop on Input/Output in Parallel and Distributed Systems (IOPADS \u0026lsquo;99), pages 10–22, Atlanta, Georgia, May 1999.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://fireflyyh.top/posts/distributionsystem/gfs/","summary":"摘要 我们设计并实现了谷歌文件系统，这是一个可扩展的分布式文件系统，适用于大型分布式数据密集型应用。该系统可在廉价的商品硬件上运行，同时提供容错功能，并能为大量客户端提供高聚合性能。\n我们的设计目标与之前的分布式文件系统有许多相同之处，但我们对应用工作负载和技术环境（包括当前和预期环境）的观察结果表明，我们的设计明显偏离了之前的一些文件系统假设。这促使我们重新审视传统的选择，探索完全不同的设计要点。\n文件系统成功地满足了我们的存储需求。它在谷歌内部被广泛部署，作为生成和处理我们的服务所使用的数据以及需要大型数据集的研发工作的存储平台。迄今为止，最大的集群在一千多台机器上的数千个磁盘上提供了数百 TB 的存储空间，并被数百个客户端并发访问。\n在本文中，我们介绍了为支持分布式应用而设计的文件系统接口扩展，讨论了我们设计的许多方面，并报告了微基准测试和实际使用的测量结果。\n1. 引言 我们设计并实施了谷歌文件系统（GFS），以满足谷歌快速增长的数据处理需求。GFS 与以前的分布式文件系统有许多相同的目标，如性能、可扩展性、可靠性和可用性。但是，在设计 GFS 时，我们对当前和预期的应用工作负载和技术环境进行了重要观察，这反映出我们明显偏离了之前的一些文件系统设计假设。我们重新审视了传统的选择，并探索了设计空间中完全不同的点。\n首先，组件故障是常态而非例外。文件系统由数百甚至数千台存储机组成，这些存储机都是用廉价的商品部件制造的，并被数量相当的客户机访问。这些组件的数量和质量几乎可以保证，在任何特定时间都会有一些组件无法正常工作，而且有些组件无法从当前故障中恢复。我们见过应用程序错误、操作系统错误、人为错误以及磁盘、内存、连接器、网络和电源故障造成的问题。因此，持续监控、错误检测、容错和自动恢复必须成为系统的组成部分。\n其次，按照传统的标准，文件是巨大的。多 GB 的文件很常见。每个文件通常包含许多应用对象，如网络文档。当我们经常处理由数十亿个对象组成的多 TB 快速增长的数据集时，即使文件系统可以支持，要管理数十亿个约 KB 大小的文件也很不方便。因此，必须重新审视 I/O 操作和块大小等设计假设和参数。\n第三，大多数文件都是通过添加新数据而不是覆盖现有数据来改变的。文件内的随机写入几乎不存在。文件一旦写入，就只能读取，而且通常只能按顺序读取。各种数据都具有这些特征。有些可能是数据分析程序扫描过的大型存储库。有些可能是运行中的应用程序持续生成的数据流。有些可能是档案数据。有些可能是在一台机器上生成并在另一台机器上处理的中间结果，无论是同时处理还是稍后处理。鉴于巨型文件的这种访问模式，追加成为性能优化和原子性保证的重点，而在客户端缓存数据块则失去了吸引力。\n第四，共同设计应用程序和文件系统 API 可以提高我们的灵活性，从而使整个系统受益。例如，我们放宽了 GFS 的一致性模型，大大简化了文件系统，而不会给应用程序带来沉重负担。我们还引入了原子追加操作，使多个客户端可以同时追加文件，而无需额外的同步。本文稍后将详细讨论这些内容。\n目前，为不同目的部署了多个 GFS 集群。最大的集群有超过 1000 个存储节点，超过 300 TB 的磁盘存储空间，数百个客户端在不同的机器上持续大量访问。\n2. 设计概述 2.1 假设 在设计满足我们需求的文件系统时，我们遵循的假设既是挑战也是机遇。我们在前面提到了一些重要的观察结果，现在详细介绍一下我们的假设。\n该系统由许多经常发生故障的廉价商品组件构成。系统必须不断进行自我监控，日常检测、容忍和及时恢复组件故障。 系统存储的大文件数量不多。我们预计会有几百万个文件，每个文件的大小通常为 100 MB 或更大。多 GB 文件是常见情况，应得到有效管理。我们必须支持小文件，但无需对其进行优化。 工作负载主要包括两种读取：大型流式读取和小型随机读取。在大数据流读取中，单个操作通常读取数百 KB，更常见的是 1 MB 或更多。来自同一客户端的连续操作通常会读取文件的连续区域。小型随机读取通常在某个任意偏移位置读取几个 KB 的数据。注重性能的应用程序通常会对小规模读取进行批处理和排序，以稳定地读取文件，而不是来回读取。 这些工作负载中还有许多向文件追加数据的大型连续写入操作。典型的操作大小与读取类似。文件一旦写入，就很少再修改。支持在文件任意位置进行小规模写入，但不一定要高效。 系统必须有效地实现多个客户端同时追加到同一文件的定义明确的语义。我们的文件通常用作生产者-消费者队列或多路合并。数以百计的生产者（每台机器运行一个）将同时追加到一个文件。同步开销最小的原子性至关重要。文件可能会在稍后被读取，或者消费者可能会同时读取文件。 高持续带宽比低延迟更重要。我们的大多数目标应用都非常重视高速批量处理数据，而很少有应用对单个读取或写入的响应时间有严格要求。 2.2 接口 GFS 提供了一个熟悉的文件系统接口，尽管它没有实现标准的 API（如 POSIX）。文件在目录中按层次组织，并用路径名标识。我们支持创建、删除、打开、关闭、读取和写入文件的常规操作。\n此外，GFS 还有快照和记录追加操作。快照以低成本创建文件或目录树的副本。记录追加允许多个客户端同时向同一个文件追加数据，同时保证每个客户端追加的原子性。它适用于实现多向合并结果和生产者-消费者队列，许多客户端可以同时追加数据而无需额外锁定。我们发现，这些类型的文件在构建大型分布式应用时非常有用。快照追加和记录追加将分别在第 3.4 节和第 3.3 节中进一步讨论。","title":"[论文翻译]The Google File System"},{"content":" 部分答案参考了官方题解和网上的答案，仅供参考，可能也有部分bug未发现或解决。\nexercise8-1 用 read、write、open 和 close 系统调用代替标准库中功能等价的函数，重写第 7 章的 cat 程序，并通过实验比较两个版本的相对执行速度。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 void filecopy(int ifp, int ofp) { char buf[BUFSIZE]; int n; while ((n = read(ifp, buf, BUFSIZE)) \u0026gt; 0) if (write(ofp, buf, n) != n) error(\u0026#34;cp: write error on file2\u0026#34;); } int main(int argc, char *argv[]) { int fd; char *prog = argv[0]; /* program name for errors */ if (argc == 1) /* no args; copy standard input */ filecopy(STDIN_FILENO, STDOUT_FILENO); else while (--argc \u0026gt; 0) if ((fd = open(*++argv, O_RDONLY, 0)) == -1) { fprintf(stderr, \u0026#34;%s: can\u0026#39;t open %s\\n\u0026#34;, prog, *argv); exit(1); } else { filecopy(fd, STDOUT_FILENO); close(fd); } if (ferror(stdout)) { fprintf(stderr, \u0026#34;%s: error writing stdout\\n\u0026#34;, prog); exit(2); } exit(0); } 运行：\n1 2 3 4 ➜ ch08 git:(main) ✗ ./Exercise8-1 test01.txt test02.txt This is test01.txt Good idea.This is test02.txt Bad idea. exercise8-2 用字段代替显式的按位操作，重写 fopen 和_fillbuf 函数。比较相应代码的长度和执行速度。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 struct flags { unsigned int _READ : 1; /* file open for reading */ unsigned int _WRITE : 1; /* file open for writing */ unsigned int _UNBUF : 1; /* file is unbuffered */ unsigned int _EOF : 1; /* EOF has occurred on this file */ unsigned int _ERR : 1; /* error occurred on this file */ }; FILE *fopen(char *name, char *mode) { int fd; FILE *fp; if (*mode != \u0026#39;r\u0026#39; \u0026amp;\u0026amp; *mode != \u0026#39;w\u0026#39; \u0026amp;\u0026amp; *mode != \u0026#39;a\u0026#39;) return NULL; for (fp = _iob; fp \u0026lt; _iob + OPEN_MAX; fp++) if ((flagsempty(fp-\u0026gt;flag) \u0026amp; (_READ | _WRITE)) == 0) break; /* found free slot */ if (fp \u0026gt;= _iob + OPEN_MAX) /* no free slots */ return NULL; if (*mode == \u0026#39;w\u0026#39;) fd = creat(name, PERMS); else if (*mode == \u0026#39;a\u0026#39;) { if ((fd = open(name, O_WRONLY, 0)) == -1) fd = creat(name, PERMS); lseek(fd, 0L, 2); } else fd = open(name, O_RDONLY, 0); if (fd == -1) /* couldn\u0026#39;t access name */ return NULL; fp-\u0026gt;fd = fd; fp-\u0026gt;cnt = 0; fp-\u0026gt;base = NULL; fp-\u0026gt;flag._READ = (*mode == \u0026#39;r\u0026#39;) ? 1 : 0; fp-\u0026gt;flag._WRITE = (*mode == \u0026#39;w\u0026#39;) ? 1 : 0; return fp; } /* _fillbuf: allocate and fill input buffer */ int _fillbuf(FILE *fp) { int bufsize; if ((flagsempty(fp-\u0026gt;flag) \u0026amp; (_READ | _EOF | _ERR)) != _READ) return EOF; bufsize = (flagsempty(fp-\u0026gt;flag) \u0026amp; _UNBUF) ? 1 : BUFSIZ; if (fp-\u0026gt;base == NULL) /* no buffer yet */ if ((fp-\u0026gt;base = (char *)malloc(bufsize)) == NULL) return EOF; /* can\u0026#39;t get buffer */ fp-\u0026gt;ptr = fp-\u0026gt;base; fp-\u0026gt;cnt = read(fp-\u0026gt;fd, fp-\u0026gt;ptr, bufsize); if (--fp-\u0026gt;cnt \u0026lt; 0) { if (fp-\u0026gt;cnt == -1) fp-\u0026gt;flag._EOF = 1; else fp-\u0026gt;flag._ERR = 1; fp-\u0026gt;cnt = 0; return EOF; } return (unsigned char)*fp-\u0026gt;ptr++; } exercise8-3 设计并编写函数_flushbuf、fflush 和 fclose。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 int _flushbuf(int c, FILE *fp) { int num_written, bufsize; unsigned char uc = c; if ((fp-\u0026gt;flag \u0026amp; (_WRITE | _EOF_ERR)) != _WRITE) return EOF; /* 如果尚未分配缓冲区并且不是无缓冲模式，尝试分配一个大小为 BUFSIZ 的缓冲区。 如果分配失败，设置为无缓冲模式；如果成功，初始化缓冲区指针和计数器。 */ if (fp-\u0026gt;base == NULL \u0026amp;\u0026amp; ((fp-\u0026gt;flag \u0026amp; _UNBUF) == 0)) { if ((fp-\u0026gt;base = malloc(BUFSIZ)) == NULL) fp-\u0026gt;flag |= _UNBUF; else { fp-\u0026gt;ptr = fp-\u0026gt;base; fp-\u0026gt;cnt = BUFSIZ - 1; } } /* 如果是无缓冲模式，直接将字符写入文件。 此时将指针和计数器设置为 NULL 和 0。若要写入的是 EOF，则直接返回。 */ if (fp-\u0026gt;flag \u0026amp; _UNBUF) { /* unbuffered write */ fp-\u0026gt;ptr = fp-\u0026gt;base = NULL; fp-\u0026gt;cnt = 0; if (c = EOF) return EOF; num_written = write(fp-\u0026gt;fd, \u0026amp;uc, 1); bufsize = 1; } /* 如果是缓冲模式且要写入的字符不是 EOF，将字符存入缓冲区，然后更新指针。 接着计算当前缓冲区的大小，并将缓冲区内容写入文件。写入后，将指针和计数器重置。 因为没有写入EOF，所以不会打印 */ else { /* buffered write */ if (c != EOF) { *fp-\u0026gt;ptr = uc; fp-\u0026gt;ptr++; } bufsize = (int)(fp-\u0026gt;ptr - fp-\u0026gt;base); num_written = write(fp-\u0026gt;fd, fp-\u0026gt;base, bufsize); fp-\u0026gt;ptr = fp-\u0026gt;base; fp-\u0026gt;cnt = bufsize - 1; } if (num_written = bufsize) return c; else { fp-\u0026gt;flag |= _ERR; return EOF; } } /* 刷新输出缓冲区 */ int fflush(FILE *f) { int retval; // 返回值 int i; retval = 0; if ((f-\u0026gt;flag \u0026amp; _WRITE) == 0) return -1; // 将EOF写入f中，代表文件结束 _flushbuf(EOF, f); if (f-\u0026gt;flag \u0026amp; _ERR) retval = -1; return retval; } /* 关闭文件 */ int fclose(FILE *f) { int fd; if (f == NULL) return -1; fd = f-\u0026gt;fd; // 将文件输出缓冲区刷新 fflush(f); // 将cnt、ptr、base、flag、fd重置，释放base指向的内存 f-\u0026gt;cnt = 0; f-\u0026gt;ptr = NULL; if (f-\u0026gt;base != NULL) free(f-\u0026gt;base); f-\u0026gt;base = NULL; f-\u0026gt;flag = 0; f-\u0026gt;fd = -1; // 关闭文件描述符 return close(fd); } int main(int argc, char *argv[]) { FILE *fp; fp = fopen(\u0026#34;test01.txt\u0026#34;, \u0026#34;r\u0026#34;); char c; while ((c = getc(fp)) != EOF) putc(c, stdout); fflush(stdout); fclose(fp); } 运行：\n1 2 3 ➜ ch08 git:(main) ✗ ./Exercise8-3 test01.txt This is test01.txt Good idea. exercise8-4 标准库函数int fseek(FILE *fp, long offset, int origin)类似于函数 lseek，所不同的是，该函数中的 fp 是一个文件指针而不是文件描述符，且返回值是一个 int 类型的状态而非位置值。编写函数 fseek，并确保该函数与库中其它函数使用的缓冲能够协同工作。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 /* 将读写指针置于一定位置 */ int fseek(FILE *fp, long offset, int origin) { if ((fp-\u0026gt;flag \u0026amp; _UNBUF) == 0 \u0026amp;\u0026amp; fp-\u0026gt;base != NULL) { // 如果是写入模式，刷新缓冲区，将缓冲区内容输出，防止写入一个不为空的缓冲区 if (fp-\u0026gt;flag \u0026amp; _WRITE) fflush(fp); // 如果是读取模式，将缓冲区内容清空，防止读取一个不为空的缓冲区 else if (fp-\u0026gt;flag \u0026amp; _READ) { fp-\u0026gt;cnt = 0; fp-\u0026gt;ptr = fp-\u0026gt;base; } } return (lseek(fp-\u0026gt;fd, offset, origin) \u0026lt; 0); } int main(int argc, char *argv[]) { FILE *fp; if (argc == 1) return 1; fp = fopen(argv[1], \u0026#34;r\u0026#34;); off_t offset = 0; if (argc == 3) offset = atol(argv[2]); char c; fseek(fp, offset, SEEK_SET); while ((c = getc(fp)) != EOF) putc(c, stdout); fflush(stdout); fclose(fp); } 运行：\n1 2 3 ➜ ch08 git:(main) ✗ ./Exercise8-4 test01.txt 12 01.txt Good idea. exercise8-5 修改 fsize 程序，打印 i 结点项中包含的其它信息。\n书中提供的代码有一些问题：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 /* readdir: read directory entries in sequence */ Dirent *mreaddir(mDIR *dp) { struct direct dirbuf; /* local directory structure */ static Dirent d; /* return: portable structure */ int readsize; // 此版本的read无法读取一个目录文件，下面的语句执行之后 readsize 始终为-1 // 在其他测试程序中单独测试了使用 read() 来读取一个目录文件，也是得到相同的结论 // 所以就在本步骤，只好使用系统提供的 readdir() 来读取一个目录文件的信息 while ((readsize = read(dp-\u0026gt;fd, (char *)\u0026amp;dirbuf, sizeof(dirbuf))) == sizeof(dirbuf)) { if (dirbuf.d_ino == 0) /* slot not in use */ continue; d.ino = dirbuf.d_ino; strncpy(d.name, dirbuf.d_name, DIRSIZ); d.name[DIRSIZ] = \u0026#39;\\0\u0026#39;; /* ensure termination */ return \u0026amp;d; } return NULL; } 经过修改，下面的代码可以实现递归打印目录中的文件及子目录内容：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 #include \u0026#34;./dirent.h\u0026#34; #define MAX_PATH 1024 Dirent *mreaddir02(DIR *dp) { struct direct *dirbuf; static Dirent d; // 静态变量 if ((dirbuf = readdir(dp)) == NULL || dirbuf-\u0026gt;d_ino == 0) return NULL; d.ino = dirbuf-\u0026gt;d_ino; strncpy(d.name, dirbuf-\u0026gt;d_name, DIRSIZ); d.name[DIRSIZ] = \u0026#39;\\0\u0026#39;; return \u0026amp;d; } /* dirwalk: apply fcn to all files in dir */ void dirwalk(char *dir, void (*fcn)(char *)) { char name[MAX_PATH]; Dirent *dp = malloc(sizeof(Dirent)); memset(dp-\u0026gt;name, 0, sizeof(dp-\u0026gt;name)); DIR *dfd; // 直接使用系统的opendir() if ((dfd = opendir(dir)) == NULL) { fprintf(stderr, \u0026#34;dirwalk: can\u0026#39;t open %s\\n\u0026#34;, dir); return; } while ((dp = mreaddir02(dfd)) != NULL) { if (strcmp(dp-\u0026gt;name, \u0026#34;.\u0026#34;) == 0 || strcmp(dp-\u0026gt;name, \u0026#34;..\u0026#34;) == 0) continue; /* skip self and parent */ if (strlen(dir) + strlen(dp-\u0026gt;name) + 2 \u0026gt; sizeof(name)) fprintf(stderr, \u0026#34;dirwalk: name %s %s too long\\n\u0026#34;, dir, dp-\u0026gt;name); else { sprintf(name, \u0026#34;%s/%s\u0026#34;, dir, dp-\u0026gt;name); (*fcn)(name); } } // 直接使用系统提供的closedir() closedir(dfd); } void fsize(char *name) { struct stat stbuf; if (stat(name, \u0026amp;stbuf) == -1) { fprintf(stderr, \u0026#34;fsize: can\u0026#39;t access %s\\n\u0026#34;, name); return; } if (S_ISDIR(stbuf.st_mode)) /* directory */ dirwalk(name, fsize); char timebuf[32]; strftime(timebuf, sizeof(timebuf), \u0026#34;%b %d %R\u0026#34;, localtime(\u0026amp;stbuf.st_mtime)); // 展示文件大小，文件的inode号，文件的最后修改时间，文件名 printf(\u0026#34;%8ldB %8ld %s %s\\n\u0026#34;, stbuf.st_size, stbuf.st_ino, timebuf, name); } 运行，打印文件的大小、inode节点号、最后修改日期、文件名\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 ➜ ch08 git:(main) ✗ ./Exercise8-5 /home/jagger/Codes/ch08 1300B 149492 Oct 19 10:11 /home/jagger/Codes/ch08/Exercise8-1.c 6917B 149495 Oct 23 12:59 /home/jagger/Codes/ch08/Exercise8-4.c 28B 149503 Oct 19 10:13 /home/jagger/Codes/ch08/test02.txt 40B 149491 Oct 19 09:49 /home/jagger/Codes/ch08/.gitignore 1461B 149502 Oct 19 11:29 /home/jagger/Codes/ch08/Exercise8-8.c 13464B 149490 Oct 23 15:12 /home/jagger/Codes/ch08/README.md 3134B 149498 Oct 20 14:04 /home/jagger/Codes/ch08/Exercise8-6.c 662B 149504 Oct 20 13:12 /home/jagger/Codes/ch08/dirent.h 399B 149505 Oct 23 13:32 /home/jagger/Codes/ch08/test.c 3362B 149497 Oct 23 15:00 /home/jagger/Codes/ch08/Exercise8-5.c 30B 149496 Oct 23 11:34 /home/jagger/Codes/ch08/test01.txt 819B 149499 Oct 20 13:43 /home/jagger/Codes/ch08/Exercise8-7.c 6202B 149494 Oct 23 11:47 /home/jagger/Codes/ch08/Exercise8-3.c 75B 149501 Oct 19 09:50 /home/jagger/Codes/ch08/createfile.sh 23016B 149506 Oct 23 15:13 /home/jagger/Codes/ch08/Exercise8-5 209B 149500 Oct 19 09:51 /home/jagger/Codes/ch08/Makefile 3511B 149493 Oct 19 11:22 /home/jagger/Codes/ch08/Exercise8-2.c 4096B 149489 Oct 23 15:13 /home/jagger/Codes/ch08 exercise8-6 标准库函数 calloc(n, size)返回一个指针，它指向 n 个长度为 size的对象，且所有分配的存储空间都被初始化为0。通过调用或修改 malloc函数来实现 calloc函数。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 void *mcalloc(size_t n, size_t size) { void *p; p = malloc(n * size); if (p != NULL) bzero(p, n * size); return p; } int main(void) { int size; int *p = NULL; printf(\u0026#34;Enter the size of memory to allocate: \u0026#34;); scanf(\u0026#34;%d\u0026#34;, \u0026amp;size); p = (int *)mcalloc(size, sizeof(*p)); if (p != NULL) { printf(\u0026#34;Memory allocated successfully\\n\u0026#34;); for (int i = 0; i \u0026lt; size; i++) { printf(\u0026#34;%08X \u0026#34;, p[i]); if (i % 8 == 7) printf(\u0026#34;\\n\u0026#34;); } } return 0; } 运行：\n1 2 3 4 Enter the size of memory to allocate: 12 Memory allocated successfully 00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000 exercise8-7 malloc 接收对存储空间的请求时，并不检查请求长度的合理性；而 free则认为被释放的块包含一个有效的长度字段。改进这些函数，使它们具有错误检查的功能。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 void *mmalloc(int size) { if (size \u0026lt;= 0 || size \u0026gt; MAXSIZE) { fprintf(stderr, \u0026#34;Invalid allocation size: %d Bytes\\n\u0026#34;, size); return NULL; } else { void *ptr = malloc(size); if (ptr == NULL) fprintf(stderr, \u0026#34;Memory allocation failed\\n\u0026#34;); printf(\u0026#34;Memory allocated successfully\\n\u0026#34;); return ptr; } } void mfree(void *ptr) { if (ptr == NULL) { fprintf(stderr, \u0026#34;Attempt to free a null pointer\\n\u0026#34;); return; } printf(\u0026#34;Memory freed successfully\\n\u0026#34;); free(ptr); } int main() { int size; printf(\u0026#34;Enter the size of memory to allocate: \u0026#34;); scanf(\u0026#34;%d\u0026#34;, \u0026amp;size); void *ptr = mmalloc(size); if (ptr != NULL) mfree(ptr); return 0; } 运行：\n1 2 Enter the size of memory to allocate: -1 Invalid allocation size: -1 Bytes ","permalink":"https://fireflyyh.top/posts/tcpl/ch08/","summary":"部分答案参考了官方题解和网上的答案，仅供参考，可能也有部分bug未发现或解决。\nexercise8-1 用 read、write、open 和 close 系统调用代替标准库中功能等价的函数，重写第 7 章的 cat 程序，并通过实验比较两个版本的相对执行速度。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 void filecopy(int ifp, int ofp) { char buf[BUFSIZE]; int n; while ((n = read(ifp, buf, BUFSIZE)) \u0026gt; 0) if (write(ofp, buf, n) !","title":"C语言程序设计第二版课后习题--第八章"},{"content":" 部分答案参考了官方题解和网上的答案，仅供参考，可能也有部分bug未发现或解决。\nexercise7-1 编写一个程序，根据它自身被调用时存放在argv[0]中的名字，实现将大写字母转换为小写字母或将小写字母转换为大写字母的功能。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;ctype.h\u0026gt; #include \u0026lt;string.h\u0026gt; int main(int argc, char **argv) { int (*handler[2])(int) = {tolower, toupper}; int type = strcmp(argv[0], \u0026#34;./lower\u0026#34;) == 0 ? 0 : strcmp(argv[0], \u0026#34;./upper\u0026#34;) == 0 ? 1 : -1; if (type == -1) { fprintf(stderr, \u0026#34;Usage: %s [lower|upper]\\n\u0026#34;, argv[0]); } else { int c; while ((c = getchar()) != EOF) putchar(handler[type](c)); } } 运行：\n1 2 3 4 5 6 7 8 9 ➜ ch07 git:(main) ✗ gcc -o lower Exercise7-1.c ➜ ch07 git:(main) ✗ ./lower This this IYUSDbusaIs iyusdbusais ➜ ch07 git:(main) ✗ gcc -o other Exercise7-1.c ➜ ch07 git:(main) ✗ ./other Usage: ./other [lower|upper] exercise7-3 改写 minprintf 函数，使它能完成 printf 函数的更多功能。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 void minprintf(char *fmt, ...) { va_list ap; /* points to each unnamed arg in turn */ char *p, *sval; int ival; double dval; va_start(ap, fmt); /* make ap point to 1st unnamed arg */ for (p = fmt; *p; p++) { if (*p != \u0026#39;%\u0026#39;) { putchar(*p); continue; } switch (*++p) { case \u0026#39;d\u0026#39;: ival = va_arg(ap, int); printf(\u0026#34;%d\u0026#34;, ival); break; case \u0026#39;f\u0026#39;: dval = va_arg(ap, double); printf(\u0026#34;%f\u0026#34;, dval); break; case \u0026#39;s\u0026#39;: for (sval = va_arg(ap, char *); *sval; sval++) putchar(*sval); break; case \u0026#39;c\u0026#39;: // 字符 ival = va_arg(ap, int); printf(\u0026#34;%c\u0026#34;, ival); break; case \u0026#39;x\u0026#39;: // 十六进制 ival = va_arg(ap, int); printf(\u0026#34;%x\u0026#34;, ival); break; case \u0026#39;o\u0026#39;: // 八进制 ival = va_arg(ap, int); printf(\u0026#34;%o\u0026#34;, ival); break; case \u0026#39;%\u0026#39;: // 百分号 putchar(\u0026#39;%\u0026#39;); break; case \u0026#39;g\u0026#39;: // 浮点数 dval = va_arg(ap, double); printf(\u0026#34;%g\u0026#34;, dval); break; default: putchar(*p); break; } } va_end(ap); /* clean up when done */ } int main() { minprintf(\u0026#34;int: %d, float: %g, string: %s\\n\u0026#34;, 10, 3.14, \u0026#34;hello\u0026#34;); minprintf(\u0026#34;char: %c, hex: %x, oct: %o, double: %g, percent: %%\\n\u0026#34;, \u0026#39;a\u0026#39;, 255, 255, 3.1415926); return 0; } 运行：\n1 2 int: 10, float: 3.14, string: hello char: a, hex: ff, oct: 377, double: 3.14159, percent: % exercise7-4 类似于上一节中的函数 minprintf，编写 scanf 函数的一个简化版本。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdarg.h\u0026gt; #include \u0026lt;ctype.h\u0026gt; void minscanf(char *fmt, ...) { va_list ap; char *p, *sval; int *ival; float *dval; unsigned *uval; int c; va_start(ap, fmt); for (p = fmt; *p; p++) { while (*p != \u0026#39;%\u0026#39;) p++; switch (*++p) { case \u0026#39;d\u0026#39;: ival = va_arg(ap, int *); scanf(\u0026#34;%d\u0026#34;, ival); break; case \u0026#39;f\u0026#39;: dval = va_arg(ap, float *); scanf(\u0026#34;%f\u0026#34;, dval); break; case \u0026#39;s\u0026#39;: sval = va_arg(ap, char *); scanf(\u0026#34;%s\u0026#34;, sval); break; case \u0026#39;c\u0026#39;: ival = va_arg(ap, int *); *ival = getchar(); break; default: break; } } va_end(ap); } int main() { int i; float f; char s[100]; char c; printf(\u0026#34;Enter an integer: \u0026#34;); minscanf(\u0026#34;%d\u0026#34;, \u0026amp;i); printf(\u0026#34;i = %d\\n\u0026#34;, i); printf(\u0026#34;Enter a float: \u0026#34;); minscanf(\u0026#34;%f\u0026#34;, \u0026amp;f); printf(\u0026#34;f = %f\\n\u0026#34;, f); printf(\u0026#34;Enter a string: \u0026#34;); minscanf(\u0026#34;%s\u0026#34;, s); printf(\u0026#34;s = %s\\n\u0026#34;, s); getchar(); // clear the input buffer printf(\u0026#34;Enter a character: \u0026#34;); minscanf(\u0026#34;%c\u0026#34;, \u0026amp;c); printf(\u0026#34;c = %c\\n\u0026#34;, c); } 运行：\n1 2 3 4 5 6 7 8 Enter an integer: 1 i = 1 Enter a float: 3.14 f = 3.140000 Enter a string: ioio s = ioio Enter a character: a c = a exercise7-5 改写第 4 章中的后缀计算器程序，用 scanf 函数和（或）sscanf 函数实现输入以及数的转换。\n其他不用改变，只需要改变主函数即可，将\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 int main() { int type; double op2; char s[MAXOP]; printf(\u0026#34;Please input expression:\\n\u0026#34;); while ((type = getop(s)) != EOF) { switch (type) { case NUMBER: push(atof(s)); break; ... } } } 修改为：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 int main() { int type; double op2; char s[MAXOP]; printf(\u0026#34;Please input expression:\\n\u0026#34;); while ((type = getop(s)) != EOF) { switch (type) { case NUMBER: int val; scanf(\u0026#34;%f\u0026#34;, \u0026amp;val); push(val); break; ... } } } exercise7-6 编写一个程序，比较两个文件并打印它们第一个不相同的行。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 void filecmp(FILE *fp1, FILE *fp2) { char *line1 = malloc(MAXLINE), *line2 = malloc(MAXLINE); int lineno = 1; while (fgets(line1, 100, fp1) != NULL \u0026amp;\u0026amp; fgets(line2, 100, fp2) != NULL) { if (strcmp(line1, line2) != 0) { printf(\u0026#34;difference in line %d\\n\u0026#34;, lineno); printf(\u0026#34;line1: %s\\n\u0026#34;, line1); printf(\u0026#34;line2: %s\\n\u0026#34;, line2); return; } lineno++; } if (feof(fp1) \u0026amp;\u0026amp; feof(fp2)) printf(\u0026#34;files are identical\\n\u0026#34;); else if (feof(fp1)) printf(\u0026#34;file2 has extra lines\\n\u0026#34;); else printf(\u0026#34;file1 has extra lines\\n\u0026#34;); } int main(int argc, char *argv[]) { FILE *fp1, *fp2; char *prog = argv[0]; /* program name for errors */ if (argc == 1 || argc == 2) /* no args; copy standard input */ fprintf(stderr, \u0026#34;Usage: %s file1 file2\\n\u0026#34;, prog); else { if ((fp1 = fopen(*++argv, \u0026#34;r\u0026#34;)) == NULL) { fprintf(stderr, \u0026#34;%s: can\u0026#39;t open %s\\n\u0026#34;, prog, *argv); exit(1); } if ((fp2 = fopen(*++argv, \u0026#34;r\u0026#34;)) == NULL) { fprintf(stderr, \u0026#34;%s: can\u0026#39;t open %s\\n\u0026#34;, prog, *argv); exit(1); } filecmp(fp1, fp2); } fclose(fp1); fclose(fp2); exit(0); } 1 2 3 4 5 ➜ ch07 git:(main) ✗ ./Exercise7-6 Exercise7-6.c Exercise7-5.c difference in line 5 line1: #define MAXLINE 1000 line2: void filecopy(FILE *ifp, FILE *ofp) exercise7-7 修改第 5 章的模式查找程序，使它从一个命名文件的集合中读取输入（有文件名参数时），如果没有文件名参数，则从标准输入中读取输入。当发现一个匹配行时，是否应该将相应的文件名打印出来？\nexercise7-8 编写一个程序，以打印一个文件集合，每个文件从新的一页开始打印，并且打印每个文件相应的标题和页数。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #define MAXLINE 1024 #define LINES_PER_PAGE 3 void print_file(char *file_name) { FILE *f; int page_number = 1; int line_count; int c; int new_page = 1; assert(file_name != NULL); char *line = malloc(MAXLINE); if ((f = fopen(file_name, \u0026#34;r\u0026#34;)) != NULL) { while (fgets(line, MAXLINE, f) != NULL) { if (new_page) { printf(\u0026#34;[%s] page %d starts\\n\u0026#34;, file_name, page_number); new_page = 0; line_count = 1; } if (!feof(f) \u0026amp;\u0026amp; ++line_count \u0026gt; LINES_PER_PAGE) { /* print out the footer */ printf(\u0026#34;[%s] page %d ends\\n\u0026#34;, file_name, page_number); /* skip another line so we can see it on screen */ putchar(\u0026#39;\\n\u0026#39;); new_page = 1; page_number++; } else { fputs(line, stdout); } } /* skip another line so we can see it on screen */ putchar(\u0026#39;\\n\u0026#39;); fclose(f); } } int main(int argc, char *argv[]) { int i; if (argc \u0026lt; 2) { fputs(\u0026#34;no files specified\\n\u0026#34;, stderr); return EXIT_FAILURE; } for (i = 1; i \u0026lt; argc; i++) print_file(argv[i]); return EXIT_SUCCESS; } 运行\n1 2 3 4 5 6 7 8 9 ➜ ch07 git:(main) ✗ ./Exercise7-8 test.txt [test.txt] page 1 starts It’s quite a good summary, but it would have even better when taking into account the importance of the number of requested rows, expected by the Cassandra client. 1) “To perform the country index lookup, every node is queried, looks up the \u0026#39;UK\u0026#39; partition and then looks up each user_accounts partition found. ” [test.txt] page 1 ends [test.txt] page 2 starts 2) “This leads to the conclusion that the best use case for Cassandra\u0026#39;s secondary indexes is when p is approximately n i.e. the number of partitions is about equal to the number of nodes.” What a narrow best use case ! Hopefully, there are other use cases where seconday index are fine (that is, for low-cardinality sets), or even finer (according to the number of resulting rows requested vs the cardinality of indexed values). exercise7-9 类似于 isupper 这样的函数可以通过某种方式实现以达到节省空间或时间的目的。考虑节省空间或时间的实现方式。\n1 2 3 4 # define isupper(c) __isctype((c), _ISupper) # define __isctype(c, type) \\ ((*__ctype_b_loc ())[(int) (c)] \u0026amp; (unsigned short int) type) 使用了宏定义\n","permalink":"https://fireflyyh.top/posts/tcpl/ch07/","summary":"部分答案参考了官方题解和网上的答案，仅供参考，可能也有部分bug未发现或解决。\nexercise7-1 编写一个程序，根据它自身被调用时存放在argv[0]中的名字，实现将大写字母转换为小写字母或将小写字母转换为大写字母的功能。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;ctype.h\u0026gt; #include \u0026lt;string.h\u0026gt; int main(int argc, char **argv) { int (*handler[2])(int) = {tolower, toupper}; int type = strcmp(argv[0], \u0026#34;./lower\u0026#34;) == 0 ? 0 : strcmp(argv[0], \u0026#34;./upper\u0026#34;) == 0 ? 1 : -1; if (type == -1) { fprintf(stderr, \u0026#34;Usage: %s [lower|upper]\\n\u0026#34;, argv[0]); } else { int c; while ((c = getchar()) !","title":"C语言程序设计第二版课后习题--第七章"},{"content":" 部分答案参考了官方题解和网上的答案，仅供参考，可能也有部分bug未发现或解决。\nexercise6-1 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 #define NKEYS (sizeof keytab / sizeof(keytab[0])) int binsearch(char *word, struct key tab[], int n) { int cond; int low, high, mid; low = 0; high = n - 1; while (low \u0026lt;= high) { mid = (low + high) / 2; if ((cond = strcmp(word, tab[mid].word)) \u0026lt; 0) high = mid - 1; else if (cond \u0026gt; 0) low = mid + 1; else return mid; } return -1; } int getword(char *word, int lim) { int c; char *w = word; while (isspace(c = getch())) ; if (c != EOF) *w++ = c; if (!isalpha(c)) { *w = \u0026#39;\\0\u0026#39;; return c; } for (; --lim \u0026gt; 0; w++) if (!isalnum(*w = getch())) { ungetch(*w); break; } *w = \u0026#39;\\0\u0026#39;; return word[0]; } int main() { int n; char word[MAXWORD]; while (getword(word, MAXWORD) != EOF) if (isalpha(word[0])) if ((n = binsearch(word, keytab, NKEYS)) \u0026gt;= 0) keytab[n].count++; for (n = 0; n \u0026lt; NKEYS; n++) if (keytab[n].count \u0026gt; 0) printf(\u0026#34;%4d %s\\n\u0026#34;, keytab[n].count, keytab[n].word); return 0; } 上述 getword 函数不能正确处理下划线、字符串常量、注释及预处理器控制指令。请编写一个更完善的 getword 函数。\n代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 enum { NORMAL, COMMENT, PREPROCESSOR, STRING, UNDERSCORE }; int getword02(char *word, int lim) { int c, d, inComment = 0, inString = 0, isPreprocessor = 0, isUnderscore = 0; // 分别表示是否在注释、字符串、预处理指令、下划线中 char *w = word; while (isspace(c = getch())) ; if (c != EOF) *w++ = c; type = NORMAL; // 默认为普通字符 if (c == \u0026#39;\u0026#34;\u0026#39;) inString = 1; else if (c == \u0026#39;/\u0026#39; \u0026amp;\u0026amp; (d = getch()) == \u0026#39;*\u0026#39;) // 注释 { *w++ = d; inComment = 1; } else if (c == \u0026#39;#\u0026#39;) // 预处理指令 { isPreprocessor = 1; } else if (c == \u0026#39;_\u0026#39;) // 下划线 { isUnderscore = 1; } else if (!isalpha(c) \u0026amp;\u0026amp; c != \u0026#39;_\u0026#39;) // 不合法字符 { *w = \u0026#39;\\0\u0026#39;; return c; } for (; --lim \u0026gt; 0; w++) { if (inString) // 如果在字符串中，直到遇到双引号才结束 { if ((*w = getch()) == \u0026#39;\u0026#34;\u0026#39;) { w++; type = STRING; break; } } else if (inComment) { if ((*w = getch()) == \u0026#39;*\u0026#39; \u0026amp;\u0026amp; (d = getch()) == \u0026#39;/\u0026#39;) // 注释结束 { w++; *w++ = d; type = COMMENT; break; } } else if (isPreprocessor) // 如果在预处理指令中，直到遇到空格才结束 { if (isspace(*w = getch())) { type = PREPROCESSOR; break; } } else if (isUnderscore) // 如果在下划线中，直到遇到空格才结束 { if (isspace(*w = getch())) { type = UNDERSCORE; break; } } else { if (!isalnum(*w = getch()) \u0026amp;\u0026amp; *w != \u0026#39;_\u0026#39;) // 如果不是字母或下划线，结束 { ungetch(*w); break; } } } *w = \u0026#39;\\0\u0026#39;; return word[0]; } int main() { int n; char word[MAXWORD]; while (getword02(word, MAXWORD) != EOF) // 读取单词 { if (type == COMMENT) printf(\u0026#34;Comment: %s\\n\u0026#34;, word); else if (type == PREPROCESSOR) printf(\u0026#34;Preprocessor: %s\\n\u0026#34;, word); else if (type == STRING) printf(\u0026#34;String: %s\\n\u0026#34;, word); else if (type == UNDERSCORE) printf(\u0026#34;Underscore: %s\\n\u0026#34;, word); else if (isalpha(word[0]) \u0026amp;\u0026amp; ((n = binsearch(word, keytab, NKEYS)) \u0026gt;= 0)) { keytab[n].count++; printf(\u0026#34;Keyword: %s\\n\u0026#34;, word); } } printf(\u0026#34;\\nkeywords:\\n\u0026#34;); for (n = 0; n \u0026lt; NKEYS; n++) if (keytab[n].count \u0026gt; 0) printf(\u0026#34;%4d %s\\n\u0026#34;, keytab[n].count, keytab[n].word); return 0; } 运行：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 /*comment*/ #define \u0026#34;string\u0026#34; while for while int _variable Comment: /*comment*/ Preprocessor: #define String: \u0026#34;string\u0026#34; Keyword: while Keyword: for Keyword: while Keyword: int Underscore: _variable keywords: 1 for 1 int 2 while exercise6-2 编写一个程序，用以读入一个 C 语言程序，并按字母表顺序分组打印变量名，要求每一组内各变量名的前 6 个字符相同，其余字符不同。字符串和注释中的单词不予考虑。请将 6 作为一个可在命令行中设定的参数。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 #define GRPLEN 6 #define NKEYS (sizeof keytab / sizeof(keytab[0])) enum { NORMAL, COMMENT, PREPROCESSOR, STRING, UNDERSCORE }; struct tnode { /* the tree node: */ char *word; /* points to the text */ int count; /* number of occurrences */ struct tnode *left; /* left child */ struct tnode *right; /* right child */ }; int group_length = GRPLEN; int type; struct tnode *talloc(void) { return (struct tnode *)malloc(sizeof(struct tnode)); } char *Strdup(char *s) /* make a duplicate of s */ { char *p; p = (char *)malloc(strlen(s) + 1); /* +1 for \u0026#39;\\0\u0026#39; */ if (p != NULL) strcpy(p, s); return p; } /* addtree: add a node with w, at or below p */ struct tnode *addtree(struct tnode *p, char *w) { int cond; if (p == NULL) { /* a new word has arrived */ p = talloc(); /* make a new node */ p-\u0026gt;word = Strdup(w); p-\u0026gt;count = 1; p-\u0026gt;left = p-\u0026gt;right = NULL; } else if ((cond = strcmp(w, p-\u0026gt;word)) == 0) p-\u0026gt;count++; /* repeated word */ else if (cond \u0026lt; 0) /* less than into left subtree */ p-\u0026gt;left = addtree(p-\u0026gt;left, w); else /* greater than into right subtree */ p-\u0026gt;right = addtree(p-\u0026gt;right, w); return p; } /* treeprint: in-order print of tree p */ void treeprint(struct tnode *p) { if (p != NULL) { treeprint(p-\u0026gt;left); printf(\u0026#34;%4d %s\\n\u0026#34;, p-\u0026gt;count, p-\u0026gt;word); treeprint(p-\u0026gt;right); } } int binsearch(char *word, struct key tab[], int n) { int cond; int low, high, mid; low = 0; high = n - 1; while (low \u0026lt;= high) { mid = (low + high) / 2; if ((cond = strcmp(word, tab[mid].word)) \u0026lt; 0) high = mid - 1; else if (cond \u0026gt; 0) low = mid + 1; else return mid; } return -1; } int getword(char *word, int lim) { int c, d, inComment = 0, inString = 0, isPreprocessor = 0, isUnderscore = 0; // 分别表示是否在注释、字符串、预处理指令、下划线中 char *w = word; while (isspace(c = getch())) ; if (c != EOF) *w++ = c; type = NORMAL; // 默认为普通字符 if (c == \u0026#39;\u0026#34;\u0026#39;) inString = 1; else if (c == \u0026#39;/\u0026#39; \u0026amp;\u0026amp; (d = getch()) == \u0026#39;*\u0026#39;) // 注释 { *w++ = d; inComment = 1; } else if (c == \u0026#39;#\u0026#39;) // 预处理指令 { isPreprocessor = 1; } else if (c == \u0026#39;_\u0026#39;) // 下划线 { isUnderscore = 1; } else if (!isalpha(c) \u0026amp;\u0026amp; c != \u0026#39;_\u0026#39;) // 不合法字符 { *w = \u0026#39;\\0\u0026#39;; return c; } for (; --lim \u0026gt; 0; w++) { if (inString) // 如果在字符串中，直到遇到双引号才结束 { if ((*w = getch()) == \u0026#39;\u0026#34;\u0026#39;) { w++; type = STRING; break; } } else if (inComment) { if ((*w = getch()) == \u0026#39;*\u0026#39; \u0026amp;\u0026amp; (d = getch()) == \u0026#39;/\u0026#39;) // 注释结束 { w++; *w++ = d; type = COMMENT; break; } } else if (isPreprocessor) // 如果在预处理指令中，直到遇到空格才结束 { if (isspace(*w = getch())) { type = PREPROCESSOR; break; } } else if (isUnderscore) // 如果在下划线中，直到遇到空格才结束 { if (isspace(*w = getch())) { type = UNDERSCORE; break; } } else { if (!isalnum(*w = getch()) \u0026amp;\u0026amp; *w != \u0026#39;_\u0026#39;) // 如果不是字母或下划线，结束 { ungetch(*w); break; } } } *w = \u0026#39;\\0\u0026#39;; return word[0]; } bool is_variable(char *word) { return binsearch(word, keytab, NKEYS) \u0026lt; 0; } void groupprint(struct tnode *p, char *prefix) { if (p != NULL) { groupprint(p-\u0026gt;left, prefix); if (strncmp(p-\u0026gt;word, prefix, group_length) == 0) { printf(\u0026#34;%4d %s\\n\u0026#34;, p-\u0026gt;count, p-\u0026gt;word); } groupprint(p-\u0026gt;right, prefix); } } void print_groups(struct tnode *root) { if (root == NULL) return; char current_prefix[MAXWORD] = \u0026#34;\u0026#34;; struct tnode *current = root; while (current != NULL) { strncpy(current_prefix, current-\u0026gt;word, group_length); current_prefix[group_length] = \u0026#39;\\0\u0026#39;; printf(\u0026#34;Group: %s\\n\u0026#34;, current_prefix); groupprint(root, current_prefix); current = current-\u0026gt;right; } } int main(int argc, char *argv[]) { if (argc \u0026gt; 1) { group_length = atoi(argv[1]); } int n; struct tnode *root = NULL; char word[MAXWORD]; while (getword(word, MAXWORD) != EOF) if (type == NORMAL \u0026amp;\u0026amp; isalpha(word[0]) \u0026amp;\u0026amp; is_variable(word)) root = addtree(root, word); print_groups(root); return 0; } 运行：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 ➜ ch06 git:(main) ./Exercise6-2 5 #include \u0026lt;stdio.h\u0026gt; int main() { int varOne = 1; int varTwo = 2; int varThree = 3; float varOneMore = 4.0; char varTwoMore = \u0026#39;a\u0026#39;; // This is a comment /* This is a block comment int varFour = 4; */ return 0; } Group: stdio 1 stdio Group: varOn 1 varOne 1 varOneMore Group: varTw 1 varTwo 1 varTwoMore Group: varTw 1 varTwo 1 varTwoMore exercise6-3 编写一个交叉引用程序，打印文档中所有单词的列表，并且每个单词还有一个列表，记录出现过该单词的行号。对 the、and 等非实义单词不予考虑。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 struct tnode { char *word; int lines[MAXLINES]; int line_count; struct tnode *left; struct tnode *right; }; int line_number = 1; struct tnode *talloc(void) { return (struct tnode *)malloc(sizeof(struct tnode)); } char *strdup(const char *s) { char *p = (char *)malloc(strlen(s) + 1); if (p != NULL) strcpy(p, s); return p; } struct tnode *addtree(struct tnode *p, char *w, int lineno) { int cond; if (p == NULL) { p = talloc(); p-\u0026gt;word = strdup(w); p-\u0026gt;lines[0] = lineno; p-\u0026gt;line_count = 1; p-\u0026gt;left = p-\u0026gt;right = NULL; } else if ((cond = strcmp(w, p-\u0026gt;word)) == 0) { if (p-\u0026gt;lines[p-\u0026gt;line_count - 1] != lineno) p-\u0026gt;lines[p-\u0026gt;line_count++] = lineno; } else if (cond \u0026lt; 0) p-\u0026gt;left = addtree(p-\u0026gt;left, w, lineno); else p-\u0026gt;right = addtree(p-\u0026gt;right, w, lineno); return p; } void treeprint(struct tnode *p) { if (p != NULL) { treeprint(p-\u0026gt;left); printf(\u0026#34;%s: \u0026#34;, p-\u0026gt;word); for (int i = 0; i \u0026lt; p-\u0026gt;line_count; i++) printf(\u0026#34;%d \u0026#34;, p-\u0026gt;lines[i]); printf(\u0026#34;\\n\u0026#34;); treeprint(p-\u0026gt;right); } } int getword(char *word, int lim) { int c; char *w = word; while (isspace(c = getch())) if (c == \u0026#39;\\n\u0026#39;) line_number++; if (c != EOF) *w++ = c; if (!isalpha(c)) { *w = \u0026#39;\\0\u0026#39;; return c; } for (; --lim \u0026gt; 0; w++) if (!isalnum(*w = getch())) { ungetch(*w); break; } *w = \u0026#39;\\0\u0026#39;; return word[0]; } int is_noise_word(char *word) { static char *noise_words[] = { \u0026#34;the\u0026#34;, \u0026#34;and\u0026#34;, \u0026#34;a\u0026#34;, \u0026#34;an\u0026#34;, \u0026#34;in\u0026#34;, \u0026#34;on\u0026#34;, \u0026#34;of\u0026#34;, \u0026#34;to\u0026#34;, \u0026#34;is\u0026#34;, \u0026#34;are\u0026#34;, \u0026#34;was\u0026#34;, \u0026#34;were\u0026#34;, \u0026#34;it\u0026#34;, \u0026#34;that\u0026#34;, \u0026#34;this\u0026#34;, \u0026#34;with\u0026#34;, \u0026#34;as\u0026#34;, \u0026#34;for\u0026#34;, \u0026#34;by\u0026#34;, \u0026#34;at\u0026#34;, \u0026#34;from\u0026#34;, \u0026#34;but\u0026#34;, \u0026#34;or\u0026#34;, \u0026#34;not\u0026#34;, \u0026#34;be\u0026#34;, \u0026#34;have\u0026#34;, \u0026#34;has\u0026#34;, \u0026#34;had\u0026#34;, \u0026#34;do\u0026#34;, \u0026#34;does\u0026#34;, \u0026#34;did\u0026#34;, \u0026#34;will\u0026#34;, \u0026#34;would\u0026#34;, \u0026#34;can\u0026#34;, \u0026#34;could\u0026#34;, \u0026#34;should\u0026#34;, \u0026#34;shall\u0026#34;, \u0026#34;may\u0026#34;, \u0026#34;might\u0026#34;, \u0026#34;must\u0026#34;, \u0026#34;if\u0026#34;, \u0026#34;then\u0026#34;, \u0026#34;else\u0026#34;, \u0026#34;when\u0026#34;, \u0026#34;where\u0026#34;, \u0026#34;which\u0026#34;, \u0026#34;who\u0026#34;, \u0026#34;whom\u0026#34;, \u0026#34;whose\u0026#34;, \u0026#34;why\u0026#34;, \u0026#34;how\u0026#34;, NULL}; for (char **p = noise_words; *p != NULL; p++) if (strcmp(word, *p) == 0) return 1; return 0; } int main(void) { struct tnode *root = NULL; char word[MAXWORD]; while (getword(word, MAXWORD) != EOF) if (isalpha(word[0]) \u0026amp;\u0026amp; !is_noise_word(word)) root = addtree(root, word, line_number); treeprint(root); return 0; } 运行：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 ➜ ch06 git:(main) ./Exercise6-3 \u0026lt; test.txt AFAIK: 3 Cassandra: 1 4 Hopefully: 5 It: 1 So: 3 This: 4 To: 2 UK: 2 Well: 3 What: 5 about: 4 according: 5 account: 1 accounts: 2 all: 3 always: 3 approximately: 4 been: 3 best: 4 5 better: 1 calls: 3 cardinality: 5 case: 4 5 cases: 5 client: 1 conclusion: 4 country: 2 e: 4 each: 2 enough: 3 equal: 4 even: 1 5 every: 2 3 expected: 1 fine: 5 finer: 5 found: 2 3 good: 1 i: 4 importance: 1 index: 2 5 indexed: 5 indexes: 4 into: 1 leads: 4 looks: 2 lookup: 2 low: 5 n: 4 narrow: 5 node: 2 3 nodes: 3 4 number: 1 4 5 other: 5 p: 4 partition: 2 partitions: 4 perform: 2 queried: 2 3 quite: 1 requested: 1 5 resulting: 5 rows: 1 3 5 s: 1 4 secondary: 4 seconday: 5 sets: 5 stop: 3 summary: 1 taking: 1 there: 5 up: 2 use: 4 5 user: 2 values: 5 vs: 5 exercise6-4 编写一个程序，根据单词的出现频率按降序打印输入的各个不同单词，并在每个单词的前面标上它的出现次数。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 // 将树转换为列表 void treeToList(struct tnode *p, struct wordinfo list[]) { if (p != NULL) { treeToList(p-\u0026gt;left, list); list[counter].word = strdup(p-\u0026gt;word); list[counter].count = p-\u0026gt;count; counter++; treeToList(p-\u0026gt;right, list); } } // 打印列表 void listprint(struct wordinfo list[]) { for (int i = 0; i \u0026lt; wordCount; i++) { printf(\u0026#34;%4d %s\\n\u0026#34;, list[i].count, list[i].word); } } // 交换两个元素 void swap(struct wordinfo list[], int i, int j) { struct wordinfo temp; temp = list[i]; list[i] = list[j]; list[j] = temp; } // 根据单词出现的频率来进行快速排序 void mqsort(struct wordinfo list[], int left, int right) { int i, last; if (left \u0026gt;= right) return; swap(list, left, (left + right) / 2); last = left; for (i = left + 1; i \u0026lt;= right; i++) if (list[i].count \u0026gt; list[left].count) swap(list, ++last, i); swap(list, left, last); mqsort(list, left, last - 1); mqsort(list, last + 1, right); } int main(void) { struct tnode *root; char word[MAXWORD]; root = NULL; while (getword(word, MAXWORD) != EOF) if (isalpha(word[0])) root = addtree(root, word); printf(\u0026#34;Count of words is %d\\n\u0026#34;, wordCount); struct wordinfo list[wordCount]; treeToList(root, list); mqsort(list, 0, wordCount - 1); listprint(list); return 0; } 运行：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 ➜ ch06 git:(main) ./Exercise6-4 \u0026lt; test.txt Count of words is 95 12 the 6 of 6 is 4 number 3 queried 3 rows 3 are 3 node 3 to 3 when 3 use 2 index 2 found 2 have 2 Cassandra 2 looks 2 cardinality 2 nodes 2 even 2 not 2 for 2 partition 2 best 2 requested 2 every 2 s 2 case 2 that 2 a 2 up 1 leads 1 So 1 This 1 e 1 or 1 enough 1 other 1 and 1 p 1 expected 1 calls 1 finer 1 partitions 1 been 1 perform 1 accounts 1 To 1 importance 1 quite 1 indexed 1 all 1 into 1 resulting 1 it 1 UK 1 better 1 always 1 low 1 secondary 1 narrow 1 seconday 1 but 1 sets 1 country 1 stop 1 equal 1 summary 1 fine 1 taking 1 good 1 cases 1 AFAIK 1 Well 1 Hopefully 1 then 1 lookup 1 there 1 It 1 What 1 each 1 client 1 account 1 conclusion 1 indexes 1 user 1 n 1 values 1 approximately 1 vs 1 according 1 about 1 i 1 where 1 by 1 would exercise6-5 编写函数 undef，它将从由 lookup 和 install 维护的表中删除一个变量及其定义。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 /* undef: remove a name and its definition from the hashtab */ void undef(char *name) { struct nlist *np, *prev = NULL; unsigned hashval = hash(name); for (np = hashtab[hashval]; np != NULL; prev = np, np = np-\u0026gt;next) // 遍历链表 { if (strcmp(name, np-\u0026gt;name) == 0) { if (prev == NULL) hashtab[hashval] = np-\u0026gt;next; else prev-\u0026gt;next = np-\u0026gt;next; free(np-\u0026gt;name); free(np-\u0026gt;defn); free(np); return; } } } int main(void) { struct nlist *np; printf(\u0026#34;test install \\\u0026#34;MAXLINE\\\u0026#34; \\\u0026#34;BUFSIZE\\\u0026#34;:\\n\u0026#34;); install(\u0026#34;MAXLINE\u0026#34;, \u0026#34;1000\u0026#34;); install(\u0026#34;BUFSIZE\u0026#34;, \u0026#34;100\u0026#34;); np = lookup(\u0026#34;MAXLINE\u0026#34;); if (np == NULL) printf(\u0026#34;install failed\\n\u0026#34;); else printf(\u0026#34;defination of \\\u0026#34;MAXLINE\\\u0026#34; is: %s\\n\u0026#34;, np-\u0026gt;defn); printf(\u0026#34;install success\\n\u0026#34;); printf(\u0026#34;\\ntest undef \\\u0026#34;BUFSIZE\\\u0026#34;:\\n\u0026#34;); undef(\u0026#34;BUFSIZE\u0026#34;); np = lookup(\u0026#34;BUFSIZE\u0026#34;); if (np == NULL) printf(\u0026#34;can not find defination of \\\u0026#34;BUFSIZE\\\u0026#34;\\nundef success\\n\u0026#34;); return 0; } 运行：\n1 2 3 4 5 6 7 8 ➜ ch06 git:(main) ✗ ./Exercise6-5 test install \u0026#34;MAXLINE\u0026#34; \u0026#34;BUFSIZE\u0026#34;: defination of \u0026#34;MAXLINE\u0026#34; is: 1000 install success test undef \u0026#34;BUFSIZE\u0026#34;: can not find defination of \u0026#34;BUFSIZE\u0026#34; undef success exercise6-6 以本节介绍的函数为基础，编写一个适合 C 语言程序使用的#define 处理器的简单版本（即无参数的情况）。你会发现 getch 和 ungetch 函数非常有用。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 void skipblanks(void) { int c; while ((c = getch()) == \u0026#39; \u0026#39; || c == \u0026#39;\\t\u0026#39;) ; ungetch(c); } void getdef(void) { int c, i; char def[BUFSIZE], name[BUFSIZE]; skipblanks(); if (!isalpha(c = getch())) { printf(\u0026#34;getdef: invalid macro name\\n\u0026#34;); return; } for (i = 0; isalnum(c) || c == \u0026#39;_\u0026#39;; c = getch()) name[i++] = c; name[i] = \u0026#39;\\0\u0026#39;; skipblanks(); if (c != \u0026#39; \u0026#39;) { printf(\u0026#34;getdef: missing space after macro name\\n\u0026#34;); return; } for (i = 0; (c = getch()) != EOF \u0026amp;\u0026amp; c != \u0026#39;\\n\u0026#39;;) def[i++] = c; def[i] = \u0026#39;\\0\u0026#39;; if (i \u0026gt; 0) install(name, def); } void procdef(void) { int c; while ((c = getch()) != EOF) { if (c == \u0026#39;#\u0026#39;) { char keyword[7]; int i; for (i = 0; i \u0026lt; 6 \u0026amp;\u0026amp; (c = getch()) != EOF; i++) { keyword[i] = c; } keyword[i] = \u0026#39;\\0\u0026#39;; if (strcmp(keyword, \u0026#34;define\u0026#34;) == 0) { getdef(); } } } } int main(void) { procdef(); printf(\u0026#34;name defination\\n\u0026#34;); for (int i = 0; i \u0026lt; HASHSIZE; i++) { struct nlist *np = hashtab[i]; while (np != NULL) { printf(\u0026#34;%-16s%s\\n\u0026#34;, np-\u0026gt;name, np-\u0026gt;defn); np = np-\u0026gt;next; } } return 0; } 对于test.c：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 #define LISTENQ 1024 #define MAXLINE 4096 #define BUFFSIZE 8192 #define SERV_PORT 9877 #define AI_PASSIVE 1 #define AI_CANONNAME 2 #define NI_MAXHOST 1025 #define NI_MAXSERV 32 #define NI_NOFQDN 1 #define NI_NUMERICHOST 2 #define NI_NAMEREQD 4 #define NI_NUMERICSERV 8 #define NI_DGRAM 16 #define EAI_ADDRFAMILY 1 #define EAI_AGAIN 2 #define EAI_BADFLAGS 3 #define EAI_FAIL 4 #define EAI_FAMILY 5 #define EAI_MEMORY 6 #define EAI_NODATA 7 #define EAI_NONAME 8 #define EAI_SERVICE 9 #define EAI_SOCKTYPE 10 #define EAI_SYSTEM 11 运行：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 ➜ ch06 git:(main) ✗ ./Exercise6-6 \u0026lt; test.c name defination AI_CANONNAME 2 NI_NUMERICHOST 2 EAI_NONAME 8 EAI_ADDRFAMILY 1 NI_NUMERICSERV 8 AI_PASSIVE 1 EAI_SERVICE 9 SERV_PORT 9877 EAI_SOCKTYPE 10 EAI_MEMORY 6 EAI_AGAIN 2 EAI_BADFLAGS 3 NI_MAXHOST 1025 EAI_FAIL 4 NI_NAMEREQD 4 EAI_NODATA 7 MAXLINE 4096 NI_MAXSERV 32 EAI_SYSTEM 11 BUFFSIZE 8192 NI_DGRAM 16 NI_NOFQDN 1 EAI_FAMILY 5 LISTENQ 1024 ","permalink":"https://fireflyyh.top/posts/tcpl/ch06/","summary":"部分答案参考了官方题解和网上的答案，仅供参考，可能也有部分bug未发现或解决。\nexercise6-1 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 #define NKEYS (sizeof keytab / sizeof(keytab[0])) int binsearch(char *word, struct key tab[], int n) { int cond; int low, high, mid; low = 0; high = n - 1; while (low \u0026lt;= high) { mid = (low + high) / 2; if ((cond = strcmp(word, tab[mid].","title":"C语言程序设计第二版课后习题--第六章"},{"content":" 部分答案参考了官方题解和网上的答案，仅供参考，可能也有部分bug未发现或解决。\nexercise5-1 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 int getint(int *pn) { int c, sign; while (isspace(c = getch())) /* skip white space */ ; if (!isdigit(c) \u0026amp;\u0026amp; c != EOF \u0026amp;\u0026amp; c != \u0026#39;+\u0026#39; \u0026amp;\u0026amp; c != \u0026#39;-\u0026#39;) { ungetch(c); /* it is not a number */ return 0; } sign = (c == \u0026#39;-\u0026#39;) ? -1 : 1; if (c == \u0026#39;+\u0026#39; || c == \u0026#39;-\u0026#39;) c = getch(); for (*pn = 0; isdigit(c); c = getch()) *pn = 10 * *pn + (c - \u0026#39;0\u0026#39;); *pn *= sign; if (c != EOF) ungetch(c); return c; } 在上面的例子中，如果符号+或-的后面紧跟的不是数字，getint 函数将把符号视为数字 0 的有效表达方式。修改该函数，将这种形式的+或-符号重新写回到输入流中。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;ctype.h\u0026gt; #define SIZE 100 #define BUFSIZE 100 char buf[BUFSIZE]; /* buffer for ungetch */ int bufp = 0; /* next free position in buf */ int notdigit = 0; /* flag for not a digit */ /* getint: get next integer from input into *pn */ int getint(int *pn) { notdigit = 0; int c, sign, foundSign; while (isspace(c = getch())) /* skip white space */ ; if (!isdigit(c) \u0026amp;\u0026amp; c != EOF \u0026amp;\u0026amp; c != \u0026#39;+\u0026#39; \u0026amp;\u0026amp; c != \u0026#39;-\u0026#39;) { notdigit = 1; // 若不是数字，将字符放回输入流，但是下次依然会读取到这个字符，所以需要注释掉ungtch(c) // ungetch(c); /* it is not a number */ return 0; } sign = (c == \u0026#39;-\u0026#39;) ? -1 : 1; if (foundSign = (c == \u0026#39;+\u0026#39; || c == \u0026#39;-\u0026#39;)) c = getch(); if (c != EOF \u0026amp;\u0026amp; !isdigit(c)) { // ungetch(c); if (foundSign) ungetch((sign = -1) ? \u0026#39;-\u0026#39; : \u0026#39;+\u0026#39;); // 将符号放回 return 0; } for (*pn = 0; isdigit(c); c = getch()) *pn = 10 * *pn + (c - \u0026#39;0\u0026#39;); *pn *= sign; if (c != EOF) ungetch(c); return c; } int main() { int n, array[SIZE], getint(int *); for (n = 0; n \u0026lt; SIZE \u0026amp;\u0026amp; getint(\u0026amp;array[n]) != EOF; n++) { if (notdigit) { printf(\u0026#34;Not a number\\n\u0026#34;); continue; } printf(\u0026#34;%d\\n\u0026#34;, array[n]); } } 1 2 3 4 5 6 7 8 9 -1 2 -1 2 s2 Not a number 2 -s2 0 -2 exercise5-2 模仿函数 getint 的实现方法，编写一个读取浮点数的函数 getfloat。getfloat 函数的返回值应该是什么类型？\n代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 int getfloat(float *pn) { notdigit = 0; int c, sign, foundSign; float power; while (isspace(c = getch())) /* skip white space */ ; if (!isdigit(c) \u0026amp;\u0026amp; c != EOF \u0026amp;\u0026amp; c != \u0026#39;+\u0026#39; \u0026amp;\u0026amp; c != \u0026#39;-\u0026#39; \u0026amp;\u0026amp; c != \u0026#39;.\u0026#39;) { notdigit = 1; return 0; } sign = (c == \u0026#39;-\u0026#39;) ? -1 : 1; if (foundSign = (c == \u0026#39;+\u0026#39; || c == \u0026#39;-\u0026#39;)) c = getch(); if (c != EOF \u0026amp;\u0026amp; !isdigit(c) \u0026amp;\u0026amp; c != \u0026#39;.\u0026#39;) { if (foundSign) ungetch((sign == -1) ? \u0026#39;-\u0026#39; : \u0026#39;+\u0026#39;); // 将符号放回 return 0; } for (*pn = 0; isdigit(c); c = getch()) *pn = 10 * *pn + (c - \u0026#39;0\u0026#39;); if (c == \u0026#39;.\u0026#39;) c = getch(); for (power = 1.0; isdigit(c); c = getch()) { *pn = 10 * *pn + (c - \u0026#39;0\u0026#39;); power *= 10; } *pn = sign * (*pn / power); if (c != EOF) ungetch(c); return c; } 运行：\n1 2 1.23 1.230000 exercise5-3 用指针方式实现第 2 章中的函数 strcat。函数 strcat(s, t)将 t 指向的字符串复制到 s 指向的字符串的尾部。\n代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 #define MAXLINE 1024 /* strcat: 将 t 指向的字符串复制到 s 指向的字符串的尾部 */ void mstrcat(char *s, const char *t) { // 找到 s 的末尾 while (*s) { s++; } // 将 t 的内容复制到 s 的末尾 while (*t) { *s = *t; s++; t++; } // 添加字符串结束符 *s = \u0026#39;\\0\u0026#39;; } int main() { char s[MAXLINE]; char t[MAXLINE]; printf(\u0026#34;Please input S and T:\\n\u0026#34;); scanf(\u0026#34;%s\u0026#34;, s); scanf(\u0026#34;%s\u0026#34;, t); mstrcat(s, t); printf(\u0026#34;ans is: %s\\n\u0026#34;, s); return 0; } 运行：\n1 2 3 Please input S and T: abc def ans is: abcdef exercise5-4 编写函数 strend(s, t)。如果字符串 t 出现在字符串 s 的尾部，该函数返回 1；否则返回 0。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 int strend(const char *s, const char *t) { int i = strlen(s) - 1; int j = strlen(t) - 1; if (j \u0026gt; i) return 0; while (j \u0026gt;= 0) if (s[i--] != t[j--]) return 0; return 1; } int main() { char s[MAXLINE]; char t[MAXLINE]; printf(\u0026#34;Please input S and T:\\n\u0026#34;); scanf(\u0026#34;%s\u0026#34;, s); scanf(\u0026#34;%s\u0026#34;, t); if (strend(s, t)) printf(\u0026#34;T appears at the end of S.\\n\u0026#34;); else printf(\u0026#34;T does not appear at the end of S.\\n\u0026#34;); } 运行：\n1 2 3 4 Please input S and T: good o String T does not appear at the end of string S. exercise5-5 实现库函数 strncpy、strncat 和 strncmp，它们最多对参数字符串中的前 n 个字符进行操作。例如，函数 strncpy(s, t, n)将 t 中最多前 n 个字符复制到 s中。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 /* mstrncpy: 将 t 中最多前 n 个字符复制到 s 中 */ char *mstrncpy(char *s, const char *t, int n) { char *ans = s; while (n-- \u0026amp;\u0026amp; (*s++ = *t++)) ; while ((n--) \u0026gt; 0) *s++ = \u0026#39;\\0\u0026#39;; return ans; } /* mstrncat: 将 t 中最多前 n 个字符连接到 s 的末尾 */ char *mstrncat(char *s, const char *t, int n) { char *ans = s; s += strlen(s); while (n-- \u0026amp;\u0026amp; (*s++ = *t++)) ; *s = \u0026#39;\\0\u0026#39;; return ans; } /* mstrncmp: 比较 s 和 t 中最多前 n 个字符 */ int mstrncmp(const char *s, const char *t, int n) { while (n-- \u0026amp;\u0026amp; *s \u0026amp;\u0026amp; (*s++ == *t++)) ; return n == -1 ? 0 : (*s - *t) != 0; } int main() { char s1[MAXLINE] = \u0026#34;gooooood\u0026#34;; char s2[MAXLINE] = \u0026#34;idea\u0026#34;; char s3[MAXLINE] = \u0026#34;good\u0026#34;; int n1 = 4; int result = mstrncmp(s1, s3, n1); printf(\u0026#34;mstrncmp(%s, %s, %d):\\n %d\\n\u0026#34;, s1, s3, n1, result); int n2 = 5; mstrncpy(s1, s3, 5); printf(\u0026#34;mstrncpy(%s, %s, %d):\\n %s\\n\u0026#34;, s1, s3, n2, s1); int n3 = 3; mstrncat(s2, s3, 3); printf(\u0026#34;mstrncat(%s, %s, %d):\\n %s\\n\u0026#34;, s2, s3, n3, s2); return 0; } 运行：\n1 2 3 4 5 6 mstrncmp(gooooood, good, 4): 1 mstrncpy(good, good, 5): good mstrncat(ideagoo, good, 3): ideagoo exercise5-7 重写函数 readlines，将输入的文本行存储到由 main 函数提供的一个数组中，而不是存储到调用 alloc 分配的存储空间中。该函数的运行速度比改写前快多少？\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;string.h\u0026gt; #include \u0026lt;malloc.h\u0026gt; #define MAXLINES 5000 /* max #lines to be sorted */ #define MAXLEN 1000 /* max length of any input line */ char *lineptr[MAXLINES]; /* pointers to text lines */ int Getline(char line[]) { int c, i; for (i = 0; i \u0026lt; MAXLEN - 1 \u0026amp;\u0026amp; (c = getchar()) != EOF \u0026amp;\u0026amp; c != \u0026#39;\\n\u0026#39;; i++) line[i] = c; if (c == \u0026#39;\\n\u0026#39;) { line[i] = c; i++; } line[i] = \u0026#39;\\0\u0026#39;; return i; } /* swap: interchange v[i] and v[j] */ void swap(char *v[], int i, int j) { char *temp; temp = v[i]; v[i] = v[j]; v[j] = temp; } /* qsort: sort v[left]...v[right] into increasing order */ void qsort(char *v[], int left, int right) { int i, last; void swap(char *v[], int i, int j); if (left \u0026gt;= right) /* do nothing if array contains */ return; /* fewer than two elements */ swap(v, left, (left + right) / 2); last = left; for (i = left + 1; i \u0026lt;= right; i++) if (strcmp(v[i], v[left]) \u0026lt; 0) swap(v, ++last, i); swap(v, left, last); qsort(v, left, last - 1); qsort(v, last + 1, right); } /* readlines: read input lines */ int readlines(char *lineptr[], int maxlines) { int len, nlines; char *p, line[MAXLEN]; nlines = 0; while ((len = Getline(line)) \u0026gt; 0) if (nlines \u0026gt;= maxlines || (p = malloc(len)) == NULL) return -1; else { line[len - 1] = \u0026#39;\\0\u0026#39;; /* delete newline */ strcpy(p, line); lineptr[nlines++] = p; } return nlines; } /* writelines: write output lines */ void writelines(char *lineptr[], int nlines) { int i; for (i = 0; i \u0026lt; nlines; i++) printf(\u0026#34;%s\\n\u0026#34;, lineptr[i]); } /* sort input lines */ int main() { int nlines; /* number of input lines read */ printf(\u0026#34;Please input lines:\\n\u0026#34;); if ((nlines = readlines(lineptr, MAXLINES)) \u0026gt;= 0) { qsort(lineptr, 0, nlines - 1); printf(\u0026#34;Sorted lines(sorted by first word):\\n\u0026#34;); writelines(lineptr, nlines); return 0; } else { printf(\u0026#34;error: input too big to sort\\n\u0026#34;); return 1; } } 增加函数：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 int readlines2(char linesarray[][MAXLEN], int maxlines) { int len, nlines; nlines = 0; while ((len = Getline(linesarray[nlines])) \u0026gt; 0) if (nlines \u0026gt;= maxlines) return -1; else linesarray[nlines++][len - 1] = \u0026#39;\\0\u0026#39;; return nlines; } int main(int argc, char *argv[]) { printf(\u0026#34;Please input lines:\u0026#34;); if (argc \u0026gt; 1 \u0026amp;\u0026amp; *argv[1] == \u0026#39;2\u0026#39;) { printf(\u0026#34;(by readlines2):\\n\u0026#34;); int nlines = readlines2(linesarray, MAXLINES); } else { printf(\u0026#34;(by readlines):\\n\u0026#34;); int nlines = readlines(lineptr, MAXLINES); } return 0; } exercise5-8 函数 day_of_year 和 month_day 中没有进行错误检查，请解决该问题。\n对输入的月份、天数进行检查\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 #include \u0026lt;stdio.h\u0026gt; static char daytab[2][13] = { {0, 31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31}, {0, 31, 29, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31}, }; /* day_of_year: set day of year from month \u0026amp; day */ int day_of_year(int year, int month, int day) { int i, leap; if (month \u0026lt; 1 || month \u0026gt; 12 || day \u0026lt; 1) return -1; leap = year % 4 == 0 \u0026amp;\u0026amp; year % 100 != 0 || year % 400 == 0; if (day \u0026gt; daytab[leap][month]) return -1; for (i = 1; i \u0026lt; month; i++) day += daytab[leap][i]; return day; } /* month_day: set month, day from day of year */ int month_day(int year, int yearday, int *pmonth, int *pday) { int i, leap; if (yearday \u0026lt; 1) return -1; leap = year % 4 == 0 \u0026amp;\u0026amp; year % 100 != 0 || year % 400 == 0; if ((leap \u0026amp;\u0026amp; yearday \u0026gt; 366) || (!leap \u0026amp;\u0026amp; yearday \u0026gt; 365)) return -1; for (i = 1; yearday \u0026gt; daytab[leap][i]; i++) yearday -= daytab[leap][i]; *pmonth = i; *pday = yearday; return 0; } int main(void) { int year, month, day, yearday; printf(\u0026#34;Test day_of_year()\\nPlease input year, month and day: \u0026#34;); scanf(\u0026#34;%d %d %d\u0026#34;, \u0026amp;year, \u0026amp;month, \u0026amp;day); yearday = day_of_year(year, month, day); if (yearday == -1) printf(\u0026#34;Wrong date!\\n\u0026#34;); else printf(\u0026#34;%d-%d-%d: the %d day in %d\\n\u0026#34;, year, month, day, yearday, year); printf(\u0026#34;\\nTest month_day()\\nPlease input year and yearday: \u0026#34;); scanf(\u0026#34;%d %d\u0026#34;, \u0026amp;year, \u0026amp;yearday); int ans = month_day(year, yearday, \u0026amp;month, \u0026amp;day); if (ans == -1) printf(\u0026#34;Wrong date!\\n\u0026#34;); else printf(\u0026#34;the %d day in %d: %d-%d-%d\\n\u0026#34;, yearday, year, year, month, day); return 0; } 运行：\n1 2 3 4 5 6 7 Test day_of_year() Please input year, month and day: 2002 10 14 2002-10-14: the 287 day in 2002 Test month_day() Please input year and yearday: 2002 287 the 287 day in 2002: 2002-10-14 exercise5-9 用指针方式代替数组下标方式改写函数 day_of_year 和 month_day。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 int day_of_year_ptr(int year, int month, int day) { int i, leap; if (month \u0026lt; 1 || month \u0026gt; 12 || day \u0026lt; 1) return -1; leap = year % 4 == 0 \u0026amp;\u0026amp; year % 100 != 0 || year % 400 == 0; char *p = \u0026amp;daytab[leap][1]; if (day \u0026gt; *(p + month - 1)) return -1; for (i = 1; i \u0026lt; month; i++) { day += *p; ++p; } return day; } /* month_day: set month, day from day of year */ int month_day_ptr(int year, int yearday, int *pmonth, int *pday) { int i, leap; if (yearday \u0026lt; 1) return -1; leap = year % 4 == 0 \u0026amp;\u0026amp; year % 100 != 0 || year % 400 == 0; if ((leap \u0026amp;\u0026amp; yearday \u0026gt; 366) || (!leap \u0026amp;\u0026amp; yearday \u0026gt; 365)) return -1; char *p = \u0026amp;daytab[leap][1]; for (i = 1; yearday \u0026gt; *p; i++) { yearday -= *p; ++p; } *pmonth = i; *pday = yearday; return 0; } 运行：\n1 2 3 4 5 6 7 Test day_of_year_ptr() Please input year, month and day: 2002 10 14 2002-10-14: the 287 day in 2002 Test month_day_ptr() Please input year and yearday: 2002 287 the 287 day in 2002: 2002-10-14 exercise5-10 编写程序 expr，以计算从命令行输入的逆波兰表达式的值，其中每个运算符或操作数用一个单独的参数表示。例如，命令 expr 2 3 4 + * 将计算表达式 2 × (3 + 4)的值。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;ctype.h\u0026gt; #include \u0026lt;string.h\u0026gt; #define NUMBER \u0026#39;0\u0026#39; #define MAXVAL 100 /* maximum depth of val stack */ int sp = 0; /* next free stack position */ double val[MAXVAL]; /* value stack */ int isnumber(char *s) { if (strlen(s) == 1 \u0026amp;\u0026amp; (s[0] == \u0026#39;/\u0026#39; || s[0] == \u0026#39;*\u0026#39; || s[0] == \u0026#39;+\u0026#39; || s[0] == \u0026#39;-\u0026#39;)) return s[0]; int i = 0; if (s[i] == \u0026#39;-\u0026#39; || s[i] == \u0026#39;+\u0026#39;) i++; for (; isdigit(s[i]); i++) ; if (s[i] == \u0026#39;.\u0026#39;) i++; for (; isdigit(s[i]); i++) ; return s[i] == \u0026#39;\\0\u0026#39; ? NUMBER : -1; } /* push: push f onto value stack */ void push(double f) { if (sp \u0026lt; MAXVAL) val[sp++] = f; else printf(\u0026#34;error: stack full, can\u0026#39;t push %g\\n\u0026#34;, f); } /* pop: pop and return top value from stack */ double pop(void) { if (sp \u0026gt; 0) return val[--sp]; else { printf(\u0026#34;error: stack empty\\n\u0026#34;); return 0.0; } } int main(int argc, char **argv) { int i; double value; for (i = 1; i \u0026lt; argc; ++i) { switch (isnumber(argv[i])) { case NUMBER: push(atof(argv[i])); break; case \u0026#39;+\u0026#39;: push(pop() + pop()); break; case \u0026#39;-\u0026#39;: value = pop(); push(pop() - value); break; case \u0026#39;*\u0026#39;: push(pop() * pop()); break; case \u0026#39;/\u0026#39;: value = pop(); push(pop() / value); break; default: printf(\u0026#34;wrong argument: %s\\n\u0026#34;, argv[i]); break; } } printf(\u0026#34;%g\\n\u0026#34;, pop()); return 0; } 运行（命令行中，\u0026rsquo;*\u0026lsquo;需要反斜杠来转义）：\n1 2 ➜ ch05 git:(main) ✗ ./Exercise5-10 2 3 4 + \\* 14 exercise5-13 编写程序 tail，将其输入中的最后 n 行打印出来。默认情况下，n 的值为10，但可通过一个可选参数改变 n 的值，因此，命令tail -n将打印其输入的最后 n 行。无论输入或 n 的值是否合理，该程序都应该能正常运行。编写的程序要充分地利用存储空间；输入行的存储方式应该同 5.6 节中排序程序的存储方式一样，而不采用固定长度的二维数组。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;string.h\u0026gt; #include \u0026lt;malloc.h\u0026gt; #define MAXLINES 5000 /* max #lines to be sorted */ #define MAXLEN 1000 /* max length of any input line */ char *lineptr[MAXLINES]; /* pointers to text lines */ char linesarray[MAXLINES][MAXLEN]; /*array that store lines*/ int Getline(char line[]) { int c, i; for (i = 0; i \u0026lt; MAXLEN - 1 \u0026amp;\u0026amp; (c = getchar()) != EOF \u0026amp;\u0026amp; c != \u0026#39;\\n\u0026#39;; i++) line[i] = c; if (c == \u0026#39;\\n\u0026#39;) { line[i] = c; i++; } line[i] = \u0026#39;\\0\u0026#39;; return i; } /* readlines: read input lines */ int readlines(char *lineptr[], int maxlines) { int len, nlines; char *p, line[MAXLEN]; nlines = 0; while ((len = Getline(line)) \u0026gt; 0) if (nlines \u0026gt;= maxlines || (p = malloc(len)) == NULL) return -1; else { line[len - 1] = \u0026#39;\\0\u0026#39;; /* delete newline */ strcpy(p, line); lineptr[nlines++] = p; } return nlines; } /* writelines: write output lines */ void writelines(char *lineptr[], int nlines, int n) { int i; for (i = nlines - n \u0026gt; 0 ? nlines - n : 0; i \u0026lt; nlines; i++) printf(\u0026#34;%s\\n\u0026#34;, lineptr[i]); } int main(int argc, char *argv[]) { printf(\u0026#34;Please input lines:\\n\u0026#34;); int nlines = readlines(lineptr, MAXLINES); if (argc \u0026gt; 1 \u0026amp;\u0026amp; argv[1][0] == \u0026#39;-\u0026#39;) { int n = atoi(argv[1] + 1); printf(\u0026#34;The last %d lines are:\\n\u0026#34;, n); writelines(lineptr, nlines, n); } else { printf(\u0026#34;The last 10 lines are:\\n\u0026#34;); writelines(lineptr, nlines, 10); } return 0; } 运行：\n1 2 3 4 5 6 7 8 ➜ ch05 git:(main) ✗ ./Exercise5-13 -2 Please input lines: sdui qi a The last 2 lines are: qi a exercise5-14 修改排序程序，使它能处理-r 标记。该标记表明，以逆序（递减）方式排序。要保证-r 和-n 能够组合在一起使用。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 int reverse; int mstrcmp(char *s1, char *s2) { char *news1 = reverse ? s2 : s1; char *news2 = reverse ? s1 : s2; return strcmp(news1, news2); } /* numcmp: compare s1 and s2 numerically */ int mnumcmp(char *s1, char *s2) { char *news1 = reverse ? s2 : s1; char *news2 = reverse ? s1 : s2; double v1, v2; v1 = atof(news1); v2 = atof(news2); if (v1 \u0026lt; v2) return -1; else if (v1 \u0026gt; v2) return 1; else return 0; } /* qsort: sort v[left]...v[right] into increasing order */ void mqsort(void *v[], int left, int right, int (*comp)(void *, void *)) { int i, last; if (left \u0026gt;= right) /* do nothing if array contains */ return; /* fewer than two elements */ swap(v, left, (left + right) / 2); last = left; for (i = left + 1; i \u0026lt;= right; i++) if ((*comp)(v[i], v[left]) \u0026lt; 0) swap(v, ++last, i); swap(v, left, last); mqsort(v, left, last - 1, comp); mqsort(v, last + 1, right, comp); } int main(int argc, char *argv[]) { int nlines; /* number of input lines read */ int numeric = 0; /* 1 if numeric sort */ reverse = 0; /* 1 if reverse sort */ if (argc \u0026gt; 1 \u0026amp;\u0026amp; strcmp(argv[1], \u0026#34;-n\u0026#34;) == 0) numeric = 1; if (argc \u0026gt; 2 \u0026amp;\u0026amp; strcmp(argv[2], \u0026#34;-r\u0026#34;) == 0) reverse = 1; printf(\u0026#34;Please input data:\\n\u0026#34;); if ((nlines = readlines(lineptr, MAXLINES)) \u0026gt;= 0) { mqsort((void **)lineptr, 0, nlines - 1, (int (*)(void *, void *))(numeric ? mnumcmp : mstrcmp)); printf(\u0026#34;After sorted:\\n\u0026#34;); writelines(lineptr, nlines); return 0; } else { printf(\u0026#34;input too big to sort\\n\u0026#34;); return 1; } } 运行：\n1 2 3 4 5 6 7 8 9 ➜ ch05 git:(main) ✗ ./Exercise5-14 -n -r Please input data: 76 44 98 After sorted: 98 76 44 exercise5-15 增加选项-f，使得排序过程不考虑字母大小写之间的区别。例如，比较 a 和 A 时认为它们相等。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 int mstrcmp(char *s1, char *s2) { char *news1 = reverse ? s2 : s1; char *news2 = reverse ? s1 : s2; return fold == 1 ? strcasecmp(news1, news2) : strcmp(news1, news2); } int main(int argc, char *argv[]) { int nlines; /* number of input lines read */ int numeric = 0; /* 1 if numeric sort */ reverse = 0; /* 1 if reverse sort */ for (int i = 1; i \u0026lt; argc; i++) switch (argv[i][1]) { case \u0026#39;n\u0026#39;: numeric = 1; break; case \u0026#39;r\u0026#39;: reverse = 1; break; case \u0026#39;f\u0026#39;: fold = 1; break; } printf(\u0026#34;Please input data:\\n\u0026#34;); if ((nlines = readlines(lineptr, MAXLINES)) \u0026gt;= 0) { mqsort((void **)lineptr, 0, nlines - 1, (int (*)(void *, void *))(numeric ? mnumcmp : mstrcmp)); printf(\u0026#34;After sorted:\\n\u0026#34;); writelines(lineptr, nlines); return 0; } else { printf(\u0026#34;input too big to sort\\n\u0026#34;); return 1; } } 1 2 3 4 5 6 7 ➜ ch05 git:(main) ✗ ./Exercise5-14 -f Please input data: aB Ab After sorted: aB Ab exercise5-16 增加选项-d（代表目录顺序）。该选项表明，只对字母、数字和空格进行比较。要保证该选项可以和-f 组合在一起使用。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 int charcmp(char c1, char c2) { if (dir) { if (!isalnum(c1) \u0026amp;\u0026amp; c1 != \u0026#39; \u0026#39;) return 0; if (!isalnum(c2) \u0026amp;\u0026amp; c2 != \u0026#39; \u0026#39;) return 0; } if (fold) { c1 = tolower(c1); c2 = tolower(c2); } return c1 - c2; } int mstrcmp(char *s1, char *s2) { char *news1 = reverse ? s2 : s1; char *news2 = reverse ? s1 : s2; while (*news1 \u0026amp;\u0026amp; *news2) { int cmp = charcmp(*news1, *news2); if (cmp != 0) return cmp; news1++; news2++; } return *news1 ? 1 : (*news2 ? -1 : 0); } /* numcmp: compare s1 and s2 numerically */ int mnumcmp(char *s1, char *s2) { char *news1 = reverse ? s2 : s1; char *news2 = reverse ? s1 : s2; double v1, v2; v1 = atof(news1); v2 = atof(news2); if (v1 \u0026lt; v2) return -1; else if (v1 \u0026gt; v2) return 1; else return 0; } /* qsort: sort v[left]...v[right] into increasing order */ void mqsort(void *v[], int left, int right, int (*comp)(void *, void *)) { int i, last; if (left \u0026gt;= right) /* do nothing if array contains */ return; /* fewer than two elements */ swap(v, left, (left + right) / 2); last = left; for (i = left + 1; i \u0026lt;= right; i++) if ((*comp)(v[i], v[left]) \u0026lt; 0) swap(v, ++last, i); swap(v, left, last); mqsort(v, left, last - 1, comp); mqsort(v, last + 1, right, comp); } int main(int argc, char *argv[]) { int nlines; /* number of input lines read */ int numeric = 0; /* 1 if numeric sort */ reverse = 0; /* 1 if reverse sort */ for (int i = 1; i \u0026lt; argc; i++) switch (argv[i][1]) { case \u0026#39;n\u0026#39;: numeric = 1; break; case \u0026#39;r\u0026#39;: reverse = 1; break; case \u0026#39;f\u0026#39;: fold = 1; break; case \u0026#39;d\u0026#39;: dir = 1; break; } printf(\u0026#34;Please input data:\\n\u0026#34;); if ((nlines = readlines(lineptr, MAXLINES)) \u0026gt;= 0) { mqsort((void **)lineptr, 0, nlines - 1, (int (*)(void *, void *))(numeric ? mnumcmp : mstrcmp)); printf(\u0026#34;After sorted:\\n\u0026#34;); writelines(lineptr, nlines); return 0; } else { printf(\u0026#34;input too big to sort\\n\u0026#34;); return 1; } } 运行：\n1 2 3 4 5 6 7 8 9 10 11 12 13 ➜ ch05 git:(main) ✗ ./Exercise5-16 -d -f Please input data: A+b a-B After sorted: A+b a-B Please input data: a-B A+b After sorted: a-B A+b exercise5-18 修改 dcl 程序，使它能够处理输入中的错误。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;string.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;ctype.h\u0026gt; #define MAXTOKEN 100 #define BUFSIZE 100 enum { NAME, PARENS, BRACKETS }; int tokentype; /* type of last token */ char token[MAXTOKEN]; /* last token string */ char name[MAXTOKEN]; /* identifier name */ char datatype[MAXTOKEN]; /* data type = char, int, etc. */ char out[1000]; void dcl(void); void dirdcl(void); /* clear remaining characters in input line to recover from errors */ void clear_input() { int c; while ((c = getch()) != \u0026#39;\\n\u0026#39; \u0026amp;\u0026amp; c != EOF) ; } /* handle and print error messages */ void errmsg(const char *msg) { printf(\u0026#34;Error: %s\\n\u0026#34;, msg); clear_input(); // Skip to the end of the current line after an error } /* gettoken: return next token */ int gettoken(void) { int c; char *p = token; while ((c = getch()) == \u0026#39; \u0026#39; || c == \u0026#39;\\t\u0026#39;) // Skip whitespace ; if (c == \u0026#39;(\u0026#39;) { if ((c = getch()) == \u0026#39;)\u0026#39;) { strcpy(token, \u0026#34;()\u0026#34;); return tokentype = PARENS; } else { ungetch(c); return tokentype = \u0026#39;(\u0026#39;; } } else if (c == \u0026#39;[\u0026#39;) { for (*p++ = c; (*p++ = getch()) != \u0026#39;]\u0026#39;;) { if (p - token \u0026gt;= MAXTOKEN - 1) // Prevent buffer overflow { errmsg(\u0026#34;brackets too long or unclosed\u0026#34;); return tokentype = -1; } } *p = \u0026#39;\\0\u0026#39;; return tokentype = BRACKETS; } else if (isalpha(c)) { for (*p++ = c; isalnum(c = getch());) { if (p - token \u0026gt;= MAXTOKEN - 1) // Prevent buffer overflow { errmsg(\u0026#34;name too long\u0026#34;); return tokentype = -1; } *p++ = c; } *p = \u0026#39;\\0\u0026#39;; ungetch(c); return tokentype = NAME; } else { return tokentype = c; } } /* dcl: parse a declarator */ void dcl(void) { int ns; for (ns = 0; gettoken() == \u0026#39;*\u0026#39;;) /* count *\u0026#39;s */ ns++; dirdcl(); while (ns-- \u0026gt; 0) strcat(out, \u0026#34; pointer to\u0026#34;); } /* dirdcl: parse a direct declarator */ void dirdcl(void) { int type; if (tokentype == \u0026#39;(\u0026#39;) { dcl(); if (tokentype != \u0026#39;)\u0026#39;) { errmsg(\u0026#34;missing )\u0026#34;); return; } } else if (tokentype == NAME) { strcpy(name, token); } else { errmsg(\u0026#34;expected name or (dcl)\u0026#34;); return; } while ((type = gettoken()) == PARENS || type == BRACKETS) { if (type == PARENS) { strcat(out, \u0026#34; function returning\u0026#34;); } else { strcat(out, \u0026#34; array\u0026#34;); strcat(out, token); strcat(out, \u0026#34; of\u0026#34;); } } } int main() /* convert declaration to words */ { while (gettoken() != EOF) { /* 1st token on line */ strcpy(datatype, token); /* is the datatype */ out[0] = \u0026#39;\\0\u0026#39;; dcl(); /* parse rest of line */ if (tokentype != \u0026#39;\\n\u0026#39;) printf(\u0026#34;syntax error\\n\u0026#34;); printf(\u0026#34;%s: %s %s\\n\u0026#34;, name, out, datatype); } } 运行：\n1 2 3 4 char *func() func: function returning pointer to char char (*func())() func: function returning pointer to function returning char exercise5-19 修改 undcl 程序，使它在把文字描述转换为声明的过程中不会生成多余的圆括号。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 /* undcl: convert word description to declaration */ int undcl(void) { int type; char temp[MAXTOKEN]; int parentheses_needed = 0; // track when parentheses are necessary while (gettoken() != EOF) { strcpy(out, token); // Initialize out with the first token while ((type = gettoken()) != \u0026#39;\\n\u0026#39;) { if (type == PARENS || type == BRACKETS) { strcat(out, token); // Append function or array notation } else if (type == \u0026#39;*\u0026#39;) { // Only add parentheses if needed for precedence (i.e., if out is a function or array) if (parentheses_needed) { sprintf(temp, \u0026#34;(*%s)\u0026#34;, out); parentheses_needed = 0; // reset parentheses flag } else { sprintf(temp, \u0026#34;*%s\u0026#34;, out); // regular pointer, no parentheses needed } strcpy(out, temp); } else if (type == NAME) { sprintf(temp, \u0026#34;%s %s\u0026#34;, token, out); // Add name to out strcpy(out, temp); } else { printf(\u0026#34;invalid input at %s\\n\u0026#34;, token); } } printf(\u0026#34;%s\\n\u0026#34;, out); } return 0; } 运行：\n1 2 x () * [] * () char char (*(*x())[])() exercise5-20 扩展 dcl 程序的功能，使它能够处理包含其它成分的声明，例如带有函数参数类型的声明、带有类似于 const 限定符的声明等。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;string.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;ctype.h\u0026gt; #define MAXTOKEN 100 #define BUFSIZE 100 enum { NAME, PARENS, BRACKETS, QUALIFIER, TYPE }; int tokentype; /* type of last token */ char token[MAXTOKEN]; /* last token string */ char name[MAXTOKEN]; /* identifier name */ char datatype[MAXTOKEN]; /* data type = char, int, etc. */ char out[1000]; char buf[BUFSIZE]; /* buffer for ungetch */ int bufp = 0; /* next free position in buf */ void dcl(void); void dirdcl(void); /* get a (possibly pushed-back) character */ int getch(void) { return (bufp \u0026gt; 0) ? buf[--bufp] : getchar(); } /* push character back on input */ void ungetch(int c) { if (bufp \u0026gt;= BUFSIZE) printf(\u0026#34;ungetch: too many characters\\n\u0026#34;); else buf[bufp++] = c; } /* clear remaining characters in input line to recover from errors */ void clear_input() { int c; while ((c = getch()) != \u0026#39;\\n\u0026#39; \u0026amp;\u0026amp; c != EOF) ; } /* handle and print error messages */ void errmsg(const char *msg) { printf(\u0026#34;Error: %s\\n\u0026#34;, msg); clear_input(); // Skip to the end of the current line after an error } /* gettoken: return next token */ int gettoken(void) { int c; char *p = token; while ((c = getch()) == \u0026#39; \u0026#39; || c == \u0026#39;\\t\u0026#39;) // Skip whitespace ; if (c == \u0026#39;(\u0026#39;) { if ((c = getch()) == \u0026#39;)\u0026#39;) { strcpy(token, \u0026#34;()\u0026#34;); return tokentype = PARENS; } else { ungetch(c); return tokentype = \u0026#39;(\u0026#39;; } } else if (c == \u0026#39;[\u0026#39;) { for (*p++ = c; (*p++ = getch()) != \u0026#39;]\u0026#39;;) { if (p - token \u0026gt;= MAXTOKEN - 1) // Prevent buffer overflow { errmsg(\u0026#34;brackets too long or unclosed\u0026#34;); return tokentype = -1; } } *p = \u0026#39;\\0\u0026#39;; return tokentype = BRACKETS; } else if (isalpha(c)) { for (*p++ = c; isalnum(c = getch());) { if (p - token \u0026gt;= MAXTOKEN - 1) // Prevent buffer overflow { errmsg(\u0026#34;name too long\u0026#34;); return tokentype = -1; } *p++ = c; } *p = \u0026#39;\\0\u0026#39;; ungetch(c); // Handle qualifiers and types like const, volatile if (strcmp(token, \u0026#34;const\u0026#34;) == 0 || strcmp(token, \u0026#34;volatile\u0026#34;) == 0) { return tokentype = QUALIFIER; } return tokentype = NAME; } else { return tokentype = c; } } /* dcl: parse a declarator */ void dcl(void) { int ns; for (ns = 0; gettoken() == \u0026#39;*\u0026#39;;) /* count *\u0026#39;s */ ns++; dirdcl(); while (ns-- \u0026gt; 0) strcat(out, \u0026#34; pointer to\u0026#34;); } /* dirdcl: parse a direct declarator */ void dirdcl(void) { int type; if (tokentype == \u0026#39;(\u0026#39;) { dcl(); if (tokentype != \u0026#39;)\u0026#39;) { errmsg(\u0026#34;missing )\u0026#34;); return; } } else if (tokentype == NAME) { strcpy(name, token); } else { errmsg(\u0026#34;expected name or (dcl)\u0026#34;); return; } while ((type = gettoken()) == PARENS || type == BRACKETS || type == QUALIFIER) { if (type == PARENS) { strcat(out, \u0026#34; function returning\u0026#34;); } else if (type == BRACKETS) { strcat(out, \u0026#34; array\u0026#34;); strcat(out, token); strcat(out, \u0026#34; of\u0026#34;); } else if (type == QUALIFIER) { strcat(out, \u0026#34; \u0026#34;); strcat(out, token); } } } /* parse a function parameter list */ void parse_param_list(void) { while (gettoken() != \u0026#39;)\u0026#39;) { if (tokentype == NAME) { strcat(out, \u0026#34; parameter \u0026#34;); strcat(out, token); } else if (tokentype == \u0026#39;,\u0026#39;) { strcat(out, \u0026#34;, \u0026#34;); } else if (tokentype == QUALIFIER || tokentype == TYPE) { strcat(out, \u0026#34; \u0026#34;); strcat(out, token); } else if (tokentype == \u0026#39;(\u0026#39;) { parse_param_list(); // Recursively handle nested parentheses } else { errmsg(\u0026#34;unexpected token in parameter list\u0026#34;); break; } } } int main() /* convert declaration to words */ { while (gettoken() != EOF) { /* 1st token on line */ strcpy(datatype, token); /* is the datatype */ out[0] = \u0026#39;\\0\u0026#39;; dcl(); /* parse rest of line */ if (tokentype != \u0026#39;\\n\u0026#39;) printf(\u0026#34;syntax error\\n\u0026#34;); printf(\u0026#34;%s: %s %s\\n\u0026#34;, name, out, datatype); } } ","permalink":"https://fireflyyh.top/posts/tcpl/ch05/","summary":"部分答案参考了官方题解和网上的答案，仅供参考，可能也有部分bug未发现或解决。\nexercise5-1 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 int getint(int *pn) { int c, sign; while (isspace(c = getch())) /* skip white space */ ; if (!isdigit(c) \u0026amp;\u0026amp; c != EOF \u0026amp;\u0026amp; c != \u0026#39;+\u0026#39; \u0026amp;\u0026amp; c != \u0026#39;-\u0026#39;) { ungetch(c); /* it is not a number */ return 0; } sign = (c == \u0026#39;-\u0026#39;) ?","title":"C语言程序设计第二版课后习题--第五章"},{"content":" 部分答案参考了官方题解和网上的答案，仅供参考，可能也有部分bug未发现或解决。代码在gitee上面。\nexercise4-1 编写函数 strindex(s, t)，它返回字符串 t 在 s 中最右边出现的位置。如果 s 中不包含 t，则返回-1。\n代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 void getLine(char s[]) { int c, i = 0; while ((c = getchar()) != EOF \u0026amp;\u0026amp; c != \u0026#39;\\n\u0026#39;) s[i++] = c; } int strindex(char s[], char t[]) { int i, j, k; int lens = strlen(s), lent = strlen(t); for (i = lens - 1; i \u0026gt;= 0; i--) { for (j = lent - 1, k = i; j \u0026gt;= 0 \u0026amp;\u0026amp; k \u0026gt;= 0 \u0026amp;\u0026amp; s[k] == t[j]; j--, k--); if (j \u0026lt; 0) return k + 1; } return -1; } int main() { char s[MAXLEN] = {0}; char t[MAXLEN] = {0}; printf(\u0026#34;Please input the string s: \\n\u0026#34;); getLine(s); printf(\u0026#34;Please input the string t: \\n\u0026#34;); getLine(t); printf(\u0026#34;The rightmost position of \u0026#39;%s\u0026#39; in \u0026#39;%s\u0026#39; is: %d\\n\u0026#34;, t, s, strindex(s, t)); return 0; } 运行：\n1 2 3 4 5 Please input the string s: this is an idea, a good idea Please input the string t: idea The rightmost position of \u0026#39;idea\u0026#39; in \u0026#39;this is an idea, a good idea\u0026#39; is: 24 exercise4-2 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;ctype.h\u0026gt; #define MAXLEN 1024 double atof(const char s[]) { double val, power; int i, sign, expSign, exp; for (i = 0; isspace(s[i]); i++) // skip white space ; sign = (s[i] == \u0026#39;-\u0026#39;) ? -1 : 1; if (s[i] == \u0026#39;+\u0026#39; || s[i] == \u0026#39;-\u0026#39;) i++; for (val = 0.0; isdigit(s[i]); i++) val = 10.0 * val + (s[i] - \u0026#39;0\u0026#39;); if (s[i] == \u0026#39;.\u0026#39;) i++; for (power = 1.0; isdigit(s[i]); i++) { val = 10.0 * val + (s[i] - \u0026#39;0\u0026#39;); power *= 10.0; } val = sign * val / power; if (s[i] == \u0026#39;e\u0026#39; || s[i] == \u0026#39;E\u0026#39;) { i++; if (s[i] == \u0026#39;+\u0026#39; || s[i] == \u0026#39;-\u0026#39;) { expSign = (s[i] == \u0026#39;-\u0026#39;) ? -1 : 1; i++; } // 指数 for (exp = 0; isdigit(s[i]); i++) exp = 10 * exp + (s[i] - \u0026#39;0\u0026#39;); if (expSign == 1) while (exp-- \u0026gt; 0) val *= 10; else while (exp-- \u0026gt; 0) val /= 10; } return val; } int main() { char s[MAXLEN] = {0}; printf(\u0026#34;Please input the string s: \\n\u0026#34;); scanf(\u0026#34;%s\u0026#34;, s); printf(\u0026#34;%g\\n\u0026#34;, atof(s)); return 0; } 运行：\n1 2 3 Please input the string s: 123e-10 1.23e-08 exercise4-3 在有了基本框架后，对计算器程序进行扩充就比较简单了。在该程序中加入取模（%）运算符，并注意考虑负数的情况。\n若要能够处理负数的情况，则需要在getop()的处理负号时进行进一步判断：需要判断下一个字符是空格还是数字，修改后的getop()如下:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 /* getop: get next character or numeric operand */ int getop(char s[]) { int i, c, next; while ((s[0] = c = getch()) == \u0026#39; \u0026#39; || c == \u0026#39;\\t\u0026#39;) ; s[1] = \u0026#39;\\0\u0026#39;; if (!isdigit(c) \u0026amp;\u0026amp; c != \u0026#39;.\u0026#39; \u0026amp;\u0026amp; c != \u0026#39;-\u0026#39;) return c; /* not a number */ i = 0; if (c == \u0026#39;-\u0026#39;) { next = getch(); if (!isdigit(next) \u0026amp;\u0026amp; next != \u0026#39;.\u0026#39;) { ungetch(next); return c; /* not a number, return \u0026#39;-\u0026#39; */ } c = next; s[++i] = c; } if (isdigit(c)) /* collect integer part */ while (isdigit(s[++i] = c = getch())) ; if (c == \u0026#39;.\u0026#39;) /* collect fraction part */ while (isdigit(s[++i] = c = getch())) ; s[i] = \u0026#39;\\0\u0026#39;; if (c != EOF) ungetch(c); return NUMBER; } 加入取模运算符，则比较简单，与处理 - 与 / 类似：\n1 2 3 4 5 /* +和*无需注意操作数的顺序，即a+b=b+a，但是-/%需要注意 */ case \u0026#39;%\u0026#39;: op2 = pop(); push((int)pop() % (int)op2); break; 运行：\n1 2 3 4 5 Please input expression: 3 2 % 1 3 0 % 3 exercise4-4 在栈操作中添加几个命令，分别用于在不弹出元素的情况下打印栈顶元素；复制栈顶元素；交换栈顶两个元素的值。另外增加一个命令用于清空栈。\n代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 /* print and return top value from stack without popping */ double top(void) { if (sp \u0026gt; 0) { printf(\u0026#34;Top of stack: %g\\n\u0026#34;, val[sp-1]); return val[sp-1]; } else { printf(\u0026#34;error: stack empty\\n\u0026#34;); return 0.0; } } /* duplicate top value to stack */ void duptop(void) { if (sp \u0026gt; 0) push(val[sp-1]); else printf(\u0026#34;error: stack empty\\n\u0026#34;); } /* swap top two values */ void swaptop(void) { if (sp \u0026gt; 1) { double temp = val[sp-1]; val[sp-1] = val[sp-2]; val[sp-2] = temp; } else printf(\u0026#34;error: not enough elements to swap\\n\u0026#34;); } exercise4-5 给计算器程序增加访问 sin、exp 与 pow 等库函数的操作。有关这些库函数的详细信息，参见附录 B.4 节中的头文件\u0026lt;math.h\u0026gt;。\n引入\u0026lt;math.h\u0026gt;头文件，然后为了编译通过，参考了Undefined reference to pow( ) in C, despite including math.h [duplicate]的解决办法。在main函数中添加了对这三种运算的支持：\n代码：\n1 2 3 4 5 6 7 8 9 10 case \u0026#39;s\u0026#39;: // sin push(sin(pop())); break; case \u0026#39;e\u0026#39;: // exp push(exp(pop())); break; case \u0026#39;p\u0026#39;: // pow op2 = pop(); push(pow(pop(), op2)); break; 运行：\n1 2 3 4 5 6 7 Please input expression: 3 e ans is: 20.085537 2 5 p ans is: 32 3.1415926 s ans is: 5.3589793e-08 exercise4-6 给计算器程序增加处理变量的命令（提供 26 个具有单个英文字母变量名的变量很容易）。增加一个变量存放最近打印的值。\n为了增加处理变量，需要在代码中设置一个变量var来存储上一次计算出来的结果，并使用一个flag来验证该变量是否有效，因为第一次计算时，var是不存在的。增加main函数中的处理\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 #define VAR \u0026#39;v\u0026#39; int getop(char s[]) { ... if (c == \u0026#39;v\u0026#39;) { return VAR; } ... } /* reverse Polish calculator */ int main() { ... switch (type) { // 变量 case VAR: if (flag == 1) push(var); else printf(\u0026#34;error: no variable\\n\u0026#34;); break; // 数值 case NUMBER: push(atof(s)); break; // 操作符 ... // 结束输入 case \u0026#39;\\n\u0026#39;: printf(\u0026#34;ans is:\\t%.8g\\n\u0026#34;, (var = pop())); flag = 1; break; ... } } 运行：\n1 2 3 4 5 6 7 Please input expression: 1 2 + ans is: 3 3 v * ans is: 9 v 3 p ans is: 729 exercise4-7 编写一个函数 ungets(s)，将整个字符串 s 压回到输入中。ungets 函数需要使用 buf 和 bufp 吗？它能否仅使用 ungetch 函数？\n不需要直接使用buf和bufp，可以直接调用ungetch函数：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 /* push entire string s back on input */ void ungets(char s[]) { int len = strlen(s); while (len \u0026gt; 0) ungetch(s[--len]); } int main() { char s[] = \u0026#34;goood!\u0026#34;; int c; ungets(s); while ((c = getch()) != EOF) putchar(c); return 0; } 运行：\n1 goood! exercise4-8 假定最多只压回一个字符。请相应地修改 getch 与 ungetch 这两个函数。\n代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 int getch(void) { int temp = buf; buf = EOF; if (temp == EOF) temp = getchar(); return temp; } /* push character back on input */ void ungetch(int c) { if (buf != EOF) printf(\u0026#34;ungetch: too many characters\\n\u0026#34;); else buf = c; } exercise4-9 以上介绍的 getch 与 ungetch 函数不能正确地处理压回的 EOF。考虑压回EOF 时应该如何处理？请实现你的设计方案。\nexercise4-8的程序可以正确处理压回的EOF\nexercise4-10 另一种方法是通过 getline 函数读入整个输入行，这种情况下可以不使用 getch 与 ungetch 函数。请运用这一方法修改计算器程序。\n代码（因完整代码过长，故只显示相对于exercise4-6的代码的增加及更改部分）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 char line[MAXLINE]; /* input line */ /* getop: get next character or numeric operand */ int getop(char s[]) { int i, c; while ((s[0] = c = line[idx++]) == \u0026#39; \u0026#39; || c == \u0026#39;\\t\u0026#39;) ; } int Getline() { int c, i; for (i = 0; i \u0026lt; MAXLINE - 1 \u0026amp;\u0026amp; (c = getchar()) != EOF \u0026amp;\u0026amp; c != \u0026#39;\\n\u0026#39;; i++) { line[i] = c; } if (c == \u0026#39;\\n\u0026#39;) line[i++] = c; line[i] = \u0026#39;\\0\u0026#39;; return i; } /* reverse Polish calculator */ int main() { int type; double op2; char s[MAXOP]; while (1) { printf(\u0026#34;Please input expression:\\n\u0026#34;); if (Getline() == 0) break; idx = 0; while ((type = getop(s)) != \u0026#39;\\0\u0026#39;) { ... } } return 0; } 运行：\n1 2 3 4 5 6 7 Please input expression: 1 2 + ans is: 3 Please input expression: 1 v / ans is: 0.33333333 Please input expression: exercise4-11 修改 getop 函数，使其不必使用 ungetch 函数。提示：可以使用一个 static 类型的内部变量解决该问题。\n修改 getop.c，使用一个 static 类型的内部变量来存储多读的字符。如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;ctype.h\u0026gt; #include \u0026#34;calc.h\u0026#34; /* getop: get next character or numeric operand */ int getop(char s[]) { /* record the character read last time */ static int lastc = \u0026#39; \u0026#39;; int i, c; while ((s[0] = c = lastc) == \u0026#39; \u0026#39; || c == \u0026#39;\\t\u0026#39;) lastc = getchar(); s[1] = \u0026#39;\\0\u0026#39;; if (!isdigit(c) \u0026amp;\u0026amp; c != \u0026#39;.\u0026#39; \u0026amp;\u0026amp; c != \u0026#39;-\u0026#39;) return c; /* not a number */ i = 0; if (c == \u0026#39;-\u0026#39;) { if (!isdigit(lastc = getchar()) \u0026amp;\u0026amp; lastc != \u0026#39;.\u0026#39;) return c; /* not a number, return \u0026#39;-\u0026#39; */ s[++i] = c = lastc; } if (isdigit(c)) /* collect integer part */ while (isdigit(s[++i] = c = getchar())) ; if (c == \u0026#39;.\u0026#39;) /* collect fraction part */ while (isdigit(s[++i] = c = getchar())) ; s[i] = \u0026#39;\\0\u0026#39;; lastc = c; return NUMBER; } exercise4-12 运用 printd 函数的设计思想编写一个递归版本的 itoa 函数，即通过递归调用把整数转换为字符串。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 void itoa(int n, char s[]) { static int i = 0; // 静态变量，用于记录字符串的当前位置 if (n \u0026lt; 0) { s[i++] = \u0026#39;-\u0026#39;; n = -n; } if (n / 10) itoa(n / 10, s); s[i++] = n % 10 + \u0026#39;0\u0026#39;; s[i] = \u0026#39;\\0\u0026#39;; // 字符串结束符 } int main() { int n; char str[MAXLEN]; printf(\u0026#34;Please input n: \u0026#34;); scanf(\u0026#34;%d\u0026#34;, \u0026amp;n); itoa(n, str); printf(\u0026#34;ans is: %s\\n\u0026#34;, str); } exercise4-13 编写一个递归版本的 reverse(s)函数，以将字符串 s 倒置。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 void reverse(char s[], int l, int r) { if (l \u0026gt;= r) return; char temp = s[l]; s[l] = s[r]; s[r] = temp; reverse(s, l + 1, r - 1); } int main() { char str[MAXLINE]; printf(\u0026#34;Please input str:\\n\u0026#34;); scanf(\u0026#34;%s\u0026#34;, str); reverse(str, 0, strlen(str) - 1); printf(\u0026#34;Reversed string: %s\\n\u0026#34;, str); return 0; } exercise4-14 定义宏 swap(t, x, y）以交换 t 类型的两个参数。（使用程序块结构会对你有所帮助。）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 #include \u0026lt;stddef.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; // 一个字节一个字节进行交换 #define swap(t, x, y) \\ do \\ { \\ unsigned char *a = (unsigned char *)(\u0026amp;(x)); \\ unsigned char *b = (unsigned char *)(\u0026amp;(y)); \\ size_t ByteCount = sizeof(t); \\ char temp; \\ while (ByteCount--) \\ { \\ temp = *a; \\ *a = *b; \\ *b = temp; \\ a++; \\ b++; \\ } \\ } while (0) int main() { int ix, iy; double dx, dy; char *cpx, *cpy; ix = 2; iy = 4; printf(\u0026#34;integers before swap: %d and %d\\n\u0026#34;, ix, iy); swap(int, ix, iy); printf(\u0026#34;integers after swap: %d and %d\\n\u0026#34;, ix, iy); dx = 225.1; dy = 417.2; printf(\u0026#34;doubles before swap: %g and %g\\n\u0026#34;, dx, dy); swap(double, dx, dy); printf(\u0026#34;doubles after swap: %g and %g\\n\u0026#34;, dx, dy); cpx = \u0026#34;gooood\u0026#34;; cpy = \u0026#34;idea\u0026#34;; printf(\u0026#34;char pointers before swap: %s and %s\\n\u0026#34;, cpx, cpy); swap(char *, cpx, cpy); printf(\u0026#34;char pointers after swap: %s and %s\\n\u0026#34;, cpx, cpy); return 0; } 1 2 3 4 5 6 integers before swap: 2 and 4 integers after swap: 4 and 2 doubles before swap: 225.1 and 417.2 doubles after swap: 417.2 and 225.1 char pointers before swap: gooood and idea char pointers after swap: idea and gooood ","permalink":"https://fireflyyh.top/posts/tcpl/ch04/","summary":"部分答案参考了官方题解和网上的答案，仅供参考，可能也有部分bug未发现或解决。代码在gitee上面。\nexercise4-1 编写函数 strindex(s, t)，它返回字符串 t 在 s 中最右边出现的位置。如果 s 中不包含 t，则返回-1。\n代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 void getLine(char s[]) { int c, i = 0; while ((c = getchar()) != EOF \u0026amp;\u0026amp; c != \u0026#39;\\n\u0026#39;) s[i++] = c; } int strindex(char s[], char t[]) { int i, j, k; int lens = strlen(s), lent = strlen(t); for (i = lens - 1; i \u0026gt;= 0; i--) { for (j = lent - 1, k = i; j \u0026gt;= 0 \u0026amp;\u0026amp; k \u0026gt;= 0 \u0026amp;\u0026amp; s[k] == t[j]; j--, k--); if (j \u0026lt; 0) return k + 1; } return -1; } int main() { char s[MAXLEN] = {0}; char t[MAXLEN] = {0}; printf(\u0026#34;Please input the string s: \\n\u0026#34;); getLine(s); printf(\u0026#34;Please input the string t: \\n\u0026#34;); getLine(t); printf(\u0026#34;The rightmost position of \u0026#39;%s\u0026#39; in \u0026#39;%s\u0026#39; is: %d\\n\u0026#34;, t, s, strindex(s, t)); return 0; } 运行：","title":"C语言程序设计第二版课后习题--第四章"},{"content":" 部分答案参考了网络上的答案和官方题解。代码在gitee上面。\nexercise3-1 在上面有关折半查找的例子中，while 循环语句内共执行了两次测试，其实只要一次就足够（代价是将更多的测试在循环外执行）。重写该函数，使得在循环内部只执行一次测试。比较两种版本函数的运行时间。\n代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;time.h\u0026gt; int binsearch(int x, int v[], int n) { int low, mid, high; low = 0; high = n - 1; while (low \u0026lt;= high) { mid = (low + high) / 2; if (x \u0026lt; v[mid]) high = mid - 1; else if (x \u0026gt; v[mid]) low = mid + 1; else return mid; } return -1; } int binsearch2(int x, int v[], int n) { int low, high, mid; low = 0; high = n - 1; mid = (low + high) / 2; while (low \u0026lt;= high \u0026amp;\u0026amp; v[mid] != x) { if (v[mid] \u0026gt; x) high = mid - 1; else low = mid + 1; mid = (low + high) / 2; } if (v[mid] == x) return mid; return -1; /* no match */ } int main() { int n = 200, testtime = 1000000; int data[n]; for (int i = 0; i \u0026lt; n; i++) data[i] = i; int x = n / 2; clock_t start, end; start = clock(); for (int i = 0; i \u0026lt; testtime; i++) binsearch(x, data, n); end = clock(); printf(\u0026#34;binsearch time: %lf seconds\\n\u0026#34;, (double)(end - start) / CLOCKS_PER_SEC); start = clock(); for (int i = 0; i \u0026lt; testtime; i++) binsearch2(x, data, n); end = clock(); printf(\u0026#34;binsearch2 time: %lf seconds\\n\u0026#34;, (double)(end - start) / CLOCKS_PER_SEC); } 运行：\n经过六次测试，在数组元素个数为200，运行次数为100万的条件下，两种方法其实并无多大差异，在六次测试中，优化后的方法消耗时间更少的次数为4次。\nbinsearch binsearch2 0.024170 0.024276 0.024337 0.019407 0.025760 0.020651 0.023006 0.017759 0.022969 0.016554 0.020334 0.025866 exercise3-2 编写一个函数 escape(s, t)，将字符串 t 复制到字符串 s 中，并在复制过程中将换行符、制表符等不可见字符分别转换为\\n、\\t 等相应的可见的转义字符序列。要求使用 swich 语句。再编写一个具有相反功能的函数，在复制过程中将转义字符序列转换为实际字符。\n代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;string.h\u0026gt; #define MAXLENGTH 1024 void getString(char t[]) { int i = 0, c; while ((c = getchar()) != EOF) t[i++] = c; } // 将换行符、制表符等不可见字符分别转换为\\n、\\t 等相应的可见的转义字符序列 void escape(char s[], char t[]) { int len = strlen(t); int i = 0, j = 0; while (i \u0026lt; len) { switch (t[i]) { case \u0026#39;\\n\u0026#39;: s[j++] = \u0026#39;\\\\\u0026#39;; s[j++] = \u0026#39;n\u0026#39;; i++; break; case \u0026#39;\\t\u0026#39;: s[j++] = \u0026#39;\\\\\u0026#39;; s[j++] = \u0026#39;t\u0026#39;; i++; break; case \u0026#39;\\v\u0026#39;: s[j++] = \u0026#39;\\\\\u0026#39;; s[j++] = \u0026#39;v\u0026#39;; i++; break; default: s[j++] = t[i++]; } } } // 将转义字符序列转换为实际字符 void enter(char s[], char t[]) { int len = strlen(t); int i = 0, j = 0; while (i \u0026lt; len) { if (t[i] == \u0026#39;\\\\\u0026#39;) { switch (t[i + 1]) { case \u0026#39;n\u0026#39;: s[j++] = \u0026#39;\\n\u0026#39;; i += 2; break; case \u0026#39;t\u0026#39;: s[j++] = \u0026#39;\\t\u0026#39;; i += 2; break; case \u0026#39;v\u0026#39;: s[j++] = \u0026#39;\\v\u0026#39;; i += 2; break; default: s[j++] = t[i++]; break; } } else { s[j++] = t[i++]; } } } int main() { char s[MAXLENGTH] = {0}, t[MAXLENGTH] = {0}, newt[MAXLENGTH] = {0}; printf(\u0026#34;Please input T(end with EOF):\\n\u0026#34;); getString(t); escape(s, t); printf(\u0026#34;S is:\\n%s\\n\u0026#34;, s); enter(newt, s); printf(\u0026#34;NewT is:\\n%s\\n\u0026#34;, newt); } 运行：\n1 2 3 4 5 6 7 8 Please input t(end with EOF): this is a go od idea S is: this\\tis a \\tgo\\nod idea\\n NewT is: this is a go od idea exercise3-3 编写函数 expand(s1, s2)，将字符串 s1 中类似于 a-z 一类的速记符号在字符串 s2 中扩展为等价的完整列表 abc…xyz。该函数可以处理大小写字母和数字，并可以处理 a-b-c、a-z0-9 与-a-z 等类似的情况。作为前导和尾随的-字符原样排印。\n代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 int check(char str[], int idx) { int len = strlen(str); if (idx == 0 || idx == len - 1) return 0; char prev = str[idx - 1]; char next = str[idx + 1]; if ((prev \u0026gt;= \u0026#39;0\u0026#39; \u0026amp;\u0026amp; prev \u0026lt;= \u0026#39;9\u0026#39; \u0026amp;\u0026amp; next \u0026gt;= \u0026#39;0\u0026#39; \u0026amp;\u0026amp; next \u0026lt;= \u0026#39;9\u0026#39; \u0026amp;\u0026amp; prev \u0026lt; next) || (prev \u0026gt;= \u0026#39;a\u0026#39; \u0026amp;\u0026amp; prev \u0026lt;= \u0026#39;z\u0026#39; \u0026amp;\u0026amp; next \u0026gt;= \u0026#39;a\u0026#39; \u0026amp;\u0026amp; next \u0026lt;= \u0026#39;z\u0026#39; \u0026amp;\u0026amp; prev \u0026lt; next) || (prev \u0026gt;= \u0026#39;A\u0026#39; \u0026amp;\u0026amp; prev \u0026lt;= \u0026#39;Z\u0026#39; \u0026amp;\u0026amp; next \u0026gt;= \u0026#39;A\u0026#39; \u0026amp;\u0026amp; next \u0026lt;= \u0026#39;Z\u0026#39; \u0026amp;\u0026amp; prev \u0026lt; next)) return 1; return 0; } void expand(char s1[], char s2[]) { int len = strlen(s1); int i = 0, j = 0; while (i \u0026lt; len) { if (s1[i] == \u0026#39;-\u0026#39; \u0026amp;\u0026amp; check(s1, i)) { int sublen = s1[i + 1] - s1[i - 1]; for (int k = 1; k \u0026lt; sublen; k++) s2[j++] = s1[i - 1] + k; i++; } else { s2[j++] = s1[i++]; } } printf(\u0026#34;%s\\n\u0026#34;, s2); } int main() { char s1[] = \u0026#34;a-c-e9\u0026#34;; char s2[MAXLINE] = {0}; expand(s1, s2); } 运行：\n1 2 3 Please input s1: a-d-f991-8 s2 is:abcdef991234567 exercise3-4 在数的对二的补码表示中，我们编写的 itoa 函数不能处理最大的负数，即 n 等于 $-2 ^{字长-1}$ 的情况。请解释其原因。修改该函数，使它在任何机器上运行时都能打印出正确的值。\n因为在原来的程序中，对于n为负数的处理：\n1 2 if ((sign = n) \u0026lt; 0) /* record sign */ n = -n; /* make n positive */ 如果 n 为 $-2 ^{字长-1}$ ，那么取n = -n的操作就无法顺利完成，因为 n 最大的正数为 $2 ^{字长-1} - 1$。因此可以修改程序：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 void itoa(int n, char s[]) { int i, sign; long temp = ((sign = n) \u0026lt; 0 ? -n : n); // 使用一个 long 型变量来存储 i = 0; do { /* generate digits in reverse order */ s[i++] = n % 10 + \u0026#39;0\u0026#39;; /* get next digit */ } while ((n /= 10) \u0026gt; 0); /* delete it */ if (sign \u0026lt; 0) s[i++] = \u0026#39;-\u0026#39;; s[i] = \u0026#39;\\0\u0026#39;; reverse(s); } 或不对 n 取反，直接在do while循环内部进行 abs()操作。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 /* itoa: convert n to characters in s */ void itoa(int n, char s[]) { int i, sign = n; i = 0; do { s[i++] = abs(n % 10) + \u0026#39;0\u0026#39;; } while (n /= 10); if (sign \u0026lt; 0) s[i++] = \u0026#39;-\u0026#39;; s[i] = \u0026#39;\\0\u0026#39;; reverse(s); } exercise3-5 编写函数 itob(n, s, b)，将整数 n 转换为以 b 为底的数，并将转换结果以字符的形式保存到字符串 s 中。例如，itob(n, s, 16)把整数 n 格式化成十六进制整数保存在 s 中。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 #define MAXLEN 65 char bases[] = \u0026#34;0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ\u0026#34;; void reverse(char s[]) { int len = strlen(s); int i = 0, j = len - 1; while (i \u0026lt; j) { char temp = s[i]; s[i] = s[j], s[j] = temp; i++, j--; } } void itob(int n, char s[], int b) { int i, sign; if ((sign = n) \u0026lt; 0) n = -n; i = 0; do { s[i++] = bases[n % b]; } while (n /= b); if (sign \u0026lt; 0) s[i++] = \u0026#39;-\u0026#39;; reverse(s); } int main() { int n, b; printf(\u0026#34;Please input n and b: \u0026#34;); scanf(\u0026#34;%d %d\u0026#34;, \u0026amp;n, \u0026amp;b); char s[MAXLEN] = {0}; if (b \u0026lt; 2 || b \u0026gt; 36) { printf(\u0026#34;wrong base!\\n\u0026#34;); return 0; } itob(n, s, b); printf(\u0026#34;%s\\n\u0026#34;, s); } 运行：\n1 2 Please input n and b: 123 11 102 exercise3-6 修改 itoa 函数，使得该函数可以接收三个参数。其中，第三个参数为最小字段宽度。为了保证转换后所得的结果至少具有第三个参数指定的最小宽度，在必要时应在所得结果的左边填充一定的空格。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 void reverse(char s[]) { int len = strlen(s); int i = 0, j = len - 1; while (i \u0026lt; j) { char temp = s[i]; s[i] = s[j], s[j] = temp; i++, j--; } } void itob(int n, char s[], int minlen) { int i, sign; if ((sign = n) \u0026lt; 0) n = -n; i = 0; do s[i++] = n % 10 + \u0026#39;0\u0026#39;; while (n /= 10); if (sign \u0026lt; 0) s[i++] = \u0026#39;-\u0026#39;; while (i \u0026lt; minlen) s[i++] = \u0026#39; \u0026#39;; reverse(s); } int main() { int n, minlen; printf(\u0026#34;Please input n and minlen: \u0026#34;); scanf(\u0026#34;%d %d\u0026#34;, \u0026amp;n, \u0026amp;minlen); char s[MAXLEN] = {0}; if (minlen \u0026lt;= 0) { printf(\u0026#34;wrong base!\\n\u0026#34;); return 0; } itob(n, s, minlen); printf(\u0026#34;%s\\n\u0026#34;, s); } 运行：\n1 2 Please input n and minlen: -123 10 -123 ","permalink":"https://fireflyyh.top/posts/tcpl/ch03/","summary":"部分答案参考了网络上的答案和官方题解。代码在gitee上面。\nexercise3-1 在上面有关折半查找的例子中，while 循环语句内共执行了两次测试，其实只要一次就足够（代价是将更多的测试在循环外执行）。重写该函数，使得在循环内部只执行一次测试。比较两种版本函数的运行时间。\n代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;time.","title":"C语言程序设计第二版课后习题--第三章"},{"content":" 部分答案参考了官方题解和网上的答案，仅供参考，可能也有部分bug未发现或解决。代码在gitee上面。\nexercise2-1 编写一个程序以确定分别由 signed 及 unsigned 限定的 char、short、int 与 long 类型变量的取值范围。采用打印标准头文件中的相应值以及直接计算两种方式实现。后一种方法的实现较困难一些，因为要确定各种浮点类型的取值范围。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;limits.h\u0026gt; int main() { printf(\u0026#34;Size of char %d\\n\u0026#34;, CHAR_BIT); printf(\u0026#34;Size of char max %d\\n\u0026#34;, CHAR_MAX); printf(\u0026#34;Size of char min %d\\n\u0026#34;, CHAR_MIN); printf(\u0026#34;Size of short min %d\\n\u0026#34;, SHRT_MIN); printf(\u0026#34;Size of short max %d\\n\u0026#34;, SHRT_MAX); printf(\u0026#34;Size of int min %d\\n\u0026#34;, INT_MIN); printf(\u0026#34;Size of int max %d\\n\u0026#34;, INT_MAX); printf(\u0026#34;Size of long min %ld\\n\u0026#34;, LONG_MIN); printf(\u0026#34;Size of long max %ld\\n\u0026#34;, LONG_MAX); printf(\u0026#34;Size of unsigned char %u\\n\u0026#34;, UCHAR_MAX); printf(\u0026#34;Size of unsigned short %u\\n\u0026#34;, USHRT_MAX); printf(\u0026#34;Size of unsigned int %u\\n\u0026#34;, UINT_MAX); printf(\u0026#34;Size of unsigned long %lu\\n\u0026#34;, ULONG_MAX); return 0; } 1 2 3 4 5 6 7 8 9 10 11 12 13 Size of char 8 Size of char max 127 Size of char min -128 Size of short min -32768 Size of short max 32767 Size of int min -2147483648 Size of int max 2147483647 Size of long min -9223372036854775808 Size of long max 9223372036854775807 Size of unsigned char 255 Size of unsigned short 65535 Size of unsigned int 4294967295 Size of unsigned long 18446744073709551615 exercise2-2 在不使用运算符\u0026amp;\u0026amp;或||的条件下编写一个与上面的 for 循环语句等价的循环语句。\n1 2 for (i = 0; ((i \u0026lt; lim - 1) + ((c = getchar()) != \u0026#39;\\n\u0026#39;) + (c != EOF)) == 3; i++) s[i] = c; 或\n1 2 for (i = 0; i \u0026lt; lim - 1 ? ((c = getchar()) != EOF ? c != \u0026#39;\\n\u0026#39; : 0) : 0; i++) s[i] = c; exercise2-3 编写函数 htoi(s)，把由十六进制数字组成的字符串（包含可选的前缀 0x或 0X）转换为与之等价的整型值。字符串中允许包含的数字包括：0～9、a～f 以及 A～F。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;string.h\u0026gt; #include \u0026lt;math.h\u0026gt; #define MAXLINE 1024 int mpow(int a, int b) { int ans = 1; while (b--) ans *= a; return ans; } int calculate(char line[]) { int len = strlen(line), ans = 0; for (int i = 0; i \u0026lt; len; i++) { ans += line[len - 1 - i] * mpow(16, i); } return ans; } int parse(char c) { if (c \u0026gt;= \u0026#39;0\u0026#39; \u0026amp;\u0026amp; c \u0026lt;= \u0026#39;9\u0026#39;) return c - \u0026#39;0\u0026#39;; if (c \u0026gt;= \u0026#39;a\u0026#39; \u0026amp;\u0026amp; c \u0026lt;= \u0026#39;f\u0026#39;) return 10 + c - \u0026#39;a\u0026#39;; if (c \u0026gt;= \u0026#39;A\u0026#39; \u0026amp;\u0026amp; c \u0026lt;= \u0026#39;F\u0026#39;) return 10 + c - \u0026#39;A\u0026#39;; return -1; } int Getline(char line[]) { int len = 0, c, digit; while ((c = getchar()) != \u0026#39;\\n\u0026#39;) { if (len == 1 \u0026amp;\u0026amp; (c == \u0026#39;x\u0026#39; || c == \u0026#39;X\u0026#39;) \u0026amp;\u0026amp; line[0] == 0) { len = 0; continue; } if ((digit = parse(c)) == -1) { printf(\u0026#34;Wrong input!\\n\u0026#34;); return -1; } else { line[len++] = digit; } } line[len] = 0; return len; } int main() { char line[MAXLINE]; while (Getline(line) != -1) { printf(\u0026#34;value is = %d\\n\u0026#34;, calculate(line)); } } 1 2 3 4 5 6 0x43997a7b value is = 1134131835 12345 value is = 74565 98765 value is = 624485 exercise2-4 squeeze(s1, s2)，将字符串 s1 中任何与字符串 s2 中字符匹配的字符都删除。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;string.h\u0026gt; void squeeze(char s1[], char s2[]) { char count[256] = {0}; // 用来记录每个字符是否出现在s2中 int len1 = strlen(s1), len2 = strlen(s2); char ans[len1 + 1]; int i, j; while (len2--) count[s2[len2]] = 1; for (i = 0, j = 0; i \u0026lt; len1; i++) if (count[s1[i]] == 0) s1[j++] = s1[i]; s1[j] = \u0026#39;\\0\u0026#39;; } int main() { char s1[] = \u0026#34;12345 6789\u0026#34;; char s2[] = \u0026#34;24 68\u0026#34;; printf(\u0026#34;s1 = %s\\ns2 = %s\\n\u0026#34;, s1, s2); squeeze(s1, s2); printf(\u0026#34;ans = %s\\n\u0026#34;, s1); } 结果\n1 2 3 s1 = 12345 6789 s2 = 24 68 ans = 13579 exercise2-5 编写函数 any(s1, s2)，将字符串 s2 中的任一字符在字符串 s1 中第一次出现的位置作为结果返回。如果 s1 中不包含 s2 中的字符，则返回-1。（标准库函数 strpbrk 具有同样的功能，但它返回的是指向该位置的指针。）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;string.h\u0026gt; void any(char s1[], char s2[], int pos[]) { // count存储字符在s2中第一次出现的位置， int len1 = strlen(s1), len2 = strlen(s2), count[256]; for (int i = 0; i \u0026lt; 256; i++) count[i] = -1; for (int i = 0; i \u0026lt; len2; i++) if (count[s2[i]] == -1) count[s2[i]] = i; // pos存储s1中每一个字符在s2中第一次出现的位置 // pos大小为s1的元素个数 for (int i = 0; i \u0026lt; len1; i++) pos[i] = count[s1[i]]; } int main() { char s1[] = \u0026#34;abcdefga\u0026#34;; char s2[] = \u0026#34;aceg\u0026#34;; printf(\u0026#34;s1 = %s\\ns2 = %s\\n\u0026#34;, s1, s2); int len = strlen(s1); int pos[len]; for (int i = 0; i \u0026lt; len; i++) pos[i] = -1; any(s1, s2, pos); printf(\u0026#34;s1中每一个字符在s2中第一次出现的位置（按照s1中的下标）：\\n\u0026#34;); for (int i = 0; i \u0026lt; len; i++) printf(\u0026#34;%d \u0026#34;, pos[i]); printf(\u0026#34;\\n\u0026#34;); return 0; } 1 2 3 4 s1 = abcdefga s2 = aceg s1中每一个字符在s2中第一次出现的位置（按照s1中的下标）： 0 -1 1 -1 2 -1 3 0 exercise2-6 编写一个函数 setbits(x, p, n, y)，该函数返回对 x 执行下列操作后的结果值：将 x 中从第 p 位开始的 n 个（二进制）位设置为 y 中最右边 n 位的值，x 的其余 各位保持不变。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 #include \u0026lt;stdio.h\u0026gt; unsigned setbits(unsigned x, int p, int n, unsigned y) { // 构建掩码，用于将x中的第p位开始的n位置为0 unsigned mask = ~(~0 \u0026lt;\u0026lt; n) \u0026lt;\u0026lt; (p + 1 - n); // x中从第p位开始的n位置为0 x = x \u0026amp; ~mask; // 取出y中最右边的n位，并将其移到合适的位置 unsigned yn = (y \u0026amp; ~(~0 \u0026lt;\u0026lt; n)) \u0026lt;\u0026lt; (p + 1 - n); return x | yn; } int main() { unsigned x = 0b10101011; unsigned y = 0b00111010; int p = 5; int n = 3; unsigned ans = setbits(x, p, n, y); printf(\u0026#34;setbits(%u(%08b), %d, %d, %u(%08b)) = %d(%08b)\\n\u0026#34;, x, x, p, n, y, y, ans, ans); } 1 setbits(171(10101011), 5, 3, 58(00111010)) = 147(10010011) exercise2-7 编写一个函数 invert(x, p, n)，该函数返回对 x 执行下列操作后的结果值：将 x 中从第 p 位开始的 n 个（二进制）位求反（即，1 变成 0，0 变成 1），x 的其余各位保持不变。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 #include \u0026lt;stdio.h\u0026gt; unsigned invert(unsigned x, int p, int n) { // 构建掩码，用于选定从第p位开始的n位 unsigned mask = (~(~0 \u0026lt;\u0026lt; n)) \u0026lt;\u0026lt; (p + 1 - n); // 对选定的位进行求反，并保持其余位不变 return x ^ mask; } int main() { unsigned x = 0b11011001; int p = 4; int n = 3; unsigned ans = invert(x, p, n); printf(\u0026#34;invert(%u(%08b), %d, %d) = %u(%08b)\\n\u0026#34;, x, x, p, n, ans, ans); } 1 invert(217(11011001), 4, 3) = 197(11000101) exercise2-8 编写一个函数 rightrot(x, n)，该函数返回将 x 循环右移（即从最右端移出的位将从最左端移入）n（二进制）位后所得到的值。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 #include \u0026lt;stdio.h\u0026gt; unsigned rightrot(unsigned x, int n) { // 制作掩码 unsigned mask = (~(~0 \u0026lt;\u0026lt; n) \u0026amp; x) \u0026lt;\u0026lt; (8 - n); // 将x右移n位之后与掩码或操作 return mask | (x \u0026gt;\u0026gt; n); } int main() { unsigned x = 0b00000111; int n = 3; unsigned ans = rightrot(x, n); printf(\u0026#34;rightrot(%u(%08b), %d) = %u(%08b)\\n\u0026#34;, x, x, n, ans, ans); } 1 rightrot(7(00000111), 3) = 224(11100000) exercise2-9 在求对二的补码时，表达式 x \u0026amp;= (x – 1)可以删除 x 中最右边值为 1 的一个二进制位。请解释这样做的道理。用这一方法重写 bitcount 函数，以加快其执行速度。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 #include \u0026lt;stdio.h\u0026gt; int bitcount(unsigned x) { int ans = 0; // 不断除去最右边的1，直至变为0 while (x != 0) { x \u0026amp;= (x - 1); ans++; } return ans; } int main() { int x = 0b00100101; int count = bitcount(x); printf(\u0026#34;bitcount(%u(%08b)) = %d\\n\u0026#34;, x, x, count); } 1 bitcount(37(00100101)) = 3 若有变量 x，在其最右边一个 1 之后比特位都为 0，若对其进行减一的操作，则在比特位上的表现为：将最后一个 1 及其右边的比特位全部反转，例如将 $00101000$变成 $00100111$，进行b \u0026amp; (b - 1)操作之后，会将反转的位都变成 0，从而实现了去除最右边一个 1 的操作。\nexercise2-10 重新编写将大写字母转换为小写字母的函数 lower，并用条件表达式替代其中的 if-else 结构。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;string.h\u0026gt; #define MAXLINE 1024 void lower(char str[]) { int len = strlen(str); for (int i = 0; i \u0026lt; len; i++) { str[i] += (str[i] \u0026gt;= \u0026#39;A\u0026#39; \u0026amp;\u0026amp; str[i] \u0026lt;= \u0026#39;Z\u0026#39;) ? \u0026#39;a\u0026#39; - \u0026#39;A\u0026#39; : 0; } } int main() { char str[MAXLINE]; scanf(\u0026#34;%[^\\n]\u0026#34;, str); // 捕获直到换行符 lower(str); printf(\u0026#34;%s\\n\u0026#34;, str); } 1 2 This Is A GOOD idea this is a good idea ","permalink":"https://fireflyyh.top/posts/tcpl/ch02/","summary":"部分答案参考了官方题解和网上的答案，仅供参考，可能也有部分bug未发现或解决。代码在gitee上面。\nexercise2-1 编写一个程序以确定分别由 signed 及 unsigned 限定的 char、short、int 与 long 类型变量的取值范围。采用打印标准头文件中的相应值以及直接计算两种方式实现。后一种方法的实现较困难一些，因为要确定各种浮点类型的取值范围。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;limits.h\u0026gt; int main() { printf(\u0026#34;Size of char %d\\n\u0026#34;, CHAR_BIT); printf(\u0026#34;Size of char max %d\\n\u0026#34;, CHAR_MAX); printf(\u0026#34;Size of char min %d\\n\u0026#34;, CHAR_MIN); printf(\u0026#34;Size of short min %d\\n\u0026#34;, SHRT_MIN); printf(\u0026#34;Size of short max %d\\n\u0026#34;, SHRT_MAX); printf(\u0026#34;Size of int min %d\\n\u0026#34;, INT_MIN); printf(\u0026#34;Size of int max %d\\n\u0026#34;, INT_MAX); printf(\u0026#34;Size of long min %ld\\n\u0026#34;, LONG_MIN); printf(\u0026#34;Size of long max %ld\\n\u0026#34;, LONG_MAX); printf(\u0026#34;Size of unsigned char %u\\n\u0026#34;, UCHAR_MAX); printf(\u0026#34;Size of unsigned short %u\\n\u0026#34;, USHRT_MAX); printf(\u0026#34;Size of unsigned int %u\\n\u0026#34;, UINT_MAX); printf(\u0026#34;Size of unsigned long %lu\\n\u0026#34;, ULONG_MAX); return 0; } 1 2 3 4 5 6 7 8 9 10 11 12 13 Size of char 8 Size of char max 127 Size of char min -128 Size of short min -32768 Size of short max 32767 Size of int min -2147483648 Size of int max 2147483647 Size of long min -9223372036854775808 Size of long max 9223372036854775807 Size of unsigned char 255 Size of unsigned short 65535 Size of unsigned int 4294967295 Size of unsigned long 18446744073709551615 exercise2-2 在不使用运算符\u0026amp;\u0026amp;或||的条件下编写一个与上面的 for 循环语句等价的循环语句。","title":"C语言程序设计第二版课后习题--第二章"},{"content":" 部分答案参考了官方题解和网上的答案，仅供参考，可能也有部分bug未发现或解决。代码在gitee上面。\nexercise1-1 在你自己的系统中运行“hello, world”程序。再有意去掉程序中的部分内容，看看会得到什么出错信息。\n1 2 3 main() { printf(\u0026#34;hello world!\u0026#34;); } 除去头文件 不报错且能运行，但是会有警告warning: implicit declaration of function ‘printf’ [-Wimplicit-function-declaration]。\n除去返回类型 不报错且能运行，但是会有警告warning: return type defaults to ‘int’ [-Wimplicit-int]。\nexercise1-2 做个实验，当 printf 函数的参数字符串中包含\\c（其中 c 是上面的转义字符序列中未曾列出的某一个字符）时，观察一下会出现什么情况。\n1 2 3 4 5 6 7 8 9 10 int main(void) { printf(\u0026#34;Experiment\\f to find out what\\f happens when \\fprintf \u0026#39;s argument string contains \\\\c\\n\u0026#34;); printf(\u0026#34;---------\\n\u0026#34;); printf(\u0026#34;Experiment\\v to find out what \\vhappens when printf \u0026#39;s \\vargument string contains \\\\c\\n\u0026#34;); printf(\u0026#34;---------\\n\u0026#34;); printf(\u0026#34;Experiment\\r to find out what \\rhappens when printf \u0026#39;s \\rargument string contains \\\\c\\n\u0026#34;); printf(\u0026#34;---------\\n\u0026#34;); return 0; } 1 2 3 4 5 6 7 8 9 10 11 12 Experiment to find out what happens when printf \u0026#39;s argument string contains \\c --------- Experiment to find out what happens when printf \u0026#39;s argument string contains \\c --------- argument string contains \\c --------- exercise1-3 修改温度转换程序，使之能在转换表的顶部打印一个标题\n1 2 3 4 5 6 7 8 9 10 11 12 int main() { float celsius; int fahr = 0, upper = 300, step = 30; printf(\u0026#34;fahr to celsius\\n\u0026#34;); while (fahr \u0026lt;= upper) { celsius = (5.0 / 9) * (fahr - 32); printf(\u0026#34;%5d %6.2f\\n\u0026#34;, fahr, celsius); fahr += step; } return 0; } 1 2 3 4 5 6 7 8 9 10 11 12 fahr to celsius 0 -17.78 30 -1.11 60 15.56 90 32.22 120 48.89 150 65.56 180 82.22 210 98.89 240 115.56 270 132.22 300 148.89 exercise1-4 编写一个程序打印摄氏温度转换为相应华氏温度的转换表。\n1 2 3 4 5 6 7 8 9 10 11 12 int main() { float fahr; int celsius = -200, upper = 300, step = 30; printf(\u0026#34;celsius to fahr\\n\u0026#34;); while (celsius \u0026lt;= upper) { fahr = (celsius + 32) * (9.0 / 5); printf(\u0026#34;%5d %6.1f\\n\u0026#34;, celsius, fahr); celsius += step; } return 0; } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 celsius to fahr -200 -302.4 -170 -248.4 -140 -194.4 -110 -140.4 -80 -86.4 -50 -32.4 -20 21.6 10 75.6 40 129.6 70 183.6 100 237.6 130 291.6 160 345.6 190 399.6 220 453.6 250 507.6 280 561.6 exercise1-5 修改温度转换程序，要求以逆序（即按照从 300 度到 0 度的顺序）打印温度转换表。\n1 2 3 4 5 6 int main() { int fahr; for (fahr = 300; fahr \u0026gt;= 0; fahr = fahr - 20) printf(\u0026#34;%3d %6.1f\\n\u0026#34;, fahr, (5.0 / 9) * (fahr - 32)); } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 300 148.9 280 137.8 260 126.7 240 115.6 220 104.4 200 93.3 180 82.2 160 71.1 140 60.0 120 48.9 100 37.8 80 26.7 60 15.6 40 4.4 20 -6.7 0 -17.8 exercise1-6 \u0026amp; exercise1-7 编写一个打印 EOF 值的程序\n1 2 3 4 5 6 7 8 9 10 11 12 int main() { int c; // ctrl + D for (;;) { c = getchar(); if (c == EOF) { printf(\u0026#34;Value of EOF is %d.\\n\u0026#34;, c); return 0; } } return 0; } 1 Value of EOF is -1. exercise1-8 编写一个统计空格、制表符与换行符个数的程序。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 #include \u0026lt;stdio.h\u0026gt; int main() { int c, cb = 0, ct = 0, cn = 0; while ((c = getchar()) != EOF) { switch (c) { case \u0026#39; \u0026#39;: cb++; break; case \u0026#39;\\t\u0026#39;: ct++; break; case \u0026#39;\\n\u0026#39;: cn++; break; default: break; } } printf(\u0026#34;count of blankspace is %d, count of \\\\t is %d, count of \\\\n is %d\\n\u0026#34;, cb, ct, cn ); } 1 2 3 4 yyy yy hh count of blankspace is 3, count of \\t is 2, count of \\n is 3 exercise1-9 编写一个将输入复制到输出的程序，并将其中连续的多个空格用一个空格代替。\n1 2 3 4 5 6 7 8 9 10 11 12 13 int main() { int c, flag = 0; while ((c = getchar()) != EOF) { if (c != \u0026#39; \u0026#39;) { putchar(c); flag = 0; } else if (flag == 0) { putchar(c); // 遇到连续空格中的第一个，就将 flag 置为1 flag = 1; } } } exercise1-10 编写一个将输入复制到输出的程序，并将其中的制表符替换为\\t，把回退符替换为\\b，把反斜杠替按为\\。这样可以将制表符和回退符以可见的方式显示出来。\n1 2 3 4 5 6 7 8 9 10 11 12 int main() { int c, flag = 0; while ((c = getchar()) != EOF) if (c == \u0026#39;\\t\u0026#39;) printf(\u0026#34;\\\\t\u0026#34;); else if (c == \u0026#39;\\b\u0026#39;) printf(\u0026#34;\\\\b\u0026#34;); else if (c == \u0026#39;\\\\\u0026#39;) printf(\u0026#34;\\\\\\\\\u0026#34;); else putchar(c); } 1 2 DCS\\d \\tDCS\\\\d\\t exercise1-11 你准备如何测试单词计数程序？如果程序中存在某种错误，那么什么样的输入最可能发现这类错误呢？\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 #define IN 1 #define OUT 0 int main() { int c, flag = OUT; int wc = 0; while ((c = getchar()) != EOF) { if (c != \u0026#39; \u0026#39; \u0026amp;\u0026amp; c != \u0026#39;\\t\u0026#39; \u0026amp;\u0026amp; c != \u0026#39;\\n\u0026#39;) { if (flag == OUT) { wc++; flag = IN; } } else { if (flag == IN) { flag = OUT; } } } printf(\u0026#34;count of word is = %d\\n\u0026#34;, wc); } 1 2 my name is blank! count of word is = 4 只需要将上面exercise1-10的程序进行修改，使用IN和OUT来记录当前遍历的字母的状态：是处于单词内部还是单词外部。如果遇到第一个非空格、换行、制表符字符，则将状态修改为IN，表示进入到了一个单词的内部，如果遇到了第一个上述字符，则将状态修改为OUT。\nexercise1-12 编写一个程序，以每行一个单词的形式打印其输入。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 #define IN 1 #define OUT 0 int main() { int c, flag = OUT; int wc = 0; while ((c = getchar()) != EOF) { if (c != \u0026#39; \u0026#39; \u0026amp;\u0026amp; c != \u0026#39;\\t\u0026#39; \u0026amp;\u0026amp; c != \u0026#39;\\n\u0026#39;) { if (flag == OUT) { wc++; flag = IN; } putchar(c); } else { if (flag == IN) { flag = OUT; putchar(\u0026#39;\\n\u0026#39;); } } } printf(\u0026#34;wc = %d\\n\u0026#34;, wc); } 1 2 3 4 5 6 my name is blank! my name is blank! wc = 4 只需要将 1-11 的代码稍加修改。\nexercise1-13 编写一个程序，打印输入中单词长度的直方图。水平方向的直方图比较容易绘制，垂直方向的直方图则要困难些。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 #define IN 1 #define OUT 0 #define MAXLENGTH 4096 int main() { int c, flag = OUT, counts[MAXLENGTH] = {0}; int l = 0, r = 0; // 分别代表当前单词的左边界和遍历的下标，当遍历到单词的右边界时，把两者相减，得到单词长度。 while ((c = getchar()) != EOF) { if (c != \u0026#39; \u0026#39; \u0026amp;\u0026amp; c != \u0026#39;\\t\u0026#39; \u0026amp;\u0026amp; c != \u0026#39;\\n\u0026#39;) { if (flag == OUT) { flag = IN; l = r; } } else { if (flag == IN) { flag = OUT; counts[r - l - 1]++; // 将对应的数组元素加一 } } r++; } printf(\u0026#34;length\\tcounts\\n\u0026#34;); for (int i = 0; i \u0026lt; MAXLENGTH; i++) { if (counts[i] != 0) { printf(\u0026#34;%6d\\t\u0026#34;, i + 1); while (counts[i]--) putchar(\u0026#39;#\u0026#39;); putchar(\u0026#39;\\n\u0026#39;); } } } 1 2 3 4 5 6 7 8 This is a sad story because I don\u0026#39;t kown why. length counts 1 ## 2 # 3 # 4 ### 5 ## 7 # exercise1-14 编写一个程序，打印输入中各个字符出现频度的直方图。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 #define MAXVALUE 256 int main() { int c, counts[MAXVALUE] = {0}; while ((c = getchar()) != EOF) if (c != \u0026#39; \u0026#39; \u0026amp;\u0026amp; c != \u0026#39;\\t\u0026#39; \u0026amp;\u0026amp; c != \u0026#39;\\n\u0026#39;) counts[c]++; printf(\u0026#34;character\\tcounts\\n\u0026#34;); for (int i = 0; i \u0026lt; MAXVALUE; i++) { if (counts[i] != 0) { printf(\u0026#34;%9c\\t\u0026#34;, i); while (counts[i]--) putchar(\u0026#39;#\u0026#39;); putchar(\u0026#39;\\n\u0026#39;); } } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 This is a sad story because I don\u0026#39;t kown why. character counts \u0026#39; # . # I # T # a ### b # c # d ## e ## h ## i ## k # n ## o ### r # s ##### t ## u # w ## y ## exercise1-15 重新编写 1.2 节中的温度转换程序，使用函数实现温度转换计算。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 float ctof(float celsius) { return (celsius + 32) * (9.0 / 5); } float ftoc(float fahr) { return (5.0 / 9) * (fahr - 32); } int main() { int fahr = 0, celsius = -200, upper = 300, step = 30; printf(\u0026#34;celsius\\t fahr\\n\u0026#34;); while (celsius \u0026lt;= upper) { printf(\u0026#34;%7d\\t %4.1f\\n\u0026#34;, celsius, ctof(celsius)); celsius += step; } printf(\u0026#34;\\nfahr\\tcelsius\\n\u0026#34;); while (fahr \u0026lt;= upper) { celsius = (5.0 / 9) * (fahr - 32); printf(\u0026#34;%4d\\t%7.2f\\n\u0026#34;, fahr, ftoc(fahr)); fahr += step; } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 celsius fahr -200 -302.4 -170 -248.4 -140 -194.4 -110 -140.4 -80 -86.4 -50 -32.4 -20 21.6 10 75.6 40 129.6 70 183.6 100 237.6 130 291.6 160 345.6 190 399.6 220 453.6 250 507.6 280 561.6 fahr celsius 0 -17.78 30 -1.11 60 15.56 90 32.22 120 48.89 150 65.56 180 82.22 210 98.89 240 115.56 270 132.22 300 148.89 exercise1-16 修改打印最长文本行的程序的主程序 main，使之可以打印任意长度的输入行的长度，并尽可能多地打印文本。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 #include \u0026lt;stdio.h\u0026gt; #define MAXLINE 4 int Getline(char line[], int maxline); void copy(char to[], char from[]); int main() { int len; int max; char line[MAXLINE]; char longest[MAXLINE]; max = 0; while ((len = Getline(line, MAXLINE)) \u0026gt; 0) if (len \u0026gt; max) { max = len; copy(longest, line); } if (max \u0026gt; 0) printf(\u0026#34;Maxlength is %d\\n and the content that can be printed is: %s\\n\u0026#34;, max, longest); return 0; } int Getline(char s[], int lim) { // i存放输入的长度，j存放接受的长度 int c, i, j; for (i = 0, j = 0; (c = getchar()) != EOF \u0026amp;\u0026amp; c != \u0026#39;\\n\u0026#39;; ++i) { if (j \u0026lt; lim - 1) s[j++] = c; } if (c == \u0026#39;\\n\u0026#39;) { if (j \u0026lt; lim - 1) { s[j] = \u0026#39;\\n\u0026#39;; j++; } i++; } s[j] = \u0026#39;\\0\u0026#39;; return i; } void copy(char to[], char from[]) { int i; i = 0; while ((to[i] = from[i]) != \u0026#39;\\0\u0026#39;) ++i; } 1 2 3 this is a happy game Maxlength is 21 and the content that can be printed is thi exercise1-17 编写一个程序，打印长度大于 80 个字符的所有输入行。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 #include \u0026lt;stdio.h\u0026gt; #define MINLINE 80 // 符合打印要求的最小字符数（包含\\n） #define MAXLINE 1024 // 每一行的最大字符数（包含\\n） int Getline(char line[]) { int c, i; for (i = 0; i \u0026lt; MAXLINE - 1 \u0026amp;\u0026amp; (c = getchar()) != EOF \u0026amp;\u0026amp; c != \u0026#39;\\n\u0026#39;; i++) line[i] = c; // 退出循环：字符限制 || 文件末尾 || 行末尾 // 如果c==\u0026#39;\\n\u0026#39;，说明以上的遍历没有达到字符限制 // 否则，则需要立刻结束遍历，将结尾置为\u0026#39;\\0\u0026#39; if (c == \u0026#39;\\n\u0026#39;) { line[i] = c; i++; } line[i] = \u0026#39;\\0\u0026#39;; return i; } int main() { int len; char line[MAXLINE]; while ((len = Getline(line)) != 0) if (len \u0026gt; MINLINE) printf(\u0026#34;%s\u0026#34;, line); } 为了便于展示，将打印长度大于 4 个字符（包含\\n）的所有输入行：\n1 2 3 4 5 6 7 8 this this is a goood goood game game exercise1-18 编写一个程序，删除每个输入行末尾的空格及制表符，并删除完全是空格的行。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 int handler(char line[], int len) { int flag = line[len - 2] == \u0026#39;\\n\u0026#39; ? 1 : 0; // 用来判断本行是否含有\\n int i = len - 2 - flag; for (; i \u0026gt;= 0 \u0026amp;\u0026amp; (line[i] == \u0026#39;\\t\u0026#39; || line[i] == \u0026#39; \u0026#39;); i--); if (flag) { line[++i] = \u0026#39;\\n\u0026#39;; } line[++i] = \u0026#39;\\0\u0026#39;; return i; // 返回实际长度 } int main() { char line[MAXLINE], len, newlen; while ((len = Getline(line)) \u0026gt; 0) { newlen = handler(line, len); printf(\u0026#34;len = %d, str = \\\u0026#34;%s\\\u0026#34;, newlen = %d\\n\u0026#34;, len, line, newlen); } } 1 2 3 4 5 6 goo ood len = 8, str = \u0026#34;goo ood\u0026#34;, newlen = 7 len = 2, str = \u0026#34;\u0026#34;, newlen = 0 wyu len = 6, str = \u0026#34; wyu\u0026#34;, newlen = 5 NOTE 为了简化报告，省去了头文件，且下文所使用的所有Getline(line)函数均为\n1 2 3 4 5 6 7 8 9 10 int Getline(char line[]) { int c, i; for (i = 0; i \u0026lt; MAXLINE - 1 \u0026amp;\u0026amp; (c = getchar()) != EOF \u0026amp;\u0026amp; c != \u0026#39;\\n\u0026#39;; i++) { line[i] = c; } if (c == \u0026#39;\\n\u0026#39;) line[i++] = c; line[i] = \u0026#39;\\0\u0026#39;; return i; } exercise1-19 编写函数 reverse(s)，将字符串 s 中的字符顺序颠倒过来。使用该函数编写一个程序，每次颠倒一个输入行中的字符顺序。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 void reverse(char line[], int len) { int flag = line[len - 2] == \u0026#39;\\n\u0026#39; ? 1 : 0; // 用来判断本行是否含有\\n int r = len - 2 - flag, l = 0; while (l \u0026lt; r) { char temp = line[r]; line[r] = line[l]; line[l] = temp; l++; r--; } } int main() { char line[MAXLINE], len; while ((len = Getline(line)) \u0026gt; 0) { reverse(line, len); printf(\u0026#34;%s\u0026#34;, line); } } 1 2 hello, everyone! !enoyreve ,olleh exercise1-20 编写程序 detab，将输入中的制表符替换成适当数目的空格，使空格充满到下一个制表符终止位的地方。假设制表符终止位的位置是固定的，比如每隔 n 列就会出现一个制表符终止位。n 应该作为变量还是符号常量呢？\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 #define TABLEN 8 void detab(char dest[], char src[], int len) { // 分别记录在src、dest中的下标 int i = 0, j = 0; while (i \u0026lt; len \u0026amp;\u0026amp; src[i] != \u0026#39;\\n\u0026#39;) { if (src[i] != \u0026#39;\\t\u0026#39;) { dest[j] = src[i]; j++; } else { // 计算还有多少字符到达下一个制表位 int count = TABLEN - (j % TABLEN); // 替换为空格 while (count--) // 为了显示清楚，用^代替空格 dest[j++] = \u0026#39;^\u0026#39;; } i++; } dest[j] = \u0026#39;\\0\u0026#39;; } int main() { int len; char src[MAXLINE], dest[MAXLINE]; while ((len = Getline(src)) \u0026gt; 0) { detab(dest, src, len); printf(\u0026#34;%s\\n\u0026#34;, dest); } } 为了为了显示清楚，用^代替空格\n1 2 hi every one! hi^^^^^^every^^^one! n 应该作为符号变量\nexercise1-21 编写程序 entab，将空格串替换为最少数量的制表符和空格，但要保持单词之间的间隔不变。假设制表符终止位的位置与练习 1-20 的 detab 程序的情况相同。当使用一个制表符或者一个空格都可以到达下一个制表符终止位时，选用哪一种替换字符比较好？\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 #define TABLEN 8 int entab(char dest[], char src[], int len) { int count = 0; for (int i = 0; i \u0026lt; len; i++) { if (src[i] == \u0026#39; \u0026#39;) count++; else count = 0; if (count == TABLEN) { i -= (TABLEN - 1); len -= (TABLEN - 1); // 为了显示效果，用^替代\\t src[i] = \u0026#39;^\u0026#39;; for (int t = i + 1; t \u0026lt; len; t++) src[t] = src[t + (TABLEN - 1)]; count = 0; src[len] = \u0026#39;\\0\u0026#39;; } } printf(\u0026#34;%s\u0026#34;, src); return 0; } int main() { char src[MAXLINE], dest[MAXLINE]; int len; while ((len = Getline(src)) \u0026gt; 0) { entab(dest, src, len); } } 当使用一个制表符或者一个空格都可以到达下一个制表符终止位时，选用一个制表符比较好，能保持对齐一致性。\nexercise1-22 编写一个程序，把较长的输入行“折”成短一些的两行或多行，折行的位置在输入行的第 n 列之前的最后一个非空格之后。要保证程序能够智能地处理输入行很长以及在指定的列前没有空格或制表符时的情况。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 #define FOLDLEN 8 int handler(char src[], int len) { if (len \u0026lt; FOLDLEN) { } else { // foldloc 用来记录折断的位置 int foldloc = FOLDLEN - 1; // 循环退出条件为遍历到最后一个字符 while (foldloc \u0026lt; len) { int i = 0; // 从后往前寻找第一个非空格，或者该段全为空格 for (; i \u0026lt; FOLDLEN; i++) if (src[foldloc - i] != \u0026#39; \u0026#39;) break; if (i != FOLDLEN) foldloc = foldloc - i + 1; src[foldloc] = \u0026#39;\\n\u0026#39;; foldloc += FOLDLEN; } } printf(\u0026#34;%s\\n\u0026#34;, src); return 0; } int main() { char src[MAXLINE]; int len; while ((len = Getline(src)) \u0026gt; 0) handler(src, len); } 1 2 3 4 5 this is also a goooood subject. this is also a g ooood su ject. exercise1-23 编写一个删除 C 语言程序中所有的注释语句。要正确处理带引号的字符串与字符常量。在 C 语言中，注释不允许嵌套。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 #include \u0026lt;stdio.h\u0026gt; #define MAXLINE 1024 #define CONTENT 0 // 内容 #define QUOTE 1 // 引号内 #define BLOCKCOMMENT 2 // 块注释 #define LINECOMMENT 3 // 行注释 int state; /* 能够正确运行的前提是要处理的C程序本身无语法错误 且没有注释嵌套 块注释的优先级大于行注释 */ enum { CONTENT, // 内容 QUOTE, // 引号内 BLOCKCOMMENT, // 块注释 LINECOMMENT // 行注释 }; int state; /* 能够正确运行的前提是要处理的C程序本身无语法错误 且没有注释嵌套 块注释的优先级大于行注释 */ void handler(char src[], int len) { int t = 0; while (t \u0026lt; len) { // 进入与离开引号 if (src[t] == \u0026#39;\u0026#34;\u0026#39;) { if (state == QUOTE) state = CONTENT; else state = QUOTE; } if (state != QUOTE) { // 进入块注释 if (src[t] == \u0026#39;/\u0026#39; \u0026amp;\u0026amp; src[t + 1] == \u0026#39;*\u0026#39;) { t += 2; state = BLOCKCOMMENT; } // 离开块注释 if (src[t] == \u0026#39;*\u0026#39; \u0026amp;\u0026amp; src[t + 1] == \u0026#39;/\u0026#39;) { t += 2; state = CONTENT; } // 进入行注释 if (src[t] == \u0026#39;/\u0026#39; \u0026amp;\u0026amp; src[t + 1] == \u0026#39;/\u0026#39;) { t += 2; state = LINECOMMENT; } // 到达行末尾，检测是否该行为行注释 if (src[t] == \u0026#39;\\n\u0026#39; \u0026amp;\u0026amp; state == LINECOMMENT) { state = CONTENT; } // 如果为注释内，则跳过该字符 if (state == BLOCKCOMMENT || state == LINECOMMENT) { t++; } else { printf(\u0026#34;%c\u0026#34;, src[t]); t++; } } else { printf(\u0026#34;%c\u0026#34;, src[t]); t++; } } } int main() { char src[MAXLINE]; int len; state = CONTENT; while ((len = Getline(src)) \u0026gt; 0) handler(src, len); } 设有一个测试文件test.c，内容为下：\n1 2 3 4 5 6 7 8 9 #include \u0026lt;stdio.h\u0026gt; /* TEST */ // uwey int main() { printf(\u0026#34;aosi/*123*/\u0026#34;); //sdui } 执行命令：./Exercise1-23 \u0026lt;test.c，将test.c的文件内容作为输入，得到下面的结果：\n1 2 3 4 5 6 7 #include \u0026lt;stdio.h\u0026gt; int main() { printf(\u0026#34;aosi/*123*/\u0026#34;); } exercise1-24 编写一个程序，查找 C 语言程序中的基本语法错误，如圆括号、方括号、花括号不配对等。要正确处理引号（包括单引号和双引号）、转义字符序列与注释。（如果读者想把该程序编写成完全通用的程序，难度会比较大。）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 typedef struct { char stack[MAXLINE]; int top; } Stack; Stack stack; int inSingleQuote = 0, inDoubleQuote = 0, inComment = 0; void initStack(Stack *s) { s-\u0026gt;top = -1; } int isFull(Stack *s) { return s-\u0026gt;top == MAXLINE - 1; } int isEmpty(Stack *s) { return s-\u0026gt;top == -1; } void push(Stack *s, char c) { if (!isFull(s)) { s-\u0026gt;stack[++s-\u0026gt;top] = c; } } char pop(Stack *s) { if (!isEmpty(s)) { return s-\u0026gt;stack[s-\u0026gt;top--]; } return \u0026#39;\\0\u0026#39;; } int matchingBrackets(char opening, char closing) { return (opening == \u0026#39;(\u0026#39; \u0026amp;\u0026amp; closing == \u0026#39;)\u0026#39;) || (opening == \u0026#39;[\u0026#39; \u0026amp;\u0026amp; closing == \u0026#39;]\u0026#39;) || (opening == \u0026#39;{\u0026#39; \u0026amp;\u0026amp; closing == \u0026#39;}\u0026#39;); } int handler(char line[], int len) { int i = 0; while (i \u0026lt; len) { char c = line[i]; if (inComment) { if (c == \u0026#39;*\u0026#39; \u0026amp;\u0026amp; line[i + 1] == \u0026#39;/\u0026#39;) { inComment = 0; i++; } } else if (inSingleQuote) { if (c == \u0026#39;\\\u0026#39;\u0026#39; \u0026amp;\u0026amp; (i == 0 || line[i - 1] != \u0026#39;\\\\\u0026#39;)) { inSingleQuote = 0; } } else if (inDoubleQuote) { if (c == \u0026#39;\u0026#34;\u0026#39; \u0026amp;\u0026amp; (i == 0 || line[i - 1] != \u0026#39;\\\\\u0026#39;)) { inDoubleQuote = 0; } } else { if (c == \u0026#39;/\u0026#39; \u0026amp;\u0026amp; line[i + 1] == \u0026#39;*\u0026#39;) { inComment = 1; i++; } else if (c == \u0026#39;\\\u0026#39;\u0026#39;) { inSingleQuote = 1; } else if (c == \u0026#39;\u0026#34;\u0026#39;) { inDoubleQuote = 1; } else if (c == \u0026#39;(\u0026#39; || c == \u0026#39;[\u0026#39; || c == \u0026#39;{\u0026#39;) { push(\u0026amp;stack, c); } else if (c == \u0026#39;)\u0026#39; || c == \u0026#39;]\u0026#39; || c == \u0026#39;}\u0026#39;) { if (isEmpty(\u0026amp;stack) || !matchingBrackets(pop(\u0026amp;stack), c)) { printf(\u0026#34;Syntax error: unmatched %c at position %d\\n\u0026#34;, c, i); return 1; } } } i++; } } int main() { initStack(\u0026amp;stack); char line[MAXLINE]; int len; while ((len = Getline(line)) \u0026gt; 0) handler(line, len); if (!isEmpty(\u0026amp;stack)) { printf(\u0026#34;Syntax error: unmatched %c\\n\u0026#34;, stack.stack[stack.top]); return 0; } printf(\u0026#34;No syntax errors found.\\n\u0026#34;); return 0; } 设有一个 test.c 文件，内容为\n1 2 3 4 5 6 7 8 #include \u0026lt;stdio.h\u0026gt; /* TEST */ // uwey int main() { printf(\u0026#34;aosi/*123*/\u0026#34;); //sdui 通过运行./Exercise1-24 \u0026lt;test.c，结果如下：\n1 Syntax error: unmatched { 检测到了缺少花括号\n","permalink":"https://fireflyyh.top/posts/tcpl/ch01/","summary":"部分答案参考了官方题解和网上的答案，仅供参考，可能也有部分bug未发现或解决。代码在gitee上面。\nexercise1-1 在你自己的系统中运行“hello, world”程序。再有意去掉程序中的部分内容，看看会得到什么出错信息。\n1 2 3 main() { printf(\u0026#34;hello world!\u0026#34;); } 除去头文件 不报错且能运行，但是会有警告warning: implicit declaration of function ‘printf’ [-Wimplicit-function-declaration]。\n除去返回类型 不报错且能运行，但是会有警告warning: return type defaults to ‘int’ [-Wimplicit-int]。\nexercise1-2 做个实验，当 printf 函数的参数字符串中包含\\c（其中 c 是上面的转义字符序列中未曾列出的某一个字符）时，观察一下会出现什么情况。\n1 2 3 4 5 6 7 8 9 10 int main(void) { printf(\u0026#34;Experiment\\f to find out what\\f happens when \\fprintf \u0026#39;s argument string contains \\\\c\\n\u0026#34;); printf(\u0026#34;---------\\n\u0026#34;); printf(\u0026#34;Experiment\\v to find out what \\vhappens when printf \u0026#39;s \\vargument string contains \\\\c\\n\u0026#34;); printf(\u0026#34;---------\\n\u0026#34;); printf(\u0026#34;Experiment\\r to find out what \\rhappens when printf \u0026#39;s \\rargument string contains \\\\c\\n\u0026#34;); printf(\u0026#34;---------\\n\u0026#34;); return 0; } 1 2 3 4 5 6 7 8 9 10 11 12 Experiment to find out what happens when printf \u0026#39;s argument string contains \\c --------- Experiment to find out what happens when printf \u0026#39;s argument string contains \\c --------- argument string contains \\c --------- exercise1-3 修改温度转换程序，使之能在转换表的顶部打印一个标题","title":"C语言程序设计第二版课后习题--第一章"},{"content":"阿里云 尝试使用windows客户端登录阿里云服务器，参考了10分钟手把手教你通过SSH，使用密钥/账号远程登录Linux服务器（Windows/macOS）\n客户端生成密钥 进入到C:\\Users\\用户名\\.ssh目录下，若没有公钥和私钥文件，则进行生成。\n执行ssh-keygen命令，之后一路回车，然后在该目录下会出现ida_rsa和ida_rsa.pub两个文件，分别存放私钥和公钥。\n部署公钥 使用密码登录服务器，在用户目录下进入到.ssh文件夹，创建或编辑authorized_keys文件，将上一步获得的公钥内容复制并追加到该文件中。\n中科大vlab Vlab实验中心，参考帮助文档\n下载私钥 进入到管理界面，下载私钥vlab-vm9164.pem。\n本地配置 将该私钥文件放置到本地C:\\Users\\用户名\\.ssh文件夹之下，并重命名为vlab.pem。\n然后即可以在 cmd 中使用ssh -i ~/.ssh/vlab.pem ubuntu@vlab.ustc.edu.cn来登录到远程主机。\n配置文件 如果需要使用vscode来进行操作，则可以使用SSH配置文件。进入到C:\\Users\\用户名\\.ssh文件夹之下，创建或编辑config文件。然后最好使用 vscode 打开该文件并编辑，追加以下内容：\n1 2 3 4 Host vlab HostName vlab.ustc.edu.cn User ubuntu IdentityFile ~/.ssh/vlab.pem 之后在vscode中就可以方便地进行连接了。\n","permalink":"https://fireflyyh.top/posts/linux/ssh/","summary":"阿里云 尝试使用windows客户端登录阿里云服务器，参考了10分钟手把手教你通过SSH，使用密钥/账号远程登录Linux服务器（Windows/macOS）\n客户端生成密钥 进入到C:\\Users\\用户名\\.ssh目录下，若没有公钥和私钥文件，则进行生成。\n执行ssh-keygen命令，之后一路回车，然后在该目录下会出现ida_rsa和ida_rsa.pub两个文件，分别存放私钥和公钥。\n部署公钥 使用密码登录服务器，在用户目录下进入到.ssh文件夹，创建或编辑authorized_keys文件，将上一步获得的公钥内容复制并追加到该文件中。\n中科大vlab Vlab实验中心，参考帮助文档\n下载私钥 进入到管理界面，下载私钥vlab-vm9164.pem。\n本地配置 将该私钥文件放置到本地C:\\Users\\用户名\\.ssh文件夹之下，并重命名为vlab.pem。\n然后即可以在 cmd 中使用ssh -i ~/.ssh/vlab.pem ubuntu@vlab.ustc.edu.cn来登录到远程主机。\n配置文件 如果需要使用vscode来进行操作，则可以使用SSH配置文件。进入到C:\\Users\\用户名\\.ssh文件夹之下，创建或编辑config文件。然后最好使用 vscode 打开该文件并编辑，追加以下内容：\n1 2 3 4 Host vlab HostName vlab.ustc.edu.cn User ubuntu IdentityFile ~/.ssh/vlab.pem 之后在vscode中就可以方便地进行连接了。","title":"SSH密钥登陆"},{"content":"TLPI 22.4：处理由硬件产生的信号 代码（为网站上获取） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 #define _GNU_SOURCE /* Get strsignal() declaration from \u0026lt;string.h\u0026gt; */ #include \u0026lt;string.h\u0026gt; #include \u0026lt;signal.h\u0026gt; #include \u0026lt;stdbool.h\u0026gt; #include \u0026#34;tlpi_hdr.h\u0026#34; /* SIGFPE信号处理器函数 */ static void sigfpeCatcher(int sig) { printf(\u0026#34;Caught signal %d (%s)\\n\u0026#34;, sig, strsignal(sig)); sleep(1); /* Slow down execution of handler */ } int main(int argc, char *argv[]) { /* 参数有三种选择， 第一种，无参数，为捕获信号并进入处理器函数 第二种，-i，为忽略信号 第三种，-b，为阻塞信号 */ if (argc \u0026gt; 1 \u0026amp;\u0026amp; strchr(argv[1], \u0026#39;i\u0026#39;) != NULL) { // strchr用于查找第一次出现\u0026#39;i\u0026#39;的位置，并返回以其为首的字符串 printf(\u0026#34;Ignoring SIGFPE\\n\u0026#34;); if (signal(SIGFPE, SIG_IGN) == SIG_ERR) // i-忽略SIGFPE errExit(\u0026#34;signal\u0026#34;); } else { printf(\u0026#34;Catching SIGFPE\\n\u0026#34;); struct sigaction sa; sigemptyset(\u0026amp;sa.sa_mask); // 不阻塞任何信号 sa.sa_flags = SA_RESTART; // 自动重启 sa.sa_handler = sigfpeCatcher; if (sigaction(SIGFPE, \u0026amp;sa, NULL) == -1) errExit(\u0026#34;sigaction\u0026#34;); } bool blocking = argc \u0026gt; 1 \u0026amp;\u0026amp; strchr(argv[1], \u0026#39;b\u0026#39;) != NULL; // b-阻塞信号 sigset_t prevMask; if (blocking) { printf(\u0026#34;Blocking SIGFPE\\n\u0026#34;); sigset_t blockSet; sigemptyset(\u0026amp;blockSet); sigaddset(\u0026amp;blockSet, SIGFPE); if (sigprocmask(SIG_BLOCK, \u0026amp;blockSet, \u0026amp;prevMask) == -1) errExit(\u0026#34;sigprocmask\u0026#34;); } printf(\u0026#34;About to generate SIGFPE\\n\u0026#34;); // 准备生成SIGFPE int x, y; y = 0; x = 1 / y; // 除零操作，生成SIGFPE y = x; /* Avoid complaints from \u0026#34;gcc -Wunused-but-set-variable\u0026#34; */ if (blocking) { printf(\u0026#34;Sleeping before unblocking\\n\u0026#34;); sleep(2); printf(\u0026#34;Unblocking SIGFPE\\n\u0026#34;); if (sigprocmask(SIG_SETMASK, \u0026amp;prevMask, NULL) == -1) errExit(\u0026#34;sigprocmask\u0026#34;); } printf(\u0026#34;Shouldn\u0026#39;t get here!\\n\u0026#34;); exit(EXIT_FAILURE); } 解释 根据参数，进行后续步骤：\n若无参数，则直接为其建立信号处理器函数，内容为打印出相关信息； 若为-i，则为忽略 SIGFPE 信号，使用signal(SIGFPE, SIG_IGN)这行代码来忽略浮点数异常； 若为-b，则为阻塞信号，先将 SIGFPE 放入信号掩码，然后在错误的浮点数运算之后取消阻塞 运行结果 默认情况 默认情况下：\n1 2 3 4 5 6 7 8 9 10 Catching SIGFPE About to generate SIGFPE Caught signal 8 (Floating point exception) Caught signal 8 (Floating point exception) Caught signal 8 (Floating point exception) Caught signal 8 (Floating point exception) Caught signal 8 (Floating point exception) Caught signal 8 (Floating point exception) Caught signal 8 (Floating point exception) ^\\[1] 116013 quit ./DEMO_SIGFPE 在除零操作之后，产生异常，产生了 SIGFPE 信号，将其捕获，打印信息，并睡眠1s。 运行结果不断出现信息的原因是，在退出信号处理器函数之后，程序又回到终端出重新运行，在本程序中，将会不断地重新进行除零操作，从而不断产生异常。\n忽略信号 在这种情况下：\n1 2 3 Ignoring SIGFPE About to generate SIGFPE [1] 113466 floating point exception ./DEMO_SIGFPE -i 结果表明，并没有成功忽略该信号，这也验证了 TLPI 中的描述：\n当由于硬件异常而产生上述信号之一时，Linux 会强制传递 信号，即使程序已经请求忽略此类信号。\n阻塞信号 在这种情况下：\n1 2 3 Blocking SIGFPE About to generate SIGFPE [1] 116212 floating point exception ./DEMO_SIGFPE -b 同样地，也并没有阻塞该信号。\n始于 Linux 2.6，如果信号遭到阻塞，那么该信号总是会立刻杀死进程，即使进程已经为此信号安装了处理器函数。\n","permalink":"https://fireflyyh.top/posts/tlpi/demo_sigfpe/","summary":"TLPI 22.4：处理由硬件产生的信号 代码（为网站上获取） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 #define _GNU_SOURCE /* Get strsignal() declaration from \u0026lt;string.","title":"硬件产生的信号"},{"content":"TLPI 21.1.2: 可重入函数和异步信号安全函数 代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 #define _XOPEN_SOURCE 600 #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;signal.h\u0026gt; #include \u0026lt;string.h\u0026gt; #include \u0026lt;crypt.h\u0026gt; #include \u0026#34;tlpi_hdr.h\u0026#34; static char *str2; static int handled = 0; // 设置处理器函数，一旦遇上SIGINT，便对str2进行加密 static void handler(int sig) { crypt(str2, \u0026#34;xx\u0026#34;); handled++; } int main(int argc, char *argv[]) { char *cr1; int callNum, mismatch; struct sigaction sa; if (argc != 3) usageErr(\u0026#34;%s str1 str2\\n\u0026#34;, argv[0]); str2 = argv[2]; // 对str1进行加密，并将结果保存到独立缓冲区中 cr1 = strdup(crypt(argv[1], \u0026#34;xx\u0026#34;)); if (cr1 == NULL) errExit(\u0026#34;strdup\u0026#34;); sigemptyset(\u0026amp;sa.sa_mask); // 初始化在执行处理器函数时将阻塞的信号 sa.sa_flags = 0; // 即sa.sa_flags = SIG_BLOCK sa.sa_handler = handler; // 设置信号处理器函数的地址 if (sigaction(SIGINT, \u0026amp;sa, NULL) == -1) errExit(\u0026#34;sigaction\u0026#34;); for (callNum = 1, mismatch = 0; ; callNum++) { if (strcmp(crypt(argv[1], \u0026#34;xx\u0026#34;), cr1) != 0) { mismatch++; printf(\u0026#34;Mismatch on call %d (mismatch=%d handled=%d)\\n\u0026#34;, callNum, mismatch, handled); } } } 解释 crypt() 需要加入#include \u0026lt;crypt.h\u0026gt;，如果不加上该头文件，会出现implicit declaration of function ‘crypt’的错误。\n针对于undefined reference to `crypt\u0026rsquo;的错误，stackoverflow有以下方案：\ncrypt.c:(.text+0xf1): undefined reference to \u0026lsquo;crypt\u0026rsquo; is a linker error. Try linking with -lcrypt : gcc crypt.c -lcrypt.\n即，在CMakeLists.txt文件中加入link_libraries(crypt)。\nfor循环内部 在这个无限循环中，不断对str1进行加密，并与正确结果进行比较。如果str1在加密的过程中不被打断，则会得到正确结果，但是如果被打断并在处理器函数中对str2进行加密，则会对str1加密的结果产生污染，导致该加密的结果不正确，以此来判断信号处理器函数是否对不可重入函数产生了影响。\n","permalink":"https://fireflyyh.top/posts/tlpi/nonreentrant/","summary":"TLPI 21.1.2: 可重入函数和异步信号安全函数 代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 #define _XOPEN_SOURCE 600 #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;signal.h\u0026gt; #include \u0026lt;string.h\u0026gt; #include \u0026lt;crypt.h\u0026gt; #include \u0026#34;tlpi_hdr.h\u0026#34; static char *str2; static int handled = 0; // 设置处理器函数，一旦遇上SIGINT，便对str2进行加密 static void handler(int sig) { crypt(str2, \u0026#34;xx\u0026#34;); handled++; } int main(int argc, char *argv[]) { char *cr1; int callNum, mismatch; struct sigaction sa; if (argc !","title":"信号处理函数中调用不可重入的函数"},{"content":"TLPI 21.3：在备选栈中处理信号：sigaltstack() 代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 static void sigsegvHandler(int sig) { int x; // 捕捉信号，并通过局部变量的位置来大致判断为当前函数所分配的空间处于什么位置 printf(\u0026#34;Caught signal %d (%s)\\n\u0026#34;, sig, strsignal(sig)); printf(\u0026#34;Top of handler stack near %10p\\n\u0026#34;, (void *)\u0026amp;x); // fflush(NULL)的作用是在程序异常终止前确保所有标准输出缓冲区的数据都被写入到相应的输出设备。 fflush(NULL); _exit(EXIT_FAILURE); } static void overflowStack(int callNum) { char a[100000]; // 此类分配数组方式为栈上分配 printf(\u0026#34;Call %4d - top of stack near %10p\\n\u0026#34;, callNum, \u0026amp;a[0]); overflowStack(callNum + 1); // 无限递归调用，不断在栈上分配空间，每次分配100000字节以上 } int main(int argc, char *argv[]) { stack_t sigstack; struct sigaction sa; int j; printf(\u0026#34;Top of standard stack is near %10p\\n\u0026#34;, (void *)\u0026amp;j); // 分配备用栈并通知内核 // 在堆当中分配备用栈 sigstack.ss_sp = malloc(SIGSTKSZ); if (sigstack.ss_sp == NULL) errExit(\u0026#34;malloc\u0026#34;); sigstack.ss_size = SIGSTKSZ; // 默认栈大小 sigstack.ss_flags = 0; // sig alt stack if (sigaltstack(\u0026amp;sigstack, NULL) == -1) errExit(\u0026#34;sigaltstack\u0026#34;); // sbrk(0)返回当前进程的堆顶地址 printf(\u0026#34;Alternate stack is at %10p-%p\\n\u0026#34;, sigstack.ss_sp, (char *)sbrk(0) - 1); // 设置信号处理器函数，并且不阻塞任何信号 sa.sa_handler = sigsegvHandler; sigemptyset(\u0026amp;sa.sa_mask); sa.sa_flags = SA_ONSTACK; if (sigaction(SIGSEGV, \u0026amp;sa, NULL) == -1) errExit(\u0026#34;sigaction\u0026#34;); // 递归调用overflowStack() overflowStack(1); } 解释 ulimit 使用ulimit -s unlimited会负责移除当前 shell 会话时设置的任何 RLIMIT_STACK 资源限制，对其他 shell 会话无影响。但是在使用了这句话之后调用程序，系统会一直打印信息至Call 78522 - top of stack near 0x7ffa472aac80，即递归调用了78522次，然后[1] 16044 killed ./T_SIGALTSTACK直接将进程杀死。并没有出现预期的Caught signal 11 (Segmentation fault)。\n于是我将限制资源回复成了默认大小，再进行调用，出现了预期的结果：\n1 2 3 4 5 6 7 8 Top of standard stack is near 0x7ffd97398ebc Alternate stack is at 0x55fb092fd6b0-0x55fb0931dfff Call 1 - top of stack near 0x7ffd973807e0 Call 2 - top of stack near 0x7ffd97368110 ... Call 83 - top of stack near 0x7ffd96bad940 Caught signal 11 (Segmentation fault) Top of handler stack near 0x55fb092ff164 经过查阅资料，当使用ulimit -s unlimited来移除栈大小限制时，程序可以无限制地使用栈空间。在本代码中，overflowStack()函数通过递归调用，不断分配大量内存（每次调用分配100000字节），很快会耗尽系统的可用内存。 当系统检测到内存耗尽时，会启动 OOM Killer 来终止占用大量内存的进程。当程序在递归调用了78522次后，占用了大量内存，触发了 OOM Killer，直接将进程终止，所以进程被直接杀死而不是触发 SIGSEGV 信号处理程序。\nfflush(NULL) 关于fflush(NULL)，是为了在程序异常终止前确保所有标准输出缓冲区的数据都被写入到相应的输出设备。尽管程序有固定的执行顺序，但标准输出（stdout）通常是缓冲的。这意味着输出的数据并不会立即被写入到屏幕或文件，而是先存储在缓冲区中，直到缓冲区满或者遇到刷新操作（如换行、fflush 调用等）才会被真正写出。\n在正常情况下，printf输出的数据会在适当的时机刷新到屏幕上。但是，如果程序异常终止，缓冲区中的数据可能没有机会被刷新，从而导致部分或全部输出丢失。exit 函数会执行标准库的清理操作，包括刷新缓冲区。但 _exit 函数是直接退出，不进行任何清理操作，包括缓冲区的刷新。这也就是为什么示例程序在_exit() 之前要进行fflush() 操作。\n","permalink":"https://fireflyyh.top/posts/tlpi/t_sigaltstack/","summary":"TLPI 21.3：在备选栈中处理信号：sigaltstack() 代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 static void sigsegvHandler(int sig) { int x; // 捕捉信号，并通过局部变量的位置来大致判断为当前函数所分配的空间处于什么位置 printf(\u0026#34;Caught signal %d (%s)\\n\u0026#34;, sig, strsignal(sig)); printf(\u0026#34;Top of handler stack near %10p\\n\u0026#34;, (void *)\u0026amp;x); // fflush(NULL)的作用是在程序异常终止前确保所有标准输出缓冲区的数据都被写入到相应的输出设备。 fflush(NULL); _exit(EXIT_FAILURE); } static void overflowStack(int callNum) { char a[100000]; // 此类分配数组方式为栈上分配 printf(\u0026#34;Call %4d - top of stack near %10p\\n\u0026#34;, callNum, \u0026amp;a[0]); overflowStack(callNum + 1); // 无限递归调用，不断在栈上分配空间，每次分配100000字节以上 } int main(int argc, char *argv[]) { stack_t sigstack; struct sigaction sa; int j; printf(\u0026#34;Top of standard stack is near %10p\\n\u0026#34;, (void *)\u0026amp;j); // 分配备用栈并通知内核 // 在堆当中分配备用栈 sigstack.","title":"在备选栈中处理信号"},{"content":"处理SIGCHLD信号 1 2 3 4 5 6 7 8 9 10 11 12 void sig_chld(int signo) { pid_t pid; int stat; // wait()是为了清理僵死进程 // pid = wait(\u0026amp;stat); // printf(\u0026#34;child %d terminated\\n\u0026#34;, pid); while ((pid = waitpid(-1, \u0026amp;stat, WNOHANG)) \u0026gt; 0) printf(\u0026#34;child %d terminated\\n\u0026#34;, pid); return; } wait版本行不通的原因 若服务器和客户端在同一主机上，则该信号处理函数只执行过一次（根据UNP的描述是这样的，但是本人实测，信号处理器函数执行了两次）。 但是如果我们在不同的主机上运行客户和服务器，那么信号处理器函数一般执行两次：一次是由第一个产生的信号引起的，由于另外4个信号在信号处理函数第一次执行时发生，因为该处理函数仅仅再被调用一次，从而留下3个僵死进程。 不过有的时候，根据FIN到达主机的时机，信号处理函数可能会执行3次甚至4次\n根据本人猜想，如果在相同主机测试，由于没有网络数据传播时延的影响，本机的客户端所有五个FIN都几乎在同一时间传递给服务器， 从而使得服务器的5个子进程基本在同一时刻终止，从而5个SIGCHLD在同一时刻发送给父进程，都在第一个信号处理函数执行之前发生， 而Unix信号一般是不排队的（这里详见TLPI对应的小节），因此信号处理函数只执行一次。\n但是如果在不同主机测试，由于网络数据传播，各个FIN到达服务器的时间差较大一些，导致FIN以不可忽略的时差到达服务器。 例如在处理第一个SIGCHLD信号时，其他FIN才到达，从而引起信号处理函数执行多次。\n1 2 3 4 5 6 7 ➜ bin git:(main) ✗ ./TCPSERV03 \u0026amp; [1] 65001 ➜ bin git:(main) ✗ ./TCPCLI04 127.0.0.1 hell hell child 65324 terminated child 65325 terminated waitpid()版本行得通 清理僵尸进程 1 2 while ((pid = waitpid(-1, \u0026amp;stat, WNOHANG)) \u0026gt; 0) printf(\u0026#34;child %d terminated\\n\u0026#34;, pid); waitpid(-1, \u0026amp;stat, WNOHANG)：这部分代码是关键。waitpid 函数用于等待子进程的状态改变。\npid = -1：表示等待任何子进程。 \u0026amp;stat：是一个指向 int 的指针，用于存储子进程的终止状态。 WNOHANG：这个选项告诉 waitpid 非阻塞运行。如果没有子进程终止，waitpid 将立即返回，而不是阻塞等待。 while 循环：这个循环会一直执行，直到没有子进程终止为止。waitpid 返回值会是：\n大于 0 的值：表示终止的子进程的 PID，表明有一个子进程结束。 0：表示没有子进程终止。 -1：表示没有更多的子进程或者调用失败。 代码总结 这段代码实现了一个信号处理函数 sig_chld，用于处理 SIGCHLD 信号。当一个子进程终止时，父进程会收到 SIGCHLD 信号，触发这个处理函数。该函数使用 waitpid 结合 WNOHANG 选项来处理所有终止的子进程，并避免产生僵尸进程。僵尸进程会占用系统资源，因此在接收到 SIGCHLD 信号时及时清理子进程的退出状态是很重要的。\n这种处理方式确保了父进程可以继续处理多个子进程的终止，而不会因为某个子进程的终止而导致阻塞，从而避免产生僵尸进程。\n运行结果：\n1 2 3 4 5 6 7 8 9 10 ➜ bin git:(main) ✗ ./TCPSERV04 \u0026amp; [1] 56786 ➜ bin git:(main) ✗ ./TCPCLI04 127.0.0.1 htl htl child 56992 terminated child 56993 terminated child 56994 terminated child 56995 terminated child 56996 terminated 不在循环内部使用wait()的原因 在信号处理函数中使用 waitpid() 而不是 wait() 的原因主要涉及到以下几个方面：\n1. 避免遗漏子进程的终止 waitpid() 在循环中与 WNOHANG 选项一起使用，可以确保所有已终止的子进程都被处理。因为 waitpid() 在每次调用时返回一个已终止的子进程的 PID，当没有更多子进程终止时返回 0。通过循环调用 waitpid()，你可以确保每个已终止的子进程都被正确处理，从而避免遗漏。\n相比之下，wait() 只能一次等待一个子进程终止。如果有多个子进程在短时间内终止，而 wait() 只被调用一次，可能会遗漏处理其中的一些子进程。这些未处理的子进程就会成为僵尸进程，浪费系统资源。\n2. 非阻塞的等待 waitpid() 与 WNOHANG 选项结合使用是非阻塞的，它允许信号处理程序检查所有子进程是否终止，而不会因没有终止的子进程而阻塞。这样，信号处理函数可以迅速返回，继续处理其他任务。\n在没有循环时，调用wait()不会导致出现阻塞等待，因为当进入该处理函数时，说明必然有函数终止了，只不过是1个还是多个的问题 无论是一个还是多个，wait()都只能处理掉一个，然后返回，退出处理器函数\n如果在循环中调用 wait()，一旦没有子进程终止，wait() 就会阻塞，这会导致整个信号处理程序挂起，不能立即返回。 例如，第一个进程终止后，父进程进入了处理器函数，处理了第一个进程之后，便会继续循环等待下一个终止进程， 若是下一个进程迟迟不进入终止状态，则父进程则需要一直阻塞等待。 阻塞在信号处理程序中通常是不被推荐的，因为这可能导致系统其他部分的延迟或不良的响应时间。\n3. 处理多个子进程的终止 在某些情况下，多个子进程可能在非常短的时间内几乎同时终止。如果仅调用 wait()，信号处理程序可能只能处理一个子进程的终止。使用 waitpid() 的循环可以确保处理所有已终止的子进程。 4. 控制和灵活性 waitpid() 提供了更多的控制和灵活性。例如，使用 waitpid() 可以指定等待特定的子进程，或根据不同的选项处理子进程。相比之下，wait() 的功能比较有限，只能简单地等待任意一个子进程的终止。 ","permalink":"https://fireflyyh.top/posts/unp/sigchldwaitpid/","summary":"处理SIGCHLD信号 1 2 3 4 5 6 7 8 9 10 11 12 void sig_chld(int signo) { pid_t pid; int stat; // wait()是为了清理僵死进程 // pid = wait(\u0026amp;stat); // printf(\u0026#34;child %d terminated\\n\u0026#34;, pid); while ((pid = waitpid(-1, \u0026amp;stat, WNOHANG)) \u0026gt; 0) printf(\u0026#34;child %d terminated\\n\u0026#34;, pid); return; } wait版本行不通的原因 若服务器和客户端在同一主机上，则该信号处理函数只执行过一次（根据UNP的描述是这样的，但是本人实测，信号处理器函数执行了两次）。 但是如果我们在不同的主机上运行客户和服务器，那么信号处理器函数一般执行两次：一次是由第一个产生的信号引起的，由于另外4个信号在信号处理函数第一次执行时发生，因为该处理函数仅仅再被调用一次，从而留下3个僵死进程。 不过有的时候，根据FIN到达主机的时机，信号处理函数可能会执行3次甚至4次\n根据本人猜想，如果在相同主机测试，由于没有网络数据传播时延的影响，本机的客户端所有五个FIN都几乎在同一时间传递给服务器， 从而使得服务器的5个子进程基本在同一时刻终止，从而5个SIGCHLD在同一时刻发送给父进程，都在第一个信号处理函数执行之前发生， 而Unix信号一般是不排队的（这里详见TLPI对应的小节），因此信号处理函数只执行一次。\n但是如果在不同主机测试，由于网络数据传播，各个FIN到达服务器的时间差较大一些，导致FIN以不可忽略的时差到达服务器。 例如在处理第一个SIGCHLD信号时，其他FIN才到达，从而引起信号处理函数执行多次。\n1 2 3 4 5 6 7 ➜ bin git:(main) ✗ ./TCPSERV03 \u0026amp; [1] 65001 ➜ bin git:(main) ✗ .","title":"处理SIGCHLD信号"},{"content":"之前搭建hexo博客，是将其部署到 github 中，通过 github.io 来访问，但是速度感人，所以本次尝试将 hugo 博客部署到阿里云服务器，通过域名进行访问，本文参考了hugo博客部署到腾讯云轻量级服务器。 由于是我第一次使用 nginx，所以如果遇到什么问题，请多海涵并且可以参考其他博客或网络资料。\n在部署之前，我已经有了阿里云服务器（配置为2核2GB）、阿里云购买的域名（fireflyyh.top）。\n1. 服务器端下载并安装nginx 1.1 安装nginx 在 ubuntu 环境下： 安装 nginx\n1 sudo apt install nginx 将 nginx 设置为开机启动：\n1 sudo systemctl enable nginx 启动 nginx：\n1 sudo systemctl start nginx 1.2 测试nginx 查看 nginx 状态\n1 sudo systemctl status nginx 如果没问题，则会出现：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 ● nginx.service - A high performance web server and a reverse proxy server Loaded: loaded (/lib/systemd/system/nginx.service; enabled; vendor preset: enabled) Active: active (running) since Fri 2024-07-26 21:46:50 CST; 1 day 13h ago Docs: man:nginx(8) Process: 164834 ExecStartPre=/usr/sbin/nginx -t -q -g daemon on; master_process on; (code=exited, status=0/SUCCESS) Process: 164836 ExecStart=/usr/sbin/nginx -g daemon on; master_process on; (code=exited, status=0/SUCCESS) Main PID: 164837 (nginx) Tasks: 3 (limit: 1947) Memory: 4.1M CPU: 26ms CGroup: /system.slice/nginx.service ├─164837 \u0026#34;nginx: master process /usr/sbin/nginx -g daemon on; master_process on;\u0026#34; ├─164838 \u0026#34;nginx: worker process\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; └─164839 \u0026#34;nginx: worker process\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; Jul 26 21:46:50 Firefly-Aliyun systemd[1]: Starting A high performance web server and a reverse proxy server... Jul 26 21:46:50 Firefly-Aliyun systemd[1]: Started A high performance web server and a reverse proxy server. 通过阿里云服务器管理面板中的安全组标签，将服务器的80端口开放。接下来访问http://\u0026lt;服务器IP地址\u0026gt;，如果出现了 nginx 页面，则代表着配置成功。\n2. 配置nginx 进入/etc/nginx/，目录树如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 . ├── conf.d ├── fastcgi.conf ├── fastcgi_params ├── koi-utf ├── koi-win ├── mime.types ├── modules-available ├── modules-enabled │ ├── 50-mod-http-geoip2.conf -\u0026gt; /usr/share/nginx/modules-available/mod-http-geoip2.conf │ ├── 50-mod-http-image-filter.conf -\u0026gt; /usr/share/nginx/modules-available/mod-http-image-filter.conf │ ├── 50-mod-http-xslt-filter.conf -\u0026gt; /usr/share/nginx/modules-available/mod-http-xslt-filter.conf │ ├── 50-mod-mail.conf -\u0026gt; /usr/share/nginx/modules-available/mod-mail.conf │ ├── 50-mod-stream.conf -\u0026gt; /usr/share/nginx/modules-available/mod-stream.conf │ └── 70-mod-stream-geoip2.conf -\u0026gt; /usr/share/nginx/modules-available/mod-stream-geoip2.conf ├── nginx.conf ├── proxy_params ├── scgi_params ├── sites-available │ └── default ├── sites-enabled │ └── default -\u0026gt; /etc/nginx/sites-available/default ├── snippets │ ├── fastcgi-php.conf │ └── snakeoil.conf ├── uwsgi_params └── win-utf 根据参考博客，要在nginx.conf文件中编辑Server字段，但是在我的这个文件中，并没有出现该字段。经过查阅资料，可以在./sites-available/default当中编辑。\n当没有SSL证书时：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 server { listen 80 default_server; listen [::]:80 default_server; # 修改页面所在目录 root /home/firefly/Codes/blog/public; # Add index.php to the list if you are using PHP index index.html index.htm index.nginx-debian.html; # 修改域名 server_name www.staryh.top; # 修改 location / { # First attempt to serve request as file, then # as directory, then fall back to displaying a 404. root /home/firefly/Codes/blog/public; index index.html index.htm; # try_files $uri $uri/ =404; } error_page 404 /404.html; location = /404.html { root /home/firefly/Codes/blog/public; } } 经过上述修改之后，输入服务器 IP 地址，就可以访问了\n3. 将域名绑定到服务器 需要域名备案，否则访问不了 在阿里云购买的域名，然后通过更改 DNS 解析来将该域名定向至该服务器的IP地址\n4. 实现本机和服务器的public文件夹同步 在这一部分，我的想法比较复杂。\n将本地的博客文件夹放到 github 中，方便更多人能够访问我的博客所有的文件。 考虑到github的访问速度，打算在 gitee 中建立一个镜像的仓库，以实现 github 和 gitee 的博客文件夹的同步。 这样服务器只需要 pull gitee 仓库中的 public 子文件夹，便可以得到本地主机 push 到 github 仓库中的 public 文件夹。 4.1 本地-\u0026gt;github 将本地博客文件夹 push 到github仓库中\n4.2 github-\u0026gt;gitee 在 gitee 上绑定 github 账号； 在 gitee 中创建同名仓库，在仓库的管理标签页，选择仓库镜像管理，添加镜像，选择镜像方向为pull gitee \u0026lt;- github，选择正确的镜像仓库，并添加私人令牌，私人令牌在github界面-\u0026gt;用户头像-\u0026gt;settings-\u0026gt;developer settings-\u0026gt;personal access tokens中获取，勾选自动同步。 这样每次本地编辑完并上传 github 之后，稍等片刻就能在 gitee 看到修改了😊 截止到写本篇博客时，gitee 的仓库镜像管理功能一直存在，且可以自动同步。如果该自动同步功能不见了，可以尝试一篇教你代码同步 Github 和 Gitee中的做法。\n4.3 gitee-\u0026gt;服务器 进入到修改页面所在目录的父目录/home/firefly/Codes/blog，删除原来通过xtfp传输来的public文件夹； 在本地仓库根目录下，通过 git config core.sparseCheckout true 来启用sparseCheckout； 打开./.git/info，然后编辑其中的sparseCheckout文件（如果没有可以新建），将需要指定 pull 的文件夹位置输入进去：/public； 回到blog目录，添加远程仓库，并 pull（在pull的时候遇到了公私钥导致无法访问的问题，具体解决参考了解决 “fatal: Could not read from remote repository.“）。 1 git remote add origin git@gitee.com:yourname/yourrepo.git 5. SSL证书 5.1 获得SSL证书 由于阿里云策略改变，目前免费的只有个人测试证书（原免费证书）。\n根据Nginx或Tengine服务器配置SSL证书来进行配置。 其中，将下载的证书相关文件解压缩到/etc/nginx/中，\n5.3 修改nginx配置 同样地，在default文件中，结合了本文提到的两个博客，增加以下内容：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 server { listen 443 ssl; server_name www.fireflyyh.top; root /home/firefly/Codes/blog/public; ssl_certificate /etc/nginx/fireflyyh.top.pem; ssl_certificate_key /etc/nginx/fireflyyh.top.key; ssl_session_cache shared:SSL:1m; ssl_session_timeout 5m; #自定义设置使用的TLS协议的类型以及加密套件（以下为配置示例，请您自行评估是否需要配置） #TLS协议版本越高，HTTPS通信的安全性越高，但是相较于低版本TLS协议，高版本TLS协议对浏览器的兼容性较差。 ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4; ssl_protocols TLSv1.1 TLSv1.2 TLSv1.3; #表示优先使用服务端加密套件。默认开启 ssl_prefer_server_ciphers on; error_page 404 /404.html; location = /404.html { root /home/firefly/Codes/blog/public; } } 然后重启nginx服务：sudo systemctl restart nginx。\n6. 站点分析 6.1 Google Analytics 本博客建立时所采用的 hugo 版本为 v0.129.0，采用的主题 PaperMod 的版本为 v7.0。\n获取追踪ID 登录Google Analytics：\n进入数据流 根据网站创建新的数据流 在设置 Google 代码的区域：\n1 2 3 4 5 6 7 8 9 \u0026lt;!-- Google tag (gtag.js) --\u0026gt; \u0026lt;script async src=\u0026#34;https://www.googletagmanager.com/gtag/js?id=G-XXXXXXXXXX\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script\u0026gt; window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag(\u0026#39;js\u0026#39;, new Date()); gtag(\u0026#39;config\u0026#39;, \u0026#39;G-XXXXXXXXXX\u0026#39;); \u0026lt;/script\u0026gt; 其中的G-XXXXXXXXXX就是所需的追踪 ID。\n修改 hugo 配置 在网站根目录中的hugo.toml中，将[params.analytics.google]字段删去，将文件开头的googleAnalytics字段修改为ID，并在末尾添加以下信息： 1 2 3 [services] [services.googleAnalytics] ID = \u0026#39;G-XXXXXXXXXX\u0026#39; 在主题的layouts文件夹下新建文件夹_internal，并在其中新建文件google_analytics.html，将之前在 Google 代码区域获得的代码放入其中。\n修改layouts/partials/文件夹中的head.html，在末尾增加：\n1 2 3 {{- with site.Config.Services.GoogleAnalytics.ID -}} {{- template \u0026#34;_internal/google_analytics.html\u0026#34; . -}} {{- end -}} 重新部署，过一段时间就能在 Google Analytics 页面看到访问的数据了。但是奇怪的是在代码 6.2 百度统计 新增站点 登录百度统计的使用设置界面，按照要求新增网站，然后点击“获取代码”按钮，将“新版统计代码获取”区域的代码复制下来。\n修改 html 进入到 PaperMod 主题的layouts/partials文件夹，修改extend_head.html文件，在其中加入刚刚复制下来的代码。\n检测生效 重新部署。然后用手动检查或者百度统计助手来检测是否添加功能成功。\n","permalink":"https://fireflyyh.top/posts/blog_configuration/deploy/","summary":"之前搭建hexo博客，是将其部署到 github 中，通过 github.io 来访问，但是速度感人，所以本次尝试将 hugo 博客部署到阿里云服务器，通过域名进行访问，本文参考了hugo博客部署到腾讯云轻量级服务器。 由于是我第一次使用 nginx，所以如果遇到什么问题，请多海涵并且可以参考其他博客或网络资料。\n在部署之前，我已经有了阿里云服务器（配置为2核2GB）、阿里云购买的域名（fireflyyh.top）。\n1. 服务器端下载并安装nginx 1.1 安装nginx 在 ubuntu 环境下： 安装 nginx\n1 sudo apt install nginx 将 nginx 设置为开机启动：\n1 sudo systemctl enable nginx 启动 nginx：\n1 sudo systemctl start nginx 1.2 测试nginx 查看 nginx 状态\n1 sudo systemctl status nginx 如果没问题，则会出现：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 ● nginx.service - A high performance web server and a reverse proxy server Loaded: loaded (/lib/systemd/system/nginx.","title":"将博客部署到阿里云服务器"},{"content":"TLPI 21.2.1：在信号处理器函数中执行非本地跳转 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 #define _GNU_SOURCE // 添加该定义以正常使用strsignal()、sigaction() #include \u0026lt;string.h\u0026gt; #include \u0026lt;setjmp.h\u0026gt; #include \u0026lt;signal.h\u0026gt; #include \u0026#34;signal_functions.h\u0026#34; #include \u0026#34;tlpi_hdr.h\u0026#34; static volatile sig_atomic_t canJump = 0; #ifdef USE_SIGSETJMP static sigjmp_buf senv; #else static jmp_buf env; #endif static void handler(int sig) { printf(\u0026#34;Received signal %d (%s), signal mask is:\\n\u0026#34;, sig, strsignal(sig)); printSigMask(stdout, NULL); if (!canJump) { // 若canJump为0 printf(\u0026#34;\u0026#39;env\u0026#39; buffer not yet set, doing a simple return\\n\u0026#34;); return; } #ifdef USE_SIGSETJMP siglongjmp(senv, 1); #else longjmp(env, 1); #endif } int main(int argc, char *argv[]) { struct sigaction sa; printSigMask(stdout, \u0026#34;Signal mask at startup:\\n\u0026#34;); // 打印最开始的信号掩码 sigemptyset(\u0026amp;sa.sa_mask); sa.sa_flags = 0; sa.sa_handler = handler; if (sigaction (SIGINT, \u0026amp;sa, NULL) == -1) errExit(\u0026#34;sigaction\u0026#34;); #ifdef USE_SIGSETJMP printf(\u0026#34;Calling sigsetjmp()\\n\u0026#34;); /* */ if (sigsetjmp(senv, 1) == 0) #else printf(\u0026#34;Calling setjmp()\\n\u0026#34;); // 设置跳转目标，并初始化env if (setjmp(env) == 0) #endif // 当从处理器函数直接返回之后才会执行该语句 canJump = 1; else // 当从处理器函数执行非本地跳转之后才会执行该语句 printSigMask(stdout, \u0026#34;After jump from handler, signal mask is:\\n\u0026#34;); printf(\u0026#34;Will be paused\\n\u0026#34;); for (;;) /* 等待信号， 若接收到SIGINT，则跳转到处理器函数中，再由longjmp()/siglongjmp()跳转到setjmp()/sigsetjmp() 具体是哪个跳转函数，则取决于是否宏定义了USE_SIGSETJMP */ pause(); } 解释 canjump的用法 接收到信号的时机有两种：\n在setjmp(env)之前，在这种情况下，跳转目标尚未建立，这将导致处理器函数使用尚未初始化的 env 缓冲区来执行非本地跳转； 在setjmp(env)之后，在这种情况下，跳转目标被建立，env已被初始化在执行longjmp()/siglongjmp()之后，可以正确地将一些信息保存。 为了避免出现第一种情况，设置了 canJump 变量，当第一次执行了setjmp(env)之后canjump被设置为1，代表着可以正确执行非本地跳转。然后在此Handler()的if (canJump)处，若 canjump 为0，说明接收到信号的时机是在 set 之前，则不能够进行跳转，而是直接从处理器函数返回。\n两种跳转方法的区别 sigsetjmp()比setjmp()多出一个参数 savesigs。如果指定 savesigs 为非 0，那么会将调用 sigsetjmp()时进程的当前信号掩码保存于 env 中，之后通过指定相同 env 参数的siglongjmp()调用进行恢复。如果 savesigs 为0，则不会保存和恢复进程的信号掩码。\n","permalink":"https://fireflyyh.top/posts/tlpi/sigmask_longjmp/","summary":"TLPI 21.2.1：在信号处理器函数中执行非本地跳转 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 #define _GNU_SOURCE // 添加该定义以正常使用strsignal()、sigaction() #include \u0026lt;string.","title":"在信号处理器函数中执行非本地跳转"},{"content":"16年 单周期数据通路 单周期数据通路是一种简单的数据通路设计，每个时钟周期执行一条完整的指令，即每条指令的CPI为1，要考虑比较慢的指令，所以处理器的时钟频率较低。 这意味着每条指令执行过程中任何数据通路单元都只能被用一次，如果需要使用多次则必须将该数据通路单元复制多份。\n控制信号是CU根据指令操作码发出的信号，对于单周期处理器来说，每条指令的执行只有一个时钟周期，而在一个时钟周期内控制信号并不会变化。\n单周期数据通路必须有独立的指令存储器和数据存储器，因为处理器在一个周期内只能操作每个部件一次，而在一个周期内不可能对一个单端口存储器进行两次存取。且无法使用单总线数据通路，因为单总线数据通路将所有寄存器的输入出端都连接在一条公共通路上，一个时钟内只允许一次操作，无法完成指令的所有操作。\nTSL指令实现互斥 1 2 3 4 5 6 do { while (TSL(\u0026amp;lock)); critical section; lock = FALSE; ...... } while (TRUE); 退出临界区的进程负责唤醒就绪态进程？\n因为在TSL方法下，一个进程只有两种状态：\n运行态：用户处于了do{ }中，那么不管是是在其中的while (TSL(\u0026amp;lock))不断地循环，还是在访问临界资源，都是占用着CPU的，也就是处于运行态； 就绪态：若是在执行过程中由于并发所需要（如时间片到了），被其他进程占用了CPU，就变成了就绪态； 但是不会处于阻塞态，因为若是在等待临界资源，则会一直处于while (TSL(\u0026amp;lock));中，而且不会主动放弃CPU变成阻塞态（阻塞是一个主动的过程）。故不存在阻塞态的进城来给退出临界区的进程唤醒。\n等待进入临界区的进程不会主动放弃CPU，故上述代码不满足“让权等待”的同步准则。因为会一直停留在执行while(TSL(\u0026amp;lock))的循环中，该语句应在开中断下进行，否则一直处于该循环且不被其他进程中断可能会导致系统终止。\n操作系统的发展 手工发展阶段（无操作系统）：\n所有工作都要人干预，用户独占全机。\n特点：用户独占全机、CPU等待手工操作；\n缺点：人机矛盾及 CPU 和 I/O 设备之间速度不匹配的矛盾，因此发展出了批处理系统。\n批处理阶段（开始出现操作系统）：\n单道批处理：系统对作业的处理是成批进行的，但内存中始终保持一道作业。\n特点：单道性、自动性、顺序性。\n缺点：每次主机内存中仅存放一道作业，每当它在运行时发出I/O请求后，高速的 CPU 便处于等待低速的 I/O 完成的状态。\n为了进一步提高资源的利用率和系统的吞吐量，引入了多道程序技术。 多道批处理：多道程序设计技术允许多个程序同时进入内存并允许它们在 CPU 中交替地运行。\n特点：多道、宏观上并行、微观上串行。\n优点：资源利用率高，多道程序共享计算机资源，从而使各种资源得到充分利用；系统吞吐量大， CPU 和其他资源保持“忙碌”状态。 缺点：用户响应的时间较长；不提供人机交互能力，用户既不能了解自己的程序的运行情况，又不能控制计算机。 因此发展出了分时操作系统。 分时操作系统：\n分时操作系统是指多个用户通过终端同时共享一台主机，这些终端连接在主机上，用户可以同时（同时性）与主机进行交互（交互性）操作而互不干扰（独立性）。分时系统采用时间片轮转方式使一台计算机同时为多个终端服务，使用户能够对系统的及时响应感到满意（及时性）。分时系统也是支持多道程序设计的系统，但它不同于多道批处理系统。多道批处理是实现作业自动控制而无须人工干预的系统，而分时系统是实现人机交互的系统。\n特点：同时性、交互性、独立性、及时性。\n优点：较好地解决了人机交互问题。\n缺点：在一些应用场合，需要系统能对外部的信息在规定的时间（比时间片的时间还短）内做出处理（比如飞机订票系统或导弹制导系统），因此，实时操作系统应运而生。\n描述 特点 优点 缺点 手工操作阶段 所有工作都要人干预 用户独占全机、CPU等待手工操作； 不会出现因资源己被其他用户占用而等待的情况 资源利用率低，人机矛盾及 CPU 和 I/O 设备之间速度不匹配的矛盾，因此发展出了批处理系统。 单道批处理 系统对作业的处理是成批进行的，但内存中始终保持一道作业。 单道性、自动性、顺序性。 （开始出现操作系统） 每次主机内存中仅存放一道作业，每当它在运行时发出I/O请求后，高速的 CPU 便处于等待低速的 I/O 完成的状态。 为了进一步提高资源的利用率和系统的吞吐量，引入了多道程序技术。 多道批处理 多道程序设计技术允许多个程序同时进入内存并允许它们在 CPU 中交替地运行。 多道性、宏观上并行、微观上串行。 资源利用率高，多道程序共享计算机资源，从而使各种资源得到充分利用；系统吞吐量大， CPU 和其他资源保持“忙碌”状态。 用户响应的时间较长；不提供人机交互能力，用户既不能了解自己的程序的运行情况，又不能控制计算机。 因此发展出了分时操作系统。 分时操作系统 用户可以同时（同时性）与主机进行交互（交互性）操作而互不干扰（独立性）。分时系统采用时间片轮转方式使一台计算机同时为多个终端服务，使用户能够对系统的及时响应感到满意（及时性）。 同时性、交互性、独立性、及时性。 较好地解决了人机交互问题。 在一些应用场合，需要系统能对外部的信息在规定的时间（比时间片的时间还短）内做出处理（比如飞机订票系统或导弹制导系统），因此，实时操作系统应运而生。 实时操作系统 为了能在某个时间限制内完成某些紧急任务而不需要时间片排队，诞生了实时操作系统。资源利用率不是其主要追求目标。 及时性、可靠性 管程 管程是由一组数据以及定义在这组数据之上的对这组数据的操作组成的软件模块，这组操作能初始化并改变管程中的数据和同步进程。管程不仅能实现进程间的互斥，而且能实现进程间的同步。\n管程由 4 部分组成：\n管程的名称； 局部于管程内部的共享数据结构说明； 对该数据结构进行操作的一组过程（或函数）； 对局部于管程内部的共享数据设置初始值的语句。 管程具有特性：\n局部于管程的数据只能被局部于管程内的过程所访问； 一个进程只有通过调用管程内的过程才能进入管程访问共享数据； 每次仅允许一个进程在管程内执行某个内部过程（实现互斥）； 互斥访问数据是由编译器实现的，程序员不用关心。 例如，若x是管程内的条件变量，则当进程执行x.wait()时所做的工作是阻塞该进程，并将之插入x的阻塞队列中。\n“条件变量”是管程内部说明和使用的一种特殊变量，其作用类似于信号量机制中的“信号量”，都是用于实现进程同步的。需要注意的是，在同一时刻，管程中只能有一个进程在执行。如果进程 A 执行了x.wait()操作，那么该进程会阻塞，并挂到条件变量 x 对应的阻塞队列上。这样，管程的使用权被释放，就可以有另一个进程进入管程。如果进程 B 执行了x.signal()操作，那么会唤醒 x 对应的阻塞队列队头进程。在 Pascal 语言的管程中，规定只有一个进程要离开管程时才能调用signal()操作。\n四次挥手各自的阶段 17年 顺序存储、链式存储对不同排序方式的影响 由顺序存储变成链式存储后，效率不会降低的有：插入排序、（简单）选择排序、冒泡排序，因为顺序存储下，时间复杂度就是$O(n^2)$，链式存储不会改变其复杂度；\n效率会降低的有：希尔排序、堆排序、快速排序，因为是利用了顺序存储的随机访问特性。\n指令级并行 超流水线：通过增加流水线级数来使更多的指令同时在流水线中重叠执行。超流水线并没有改变CPI的值，CPI还是1，但是，因为理想情况下流水线的加速比与流水段的数目成正比，流水段越多，时钟周期越短，主频越高，指令吞吐率越高，所以超流水线的性能比普通流水线好。然而，流水线级数越多，用于流水段寄存器的开销就越大，因而流水线级数是有限制的，不可能无限增加。 在《计算机组成与设计：软件/硬件接口》书中，有一个形象的解释：\n任何一个经常光顾洗衣店的人都会不自觉地使用流水线技术。非流水线方式的洗衣过程包括如下几个步骤：\n把一批脏衣服放入洗衣机里清洗 洗衣机洗完后，把衣服取出并放入烘干机中。 烘干衣服后，将衣服从烘干机中取出，然后放在桌子上叠起来。 叠好衣服后，请你的室友帮忙把桌子上的衣服收好。 当你的室友把这批干净衣服从桌子上拿走后，再开始洗下一批脏衣服。采用流水线的方法将节省大量的时间，如图 4-25 所示。当把第一批脏衣服从洗衣机里取出放入烘干机之后，就可以把第二批脏衣服放入洗衣机里进行清洗了。当第一批衣服被烘干之后，就可以将它们叠起来，同时把洗净的下一批湿衣服放入烘干机中，同时再将下一批脏衣服放入洗衣机里清洗。接着让你的室友把第一批衣服从桌子上收好，而你开始叠第二批衣服，这时烘干机中放的是第三批衣服，同时可以把第四批脏衣服放入洗衣机清洗了。这样，所有的洗衣步骤（流水线的步骤）都在同时操作。只要在每一个操作步骤中都有独立的工作单元时，我们就可以采用流水线的方式来快速完成任务了。\n有两种方法可以增加潜在的指令级并行程度：\n第一种是增加流水线的深度以重叠更多的指令。还是用洗衣店的例子来说明，假设洗衣机周期比其他机器的周期要长，我们可以把洗衣机划分成三个机器，分别完成原洗衣机洗、漂、甩三个功能。这样我们就将四级流水线变成了六级流水线。为了达到完全的加速效果，我们需要重新平衡其他步骤使得它们的长度相同，在处理器和洗衣店中都是这样。因为更多的操作被重叠，有更多的并行性被挖掘出来。\n通过增加流水线级数来使更多的指令同时在流水线中重叠执行。超流水线并没有改变CPI的值，CPI还是1，但是，因为理想情况下流水线的加速比与流水段的数目成正比，流水段越多，时钟周期越短，主频越高，指令吞吐率越高，所以超流水线的性能比普通流水线好。然而，流水线级数越多，用于流水段寄存器的开销就越大，因而流水线级数是有限制的，不可能无限增加。\n另一种方法是复制计算机内部部件的数量，使得每个流水级可以启动多条指令。这种技术一般被称为多发射。一个多发射的洗衣店会把原有的一台洗衣机和烘干机替换为三台洗衣机和三台烘干机。还需要雇用更多的洗衣工来折叠和存储三倍于原来的衣服。这种方法的缺点是需要额外的工作让所有机器同时运转并将负载传到下个流水级。\n实现多发射流水线必须完成以下两个任务：指令打包和冒险处理。指令打包任务就是将能够并行处理的多条指令同时发送到发射槽中，因此处理器必须知道每个周期能发射几条指令，哪些指令可以同时发射。这通过推测技术来完成，可以由编译器或处理器通过猜测指令执行结果来调整指令执行顺序。根据推测任务主要由编译器静态完成还是由处理器动态执行，可将多发射技术分为两类：静态多发射和动态多发射：\n静态多发射主要通过编译器静态推测来辅助完成“指令打包”和“冒险处理”。指令打包的结果可看成将同时发射的多条指令合并到一个长指令中。通常将一个时钟周期内发射的多个指令看成一条多个操作的长指令，称为一个“发射包“。所以，静态多发射指令最初被称为“超长指令字”。\n动态多发射由处理器硬件动态进行流水线调度来完成“指令打包“和“冒险处理”，能在一个时钟周期内执行一条以上指令。采用动态多发射流水线技术的处理器称为超标量处理器。在简单的超标量处理器中，指令按顺序发射，每个周期由处理器决定是发射一条或多条指令。能结合动态调度技术提高指令执行并行性。\n数据通路包含哪些 机器指令的执行是在数据通路中完成的，通常将指令执行过程中数据所经过的路径（包括路径上的部件）称为数据通路。程序计数器、ALU、通用寄存器、状态寄存器、cache、MMU（主存管理单元）、浮点运算逻辑、异常和中断处理逻辑等都是指令执行过程中数据流经的部件，都属于数据通路的一部分。通常把数据通路中专门进行数据运算的部件称为执行部件(execution unit) 或功能部件(function unit)。数据通路由控制部件进行控制。控制部件根据每条指令功能的不同生成对数据通路的控制信号，因此数据通路不包括控制部件。\n指令执行所用到的元件有两类：组合逻辑元件（也称操作元件）和时序逻辑元件（也称状态元件或存储元件）。故也可以说数据通路由组合逻辑电路和时序逻辑电路组合而成。\n组合逻辑元件的输出只取决于当前的输人。若输入一样，其输出也一样。组合电路的定时不受时钟信号的控制，所有输入信号到达后，经过一定的逻辑门延迟，输出端的值被改变，并一直保持其值不变，直到输入信号改变。数据通路中常用的组合逻辑元件有多路选择器（MUX） 、加法器（Adder） 、算术逻辑部件（ALU）、译码器（Decoder）等。\n时序逻辑元件具有存储功能，输人状态在时钟控制下被写到电路中，并保持电路的输出值不变，直到下一个时钟到达。输人端状态由时钟决定何时被写入，输出端状态随时可以读出。数据通路中的寄存器是一种典型的状态存储元件，根据功能和实现方式的不同，有各种不同类型的寄存器。\n磁盘初始化 低级格式化（物理格式化）：一个新的磁盘是一个空白版，必须分成扇区以便磁盘控制器能读和写，这个过程称为低级格式化（或物理格式化）。低级格式化为磁盘的每个扇区采用特别的数据结构，包括校验码。 磁盘分区：磁盘分为由一个或多个柱面组成的分区，每个分区可以作为一个独立的磁盘。 逻辑格式化（创建文件系统）：在这一步，操作系统将初始的文件系统数据结构存储到磁盘上，包括创建文件系统的根目录，对空闲磁盘块进行管理的数据结构进行初始化（如位示图、空闲分区表、i结点区） 划分扇区不等于磁盘分区。\nMAC帧的地址 “接化发”\n18年 行地址位数和列地址位数的大小关系 在采用引脚复用时，为了提高DRAM的性价比，通常设置行地址位数$r$和列地址位数$c$满足$r\\leq c$且$|r-c|$最小。\n可以提高文件访问速度的措施 提前读：提前读是指读当前盘块时，将下个可能要访问的盘块数据读入缓冲区，以便需要时直接从缓冲区中读取，提高了文件的访问速度； 为文件分配连续的簇； 延迟写：延迟写是先将写数据写入缓冲区，并置上“延迟写”标志，以备不久之后、问，当缓冲区需要再次被分配出去时才将缓冲区数据写入磁盘，减少了访问磁盘的次数，高了文件的访问速度； 采用磁盘高速缓存； 分用复用 发送方的某些应用进程所发送的不同的应用报文，在传输层使用UDP协议进行封装，称为UDP复用，TCP复用概念类似。传输层发送端使用源端口号来区分不同的应用进程； 不管是UDP封装的UDP用户数据报还是TCP协议封装的TCP报文段，在网络层都需要使用IP协议来封装成IP数据报，称为IP复用，IP数据报首部的协议字段的值用来表明封装的是何种协议数据单元，如取值为6表示封装的是TCP报文段，取值为17表示封装的是UDP用户数据报； 接收方网络层收到IP数据报后进行IP分用，根据IP首部的协议字段来向上交付给传输层对应的协议。 接收方传输层根据UDP数据报或TCP报文段首部的目的端口号，向上交付给应用层的相应应用进程。 19年 森林的遍历、多叉树的遍历 树 森林 二叉树 先根遍历 先序遍历 先序遍历 后根遍历 中序遍历 中序遍历 森林的先序遍历也称为先根遍历，中序遍历也称为中根遍历、后根遍历。\n结合了cache和虚拟存储器的CPU访存过程 cache缺失由硬件完成；缺页处理由软件完成，操作系统通过缺页异常处理程序来实现；TLB缺失既可以由硬件来处理也可以软件来处理。用软件处理时，OS通过专门的TLB缺失异常处理程序来实现。\nDMA的一些细节 DMA的数据传送分为预处理、数据传送和后处理3个阶段。\nDMA预处理阶段需要CPU参与，由CPU完成必要的准备工作，由设备驱动程序设置传送参数**。每类设备都配置一个设备驱动程序，设备驱动程序向上层用户程序提供一组标准接口，负责实现对设备发出各种具体操作指令，**用户程序不能直接和 DMA 打交道。 在DMA传送过程中，DMA控制器直接控制总线传输。每次将一个数据块送到主存中后，在下次数据传送前，DMA控制器会再次请求总线使用权（即DMA请求），该请求的响应无需CPU干预； 在所有所需的块传送完成后，DMA传送结束，进入后处理阶段，DMA控制器发出DMA中断，CPU参与中断的处理。 各种动态分区管理方式特点 首次适应（ First Fit ）算法。空闲分区以地址递增的次序链接。分配内存时，从链首开始顺序查找，找到大小能满足要求的第一个空闲分区分配给作业。 邻近适应（ Next Fit) 算法。又称循环首次适应算法，由首次适应算法演变而成。不同之处是，分配内存时从上次查找结束的位置开始继续查找。 最佳适应（ Best Fit ）算法。空闲分区按容量递增的次序形成空闲分区链，找到第一个能满足要求且最小的空闲分区分配给作业，避免“大材小用”。 最坏适应 (Worst Fit ）算法。空闲分区以容量递减的次序链接，找到第一个能满足要求的，即最大的分区，从中分割一部分存储空间给作业。 首次适应算法最简单，通常也是最好和最快的。不过，首次适应算法会使得内存的低地址部分出现很多小的空闲分区，而每次分配查找时都要经过这些分区，因此增加了开销。\n邻近适应算法试图解决这个问题。但它常常导致在内存空间的尾部（因为在一遍扫描中，内存前面部分使用后再释放时，不会参与分配）分裂成小碎片。通常比首次适应算法要差。\n最佳适应算法虽然称为“最佳”，但是性能通常很差，因为每次最佳的分配会留下很小的难以利用的内存块，会产生最多的外部碎片。\n最坏适应算法与最佳适应算法相反，它选择最大的可用块，这看起来最不容易产生碎片，但是却把最大的连续内存划分开，会很快导致没有可用的大内存块，因此性能也非常差。\n物理层介质总结 同轴电缆：coaxial cable\n双绞线：Twisted pair（T）\n绞合的作用：\n减少相邻导线间的电磁干扰 抵御部分来自外界的电磁干扰 光纤：Optical fiber（F）\n光纤的优点：\n通信容量非常大 抗雷电和电磁千扰 性能好，传输损耗小，中继距离长 无串音，干扰保密性好 体积小，重量轻 光线的缺点：\n切割光纤需要较贵的专用设备 目前光电接口还比较昂贵 GBN确认号、TCP确认号 在GBN中，若本次A发送给B的帧序号为n，B发送给A的确认序号为n，说明已经收到了前n个帧；\n在TCP中，若本次B发送的确认报文段中的确认号为n+1，说明已经收到了A发送给B的前n个报文段，期待收到第n+1个报文段；\n","permalink":"https://fireflyyh.top/posts/408/summary02/","summary":"16年 单周期数据通路 单周期数据通路是一种简单的数据通路设计，每个时钟周期执行一条完整的指令，即每条指令的CPI为1，要考虑比较慢的指令，所以处理器的时钟频率较低。 这意味着每条指令执行过程中任何数据通路单元都只能被用一次，如果需要使用多次则必须将该数据通路单元复制多份。\n控制信号是CU根据指令操作码发出的信号，对于单周期处理器来说，每条指令的执行只有一个时钟周期，而在一个时钟周期内控制信号并不会变化。\n单周期数据通路必须有独立的指令存储器和数据存储器，因为处理器在一个周期内只能操作每个部件一次，而在一个周期内不可能对一个单端口存储器进行两次存取。且无法使用单总线数据通路，因为单总线数据通路将所有寄存器的输入出端都连接在一条公共通路上，一个时钟内只允许一次操作，无法完成指令的所有操作。\nTSL指令实现互斥 1 2 3 4 5 6 do { while (TSL(\u0026amp;lock)); critical section; lock = FALSE; ...... } while (TRUE); 退出临界区的进程负责唤醒就绪态进程？\n因为在TSL方法下，一个进程只有两种状态：\n运行态：用户处于了do{ }中，那么不管是是在其中的while (TSL(\u0026amp;lock))不断地循环，还是在访问临界资源，都是占用着CPU的，也就是处于运行态； 就绪态：若是在执行过程中由于并发所需要（如时间片到了），被其他进程占用了CPU，就变成了就绪态； 但是不会处于阻塞态，因为若是在等待临界资源，则会一直处于while (TSL(\u0026amp;lock));中，而且不会主动放弃CPU变成阻塞态（阻塞是一个主动的过程）。故不存在阻塞态的进城来给退出临界区的进程唤醒。\n等待进入临界区的进程不会主动放弃CPU，故上述代码不满足“让权等待”的同步准则。因为会一直停留在执行while(TSL(\u0026amp;lock))的循环中，该语句应在开中断下进行，否则一直处于该循环且不被其他进程中断可能会导致系统终止。\n操作系统的发展 手工发展阶段（无操作系统）：\n所有工作都要人干预，用户独占全机。\n特点：用户独占全机、CPU等待手工操作；\n缺点：人机矛盾及 CPU 和 I/O 设备之间速度不匹配的矛盾，因此发展出了批处理系统。\n批处理阶段（开始出现操作系统）：\n单道批处理：系统对作业的处理是成批进行的，但内存中始终保持一道作业。\n特点：单道性、自动性、顺序性。\n缺点：每次主机内存中仅存放一道作业，每当它在运行时发出I/O请求后，高速的 CPU 便处于等待低速的 I/O 完成的状态。\n为了进一步提高资源的利用率和系统的吞吐量，引入了多道程序技术。 多道批处理：多道程序设计技术允许多个程序同时进入内存并允许它们在 CPU 中交替地运行。\n特点：多道、宏观上并行、微观上串行。\n优点：资源利用率高，多道程序共享计算机资源，从而使各种资源得到充分利用；系统吞吐量大， CPU 和其他资源保持“忙碌”状态。 缺点：用户响应的时间较长；不提供人机交互能力，用户既不能了解自己的程序的运行情况，又不能控制计算机。 因此发展出了分时操作系统。 分时操作系统：\n分时操作系统是指多个用户通过终端同时共享一台主机，这些终端连接在主机上，用户可以同时（同时性）与主机进行交互（交互性）操作而互不干扰（独立性）。分时系统采用时间片轮转方式使一台计算机同时为多个终端服务，使用户能够对系统的及时响应感到满意（及时性）。分时系统也是支持多道程序设计的系统，但它不同于多道批处理系统。多道批处理是实现作业自动控制而无须人工干预的系统，而分时系统是实现人机交互的系统。\n特点：同时性、交互性、独立性、及时性。\n优点：较好地解决了人机交互问题。\n缺点：在一些应用场合，需要系统能对外部的信息在规定的时间（比时间片的时间还短）内做出处理（比如飞机订票系统或导弹制导系统），因此，实时操作系统应运而生。\n描述 特点 优点 缺点 手工操作阶段 所有工作都要人干预 用户独占全机、CPU等待手工操作； 不会出现因资源己被其他用户占用而等待的情况 资源利用率低，人机矛盾及 CPU 和 I/O 设备之间速度不匹配的矛盾，因此发展出了批处理系统。 单道批处理 系统对作业的处理是成批进行的，但内存中始终保持一道作业。 单道性、自动性、顺序性。 （开始出现操作系统） 每次主机内存中仅存放一道作业，每当它在运行时发出I/O请求后，高速的 CPU 便处于等待低速的 I/O 完成的状态。 为了进一步提高资源的利用率和系统的吞吐量，引入了多道程序技术。 多道批处理 多道程序设计技术允许多个程序同时进入内存并允许它们在 CPU 中交替地运行。 多道性、宏观上并行、微观上串行。 资源利用率高，多道程序共享计算机资源，从而使各种资源得到充分利用；系统吞吐量大， CPU 和其他资源保持“忙碌”状态。 用户响应的时间较长；不提供人机交互能力，用户既不能了解自己的程序的运行情况，又不能控制计算机。 因此发展出了分时操作系统。 分时操作系统 用户可以同时（同时性）与主机进行交互（交互性）操作而互不干扰（独立性）。分时系统采用时间片轮转方式使一台计算机同时为多个终端服务，使用户能够对系统的及时响应感到满意（及时性）。 同时性、交互性、独立性、及时性。 较好地解决了人机交互问题。 在一些应用场合，需要系统能对外部的信息在规定的时间（比时间片的时间还短）内做出处理（比如飞机订票系统或导弹制导系统），因此，实时操作系统应运而生。 实时操作系统 为了能在某个时间限制内完成某些紧急任务而不需要时间片排队，诞生了实时操作系统。资源利用率不是其主要追求目标。 及时性、可靠性 管程 管程是由一组数据以及定义在这组数据之上的对这组数据的操作组成的软件模块，这组操作能初始化并改变管程中的数据和同步进程。管程不仅能实现进程间的互斥，而且能实现进程间的同步。","title":"真题总结2"},{"content":"10年 平衡二叉树的调整 LL调整 RR调整 RL调整 例如（原谅我图画的难看😂）：\nLR调整 二分查找的次数（成功失败）、折半查找判定树与二叉搜索树的关系 平衡二叉树是一种特殊的二叉查找树，它要求任何节点的两棵子树的高度差不超过1（同一棵树的不同节点的子树高度差可以为1、0、-1）。平衡二叉树通过在插入和删除节点时做旋转来维持树的平衡。\n折半查找判定树是一种特殊的平衡二叉树，它要求更加严格。同一棵树节点的左子树和右子树的差不能同时存在1和-1（即为统一向上取整或统一向下取整）。查找时，根据比较的结果折半排除一边的树。折半查找判定树中，只有最下面一层才可以不满。 根据完全二叉树的高度计算公式，元素个数为n时，树高 $h=\\lceil log_2(n+1)\\rceil$ 或 $h=\\lfloor log_2(n)\\rfloor+1$ 。在折半查找中，\n查找成功的最小比较次数为1，最大比较次数为$h$； 查找失败的最小比较次数为：若$n=2^h-1$，则为$h$，否则为$h-1$，最大比较次数：$h$。 数据类型转换造成的精度丢失等问题 将高精度数转换为低精度数可能会引起：\n精度丢失：高精度数通常能够表示更大范围和更高精度的数字，但当将其转换为低精度数时，可能会导致小数部分被截断或丢失，从而引起精度丧失。 溢出：如果高精度数的值超出了低精度数所能表示的范围，会导致溢出。 将整型数转换为浮点数一般不会出现问题，但特殊情况下会导致精度丢失，对于非常大或非常小的整数，可能无法精确表示。如int类型数据二进制表示有32位，但是对于float类型，在IEEE 754格式下，尾数部分只有23位，可能无法完全表示某一个int类型数，造成精度的丢失。 单精度与双精度浮点数的运算也有可能会有一些问题，例如10年真题$T_{14}$，$f=1.5678e3,d=1.5e100$，进行$(d+f)-d$运算，在$d+f$时，需要先进行对阶（小阶向大阶对齐），由于格式中的尾数限制，对阶后，$f$的尾数被舍去而变成了0，故$d+f$仍然为$d$，再减去$d$结果为0，而不是$f$。\n字扩展、位扩展与相关的芯片最低地址问题 位扩展\n位扩展是指用若干片位数较少的存储器芯片构成给定字长的存储器，容量改变，位数改变，地址单元个数不变。\n在袁春风老师的《计算机系统基础》中的一个例子如下：\n注意到8个$16M\\times8bit$的芯片扩展构成一个128M内存条。在进行扩展之前，对于单个芯片，地址位数为24bit。即地址单元个数为$16M=2^{24}$ 。每个地址单元存储8bit。\n在进行扩展之后，$128M=2^{27}$，而行列地址位数加起来一共$24bit$，$2^{24}=16M$，则说明此次扩展为位扩展。一个地址单元中的数据位数增加，但是总的地址单元个数并未改变。\n12位行地址$i$和12位列地址$j$分别送到DRAM芯片内部的行地址译码器和列地址译码器，选择行列地址交叉点$(i,j)$的8位数据同时进行读写，8个芯片就可以同时读取64bit，组合成总线所需要的64位传输宽度，再通过存储器总线进行传输。\n字扩展\n字扩展，容量改变，地址单元个数改变，即地址位数会改变，位数不会改变。\n另外，对于某一存储器，由多个DRAM经过字扩展而成，那么对于单个DRAM芯片来说，其行地址RAS位数、列地址CAS位数也不会变，但是整体存储器的总地址位数会变，会增加片选信号位数。 此时，对于一个主存地址，可以理解为芯片序号+芯片内的位置 。 也就是说，无论是位扩展还是字扩展，对于单一的DRAM芯片，其行列地址位数均不含会改变。（14年T15）\n引起进程状态改变的一些典型事件 进程状态可以在以下情况下发生改变：\n创建新进程：当操作系统启动一个新的程序时，会创建一个新的进程，并将其状态设置为就绪状态。\n进程等待：当一个进程等待某些事件发生，例如等待用户输入、等待某个文件就绪等，它的状态会从运行状态变为阻塞状态。\n时间片用完：如果一个进程在分配给它的时间片用完之后，调度器会将其状态从运行状态变为就绪状态，降低其进程优先级，然后选择下一个要执行的进程。\nI/O操作完成：当一个进程等待的I/O操作完成后，它的状态会从阻塞状态变为就绪状态。\n进程终止：当一个进程完成了它的任务，或者由于某种原因需要被终止，它的状态会从运行状态变为终止状态。\n进程被阻塞的资源可用：当一个进程等待的资源（如锁或信号量）变为可用时，它的状态会从阻塞状态变为就绪状态。设备分配是在一个已经存在的进程中进行的，不会导致创建新进程。\n进程被唤醒：在多任务环境中，一个进程可能会被另一个进程唤醒，使得它从阻塞状态变为就绪状态。\n进程被挂起或恢复：操作系统可以将一个进程从内存中挂起（暂时移出内存）或者从挂起状态恢复（重新加载到内存中）。\n父进程等待子进程：当一个父进程等待其子进程结束时，它的状态可能会从运行状态变为阻塞状态。\n发生错误或异常：当一个进程遇到错误或异常情况时，它的状态可能会从运行状态变为终止状态或者阻塞状态（如果它在等待某些事件发生时发生了错误）。\nIO系统的分层结构 碰撞域、广播域 冲突域：在同一个冲突域中，每一个结点都能收到所有其他结点发送的帧。简单地说，冲突域为同一时间内只能有一台设备发送信息的范围。 广播域：网络中能接收任意设备发出的广播帧的所有设备的集合。即，如果站点发出一个广播信号，所有能接收到这个信号的设备范围被称为一个广播域。 通常一个网段为一个冲突域，一个局域网为一个广播域。\n磁盘的调度策略 磁盘调度算法是操作系统中用于管理磁盘上的I/O请求的一种策略。以下是一些常见的磁盘调度算法：\n先来先服务（FCFS）：最简单的磁盘调度算法，按照请求的到达顺序依次执行。但可能会出现“早来的请求等待时间长”的问题。 最短寻道时间优先（SSTF）：选择当前磁头位置最近的请求进行服务，以最小化寻道时间。但可能会导致某些请求长时间等待。 SCAN算法：扫描算法，也称为电梯算法，类似于电梯的运行方式，磁头按一个方向移动，直到最后一个磁道后再改变方向。 C-SCAN算法：循环扫描算法，磁头按同一个方向移动，直到到达最后一个磁道后，立即直接返回到磁道0处，再继续扫描。 LOOK 算法：类似于扫描算法，但在到达最远的请求后不会立即返回，而是根据当前请求的方向决定下一个服务的磁道。在朝一个给定方向移动前查看是否有请求。 C-LOOK 算法：类似于 C-SCAN 算法，但在到达最远的请求后不会立即返回，而是直接返回到最远端的有请求的磁道。 注意，在做题时，若无特别说明，也可以默认SCAN算法和C-SCAN算法为LOOK和C-LOOK调度。\n09年 B树与B+树的异同 B树和B+树都是一种常用的多路搜索树数据结构，用于存储有序的数据集合，特别是在磁盘存储和数据库系统中应用广泛。\n数据存储： B树：B树的叶子节点和非叶子节点的结构基本相同，都可以存储数据。 B+树：在B+树中，只有叶子节点存储数据，非叶子节点只存储索引（有点像文件管理中的索引顺序文件），叶子节点之间通过指针连接，形成一个有序的链表。 范围查询效率： B树：由于B树的叶子节点也存储数据，因此可以直接进行范围查询。 B+树：由于B+树的非叶子节点不存储数据，只有叶子节点存储数据，因此范围查询需要在叶子节点构成的链表上进行。 查询性能： B树：由于B树的非叶子节点也存储数据，单次查询可能直接在非叶子节点找到结果，因此查询性能相对于B+树可能更快。 B+树：B+树的查询性能相对于B树可能稍慢，因为每次查询都需要在叶子节点链表上进行。 浮点数加减的步骤（IEEE 754） 正常方法：对阶（小阶向大阶对齐）、尾数运算、规格化（左规、右规）、舍入、判断溢出（判断舍入后的阶数是否超过了所能表示的范围）；\n偷懒方法：直接计算（按照大的阶数）、在规格化后判断是否溢出（判断阶数是否超过了所能表示的范围）（如10年T13）\nCISC与RISC的区别 CISC 指令系统设计的主要特点如下：\n指令系统复杂且多。指令条数多，寻址方式多，指令格式多而复杂，指令长度可变，操作码长度可变。 各种指令都能访问存储器，有些指令还需要多次访问存储器。 不利于实现流水线。因为指令周期长且差距大。绝大多数指令需要多个时钟周期才能完成，简单指令和复杂指令所用的时钟周期数相差很大。 复杂指令系统使得其实现越来越复杂，不仅增加了研制周期和成本，而且难以保证正确性，甚至因为指令太复杂而无法采用硬连线路控制器，导致大多数系统只能采用慢速的微程序控制器。 难以进行编译优化。由于编译器可选指令序列增多，使得目标代码组合增加，从而增加了目标代码优化的难度。 相关指令会产生显式的条件码，存放在专门的标志寄存器（或称状态寄存器）中，可用于条件转移和条件传送等指令。 相较于CISC，RISC 指令系统设计的主要特点如下：\n**指令数目少且规整。**只包含使用频度高的简单指令，寻址方式少，指令格式少，指令长度一致，指令中操作码和寄存器编号等位置固定，便于取指令、指令译码以及提前读取寄存器中操作数等。 采用 load/store 型指令设计风格。一条指令的执行阶段最多只有一次存储器访问操作。 采用流水线方式执行指令。规整的指令格式有利于采用流水线方式执行，除 load/store指令外，其他指令都只需一个或小于一个时钟周期就可完成，指令周期短。 采用硬连线路控制器。指令少而规整使得控制器的实现变得简单，可以不用或少用微程序控制器。 指令数量少，固然使编译工作量加大，但由于指令系统中的指令都是精选的，编译时间少，反过来对编译程序的优化又是有利的。 采用大量通用寄存器。编译器可将更多的局部变量分配到寄存器中，并且在过程调用时通过寄存器进行参数传递而不是通过栈进行传递，以减少访存次数。 硬布线控制器与微程序控制器的对比 硬布线控制器 微程序控制器 实现方式 通过硬件电路来实现的，通常是由逻辑门、寄存器和触发器等组件组成。 使用一组存储在控制存储器中的微指令序列来实现。 性能 硬件实现，因此执行速度通常非常快 略慢一些，每个微指令的执行需要额外的时钟周期。 复杂性 较高 相对更为简单 灵活性 控制逻辑固定在硬件中，不容易进行修改或升级，缺乏灵活性。 可以通过修改控制存储器中的微指令来改变控制逻辑，灵活性较高。 文件访问控制 口令保护 为文件设置一个“口令“，用户想要访问文件时需要提供口令，由系统验证口令是否正确。 实现开销小，但“口令“一般存放在FCB或索引结点中（也就是存放在系统中）因此不太安全。 加密保护 用一个“密码“对文件加密，用户想要访问文件时，需要提供相同的“密码“才能正确的解密。 安全性高，即使文件被非法获取，没有密码也无法正确读取其中的内容。但加密/解密需要耗费一定的时间。 访问控制 用一个访问控制表 (ACL) 记录各个用户（或各组用户）对文件的访问权限，对文件的访问类型可以分为，读写/执行/删除等。 实现灵活，可以实现复杂的文件保护功能，存放文件访问控制信息的合理位置为FCB或索引节点。 软硬链接的区别 硬链接 硬链接的实现只是在要创建链接的目录中创建了另一个名称，并将其指向原有文件的相同inode号（即低级别名称）。该文件不以任何方式复制。在创建文件的硬链接之后，在文件系统中，原有文件名（file）和新创建的文件名（file2）之间没有区别。实际上，它们都只是指向文件底层元数据的链接，可以在同一个inode中找到。 硬链接有个局限在于：不能创建目录的硬链接（因为担心会在目录树中创建一个环）。不能硬链接到其他磁盘分区或文件系统中的文件（因为 inode 号在特定文件系统中是唯一的，而不是跨文件系统）等等。注意：在Windows操作系统中，磁盘分区通常是以盘符（如C盘、D盘等）来表示的，但这并不等同于Unix或类Unix系统中的文件系统中的概念。如果C盘和D盘属于同一物理磁盘（硬盘），可以在它们之间创建硬链接。然而，如果它们代表了两个不同的物理磁盘，那么在它们之间创建硬链接通常是不可能的。 符号链接（软链接） 因此，人们创建了一种称为符号链接（软链接）的新型链接。符号链接本身实际上是一个不同类型的文件。除了常规文件和目录之外，符号链接是文件系统知道的第三种类型。因为形成符号链接的方式是指向文件的路径名作为链接文件的数据，所以符号链接文件的大小于所指向的文件的路径名的长度有关系，且有可能造成所谓的悬空引用。 奈奎斯特定理和香农定理 奈奎斯特定理规定，为了避免信号在数字化过程中产生失真，需要以至少两倍于信号最高频率的采样率对信号进行采样。\nFTP 在FTP中，数据传输可以采用两种模式：主动模式和被动模式。\n主动模式：\n客户端向FTP服务器的默认数据端口（通常是端口20）发起连接请求，请求建立数据连接。 服务器在接收到客户端的连接请求后，会从自己的数据端口（通常是端口20）向客户端的随机端口发起连接请求，请求建立数据连接。（服务器发起数据连接请求） 被动模式：\n客户端向FTP服务器的命令端口（通常是端口21）发送PASV命令，请求进入被动模式。 服务器收到PASV命令后，会打开一个随机的端口，监听客户端的连接请求，同时将该端口号发送给客户端。 客户端收到服务器返回的端口号后，会从自己的端口向服务器的指定端口发起连接请求，请求建立数据连接。（客户端发起数据连接请求） 11年 计算机性能评价相关词条 IEEE 754格式化 IEEE 754单精度浮点数的解释\n值的类型 符号 阶码 尾数 值 正零 $0$ $0$ $0$ $0$ 负零 $1$ $0$ $0$ $-0$ 正无穷大 $0$ $255(全1)$ $0$ $\\infty$ 负无穷大 $1$ $255(全1)$ $0$ $-\\infty$ 无定义数（非数） $0或1$ $255(全1)$ $\\ne0$ $\\text{NaN}$ 规格化非零正数 $0$ $0\u0026lt;e\u0026lt;255$ $f$ $2^{e-127}(1.f)$ 规格化非零负数 $1$ $0\u0026lt;e\u0026lt;255$ $f$ $-2^{e-127}(1.f)$ 非规格化正数 $0$ $0$ $f\\ne0$ $2^{126}(0.f)$ 非规格化负数 $1$ $0$ $f\\ne0$ $-2^{126}(0.f)$ IEEE 754的范围\n格式 最小值 最大值 单精度 $E=1,M=0$\n$1.0\\times2^{1-127}=2^{-126}$ $E=254,M=.111\\cdots,1.111\\cdots1\\times2^{254-127}=2^{127}\\times(2-2^{-23})=2^{128}-2^{104}$ 双精度 $E=1,M=0$\n$1.0\\times2^{1-1023}=2^{-1022}$ $E=2046,M=.111\\cdots,1.111\\cdots1\\times2^{2046-1023}=2^{1023}\\times(2-2^{-52})=2^{1024}-2^{971}$ 加减法法电路 电路\n标志位\n系统总线的各条线传输的是什么 在取指令时，指令便是在数据线上传输的。操作数显然在数据线上传输。中断类型号用以指出中断向量的地址，CPU响应中断请求后，将中断应答信号 (INTR) 发回到数据总线上，CPU从数据总线上读取中断类型号后，查找中断向量表，找到相应的中断处理程序入口。而握手（应答）信号属于通信联络控制信号，应在通信总线上传输。\nOSI模型与TCP/IP模型各层的功能区别 OSI模型：\n物理层：解决使用何种信号来传输比特0和1的问题。负责定义物理媒介、传输速率、编码方法等，提供了物理介质上的原始数据传输。 数据链路层：解决帧在一个网络（或一段链路）上传输的问题。负责数据帧的传输、接收、错误检测和纠正，确保数据在物理层上可靠地传输。 网络层：解决分组在多个网络之间传输（路由）的问题。负责在不同网络之间进行路由选择，进行分组的转发和寻址，以及定义子网等网络层面的逻辑结构。 传输层：解决进程之间基于网络的通信问题。提供端到端的通信，保证数据的可靠传输，处理数据的分段和重组，以及流量控制和拥塞控制。 会话层：解决进程之间进行会话的问题。建立、管理和终止会话连接，提供了通信会话的控制和同步功能。 表示层：解决通信双方交换信息的表示问题。负责数据的格式转换、加密解密、压缩解压缩等，保证数据的可靠传输。 应用层：解决通过应用进程之间的交互来实现特定网络应用的问题。为用户提供各种网络应用服务，如文件传输、电子邮件、远程登录等。 TCP/IP模型：\n应用层：与OSI模型的应用层类似，提供网络应用服务。\n传输层：与OSI模型的传输层类似，负责提供端到端的通信服务。\n网络层：与OSI模型的网络层类似，负责在不同网络之间进行路由选择。\n链路层：包括了OSI模型的物理层和数据链路层的功能，负责在相邻节点间提供可靠的数据传输。\n在实际应用中，TCP/IP模型是目前广泛使用的网络模型，而OSI模型在理论上用于描述通信系统的功能。\n对正确接收到的数据帧进行确认的MAC协议 为什么是CSMA/CA协议？\nCSMA/CA协议，是一种用于在无线网络中进行数据通信的协议，针对无线环境中信道容量有限、易受干扰的特点而设计。它采用了一些机制来避免碰撞并提高数据传输的可靠性：\n监听信道：发送方在发送数据前会先监听信道，确保信道是空闲的，避免发生碰撞（减少概率，不能一定避免）。\nRTS/CTS帧：在CSMA/CA中，还引入了请求发送（Request to Send，RTS）和清除发送（Clear to Send，CTS）帧的概念。发送方在发送数据前会先发送一个RTS帧，接收方如果收到并确认了RTS帧，就会发送一个CTS帧给发送方，表示信道已经为发送方保留。这个过程可以有效避免隐藏节点问题和减少碰撞的发生。\n等待确认：发送方在发送数据后会等待接收方的确认，只有在收到确认后才会发送下一个数据帧。\n重传机制：如果发送方没有收到确认，会认为数据帧可能丢失，会进行重传。\n特殊的IP及其作用、使用方法 以下是RFC文档中的内容Special-Use IPv4 Addresses RFC 3330\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 Address Block Present Use Reference --------------------------------------------------------------------- 0.0.0.0/8 \u0026#34;This\u0026#34; Network [RFC1700, page 4] 10.0.0.0/8 Private-Use Networks [RFC1918] 14.0.0.0/8 Public-Data Networks [RFC1700, page 181] 24.0.0.0/8 Cable Television Networks -- 39.0.0.0/8 Reserved but subject to allocation [RFC1797] 127.0.0.0/8 Loopback [RFC1700, page 5] 128.0.0.0/16 Reserved but subject to allocation -- 169.254.0.0/16 Link Local -- 172.16.0.0/12 Private-Use Networks [RFC1918] 191.255.0.0/16 Reserved but subject to allocation -- 192.0.0.0/24 Reserved but subject to allocation -- 192.0.2.0/24 Test-Net 192.88.99.0/24 6to4 Relay Anycast [RFC3068] 192.168.0.0/16 Private-Use Networks [RFC1918] 198.18.0.0/15 Network Interconnect Device Benchmark Testing [RFC2544] 223.255.255.0/24 Reserved but subject to allocation -- 224.0.0.0/4 Multicast [RFC3171] 240.0.0.0/4 Reserved for Future Use [RFC1700, page 4] 12年 上三角矩阵和拓扑排序 若用邻接矩阵存储有向图，矩阵中主对角线及以下的元素均为零（或主对角线及以上的元素均为零），则该图的拓扑序列一定存在，但不一定唯一。\n例如，如果一个有向图使用邻接矩阵进行存储，并且矩阵中主对角线及以下的元素均为零，那么这个图的拓扑序列一定存在。因为拓扑序列是一个图中所有顶点的线性排序，使得对于每一条有向边 \u0026lt;u,v\u0026gt;，顶点 u 在序列中都出现在顶点 v 之前。在这种情况下，由于主对角线以下的元素都是零，表明没有顶点指向自己，也就不存在环路，因此必然存在拓扑排序。\n然而，拓扑序列可能不是唯一的。这是因为在一个有向无环图中，可能存在多个顶点没有前驱（即入度为零），这些顶点的相对顺序可以任意排列，只要它们在拓扑排序中排在其他顶点之前即可。因此，可能存在多个合法的拓扑序列。\n反之，如果存在拓扑序列，邻接矩阵不一定满足主对角线及以下的元素均为零（或主对角线及以上的元素均为零）。\n数据线、地址线、控制线 参考【组成原理·总线】总线的概念和计算\n在单总线结构中：\n数据线：用于在各个设备（包括CPU、主存、外设）之间传递数据。\n地址线：传输地址信息，用于指示要访问的特定内存单元或外设的地址。地址线的数量决定了总线的寻址能力，也就是可以寻址的内存或设备数量。\n控制线：传输各种控制信号，如读取、写入、使能等信号，以控制数据的流动和操作。控制线还可能包括时钟信号等。也可以传输主存返回 CPU 的反馈信号。\n在IO接口中：\n数据线：可以传输IO接口中的命令字、状态字、中断类型号，在接口中的数据缓冲寄存器、内存、CPU中的寄存器之间进行数据传送。**（可双向传输）**同时接口和设备的状态信息被记录在状态寄存器中，通过数据线将状态信息送到 CPU。CPU 对外设的控制命令也通过数据线传送。 地址线：接口中的地址线用于给出要访问的 I/O 接口中的寄存器的地址，它和读/写控制信号一起被送到 I/O 接口的控制逻辑部件。(只能单向) 控制线：通过控制线传送来的读/写信号确认是读寄存器还是写寄存器，此外控制线还会传送一些仲裁信号和握手信号。（只能单向） 中断处理和子程序调用的区别 触发方式： 中断处理：中断是由硬件或外部事件触发的。当发生了某个预定义的事件（如设备输入、时钟周期等），硬件会暂停当前程序的执行，并跳转到相应的中断处理程序中执行。 子程序调用：子程序调用是由程序内部通过软件指令来触发的。程序会通过调用指令跳转到指定的子程序中执行，执行完后再返回到原来的程序。 上下文切换： 中断处理：中断处理涉及到从用户态切换到内核态，然后再返回用户态的过程。这涉及到硬件和操作系统的支持，需要保存和恢复相应的寄存器和状态，如断点（PC）、程序状态字寄存器（PSW）。（中断处理中最重要的两个寄存器） 子程序调用：子程序调用是在同一程序执行流中完成的，没有涉及到从用户态到内核态的切换。因此，它比中断处理的上下文切换开销要小，只需要保存程序断点。 异步性质： 中断处理：中断是异步的，它可以随时发生并打断当前的程序执行。因此，中断处理必须能够处理不可预知的事件。 子程序调用：子程序调用是同步的，它是由程序内部明确地发起的，执行完子程序后会继续执行后续的指令。 权限级别： 中断处理：中断处理通常需要在内核态执行。 子程序调用：子程序可以在用户态或内核态中执行，具体取决于程序的权限和需要。 物理接口各个特性的功能 机械特性：指明接口所用接线器的形状和尺寸、引脚数目和排列、固定和锁定装置等。 电气特性：指明在接口电缆的各条线上出现的电压的范围。 功能特性：指明某条线上出现的某一电平的电压表示何种意义。 过程特性：或称规程特性。指明对于不同功能的各种可能事件的出现顺序。 协议的三部分 协议由语法、语义和同步三部分组成。\n语法规定了传输数据的格式； 语义规定了所要完成的功能，即需要发出何种控制信息、完成何种动作及做出何种应答； 同步规定了执行各种操作的条件、时序关系等，即事件实现顺序的详细说明。 一个完整的协议通常应具有线路管理（建立、释放连接）、差错控制、数据转换等功能。协议并不关心具体如何实现，只要求实现什么功能。\n各层协议有无连接、可不可靠？ 数据链路层：\n以太网的MAC协议提供的是无连接不可靠服务：考虑到局域网信道质量好，以太网采取了两项重要的措施以使通信更简便：采用无连接的工作方式；不对发送的数据帧进行编号，也不要求对方发回确认。因此，以太网提供的服务是不可靠的服务，即尽最大努力的交付。差错的纠正由高层完成。 无线局域网的MAC协议提供的是无连接可靠服务：并没有“握手”的过程，即传输数据之前并没有连接。 网络层：\nIP协议提供的是无连接不可靠服务：IP协议不需要在传输数据前建立连接，也不需要在传输过程中保持连接状态。每个IP数据包都是独立传输的，它们之间没有直接的关联。IP数据包的传输是不可靠的，这意味着它们可能会丢失、延迟、重复或者乱序。IP协议不提供任何机制来保证数据的可靠性，也不负责处理丢失的数据包。 传输层：\nTCP协议提供的是有连接可靠服务：通过序号、确认、重传等机制来保证数据的完整性和有序性。 UDP协议提供的是无连接不可靠服务：将数据分割成报文段，并将报文段发送到目标，无需建立连接或维护会话状态。但是可以通过在应用层实现自定义的可靠性机制，使得UDP的通信变得可靠。 协议A直接为协议B提供服务 协议A 协议B TCP BGP IP OSPF UDP RIP IP ICMP IP TCP IP UDP UDP DNS TCP HTTP TCP SMTP TCP POP3 IP IGMP TCP FTP 13年 最佳归并树 有n个初始归并段，需要做k路平衡归并排序，可以根据哈夫曼树的思想来优化WPL。\nRAID相关知识 RAID0方案是无冗余和无校验的磁盘阵列，而RAID1-5方案均是加入了冗余（镜像）或校验的磁盘阵列。能够提高 RAID 可靠性的措施主要是对磁盘进行镜像处理和奇偶校验。\n条带化技术是一种自动地将I/O的负载均衡到多个物理磁盘上的技术。条带化技术就是将一块连续的数据分成很多小部分并把它们分别存储到不同磁盘上去。这就能使多个进程同时访问数据的多个不同部分但不会造成磁盘冲突，而且在需要对这种数据进行顺序访问的时候可以获得最大程度上的I/O并行能力，从而获得非常好的性能。\n中断I/O方式和DMA方式的比较 中断处理方式： 在设备输入每个数据的过程中，由于无须 CPU 干预，因而可使CPU与I/O设备并行工作。仅当输完一个数据时，才需 CPU 花费极短的时间去做些中断处理，因此中断申请使用的是 CPU 处理时间； 中断响应发生的时间是在一条指令执行结束之后； 数据是在软件（中断服务程序）的控制下完成传送的。 DMA方式： 数据传输的基本单位是数据块； 每个数据块传送完毕时，都会发生DMA请求，DMA请求每次申请的是总线的使用权，所传送的数据是从设备直接送入内存的，或者相反； 仅在传送一个或多个数据块的开始和结束时，才需 CPU 干预，整块数据的传送是在硬件（DMA控制器）的控制下完成的。 IO密集型的进程和计算密集型的进程优先级 当系统中存在大量IO密集型任务时，优先处理这类任务可以减少IO等待时间，提高IO设备的利用率，同时可以充分利用CPU资源等待IO操作完成。\n操作系统的加载 操作系统最终被加载到RAM中。\n预防死锁、避免死锁的区别 预防死锁：预防死锁的方法是在设计阶段就采取措施，使得系统不会发生死锁。这种方法主要通过破坏死锁产生的四个必要条件（互斥访问、不可剥夺、请求和保持、循环等待）来实现。预防死锁是一种静态的、全局的策略，需要在系统设计和实施阶段进行考虑和实施。 避免死锁：避免死锁是在系统运行时根据进程的动态行为来避免死锁的发生。这种方法会通过对资源的合理分配和释放（如银行家算法）来避免进入死锁状态。避免死锁是一种动态的、局部的策略，根据当前系统状态来进行判断和处理。 物理层基带传输信号 图源《通信原理》（樊昌信\u0026ndash;第六版）\n(a) 单极性非归零编码\n(b) 双极性非归零编码\n(c) 单极性归零编码\n(d) 双极性归零编码\n(e) 差分编码\n图源王道《计算机网络考研复习指导》\n以太网使用的编码方式就是曼彻斯特编码\nSMTP协议 14年 指令cache与数据cache分离的主要目的 可以减少指令流水线资源冲突。如一个进程在取指令时，另一条指令可以同时取数据。\n管道通信的定义、特点 **管道是驻留在内存中的伪文件，可以使用标准文件函数对其进行访问。**与磁盘文件不同，它是临时的，且并不占用磁盘或者其他外部存储的空间，而是占用内存空间。Linux系统直接把管道实现成了一种文件系统，借助VFS给应用程序提供操作接口。所以，Linux上的管道就是一个操作方式为文件的内存缓冲区。 管道的容量大小通常为内存上的一页，它的大小并不是受磁盘容量大小的限制。 它常用于父子进程之间的通信。类似于通信中半双工信道的进程通信机制，一个管道同一个时刻只能最多有一个方向的传输，不能两个方向同时进行。若要实现父子进程双向通信，则需要定义两个管道。 一个进程可以向管道写入数据，另一个进程可以同时从管道读取数据。当管道满时，进程在写管道会被阻塞，而当管道空时，进程在读管道会被阻塞。 从管道读数据是一次性操作，数据一旦被读取，就释放空间以便写更多数据。 关于管道不是文件这一点，参考知乎文章Linux 的进程间通信：管道以及Windows应用开发\n交换区和内存映射 内存映射和交换区（Swap）都是操作系统中用于管理内存的重要机制，但它们有着不同的作用和实现方式。\n内存映射：\n作用：内存映射是一种将磁盘上的文件或设备映射到进程的地址空间中的机制。它允许程序直接访问磁盘上的文件，而无需通过常规的文件读写操作。通过内存映射，程序可以将文件的内容视为内存中的一部分，从而实现对文件的高效访问。\n实现：内存映射是通过将磁盘文件的某个区域映射到进程的虚拟地址空间中，从而让程序可以直接读写这块区域的内容。在某种程度上，内存映射可以看作是文件和内存之间的一个透明的接口。\n交换区：\n作用：交换区是一块硬盘空间，用于暂时存储在物理内存中暂时不活跃的数据和程序。当物理内存不足以容纳当前运行的程序和数据时，操作系统会将一部分数据移到交换区中，从而释放出物理内存。\n实现：交换区是一块硬盘或者固态硬盘的空间，它用于作为物理内存的扩展。当系统需要释放物理内存时，它会将部分不活动的数据和程序写入到交换区中。当需要时，可以将交换区中的数据重新读取到物理内存中。\n区别：\n作用不同：内存映射主要用于实现文件和内存之间的高效访问，而交换区用于在物理内存不足时暂存数据。\n实现方式不同：内存映射是通过将文件或设备映射到进程的地址空间中实现的，而交换区是通过将部分不活动的数据写入到硬盘空间中实现的。\n适用场景不同：内存映射适用于需要频繁访问文件内容的场景，而交换区是用于解决物理内存不足的问题。\n15年 卡特兰数 $\\frac{1}{n+1}C^n_{2n}$\n例如，n个不同的元素进栈，出栈元素不同排列的个数为$\\frac{1}{n+1}C^n_{2n}$\n例如，求先序序列为abcd的不同二叉树的个数也可以利用此解法：\n根据二叉树前序遍历和中序遍历的递归算法中递归工作栈的状态变化得出：前序序列和中序序列的关系相当于以前序序列为入栈次序，以中序序列为出栈次序。因为前序序列和中序序列可以唯一地确定一棵二叉树，所以题意相当于“以序列abcd为入栈次序，则出栈序列的个数为多少”，对于n个不同元素进栈，出栈序列的个数为卡特兰数。\n堆调整时的比较次数 例如，对于大根堆：\n调整乱序初始堆：从全部结点的一半处n/2，开始调整： 调整i及其子树：向下调整：需要先两个孩子进行比较，再和较大者进行交换； i\u0026ndash;：对左兄弟结点或父结点进行调整，重复上一步。 插入节点后：自底向上比较调整，每次向上调整，只需要和父节点进行比较，如果比父节点大，则上移，否则不动；而不是先和兄弟节点比较谁大，因为兄弟节点必定比父节点小。 删除节点后：自顶向下比较调整，每次上下调整，需要先两个孩子进行比较，再和较大者进行交换，因为本节点和两个孩子的大小关系、两个孩子之间的大小都未知。 浮点数溢出问题 对阶操作不会引起阶码上溢或下溢（小阶向大阶对齐，这里前提是小阶能对齐到大阶，如果大的阶数超过了小阶数的阶码所能表示的范围，那么对阶时也会发生溢出）； 左规时可能引起阶码下溢； 右规和尾数舍入（0舍1入法）都可能引起阶码上溢； 尾数溢出时，结果不一定溢出，因为尾数溢出可以通过右规操作来纠正，结果可能产生误差，但不一定会溢出。 DRAM的刷新 对于ROM，即使断电信息也不会丢失。\n对于SRAM，其存储元（区别于存储单位）是双稳态触发器（六晶体管MOS），即使信息被读出后，仍保持原状态而不需要再生（非破坏性读出）。但是断电后信息会丢失。\n对于DRAM，其存储元通常只使用一个晶体管。DRAM电容上的电荷一般只能维持1~2ms，即使电源不断电，信息也会自动消失，因此必须每隔一段时间进行刷新，称为刷新周期，常见的刷新方式有3种：\n集中刷新：指在一个刷新周期内，利用一段固定的时间，依次对存储器的所有行进行逐一再生，在此期间停止对存储器的读写操作，称为“死时间”，又称访存“死区”。优点是读写操作时不受刷新工作的影响；缺点是在集中刷新期间不能访问存储器。 分散刷新：把对每行的刷新分散到各个工作周期中。这样，一个存储器的系统工作周期分为两部分：前半部分用于正常读、写或保持；后半部分用于刷新。优点是没有死区；缺点是加长了系统的存取周期。 异步刷新：异步刷新是前两种方法的结合。具体做法是将刷新周期除以行数，得到两次刷新操作之间的时间间隔t，利用逻辑电路每隔时间t产生一次刷新请求。这样可以避免使CPU连续等待过长的时间，而且减少了刷新次数，从根本上提高了整机的工作效率。 DRAM 的刷新需要注意以下问题：\n刷新对CPU是透明的，即刷新不依赖于外部的访问，不需要CPU控制； DRAM的刷新单位是行，由芯片内部自行生成行地址； 刷新操作类似于读操作，但又有所不同。另外，刷新时不需要选片，即整个存储器中的所有芯片同时被刷新。 总线定时 **同步定时方式：**系统采用一个统一的时钟信号来协调发送和接收双方的传送定时关系。\n异步定时方式：没有统一的时钟，也没有固定的时间间隔，完全依靠传送双方相互制约的“握手”信号来实现定时控制。\n不互锁方式：主设备发出“请求”信号后，不必等到接到从设备的“回答”信号，而是经过一段时间，便撤销“请求”信号。而从设备在接到“请求”信号后，发出“回答”信号，并经过一段时间，自动撤销“回答”信号。双方不存在互锁关系。速度最快，可靠性最差 半互锁方式：主设备发出“请求”信号后，必须待接到从设备的“回答”信号后，才撤销“请求”信号，有互锁的关系。而从设备在接到“请求”信号后，发出“回答”信号，但不必等待获知主设备的“请求”信号已经撤销，而是隔一段时间后自动撤销“回答”信号，不存在互锁关系； 全互锁方式：主设备发出“请求”信号后，必须待从设备“回答”后，才撤销“请求”信号；从设备发出“回答”信号，必须待获知主设备“请求”信号已撤销后，再撤销其“回答”信号。双方存在互锁关系。速度最慢，可靠性最好 优点：总线周期长度可变，能保证两个工作速度相差很大的部件或设备之间可靠地进行信息交换，自动适应时间的配合。 缺点：比同步控制方式稍复杂一些，速度比同步定时方式慢\n半同步定时方式：统一时钟的基础上，增加一个“等待”响应信号；\n分离式通信：$\\cdots$\nDHCP报文地址问题 ","permalink":"https://fireflyyh.top/posts/408/summary01/","summary":"10年 平衡二叉树的调整 LL调整 RR调整 RL调整 例如（原谅我图画的难看😂）：\nLR调整 二分查找的次数（成功失败）、折半查找判定树与二叉搜索树的关系 平衡二叉树是一种特殊的二叉查找树，它要求任何节点的两棵子树的高度差不超过1（同一棵树的不同节点的子树高度差可以为1、0、-1）。平衡二叉树通过在插入和删除节点时做旋转来维持树的平衡。\n折半查找判定树是一种特殊的平衡二叉树，它要求更加严格。同一棵树节点的左子树和右子树的差不能同时存在1和-1（即为统一向上取整或统一向下取整）。查找时，根据比较的结果折半排除一边的树。折半查找判定树中，只有最下面一层才可以不满。 根据完全二叉树的高度计算公式，元素个数为n时，树高 $h=\\lceil log_2(n+1)\\rceil$ 或 $h=\\lfloor log_2(n)\\rfloor+1$ 。在折半查找中，\n查找成功的最小比较次数为1，最大比较次数为$h$； 查找失败的最小比较次数为：若$n=2^h-1$，则为$h$，否则为$h-1$，最大比较次数：$h$。 数据类型转换造成的精度丢失等问题 将高精度数转换为低精度数可能会引起：\n精度丢失：高精度数通常能够表示更大范围和更高精度的数字，但当将其转换为低精度数时，可能会导致小数部分被截断或丢失，从而引起精度丧失。 溢出：如果高精度数的值超出了低精度数所能表示的范围，会导致溢出。 将整型数转换为浮点数一般不会出现问题，但特殊情况下会导致精度丢失，对于非常大或非常小的整数，可能无法精确表示。如int类型数据二进制表示有32位，但是对于float类型，在IEEE 754格式下，尾数部分只有23位，可能无法完全表示某一个int类型数，造成精度的丢失。 单精度与双精度浮点数的运算也有可能会有一些问题，例如10年真题$T_{14}$，$f=1.5678e3,d=1.5e100$，进行$(d+f)-d$运算，在$d+f$时，需要先进行对阶（小阶向大阶对齐），由于格式中的尾数限制，对阶后，$f$的尾数被舍去而变成了0，故$d+f$仍然为$d$，再减去$d$结果为0，而不是$f$。\n字扩展、位扩展与相关的芯片最低地址问题 位扩展\n位扩展是指用若干片位数较少的存储器芯片构成给定字长的存储器，容量改变，位数改变，地址单元个数不变。\n在袁春风老师的《计算机系统基础》中的一个例子如下：\n注意到8个$16M\\times8bit$的芯片扩展构成一个128M内存条。在进行扩展之前，对于单个芯片，地址位数为24bit。即地址单元个数为$16M=2^{24}$ 。每个地址单元存储8bit。\n在进行扩展之后，$128M=2^{27}$，而行列地址位数加起来一共$24bit$，$2^{24}=16M$，则说明此次扩展为位扩展。一个地址单元中的数据位数增加，但是总的地址单元个数并未改变。\n12位行地址$i$和12位列地址$j$分别送到DRAM芯片内部的行地址译码器和列地址译码器，选择行列地址交叉点$(i,j)$的8位数据同时进行读写，8个芯片就可以同时读取64bit，组合成总线所需要的64位传输宽度，再通过存储器总线进行传输。\n字扩展\n字扩展，容量改变，地址单元个数改变，即地址位数会改变，位数不会改变。\n另外，对于某一存储器，由多个DRAM经过字扩展而成，那么对于单个DRAM芯片来说，其行地址RAS位数、列地址CAS位数也不会变，但是整体存储器的总地址位数会变，会增加片选信号位数。 此时，对于一个主存地址，可以理解为芯片序号+芯片内的位置 。 也就是说，无论是位扩展还是字扩展，对于单一的DRAM芯片，其行列地址位数均不含会改变。（14年T15）\n引起进程状态改变的一些典型事件 进程状态可以在以下情况下发生改变：\n创建新进程：当操作系统启动一个新的程序时，会创建一个新的进程，并将其状态设置为就绪状态。\n进程等待：当一个进程等待某些事件发生，例如等待用户输入、等待某个文件就绪等，它的状态会从运行状态变为阻塞状态。\n时间片用完：如果一个进程在分配给它的时间片用完之后，调度器会将其状态从运行状态变为就绪状态，降低其进程优先级，然后选择下一个要执行的进程。\nI/O操作完成：当一个进程等待的I/O操作完成后，它的状态会从阻塞状态变为就绪状态。\n进程终止：当一个进程完成了它的任务，或者由于某种原因需要被终止，它的状态会从运行状态变为终止状态。\n进程被阻塞的资源可用：当一个进程等待的资源（如锁或信号量）变为可用时，它的状态会从阻塞状态变为就绪状态。设备分配是在一个已经存在的进程中进行的，不会导致创建新进程。\n进程被唤醒：在多任务环境中，一个进程可能会被另一个进程唤醒，使得它从阻塞状态变为就绪状态。\n进程被挂起或恢复：操作系统可以将一个进程从内存中挂起（暂时移出内存）或者从挂起状态恢复（重新加载到内存中）。\n父进程等待子进程：当一个父进程等待其子进程结束时，它的状态可能会从运行状态变为阻塞状态。\n发生错误或异常：当一个进程遇到错误或异常情况时，它的状态可能会从运行状态变为终止状态或者阻塞状态（如果它在等待某些事件发生时发生了错误）。\nIO系统的分层结构 碰撞域、广播域 冲突域：在同一个冲突域中，每一个结点都能收到所有其他结点发送的帧。简单地说，冲突域为同一时间内只能有一台设备发送信息的范围。 广播域：网络中能接收任意设备发出的广播帧的所有设备的集合。即，如果站点发出一个广播信号，所有能接收到这个信号的设备范围被称为一个广播域。 通常一个网段为一个冲突域，一个局域网为一个广播域。\n磁盘的调度策略 磁盘调度算法是操作系统中用于管理磁盘上的I/O请求的一种策略。以下是一些常见的磁盘调度算法：\n先来先服务（FCFS）：最简单的磁盘调度算法，按照请求的到达顺序依次执行。但可能会出现“早来的请求等待时间长”的问题。 最短寻道时间优先（SSTF）：选择当前磁头位置最近的请求进行服务，以最小化寻道时间。但可能会导致某些请求长时间等待。 SCAN算法：扫描算法，也称为电梯算法，类似于电梯的运行方式，磁头按一个方向移动，直到最后一个磁道后再改变方向。 C-SCAN算法：循环扫描算法，磁头按同一个方向移动，直到到达最后一个磁道后，立即直接返回到磁道0处，再继续扫描。 LOOK 算法：类似于扫描算法，但在到达最远的请求后不会立即返回，而是根据当前请求的方向决定下一个服务的磁道。在朝一个给定方向移动前查看是否有请求。 C-LOOK 算法：类似于 C-SCAN 算法，但在到达最远的请求后不会立即返回，而是直接返回到最远端的有请求的磁道。 注意，在做题时，若无特别说明，也可以默认SCAN算法和C-SCAN算法为LOOK和C-LOOK调度。","title":"真题总结1"},{"content":"本博客使用了Hugo等技术进行搭建，使用的主题为PaperMod，并对其进行了一定的修改，在这过程也参考了其他博客的实现，如Sulv\u0026rsquo;s Blog。\n你也可以通过以下途径联系我：\nGithub 邮箱 ","permalink":"https://fireflyyh.top/about/","summary":"about","title":"About me"}]