[{"content":"TLPI 21.1.2: 可重入函数和异步信号安全函数 代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 #define _XOPEN_SOURCE 600 #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;signal.h\u0026gt; #include \u0026lt;string.h\u0026gt; #include \u0026lt;crypt.h\u0026gt; #include \u0026#34;tlpi_hdr.h\u0026#34; static char *str2; static int handled = 0; // 设置处理器函数，一旦遇上SIGINT，便对str2进行加密 static void handler(int sig) { crypt(str2, \u0026#34;xx\u0026#34;); handled++; } int main(int argc, char *argv[]) { char *cr1; int callNum, mismatch; struct sigaction sa; if (argc != 3) usageErr(\u0026#34;%s str1 str2\\n\u0026#34;, argv[0]); str2 = argv[2]; // 对str1进行加密，并将结果保存到独立缓冲区中 cr1 = strdup(crypt(argv[1], \u0026#34;xx\u0026#34;)); if (cr1 == NULL) errExit(\u0026#34;strdup\u0026#34;); sigemptyset(\u0026amp;sa.sa_mask); // 初始化在执行处理器函数时将阻塞的信号 sa.sa_flags = 0; // 即sa.sa_flags = SIG_BLOCK sa.sa_handler = handler; // 设置信号处理器函数的地址 if (sigaction(SIGINT, \u0026amp;sa, NULL) == -1) errExit(\u0026#34;sigaction\u0026#34;); for (callNum = 1, mismatch = 0; ; callNum++) { if (strcmp(crypt(argv[1], \u0026#34;xx\u0026#34;), cr1) != 0) { mismatch++; printf(\u0026#34;Mismatch on call %d (mismatch=%d handled=%d)\\n\u0026#34;, callNum, mismatch, handled); } } } 解释 crypt() 需要加入#include \u0026lt;crypt.h\u0026gt;，如果不加上该头文件，会出现implicit declaration of function ‘crypt’的错误。\n针对于undefined reference to `crypt\u0026rsquo;的错误，stackoverflow有以下方案：\ncrypt.c:(.text+0xf1): undefined reference to \u0026lsquo;crypt\u0026rsquo; is a linker error. Try linking with -lcrypt : gcc crypt.c -lcrypt.\n即，在CMakeLists.txt文件中加入link_libraries(crypt)。\nfor循环内部 在这个无限循环中，不断对str1进行加密，并与正确结果进行比较。如果str1在加密的过程中不被打断，则会得到正确结果，但是如果被打断并在处理器函数中对str2进行加密，则会对str1加密的结果产生污染，导致该加密的结果不正确，以此来判断信号处理器函数是否对不可重入函数产生了影响。\n","permalink":"https://fireflyyh.top/posts/tlpi/nonreentrant/","summary":"TLPI 21.1.2: 可重入函数和异步信号安全函数 代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 #define _XOPEN_SOURCE 600 #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;signal.h\u0026gt; #include \u0026lt;string.h\u0026gt; #include \u0026lt;crypt.h\u0026gt; #include \u0026#34;tlpi_hdr.h\u0026#34; static char *str2; static int handled = 0; // 设置处理器函数，一旦遇上SIGINT，便对str2进行加密 static void handler(int sig) { crypt(str2, \u0026#34;xx\u0026#34;); handled++; } int main(int argc, char *argv[]) { char *cr1; int callNum, mismatch; struct sigaction sa; if (argc !","title":"信号处理函数中调用不可重入的函数"},{"content":"TLPI 21.3：在备选栈中处理信号：sigaltstack() 代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 static void sigsegvHandler(int sig) { int x; // 捕捉信号，并通过局部变量的位置来大致判断为当前函数所分配的空间处于什么位置 printf(\u0026#34;Caught signal %d (%s)\\n\u0026#34;, sig, strsignal(sig)); printf(\u0026#34;Top of handler stack near %10p\\n\u0026#34;, (void *)\u0026amp;x); // fflush(NULL)的作用是在程序异常终止前确保所有标准输出缓冲区的数据都被写入到相应的输出设备。 fflush(NULL); _exit(EXIT_FAILURE); } static void overflowStack(int callNum) { char a[100000]; // 此类分配数组方式为栈上分配 printf(\u0026#34;Call %4d - top of stack near %10p\\n\u0026#34;, callNum, \u0026amp;a[0]); overflowStack(callNum + 1); // 无限递归调用，不断在栈上分配空间，每次分配100000字节以上 } int main(int argc, char *argv[]) { stack_t sigstack; struct sigaction sa; int j; printf(\u0026#34;Top of standard stack is near %10p\\n\u0026#34;, (void *)\u0026amp;j); // 分配备用栈并通知内核 // 在堆当中分配备用栈 sigstack.ss_sp = malloc(SIGSTKSZ); if (sigstack.ss_sp == NULL) errExit(\u0026#34;malloc\u0026#34;); sigstack.ss_size = SIGSTKSZ; // 默认栈大小 sigstack.ss_flags = 0; // sig alt stack if (sigaltstack(\u0026amp;sigstack, NULL) == -1) errExit(\u0026#34;sigaltstack\u0026#34;); // sbrk(0)返回当前进程的堆顶地址 printf(\u0026#34;Alternate stack is at %10p-%p\\n\u0026#34;, sigstack.ss_sp, (char *)sbrk(0) - 1); // 设置信号处理器函数，并且不阻塞任何信号 sa.sa_handler = sigsegvHandler; sigemptyset(\u0026amp;sa.sa_mask); sa.sa_flags = SA_ONSTACK; if (sigaction(SIGSEGV, \u0026amp;sa, NULL) == -1) errExit(\u0026#34;sigaction\u0026#34;); // 递归调用overflowStack() overflowStack(1); } 解释 ulimit 使用ulimit -s unlimited会负责移除当前 shell 会话时设置的任何 RLIMIT_STACK 资源限制，对其他 shell 会话无影响。但是在使用了这句话之后调用程序，系统会一直打印信息至Call 78522 - top of stack near 0x7ffa472aac80，即递归调用了78522次，然后[1] 16044 killed ./T_SIGALTSTACK直接将进程杀死。并没有出现预期的Caught signal 11 (Segmentation fault)。\n于是我将限制资源回复成了默认大小，再进行调用，出现了预期的结果：\n1 2 3 4 5 6 7 8 Top of standard stack is near 0x7ffd97398ebc Alternate stack is at 0x55fb092fd6b0-0x55fb0931dfff Call 1 - top of stack near 0x7ffd973807e0 Call 2 - top of stack near 0x7ffd97368110 ... Call 83 - top of stack near 0x7ffd96bad940 Caught signal 11 (Segmentation fault) Top of handler stack near 0x55fb092ff164 经过查阅资料，当使用ulimit -s unlimited来移除栈大小限制时，程序可以无限制地使用栈空间。在本代码中，overflowStack()函数通过递归调用，不断分配大量内存（每次调用分配100000字节），很快会耗尽系统的可用内存。 当系统检测到内存耗尽时，会启动 OOM Killer 来终止占用大量内存的进程。当程序在递归调用了78522次后，占用了大量内存，触发了 OOM Killer，直接将进程终止，所以进程被直接杀死而不是触发 SIGSEGV 信号处理程序。\nfflush(NULL) 关于fflush(NULL)，是为了在程序异常终止前确保所有标准输出缓冲区的数据都被写入到相应的输出设备。尽管程序有固定的执行顺序，但标准输出（stdout）通常是缓冲的。这意味着输出的数据并不会立即被写入到屏幕或文件，而是先存储在缓冲区中，直到缓冲区满或者遇到刷新操作（如换行、fflush 调用等）才会被真正写出。\n在正常情况下，printf输出的数据会在适当的时机刷新到屏幕上。但是，如果程序异常终止，缓冲区中的数据可能没有机会被刷新，从而导致部分或全部输出丢失。exit 函数会执行标准库的清理操作，包括刷新缓冲区。但 _exit 函数是直接退出，不进行任何清理操作，包括缓冲区的刷新。这也就是为什么示例程序在_exit() 之前要进行fflush() 操作。\n","permalink":"https://fireflyyh.top/posts/tlpi/t_sigaltstack/","summary":"TLPI 21.3：在备选栈中处理信号：sigaltstack() 代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 static void sigsegvHandler(int sig) { int x; // 捕捉信号，并通过局部变量的位置来大致判断为当前函数所分配的空间处于什么位置 printf(\u0026#34;Caught signal %d (%s)\\n\u0026#34;, sig, strsignal(sig)); printf(\u0026#34;Top of handler stack near %10p\\n\u0026#34;, (void *)\u0026amp;x); // fflush(NULL)的作用是在程序异常终止前确保所有标准输出缓冲区的数据都被写入到相应的输出设备。 fflush(NULL); _exit(EXIT_FAILURE); } static void overflowStack(int callNum) { char a[100000]; // 此类分配数组方式为栈上分配 printf(\u0026#34;Call %4d - top of stack near %10p\\n\u0026#34;, callNum, \u0026amp;a[0]); overflowStack(callNum + 1); // 无限递归调用，不断在栈上分配空间，每次分配100000字节以上 } int main(int argc, char *argv[]) { stack_t sigstack; struct sigaction sa; int j; printf(\u0026#34;Top of standard stack is near %10p\\n\u0026#34;, (void *)\u0026amp;j); // 分配备用栈并通知内核 // 在堆当中分配备用栈 sigstack.","title":"在备选栈中处理信号"},{"content":"之前搭建hexo博客，是将其部署到github中，通过github.io来访问，但是速度感人，所以本次尝试将hugo博客部署到阿里云服务器，通过域名进行访问，本文参考了hugo博客部署到腾讯云轻量级服务器。 由于是我第一次使用nginx，所以如果遇到什么问题，请多海涵并且可以参考其他博客或网络资料。\n在部署之前，我已经有了阿里云服务器（配置为2核2GB）、域国外平台购买的域名（staryh.top）。\n1. 服务器端下载并安装nginx 1.1 安装nginx 在ubuntu环境下： 安装nginx\n1 sudo apt install nginx 将nginx设置为开机启动：\n1 sudo systemctl enable nginx 启动nginx：\n1 sudo systemctl start nginx 1.2 测试nginx 查看nginx状态\n1 sudo systemctl status nginx 如果没问题，则会出现：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 ● nginx.service - A high performance web server and a reverse proxy server Loaded: loaded (/lib/systemd/system/nginx.service; enabled; vendor preset: enabled) Active: active (running) since Fri 2024-07-26 21:46:50 CST; 1 day 13h ago Docs: man:nginx(8) Process: 164834 ExecStartPre=/usr/sbin/nginx -t -q -g daemon on; master_process on; (code=exited, status=0/SUCCESS) Process: 164836 ExecStart=/usr/sbin/nginx -g daemon on; master_process on; (code=exited, status=0/SUCCESS) Main PID: 164837 (nginx) Tasks: 3 (limit: 1947) Memory: 4.1M CPU: 26ms CGroup: /system.slice/nginx.service ├─164837 \u0026#34;nginx: master process /usr/sbin/nginx -g daemon on; master_process on;\u0026#34; ├─164838 \u0026#34;nginx: worker process\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; └─164839 \u0026#34;nginx: worker process\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; Jul 26 21:46:50 Firefly-Aliyun systemd[1]: Starting A high performance web server and a reverse proxy server... Jul 26 21:46:50 Firefly-Aliyun systemd[1]: Started A high performance web server and a reverse proxy server. 通过阿里云服务器管理面板中的安全组标签，将服务器的80端口开放。接下来访问http://\u0026lt;服务器IP地址\u0026gt;，如果出现了nginx页面，则代表着配置成功。\n2. 配置nginx 进入/etc/nginx/，目录树如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 . ├── conf.d ├── fastcgi.conf ├── fastcgi_params ├── koi-utf ├── koi-win ├── mime.types ├── modules-available ├── modules-enabled │ ├── 50-mod-http-geoip2.conf -\u0026gt; /usr/share/nginx/modules-available/mod-http-geoip2.conf │ ├── 50-mod-http-image-filter.conf -\u0026gt; /usr/share/nginx/modules-available/mod-http-image-filter.conf │ ├── 50-mod-http-xslt-filter.conf -\u0026gt; /usr/share/nginx/modules-available/mod-http-xslt-filter.conf │ ├── 50-mod-mail.conf -\u0026gt; /usr/share/nginx/modules-available/mod-mail.conf │ ├── 50-mod-stream.conf -\u0026gt; /usr/share/nginx/modules-available/mod-stream.conf │ └── 70-mod-stream-geoip2.conf -\u0026gt; /usr/share/nginx/modules-available/mod-stream-geoip2.conf ├── nginx.conf ├── proxy_params ├── scgi_params ├── sites-available │ └── default ├── sites-enabled │ └── default -\u0026gt; /etc/nginx/sites-available/default ├── snippets │ ├── fastcgi-php.conf │ └── snakeoil.conf ├── uwsgi_params └── win-utf 根据参考博客，要在nginx.conf文件中编辑Server字段，但是在我的这个文件中，并没有出现该字段。经过查阅资料，可以在./sites-available/default当中编辑。\n当没有SSL证书时：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 server { listen 80 default_server; listen [::]:80 default_server; # 修改页面所在目录 root /home/firefly/Codes/blog/public; # Add index.php to the list if you are using PHP index index.html index.htm index.nginx-debian.html; # 修改域名 server_name www.staryh.top; # 修改 location / { # First attempt to serve request as file, then # as directory, then fall back to displaying a 404. root /home/firefly/Codes/blog/public; index index.html index.htm; # try_files $uri $uri/ =404; } error_page 404 /404.html; location = /404.html { root /home/firefly/Codes/blog/public; } } 经过上述修改之后，输入服务器IP地址，就可以访问了\n3. 将域名绑定到服务器 需要域名备案，否则访问不了\n在namecheap上面购买的域名，然后通过cloudflare来对域名解析进行管理。这一步比较简单，参考了域名注册和解析\n4. 实现本机和服务器的public文件夹同步 在这一部分，我的想法比较复杂。\n将本地的博客文件夹放到github中，方便更多人能够访问我的博客所有的文件。 考虑到github的访问速度，打算在gitee中建立一个镜像的仓库，以实现github和gitee的博客文件夹的同步。 这样服务器只需要pull gitee 仓库中的public子文件夹，便可以得到本地主机push到github仓库中的public文件夹。 4.1 本地-\u0026gt;github 将本地博客文件夹push到github仓库中\n4.2 github-\u0026gt;gitee 在gitee上绑定github账号； 在gitee中创建同名仓库，在仓库的管理标签页，选择仓库镜像管理，添加镜像，选择镜像方向为pull gitee \u0026lt;- github，选择正确的镜像仓库，并添加私人令牌，私人令牌在github界面-\u0026gt;用户头像-\u0026gt;settings-\u0026gt;developer settings-\u0026gt;personal access tokens中获取，勾选自动同步。 这样每次本地编辑完并上传github之后，稍等片刻就能在gitee看到修改了😊 截止到写本篇博客时，gitee的仓库镜像管理功能一直存在，且可以自动同步。如果该自动同步功能不见了，可以尝试一篇教你代码同步 Github 和 Gitee中的做法。\n4.3 gitee-\u0026gt;服务器 进入到修改页面所在目录的父目录/home/firefly/Codes/blog，删除原来通过xtfp传输来的public文件夹；\n在本地仓库启用sparseCheckout\n1 git config core.sparseCheckout true 打开./.git/info，然后编辑其中的sparseCheckout文件（如果没有可以新建），将需要指定pull的文件夹位置输入进去：/public；\n回到blog目录，添加远程仓库，并pull（在pull的时候遇到了公私钥导致无法访问的问题，具体解决参考了解决 “fatal: Could not read from remote repository.“）。\n1 git remote add origin git@gitee.com:yourname/yourrepo.git 5. SSL证书 5.1 获得SSL证书 由于阿里云策略改变，目前免费的只有个人测试证书（原免费证书）。\n根据Nginx或Tengine服务器配置SSL证书来进行配置。 其中，将下载的证书相关文件解压缩到/etc/nginx/中，\n5.3 修改nginx配置 同样地，在default文件中，结合了本文提到的两个博客，增加以下内容：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 server { listen 443 ssl; server_name www.fireflyyh.top; root /home/firefly/Codes/blog/public; ssl_certificate /etc/nginx/fireflyyh.top.pem; ssl_certificate_key /etc/nginx/fireflyyh.top.key; ssl_session_cache shared:SSL:1m; ssl_session_timeout 5m; #自定义设置使用的TLS协议的类型以及加密套件（以下为配置示例，请您自行评估是否需要配置） #TLS协议版本越高，HTTPS通信的安全性越高，但是相较于低版本TLS协议，高版本TLS协议对浏览器的兼容性较差。 ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4; ssl_protocols TLSv1.1 TLSv1.2 TLSv1.3; #表示优先使用服务端加密套件。默认开启 ssl_prefer_server_ciphers on; error_page 404 /404.html; location = /404.html { root /home/firefly/Codes/blog/public; } } ","permalink":"https://fireflyyh.top/posts/blog_configuration/deploy/","summary":"之前搭建hexo博客，是将其部署到github中，通过github.io来访问，但是速度感人，所以本次尝试将hugo博客部署到阿里云服务器，通过域名进行访问，本文参考了hugo博客部署到腾讯云轻量级服务器。 由于是我第一次使用nginx，所以如果遇到什么问题，请多海涵并且可以参考其他博客或网络资料。\n在部署之前，我已经有了阿里云服务器（配置为2核2GB）、域国外平台购买的域名（staryh.top）。\n1. 服务器端下载并安装nginx 1.1 安装nginx 在ubuntu环境下： 安装nginx\n1 sudo apt install nginx 将nginx设置为开机启动：\n1 sudo systemctl enable nginx 启动nginx：\n1 sudo systemctl start nginx 1.2 测试nginx 查看nginx状态\n1 sudo systemctl status nginx 如果没问题，则会出现：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 ● nginx.service - A high performance web server and a reverse proxy server Loaded: loaded (/lib/systemd/system/nginx.service; enabled; vendor preset: enabled) Active: active (running) since Fri 2024-07-26 21:46:50 CST; 1 day 13h ago Docs: man:nginx(8) Process: 164834 ExecStartPre=/usr/sbin/nginx -t -q -g daemon on; master_process on; (code=exited, status=0/SUCCESS) Process: 164836 ExecStart=/usr/sbin/nginx -g daemon on; master_process on; (code=exited, status=0/SUCCESS) Main PID: 164837 (nginx) Tasks: 3 (limit: 1947) Memory: 4.","title":"将博客部署到阿里云服务器"},{"content":"TLPI 21.2.1：在信号处理器函数中执行非本地跳转 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 #define _GNU_SOURCE // 添加该定义以正常使用strsignal() #include \u0026lt;string.h\u0026gt; #include \u0026lt;setjmp.h\u0026gt; #include \u0026lt;signal.h\u0026gt; #include \u0026#34;signal_functions.h\u0026#34; #include \u0026#34;tlpi_hdr.h\u0026#34; static volatile sig_atomic_t canJump = 0; #ifdef USE_SIGSETJMP static sigjmp_buf senv; #else static jmp_buf env; #endif static void handler(int sig) { printf(\u0026#34;Received signal %d (%s), signal mask is:\\n\u0026#34;, sig, strsignal(sig)); printSigMask(stdout, NULL); if (!canJump) { // 若canJump为0 printf(\u0026#34;\u0026#39;env\u0026#39; buffer not yet set, doing a simple return\\n\u0026#34;); return; } #ifdef USE_SIGSETJMP siglongjmp(senv, 1); #else longjmp(env, 1); #endif } int main(int argc, char *argv[]) { struct sigaction sa; printSigMask(stdout, \u0026#34;Signal mask at startup:\\n\u0026#34;); // 打印最开始的信号掩码 sigemptyset(\u0026amp;sa.sa_mask); sa.sa_flags = 0; sa.sa_handler = handler; if (sigaction (SIGINT, \u0026amp;sa, NULL) == -1) errExit(\u0026#34;sigaction\u0026#34;); #ifdef USE_SIGSETJMP printf(\u0026#34;Calling sigsetjmp()\\n\u0026#34;); /* */ if (sigsetjmp(senv, 1) == 0) #else printf(\u0026#34;Calling setjmp()\\n\u0026#34;); // 设置跳转目标，并初始化env if (setjmp(env) == 0) #endif // 当从处理器函数直接返回之后才会执行该语句 canJump = 1; else // 当从处理器函数执行非本地跳转之后才会执行该语句 printSigMask(stdout, \u0026#34;After jump from handler, signal mask is:\\n\u0026#34;); printf(\u0026#34;Will be paused\\n\u0026#34;); for (;;) /* 等待信号， 若接收到SIGINT，则跳转到处理器函数中，再由longjmp()/siglongjmp()跳转到setjmp()/sigsetjmp() 具体是哪个跳转函数，则取决于是否宏定义了USE_SIGSETJMP */ pause(); } 解释 canjump的用法 接收到信号的时机有两种：\n在setjmp(env)之前，在这种情况下，跳转目标尚未建立，这将导致处理器函数使用尚未初始化的 env 缓冲区来执行非本地跳转； 在setjmp(env)之后，在这种情况下，跳转目标被建立，env已被初始化在执行longjmp()/siglongjmp()之后，可以正确地将一些信息保存。 为了避免出现第一种情况，设置了 canJump 变量，当第一次执行了setjmp(env)之后canjump被设置为1，代表着可以正确执行非本地跳转。然后在此Handler()的if (canJump)处，若 canjump 为0，说明接收到信号的时机是在 set 之前，则不能够进行跳转，而是直接从处理器函数返回。\n两种跳转方法的区别 sigsetjmp()比setjmp()多出一个参数 savesigs。如果指定 savesigs 为非 0，那么会将调用 sigsetjmp()时进程的当前信号掩码保存于 env 中，之后通过指定相同 env 参数的siglongjmp()调用进行恢复。如果 savesigs 为0，则不会保存和恢复进程的信号掩码。\n","permalink":"https://fireflyyh.top/posts/tlpi/sigmask_longjmp/","summary":"TLPI 21.2.1：在信号处理器函数中执行非本地跳转 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 #define _GNU_SOURCE // 添加该定义以正常使用strsignal() #include \u0026lt;string.","title":"在信号处理器函数中执行非本地跳转"},{"content":"16年 单周期数据通路 单周期数据通路是一种简单的数据通路设计，每个时钟周期执行一条完整的指令，即每条指令的CPI为1，要考虑比较慢的指令，所以处理器的时钟频率较低。 这意味着每条指令执行过程中任何数据通路单元都只能被用一次，如果需要使用多次则必须将该数据通路单元复制多份。\n控制信号是CU根据指令操作码发出的信号，对于单周期处理器来说，每条指令的执行只有一个时钟周期，而在一个时钟周期内控制信号并不会变化。\n单周期数据通路必须有独立的指令存储器和数据存储器，因为处理器在一个周期内只能操作每个部件一次，而在一个周期内不可能对一个单端口存储器进行两次存取。且无法使用单总线数据通路，因为单总线数据通路将所有寄存器的输入出端都连接在一条公共通路上，一个时钟内只允许一次操作，无法完成指令的所有操作。\nTSL指令实现互斥 1 2 3 4 5 6 do { while (TSL(\u0026amp;lock)); critical section; lock = FALSE; ...... } while (TRUE); 退出临界区的进程负责唤醒就绪态进程？？？\n因为在TSL方法下，一个进程只有两种状态：\n运行态：用户处于了do{ }中，那么不管是是在其中的while (TSL(\u0026amp;lock))不断地循环，还是在访问临界资源，都是占用着CPU的，也就是处于运行态； 就绪态：若是在执行过程中由于并发所需要（如时间片到了），被其他进程占用了CPU，就变成了就绪态； 但是不会处于阻塞态，因为若是在等待临界资源，则会一直处于while (TSL(\u0026amp;lock));中，而且不会主动放弃CPU变成阻塞态（阻塞是一个主动的过程）。故不存在阻塞态的进城来给退出临界区的进程唤醒。\n等待进入临界区的进程不会主动放弃CPU，故上述代码不满足“让权等待”的同步准则。因为会一直停留在执行while(TSL(\u0026amp;lock))的循环中，该语句应在开中断下进行，否则一直处于该循环且不被其他进程中断可能会导致系统终止。\n操作系统的发展 手工发展阶段（无操作系统）：\n所有工作都要人干预，用户独占全机。\n特点：用户独占全机、CPU等待手工操作；\n缺点：人机矛盾及 CPU 和 I/O 设备之间速度不匹配的矛盾，因此发展出了批处理系统。\n批处理阶段（开始出现操作系统）：\n单道批处理：系统对作业的处理是成批进行的，但内存中始终保持一道作业。\n特点：单道性、自动性、顺序性。\n缺点：每次主机内存中仅存放一道作业，每当它在运行时发出I/O请求后，高速的 CPU 便处于等待低速的 I/O 完成的状态。\n为了进一步提高资源的利用率和系统的吞吐量，引入了多道程序技术。 多道批处理：多道程序设计技术允许多个程序同时进入内存并允许它们在 CPU 中交替地运行。\n特点：多道、宏观上并行、微观上串行。\n优点：资源利用率高，多道程序共享计算机资源，从而使各种资源得到充分利用；系统吞吐量大， CPU 和其他资源保持“忙碌”状态。 缺点：用户响应的时间较长；不提供人机交互能力，用户既不能了解自己的程序的运行情况，又不能控制计算机。 因此发展出了分时操作系统。 分时操作系统：\n分时操作系统是指多个用户通过终端同时共享一台主机，这些终端连接在主机上，用户可以同时（同时性）与主机进行交互（交互性）操作而互不干扰（独立性）。分时系统采用时间片轮转方式使一台计算机同时为多个终端服务，使用户能够对系统的及时响应感到满意（及时性）。分时系统也是支持多道程序设计的系统，但它不同于多道批处理系统。多道批处理是实现作业自动控制而无须人工干预的系统，而分时系统是实现人机交互的系统。\n特点：同时性、交互性、独立性、及时性。\n优点：较好地解决了人机交互问题。\n缺点：在一些应用场合，需要系统能对外部的信息在规定的时间（比时间片的时间还短）内做出处理（比如飞机订票系统或导弹制导系统），因此，实时操作系统应运而生。\n描述 特点 优点 缺点 手工操作阶段 所有工作都要人干预 用户独占全机、CPU等待手工操作； 不会出现因资源己被其他用户占用而等待的情况 资源利用率低，人机矛盾及 CPU 和 I/O 设备之间速度不匹配的矛盾，因此发展出了批处理系统。 单道批处理 系统对作业的处理是成批进行的，但内存中始终保持一道作业。 单道性、自动性、顺序性。 （开始出现操作系统） 每次主机内存中仅存放一道作业，每当它在运行时发出I/O请求后，高速的 CPU 便处于等待低速的 I/O 完成的状态。 为了进一步提高资源的利用率和系统的吞吐量，引入了多道程序技术。 多道批处理 多道程序设计技术允许多个程序同时进入内存并允许它们在 CPU 中交替地运行。 多道性、宏观上并行、微观上串行。 资源利用率高，多道程序共享计算机资源，从而使各种资源得到充分利用；系统吞吐量大， CPU 和其他资源保持“忙碌”状态。 用户响应的时间较长；不提供人机交互能力，用户既不能了解自己的程序的运行情况，又不能控制计算机。 因此发展出了分时操作系统。 分时操作系统 用户可以同时（同时性）与主机进行交互（交互性）操作而互不干扰（独立性）。分时系统采用时间片轮转方式使一台计算机同时为多个终端服务，使用户能够对系统的及时响应感到满意（及时性）。 同时性、交互性、独立性、及时性。 较好地解决了人机交互问题。 在一些应用场合，需要系统能对外部的信息在规定的时间（比时间片的时间还短）内做出处理（比如飞机订票系统或导弹制导系统），因此，实时操作系统应运而生。 实时操作系统 为了能在某个时间限制内完成某些紧急任务而不需要时间片排队，诞生了实时操作系统。资源利用率不是其主要追求目标。 及时性、可靠性 管程 管程是由一组数据以及定义在这组数据之上的对这组数据的操作组成的软件模块，这组操作能初始化并改变管程中的数据和同步进程。管程不仅能实现进程间的互斥，而且能实现进程间的同步。\n管程由 4 部分组成：\n管程的名称； 局部于管程内部的共享数据结构说明； 对该数据结构进行操作的一组过程（或函数）； 对局部于管程内部的共享数据设置初始值的语句。 管程具有特性：\n局部于管程的数据只能被局部于管程内的过程所访问； 一个进程只有通过调用管程内的过程才能进入管程访问共享数据； 每次仅允许一个进程在管程内执行某个内部过程（实现互斥）； 互斥访问数据是由编译器实现的，程序员不用关心。 例如，若x是管程内的条件变量，则当进程执行x.wait()时所做的工作是阻塞该进程，并将之插入x的阻塞队列中。\n“条件变量”是管程内部说明和使用的一种特殊变量，其作用类似于信号量机制中的“信号量”，都是用于实现进程同步的。需要注意的是，在同一时刻，管程中只能有一个进程在执行。如果进程 A 执行了x.wait()操作，那么该进程会阻塞，并挂到条件变量 x 对应的阻塞队列上。这样，管程的使用权被释放，就可以有另一个进程进入管程。如果进程 B 执行了x.signal()操作，那么会唤醒 x 对应的阻塞队列队头进程。在 Pascal 语言的管程中，规定只有一个进程要离开管程时才能调用signal()操作。\nSPOOLing技术 四次挥手各自的阶段 为什么是三次握手而不是两次握手？ 为什么是四次挥手而不是三次挥手？ 17年 顺序存储、链式存储对不同排序方式的影响 由顺序存储变成链式存储后，效率不会降低的有：插入排序、（简单）选择排序、冒泡排序，因为顺序存储下，时间复杂度就是$O(n^2)$，链式存储不会改变其复杂度；\n效率会降低的有：希尔排序、堆排序、快速排序，因为是利用了顺序存储的随机访问特性。\n指令级并行 超流水线：通过增加流水线级数来使更多的指令同时在流水线中重叠执行。超流水线并没有改变CPI的值，CPI还是1，但是，因为理想情况下流水线的加速比与流水段的数目成正比，流水段越多，时钟周期越短，主频越高，指令吞吐率越高，所以超流水线的性能比普通流水线好。然而，流水线级数越多，用于流水段寄存器的开销就越大，因而流水线级数是有限制的，不可能无限增加。 在《计算机组成与设计：软件/硬件接口》书中，有一个形象的解释：\n任何一个经常光顾洗衣店的人都会不自觉地使用流水线技术。非流水线方式的洗衣过程包括如下几个步骤：\n把一批脏衣服放入洗衣机里清洗 洗衣机洗完后，把衣服取出并放入烘干机中。 烘干衣服后，将衣服从烘干机中取出，然后放在桌子上叠起来。 叠好衣服后，请你的室友帮忙把桌子上的衣服收好。 当你的室友把这批干净衣服从桌子上拿走后，再开始洗下一批脏衣服。采用流水线的方法将节省大量的时间，如图 4-25 所示。当把第一批脏衣服从洗衣机里取出放入烘干机之后，就可以把第二批脏衣服放入洗衣机里进行清洗了。当第一批衣服被烘干之后，就可以将它们叠起来，同时把洗净的下一批湿衣服放入烘干机中，同时再将下一批脏衣服放入洗衣机里清洗。接着让你的室友把第一批衣服从桌子上收好，而你开始叠第二批衣服，这时烘干机中放的是第三批衣服，同时可以把第四批脏衣服放入洗衣机清洗了。这样，所有的洗衣步骤（流水线的步骤）都在同时操作。只要在每一个操作步骤中都有独立的工作单元时，我们就可以采用流水线的方式来快速完成任务了。\n有两种方法可以增加潜在的指令级并行程度：\n第一种是增加流水线的深度以重叠更多的指令。还是用洗衣店的例子来说明，假设洗衣机周期比其他机器的周期要长，我们可以把洗衣机划分成三个机器，分别完成原洗衣机洗、漂、甩三个功能。这样我们就将四级流水线变成了六级流水线。为了达到完全的加速效果，我们需要重新平衡其他步骤使得它们的长度相同，在处理器和洗衣店中都是这样。因为更多的操作被重叠，有更多的并行性被挖掘出来。\n通过增加流水线级数来使更多的指令同时在流水线中重叠执行。超流水线并没有改变CPI的值，CPI还是1，但是，因为理想情况下流水线的加速比与流水段的数目成正比，流水段越多，时钟周期越短，主频越高，指令吞吐率越高，所以超流水线的性能比普通流水线好。然而，流水线级数越多，用于流水段寄存器的开销就越大，因而流水线级数是有限制的，不可能无限增加。\n另一种方法是复制计算机内部部件的数量，使得每个流水级可以启动多条指令。这种技术一般被称为多发射。一个多发射的洗衣店会把原有的一台洗衣机和烘干机替换为三台洗衣机和三台烘干机。还需要雇用更多的洗衣工来折叠和存储三倍于原来的衣服。这种方法的缺点是需要额外的工作让所有机器同时运转并将负载传到下个流水级。\n实现多发射流水线必须完成以下两个任务：指令打包和冒险处理。指令打包任务就是将能够并行处理的多条指令同时发送到发射槽中，因此处理器必须知道每个周期能发射几条指令，哪些指令可以同时发射。这通过推测技术来完成，可以由编译器或处理器通过猜测指令执行结果来调整指令执行顺序。根据推测任务主要由编译器静态完成还是由处理器动态执行，可将多发射技术分为两类：静态多发射和动态多发射：\n静态多发射主要通过编译器静态推测来辅助完成“指令打包”和“冒险处理”。指令打包的结果可看成将同时发射的多条指令合并到一个长指令中。通常将一个时钟周期内发射的多个指令看成一条多个操作的长指令，称为一个“发射包“。所以，静态多发射指令最初被称为“超长指令字”。\n动态多发射由处理器硬件动态进行流水线调度来完成“指令打包“和“冒险处理”，能在一个时钟周期内执行一条以上指令。采用动态多发射流水线技术的处理器称为超标量处理器。在简单的超标量处理器中，指令按顺序发射，每个周期由处理器决定是发射一条或多条指令。能结合动态调度技术提高指令执行并行性。\n数据通路包含哪些 机器指令的执行是在数据通路中完成的，通常将指令执行过程中数据所经过的路径（包括路径上的部件）称为数据通路。程序计数器、ALU、通用寄存器、状态寄存器、cache、MMU（主存管理单元）、浮点运算逻辑、异常和中断处理逻辑等都是指令执行过程中数据流经的部件，都属于数据通路的一部分。通常把数据通路中专门进行数据运算的部件称为执行部件(execution unit) 或功能部件(function unit)。数据通路由控制部件进行控制。控制部件根据每条指令功能的不同生成对数据通路的控制信号，因此数据通路不包括控制部件。\n指令执行所用到的元件有两类：组合逻辑元件（也称操作元件）和时序逻辑元件（也称状态元件或存储元件）。故也可以说数据通路由组合逻辑电路和时序逻辑电路组合而成。\n组合逻辑元件的输出只取决于当前的输人。若输入一样，其输出也一样。组合电路的定时不受时钟信号的控制，所有输入信号到达后，经过一定的逻辑门延迟，输出端的值被改变，并一直保持其值不变，直到输入信号改变。数据通路中常用的组合逻辑元件有多路选择器（MUX） 、加法器（Adder） 、算术逻辑部件（ALU）、译码器（Decoder）等。\n时序逻辑元件具有存储功能，输人状态在时钟控制下被写到电路中，并保持电路的输出值不变，直到下一个时钟到达。输人端状态由时钟决定何时被写入，输出端状态随时可以读出。数据通路中的寄存器是一种典型的状态存储元件，根据功能和实现方式的不同，有各种不同类型的寄存器。\n磁盘初始化 低级格式化（物理格式化）：一个新的磁盘是一个空白版，必须分成扇区以便磁盘控制器能读和写，这个过程称为低级格式化（或物理格式化）。低级格式化为磁盘的每个扇区采用特别的数据结构，包括校验码。 磁盘分区：磁盘分为由一个或多个柱面组成的分区，每个分区可以作为一个独立的磁盘。 逻辑格式化（创建文件系统）：在这一步，操作系统将初始的文件系统数据结构存储到磁盘上，包括创建文件系统的根目录，对空闲磁盘块进行管理的数据结构进行初始化（如位示图、空闲分区表、i结点区） 划分扇区不等于磁盘分区。\nMAC帧的地址 “接化发”\n滑动窗口的窗口尺寸及序号 18年 行地址位数和列地址位数的大小关系 在采用引脚复用时，为了提高DRAM的性价比，通常设置行地址位数$r$和列地址位数$c$满足$r\\leq c$且$|r-c|$最小。\n可以提高文件访问速度的措施 提前读：提前读是指读当前盘块时，将下个可能要访问的盘块数据读入缓冲区，以便需要时直接从缓冲区中读取，提高了文件的访问速度； 为文件分配连续的簇； 延迟写：延迟写是先将写数据写入缓冲区，并置上“延迟写”标志，以备不久之后、问，当缓冲区需要再次被分配出去时才将缓冲区数据写入磁盘，减少了访问磁盘的次数，高了文件的访问速度； 采用磁盘高速缓存； 分用复用 发送方的某些应用进程所发送的不同的应用报文，在传输层使用UDP协议进行封装，称为UDP复用，TCP复用概念类似。传输层发送端使用源端口号来区分不同的应用进程； 不管是UDP封装的UDP用户数据报还是TCP协议封装的TCP报文段，在网络层都需要使用IP协议来封装成IP数据报，称为IP复用，IP数据报首部的协议字段的值用来表明封装的是何种协议数据单元，如取值为6表示封装的是TCP报文段，取值为17表示封装的是UDP用户数据报； 接收方网络层收到IP数据报后进行IP分用，根据IP首部的协议字段来向上交付给传输层对应的协议。 接收方传输层根据UDP数据报或TCP报文段首部的目的端口号，向上交付给应用层的相应应用进程。 19年 森林的遍历、多叉树的遍历 树 森林 二叉树 先根遍历 先序遍历 先序遍历 后根遍历 中序遍历 中序遍历 森林的先序遍历也称为先根遍历，中序遍历也称为中根遍历、后根遍历。\n根据虚拟地址访存过程 结合了cache和虚拟存储器的CPU访存过程 cache缺失由硬件完成；缺页处理由软件完成，操作系统通过缺页异常处理程序来实现；TLB缺失既可以由硬件来处理也可以软件来处理。用软件处理时，OS通过专门的TLB缺失异常处理程序来实现。\nDMA的一些细节 DMA的数据传送分为预处理、数据传送和后处理3个阶段。\nDMA预处理阶段需要CPU参与，由CPU完成必要的准备工作，由设备驱动程序设置传送参数**。每类设备都配置一个设备驱动程序，设备驱动程序向上层用户程序提供一组标准接口，负责实现对设备发出各种具体操作指令，**用户程序不能直接和 DMA 打交道。 在DMA传送过程中，DMA控制器直接控制总线传输。每次将一个数据块送到主存中后，在下次数据传送前，DMA控制器会再次请求总线使用权（即DMA请求），该请求的响应无需CPU干预； 在所有所需的块传送完成后，DMA传送结束，进入后处理阶段，DMA控制器发出DMA中断，CPU参与中断的处理。 用户级线程、内核级线程 各种动态分区管理方式特点 首次适应（ First Fit ）算法。空闲分区以地址递增的次序链接。分配内存时，从链首开始顺序查找，找到大小能满足要求的第一个空闲分区分配给作业。 邻近适应（ Next Fit) 算法。又称循环首次适应算法，由首次适应算法演变而成。不同之处是，分配内存时从上次查找结束的位置开始继续查找。 最佳适应（ Best Fit ）算法。空闲分区按容量递增的次序形成空闲分区链，找到第一个能满足要求且最小的空闲分区分配给作业，避免“大材小用”。 最坏适应 (Worst Fit ）算法。空闲分区以容量递减的次序链接，找到第一个能满足要求的，即最大的分区，从中分割一部分存储空间给作业。 首次适应算法最简单，通常也是最好和最快的。不过，首次适应算法会使得内存的低地址部分出现很多小的空闲分区，而每次分配查找时都要经过这些分区，因此增加了开销。\n邻近适应算法试图解决这个问题。但它常常导致在内存空间的尾部（因为在一遍扫描中，内存前面部分使用后再释放时，不会参与分配）分裂成小碎片。通常比首次适应算法要差。\n最佳适应算法虽然称为“最佳”，但是性能通常很差，因为每次最佳的分配会留下很小的难以利用的内存块，会产生最多的外部碎片。\n最坏适应算法与最佳适应算法相反，它选择最大的可用块，这看起来最不容易产生碎片，但是却把最大的连续内存划分开，会很快导致没有可用的大内存块，因此性能也非常差。\n物理层介质总结 同轴电缆：coaxial cable\n双绞线：Twisted pair（T）\n绞合的作用：\n减少相邻导线间的电磁干扰 抵御部分来自外界的电磁干扰 光纤：Optical fiber（F）\n光纤的优点：\n通信容量非常大 抗雷电和电磁千扰 性能好，传输损耗小，中继距离长 无串音，干扰保密性好 体积小，重量轻 光线的缺点：\n切割光纤需要较贵的专用设备 目前光电接口还比较昂贵 GBN确认号、TCP确认号 在GBN中，若本次A发送给B的帧序号为n，B发送给A的确认序号为n，说明已经收到了前n个帧；\n在TCP中，若本次B发送的确认报文段中的确认号为n+1，说明已经收到了A发送给B的前n个报文段，期待收到第n+1个报文段；\n","permalink":"https://fireflyyh.top/posts/408/%E7%9C%9F%E9%A2%98%E6%80%BB%E7%BB%932/","summary":"16年 单周期数据通路 单周期数据通路是一种简单的数据通路设计，每个时钟周期执行一条完整的指令，即每条指令的CPI为1，要考虑比较慢的指令，所以处理器的时钟频率较低。 这意味着每条指令执行过程中任何数据通路单元都只能被用一次，如果需要使用多次则必须将该数据通路单元复制多份。\n控制信号是CU根据指令操作码发出的信号，对于单周期处理器来说，每条指令的执行只有一个时钟周期，而在一个时钟周期内控制信号并不会变化。\n单周期数据通路必须有独立的指令存储器和数据存储器，因为处理器在一个周期内只能操作每个部件一次，而在一个周期内不可能对一个单端口存储器进行两次存取。且无法使用单总线数据通路，因为单总线数据通路将所有寄存器的输入出端都连接在一条公共通路上，一个时钟内只允许一次操作，无法完成指令的所有操作。\nTSL指令实现互斥 1 2 3 4 5 6 do { while (TSL(\u0026amp;lock)); critical section; lock = FALSE; ...... } while (TRUE); 退出临界区的进程负责唤醒就绪态进程？？？\n因为在TSL方法下，一个进程只有两种状态：\n运行态：用户处于了do{ }中，那么不管是是在其中的while (TSL(\u0026amp;lock))不断地循环，还是在访问临界资源，都是占用着CPU的，也就是处于运行态； 就绪态：若是在执行过程中由于并发所需要（如时间片到了），被其他进程占用了CPU，就变成了就绪态； 但是不会处于阻塞态，因为若是在等待临界资源，则会一直处于while (TSL(\u0026amp;lock));中，而且不会主动放弃CPU变成阻塞态（阻塞是一个主动的过程）。故不存在阻塞态的进城来给退出临界区的进程唤醒。\n等待进入临界区的进程不会主动放弃CPU，故上述代码不满足“让权等待”的同步准则。因为会一直停留在执行while(TSL(\u0026amp;lock))的循环中，该语句应在开中断下进行，否则一直处于该循环且不被其他进程中断可能会导致系统终止。\n操作系统的发展 手工发展阶段（无操作系统）：\n所有工作都要人干预，用户独占全机。\n特点：用户独占全机、CPU等待手工操作；\n缺点：人机矛盾及 CPU 和 I/O 设备之间速度不匹配的矛盾，因此发展出了批处理系统。\n批处理阶段（开始出现操作系统）：\n单道批处理：系统对作业的处理是成批进行的，但内存中始终保持一道作业。\n特点：单道性、自动性、顺序性。\n缺点：每次主机内存中仅存放一道作业，每当它在运行时发出I/O请求后，高速的 CPU 便处于等待低速的 I/O 完成的状态。\n为了进一步提高资源的利用率和系统的吞吐量，引入了多道程序技术。 多道批处理：多道程序设计技术允许多个程序同时进入内存并允许它们在 CPU 中交替地运行。\n特点：多道、宏观上并行、微观上串行。\n优点：资源利用率高，多道程序共享计算机资源，从而使各种资源得到充分利用；系统吞吐量大， CPU 和其他资源保持“忙碌”状态。 缺点：用户响应的时间较长；不提供人机交互能力，用户既不能了解自己的程序的运行情况，又不能控制计算机。 因此发展出了分时操作系统。 分时操作系统：\n分时操作系统是指多个用户通过终端同时共享一台主机，这些终端连接在主机上，用户可以同时（同时性）与主机进行交互（交互性）操作而互不干扰（独立性）。分时系统采用时间片轮转方式使一台计算机同时为多个终端服务，使用户能够对系统的及时响应感到满意（及时性）。分时系统也是支持多道程序设计的系统，但它不同于多道批处理系统。多道批处理是实现作业自动控制而无须人工干预的系统，而分时系统是实现人机交互的系统。\n特点：同时性、交互性、独立性、及时性。\n优点：较好地解决了人机交互问题。\n缺点：在一些应用场合，需要系统能对外部的信息在规定的时间（比时间片的时间还短）内做出处理（比如飞机订票系统或导弹制导系统），因此，实时操作系统应运而生。\n描述 特点 优点 缺点 手工操作阶段 所有工作都要人干预 用户独占全机、CPU等待手工操作； 不会出现因资源己被其他用户占用而等待的情况 资源利用率低，人机矛盾及 CPU 和 I/O 设备之间速度不匹配的矛盾，因此发展出了批处理系统。 单道批处理 系统对作业的处理是成批进行的，但内存中始终保持一道作业。 单道性、自动性、顺序性。 （开始出现操作系统） 每次主机内存中仅存放一道作业，每当它在运行时发出I/O请求后，高速的 CPU 便处于等待低速的 I/O 完成的状态。 为了进一步提高资源的利用率和系统的吞吐量，引入了多道程序技术。 多道批处理 多道程序设计技术允许多个程序同时进入内存并允许它们在 CPU 中交替地运行。 多道性、宏观上并行、微观上串行。 资源利用率高，多道程序共享计算机资源，从而使各种资源得到充分利用；系统吞吐量大， CPU 和其他资源保持“忙碌”状态。 用户响应的时间较长；不提供人机交互能力，用户既不能了解自己的程序的运行情况，又不能控制计算机。 因此发展出了分时操作系统。 分时操作系统 用户可以同时（同时性）与主机进行交互（交互性）操作而互不干扰（独立性）。分时系统采用时间片轮转方式使一台计算机同时为多个终端服务，使用户能够对系统的及时响应感到满意（及时性）。 同时性、交互性、独立性、及时性。 较好地解决了人机交互问题。 在一些应用场合，需要系统能对外部的信息在规定的时间（比时间片的时间还短）内做出处理（比如飞机订票系统或导弹制导系统），因此，实时操作系统应运而生。 实时操作系统 为了能在某个时间限制内完成某些紧急任务而不需要时间片排队，诞生了实时操作系统。资源利用率不是其主要追求目标。 及时性、可靠性 管程 管程是由一组数据以及定义在这组数据之上的对这组数据的操作组成的软件模块，这组操作能初始化并改变管程中的数据和同步进程。管程不仅能实现进程间的互斥，而且能实现进程间的同步。","title":"真题总结2"},{"content":"10年 平衡二叉树的调整 LL调整 RR调整 RL调整 例如（原谅我图画的难看😂）：\nLR调整 二分查找的次数（成功失败）、折半查找判定树与二叉搜索树的关系 平衡二叉树是一种特殊的二叉查找树，它要求任何节点的两棵子树的高度差不超过1（同一棵树的不同节点的子树高度差可以为1、0、-1）。平衡二叉树通过在插入和删除节点时做旋转来维持树的平衡。\n折半查找判定树是一种特殊的平衡二叉树，它要求更加严格。同一棵树节点的左子树和右子树的差不能同时存在1和-1（即为统一向上取整或统一向下取整)。查找时，根据比较的结果折半排除一边的树。折半查找判定树中，只有最下面一层才可以不满。\n根据完全二叉树的高度计算公式，元素个数为n时，树高$h=\\lceil log_2(n+1)\\rceil$或$h=\\lfloor log_2(n)\\rfloor+1$。在折半查找中，\n查找成功的最小比较次数为1，最大比较次数为$h$； 查找失败的最小比较次数为：若$n=2^h-1$，则为$h$，否则为$h-1$，最大比较次数：$h$。 数据类型转换造成的精度丢失等问题 将高精度数转换为低精度数可能会引起：\n精度丢失：高精度数通常能够表示更大范围和更高精度的数字，但当将其转换为低精度数时，可能会导致小数部分被截断或丢失，从而引起精度丧失。 溢出：如果高精度数的值超出了低精度数所能表示的范围，会导致溢出。 将整型数转换为浮点数一般不会出现问题，但特殊情况下会导致精度丢失，对于非常大或非常小的整数，可能无法精确表示。如int类型数据二进制表示有32位，但是对于float类型，在IEEE 754格式下，尾数部分只有23位，可能无法完全表示某一个int类型数，造成精度的丢失。\n单精度与双精度浮点数的运算也有可能会有一些问题，例如10年真题$T_{14}$，$f=1.5678e3,d=1.5e100$，进行$(d+f)-d$运算，在$d+f$时，需要先进行对阶（小阶向大阶对齐），由于格式中的尾数限制，对阶后，$f$的尾数被舍去而变成了0，故$d+f$仍然为$d$，再减去$d$结果为0，而不是$f$。\n字扩展、位扩展与相关的芯片最低地址问题 位扩展\n位扩展是指用若干片位数较少的存储器芯片构成给定字长的存储器，容量改变，位数改变，地址单元个数不变。\n在袁春风老师的《计算机系统基础》中的一个例子如下：\n注意到8个$16M\\times8bit$的芯片扩展构成一个128M内存条。在进行扩展之前，对于单个芯片，地址位数为24bit。即地址单元个数为$16M=2^{24}$ 。每个地址单元存储8bit。\n在进行扩展之后，$128M=2^{27}$，而行列地址位数加起来一共$24bit$，$2^{24}=16M$，则说明此次扩展为位扩展。一个地址单元中的数据位数增加，但是总的地址单元个数并未改变。\n12位行地址$i$和12位列地址$j$分别送到DRAM芯片内部的行地址译码器和列地址译码器，选择行列地址交叉点$(i,j)$的8位数据同时进行读写，8个芯片就可以同时读取64bit，组合成总线所需要的64位传输宽度，再通过存储器总线进行传输。\n字扩展\n字扩展，容量改变，地址单元个数改变，即地址位数会改变，位数不会改变。\n另外，对于某一存储器，由多个DRAM经过字扩展而成，那么对于单个DRAM芯片来说，其行地址RAS位数、列地址CAS位数也不会变，但是整体存储器的总地址位数会变，会增加片选信号位数。 此时，对于一个主存地址，可以理解为芯片序号+芯片内的位置 。\n也就是说，无论是位扩展还是字扩展，对于单一的DRAM芯片，其行列地址位数均不含会改变。（14年T15）\n引起进程状态改变的一些典型事件 进程状态可以在以下情况下发生改变：\n创建新进程：当操作系统启动一个新的程序时，会创建一个新的进程，并将其状态设置为就绪状态。\n进程等待：当一个进程等待某些事件发生，例如等待用户输入、等待某个文件就绪等，它的状态会从运行状态变为阻塞状态。\n时间片用完：如果一个进程在分配给它的时间片用完之后，调度器会将其状态从运行状态变为就绪状态，降低其进程优先级，然后选择下一个要执行的进程。\nI/O操作完成：当一个进程等待的I/O操作完成后，它的状态会从阻塞状态变为就绪状态。\n进程终止：当一个进程完成了它的任务，或者由于某种原因需要被终止，它的状态会从运行状态变为终止状态。\n进程被阻塞的资源可用：当一个进程等待的资源（如锁或信号量）变为可用时，它的状态会从阻塞状态变为就绪状态。设备分配是在一个已经存在的进程中进行的，不会导致创建新进程。\n进程被唤醒：在多任务环境中，一个进程可能会被另一个进程唤醒，使得它从阻塞状态变为就绪状态。\n进程被挂起或恢复：操作系统可以将一个进程从内存中挂起（暂时移出内存）或者从挂起状态恢复（重新加载到内存中）。\n父进程等待子进程：当一个父进程等待其子进程结束时，它的状态可能会从运行状态变为阻塞状态。\n发生错误或异常：当一个进程遇到错误或异常情况时，它的状态可能会从运行状态变为终止状态或者阻塞状态（如果它在等待某些事件发生时发生了错误）。\n四种动态分区管理方式 IO系统的分层结构 最大帧长、最小帧长、数据报长度 RIP协议 碰撞域、广播域 冲突域：在同一个冲突域中，每一个结点都能收到所有其他结点发送的帧。简单地说，冲突域为同一时间内只能有一台设备发送信息的范围。 广播域：网络中能接收任意设备发出的广播帧的所有设备的集合。即，如果站点发出一个广播信号，所有能接收到这个信号的设备范围被称为一个广播域。 通常一个网段为一个冲突域，一个局域网为一个广播域。\n磁盘的调度策略 磁盘调度算法是操作系统中用于管理磁盘上的I/O请求的一种策略。以下是一些常见的磁盘调度算法：\n先来先服务（FCFS）：最简单的磁盘调度算法，按照请求的到达顺序依次执行。但可能会出现“早来的请求等待时间长”的问题。 最短寻道时间优先（SSTF）：选择当前磁头位置最近的请求进行服务，以最小化寻道时间。但可能会导致某些请求长时间等待。 SCAN算法：扫描算法，也称为电梯算法，类似于电梯的运行方式，磁头按一个方向移动，直到最后一个磁道后再改变方向。 C-SCAN算法：循环扫描算法，磁头按同一个方向移动，直到到达最后一个磁道后，立即直接返回到磁道0处，再继续扫描。 LOOK 算法：类似于扫描算法，但在到达最远的请求后不会立即返回，而是根据当前请求的方向决定下一个服务的磁道。在朝一个给定方向移动前查看是否有请求。 C-LOOK 算法：类似于 C-SCAN 算法，但在到达最远的请求后不会立即返回，而是直接返回到最远端的有请求的磁道。 注意，在做题时，若无特别说明，也可以默认SCAN算法和C-SCAN算法为LOOK和C-LOOK调度。\n磁盘块空闲状态的管理 FAT\n位示图\n09年 B树与B+树的异同 B树和B+树都是一种常用的多路搜索树数据结构，用于存储有序的数据集合，特别是在磁盘存储和数据库系统中应用广泛。\n数据存储：\nB树：B树的叶子节点和非叶子节点的结构基本相同，都可以存储数据。\nB+树：在B+树中，只有叶子节点存储数据，非叶子节点只存储索引（有点像文件管理中的索引顺序文件），叶子节点之间通过指针连接，形成一个有序的链表。\n范围查询效率：\nB树：由于B树的叶子节点也存储数据，因此可以直接进行范围查询。\nB+树：由于B+树的非叶子节点不存储数据，只有叶子节点存储数据，因此范围查询需要在叶子节点构成的链表上进行。\n查询性能：\nB树：由于B树的非叶子节点也存储数据，单次查询可能直接在非叶子节点找到结果，因此查询性能相对于B+树可能更快。\nB+树：B+树的查询性能相对于B树可能稍慢，因为每次查询都需要在叶子节点链表上进行。\n浮点数加减的步骤（IEEE 754） 正常方法：对阶（小阶向大阶对齐）、尾数运算、规格化（左规、右规）、舍入、判断溢出（判断舍入后的阶数是否超过了所能表示的范围）；\n偷懒方法：直接计算（按照大的阶数）、在规格化后判断是否溢出（判断阶数是否超过了所能表示的范围）（如10年T13）\nCISC与RISC的区别 CISC 指令系统设计的主要特点如下：\n指令系统复杂且多。指令条数多，寻址方式多，指令格式多而复杂，指令长度可变，操作码长度可变。 各种指令都能访问存储器，有些指令还需要多次访问存储器。 不利于实现流水线。因为指令周期长且差距大。绝大多数指令需要多个时钟周期才能完成，简单指令和复杂指令所用的时钟周期数相差很大。 复杂指令系统使得其实现越来越复杂，不仅增加了研制周期和成本，而且难以保证正确性，甚至因为指令太复杂而无法采用硬连线路控制器，导致大多数系统只能采用慢速的微程序控制器。 难以进行编译优化。由于编译器可选指令序列增多，使得目标代码组合增加，从而增加了目标代码优化的难度。 相关指令会产生显式的条件码，存放在专门的标志寄存器（或称状态寄存器）中，可用于条件转移和条件传送等指令。 相较于CISC，RISC 指令系统设计的主要特点如下：\n**指令数目少且规整。**只包含使用频度高的简单指令，寻址方式少，指令格式少，指令长度一致，指令中操作码和寄存器编号等位置固定，便于取指令、指令译码以及提前读取寄存器中操作数等。 采用 load/store 型指令设计风格。一条指令的执行阶段最多只有一次存储器访问操作。 采用流水线方式执行指令。规整的指令格式有利于采用流水线方式执行，除 load/store指令外，其他指令都只需一个或小于一个时钟周期就可完成，指令周期短。 采用硬连线路控制器。指令少而规整使得控制器的实现变得简单，可以不用或少用微程序控制器。 指令数量少，固然使编译工作量加大，但由于指令系统中的指令都是精选的，编译时间少，反过来对编译程序的优化又是有利的。 采用大量通用寄存器。编译器可将更多的局部变量分配到寄存器中，并且在过程调用时通过寄存器进行参数传递而不是通过栈进行传递，以减少访存次数。 硬布线控制器与微程序控制器的对比 硬布线控制器 微程序控制器 实现方式 通过硬件电路来实现的，通常是由逻辑门、寄存器和触发器等组件组成。 使用一组存储在控制存储器中的微指令序列来实现。 性能 硬件实现，因此执行速度通常非常快 略慢一些，每个微指令的执行需要额外的时钟周期。 复杂性 较高 相对更为简单 灵活性 控制逻辑固定在硬件中，不容易进行修改或升级，缺乏灵活性。 可以通过修改控制存储器中的微指令来改变控制逻辑，灵活性较高。 内存管理的主要保护措施 文件访问控制 口令保护\n为文件设置一个“口令“，用户想要访问文件时需要提供口令，由系统验证口令是否正确。\n实现开销小，但“口令“一般存放在FCB或索引结点中（也就是存放在系统中）因此不太安全。\n加密保护\n用一个“密码“对文件加密，用户想要访问文件时，需要提供相同的“密码“才能正确的解密。\n安全性高，即使文件被非法获取，没有密码也无法正确读取其中的内容。但加密/解密需要耗费一定的时间。\n访问控制\n用一个访问控制表 (ACL) 记录各个用户（或各组用户）对文件的访问权限，对文件的访问类型可以分为，读写/执行/删除等。\n实现灵活，可以实现复杂的文件保护功能，存放文件访问控制信息的合理位置为FCB或索引节点。\n软硬链接的区别 硬链接\n硬链接的实现只是在要创建链接的目录中创建了另一个名称，并将其指向原有文件的相同inode号（即低级别名称）。该文件不以任何方式复制。在创建文件的硬链接之后，在文件系统中，原有文件名（file）和新创建的文件名（file2）之间没有区别。实际上，它们都只是指向文件底层元数据的链接，可以在同一个inode中找到。\n硬链接有个局限在于：不能创建目录的硬链接（因为担心会在目录树中创建一个环）。不能硬链接到其他磁盘分区或文件系统中的文件（因为 inode 号在特定文件系统中是唯一的，而不是跨文件系统）等等。注意：在Windows操作系统中，磁盘分区通常是以盘符（如C盘、D盘等）来表示的，但这并不等同于Unix或类Unix系统中的文件系统中的概念。如果C盘和D盘属于同一物理磁盘（硬盘），可以在它们之间创建硬链接。然而，如果它们代表了两个不同的物理磁盘，那么在它们之间创建硬链接通常是不可能的。\n符号链接（软链接）\n因此，人们创建了一种称为符号链接（软链接）的新型链接。符号链接本身实际上是一个不同类型的文件。除了常规文件和目录之外，符号链接是文件系统知道的第三种类型。因为形成符号链接的方式是指向文件的路径名作为链接文件的数据，所以符号链接文件的大小于所指向的文件的路径名的长度有关系，且有可能造成所谓的悬空引用。\n奈奎斯特定理和香农定理 奈奎斯特定理规定，为了避免信号在数字化过程中产生失真，需要以至少两倍于信号最高频率的采样率对信号进行采样。\nFTP 在FTP中，数据传输可以采用两种模式：主动模式和被动模式。\n主动模式：\n客户端向FTP服务器的默认数据端口（通常是端口20）发起连接请求，请求建立数据连接。 服务器在接收到客户端的连接请求后，会从自己的数据端口（通常是端口20）向客户端的随机端口发起连接请求，请求建立数据连接。（服务器发起数据连接请求） 被动模式：\n客户端向FTP服务器的命令端口（通常是端口21）发送PASV命令，请求进入被动模式。 服务器收到PASV命令后，会打开一个随机的端口，监听客户端的连接请求，同时将该端口号发送给客户端。 客户端收到服务器返回的端口号后，会从自己的端口向服务器的指定端口发起连接请求，请求建立数据连接。（客户端发起数据连接请求） 11年 计算机性能评价相关词条 IEEE 754格式化 IEEE 754单精度浮点数的解释\n值的类型 符号 阶码 尾数 值 正零 $0$ $0$ $0$ $0$ 负零 $1$ $0$ $0$ $-0$ 正无穷大 $0$ $255(全1)$ $0$ $\\infty$ 负无穷大 $1$ $255(全1)$ $0$ $-\\infty$ 无定义数（非数） $0或1$ $255(全1)$ $\\ne0$ $\\text{NaN}$ 规格化非零正数 $0$ $0\u0026lt;e\u0026lt;255$ $f$ $2^{e-127}(1.f)$ 规格化非零负数 $1$ $0\u0026lt;e\u0026lt;255$ $f$ $-2^{e-127}(1.f)$ 非规格化正数 $0$ $0$ $f\\ne0$ $2^{126}(0.f)$ 非规格化负数 $1$ $0$ $f\\ne0$ $-2^{126}(0.f)$ IEEE 754的范围\n格式 最小值 最大值 单精度 $E=1,M=0$$1.0\\times2^{1-127}=2^{-126}$ $E=254,M=.111\\cdots,1.111\\cdots1\\times2^{254-127}=2^{127}\\times(2-2^{-23})=2^{128}-2^{104}$ 双精度 $E=1,M=0$$1.0\\times2^{1-1023}=2^{-1022}$ $E=2046,M=.111\\cdots,1.111\\cdots1\\times2^{2046-1023}=2^{1023}\\times(2-2^{-52})=2^{1024}-2^{971}$ 加减法法电路 电路\n标志位\n判断溢出\n系统总线的各条线传输的是什么 在取指令时，指令便是在数据线上传输的。操作数显然在数据线上传输。中断类型号用以指出中断向量的地址，CPU响应中断请求后，将中断应答信号 (INTR) 发回到数据总线上，CPU从数据总线上读取中断类型号后，查找中断向量表，找到相应的中断处理程序入口。而握手（应答）信号属于通信联络控制信号，应在通信总线上传输。\n抖动 OSI模型与TCP/IP模型各层的功能区别 OSI模型：\n物理层：解决使用何种信号来传输比特0和1的问题。负责定义物理媒介、传输速率、编码方法等，提供了物理介质上的原始数据传输。 数据链路层：解决帧在一个网络（或一段链路）上传输的问题。负责数据帧的传输、接收、错误检测和纠正，确保数据在物理层上可靠地传输。 网络层：解决分组在多个网络之间传输（路由）的问题。负责在不同网络之间进行路由选择，进行分组的转发和寻址，以及定义子网等网络层面的逻辑结构。 传输层：解决进程之间基于网络的通信问题。提供端到端的通信，保证数据的可靠传输，处理数据的分段和重组，以及流量控制和拥塞控制。 会话层：解决进程之间进行会话的问题。建立、管理和终止会话连接，提供了通信会话的控制和同步功能。 表示层：解决通信双方交换信息的表示问题。负责数据的格式转换、加密解密、压缩解压缩等，保证数据的可靠传输。 应用层：解决通过应用进程之间的交互来实现特定网络应用的问题。为用户提供各种网络应用服务，如文件传输、电子邮件、远程登录等。 TCP/IP模型：\n应用层：与OSI模型的应用层类似，提供网络应用服务。\n传输层：与OSI模型的传输层类似，负责提供端到端的通信服务。\n网络层：与OSI模型的网络层类似，负责在不同网络之间进行路由选择。\n链路层：包括了OSI模型的物理层和数据链路层的功能，负责在相邻节点间提供可靠的数据传输。\n在实际应用中，TCP/IP模型是目前广泛使用的网络模型，而OSI模型在理论上用于描述通信系统的功能。\n对正确接收到的数据帧进行确认的MAC协议 为什么是CSMA/CA协议？\nCSMA/CA协议，是一种用于在无线网络中进行数据通信的协议，针对无线环境中信道容量有限、易受干扰的特点而设计。它采用了一些机制来避免碰撞并提高数据传输的可靠性：\n监听信道：发送方在发送数据前会先监听信道，确保信道是空闲的，避免发生碰撞（减少概率，不能一定避免）。\nRTS/CTS帧：在CSMA/CA中，还引入了请求发送（Request to Send，RTS）和清除发送（Clear to Send，CTS）帧的概念。发送方在发送数据前会先发送一个RTS帧，接收方如果收到并确认了RTS帧，就会发送一个CTS帧给发送方，表示信道已经为发送方保留。这个过程可以有效避免隐藏节点问题和减少碰撞的发生。\n等待确认：发送方在发送数据后会等待接收方的确认，只有在收到确认后才会发送下一个数据帧。\n重传机制：如果发送方没有收到确认，会认为数据帧可能丢失，会进行重传。\n特殊的IP及其作用、使用方法 以下是RFC文档中的内容Special-Use IPv4 Addresses RFC 3330\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 Address Block Present Use Reference --------------------------------------------------------------------- 0.0.0.0/8 \u0026#34;This\u0026#34; Network [RFC1700, page 4] 10.0.0.0/8 Private-Use Networks [RFC1918] 14.0.0.0/8 Public-Data Networks [RFC1700, page 181] 24.0.0.0/8 Cable Television Networks -- 39.0.0.0/8 Reserved but subject to allocation [RFC1797] 127.0.0.0/8 Loopback [RFC1700, page 5] 128.0.0.0/16 Reserved but subject to allocation -- 169.254.0.0/16 Link Local -- 172.16.0.0/12 Private-Use Networks [RFC1918] 191.255.0.0/16 Reserved but subject to allocation -- 192.0.0.0/24 Reserved but subject to allocation -- 192.0.2.0/24 Test-Net 192.88.99.0/24 6to4 Relay Anycast [RFC3068] 192.168.0.0/16 Private-Use Networks [RFC1918] 198.18.0.0/15 Network Interconnect Device Benchmark Testing [RFC2544] 223.255.255.0/24 Reserved but subject to allocation -- 224.0.0.0/4 Multicast [RFC3171] 240.0.0.0/4 Reserved for Future Use [RFC1700, page 4] TCP头部各字段意义 12年 图在邻接表、邻接矩阵下的（空间）时间复杂度 邻接矩阵 邻接表 BFS $O( V )$$O( DFS $O( V )$$O( Prim $O( Kruskal $O(log Dijkstra $O( V ^2)$ Floyd $O( 拓扑排序 $O( V ^2)$ 上三角矩阵和拓扑排序 若用邻接矩阵存储有向图，矩阵中主对角线及以下的元素均为零（或主对角线及以上的元素均为零），则该图的拓扑序列一定存在，但不一定唯一。\n例如，如果一个有向图使用邻接矩阵进行存储，并且矩阵中主对角线及以下的元素均为零，那么这个图的拓扑序列一定存在。因为拓扑序列是一个图中所有顶点的线性排序，使得对于每一条有向边 \u0026lt;u,v\u0026gt;，顶点 u 在序列中都出现在顶点 v 之前。在这种情况下，由于主对角线以下的元素都是零，表明没有顶点指向自己，也就不存在环路，因此必然存在拓扑排序。\n然而，拓扑序列可能不是唯一的。这是因为在一个有向无环图中，可能存在多个顶点没有前驱（即入度为零），这些顶点的相对顺序可以任意排列，只要它们在拓扑排序中排在其他顶点之前即可。因此，可能存在多个合法的拓扑序列。\n反之，如果存在拓扑序列，邻接矩阵不一定满足主对角线及以下的元素均为零（或主对角线及以上的元素均为零）。\n闪存 数据线、地址线、控制线 参考【组成原理·总线】总线的概念和计算\n在单总线结构中：\n数据线：用于在各个设备（包括CPU、主存、外设）之间传递数据。\n地址线：传输地址信息，用于指示要访问的特定内存单元或外设的地址。地址线的数量决定了总线的寻址能力，也就是可以寻址的内存或设备数量。\n控制线：传输各种控制信号，如读取、写入、使能等信号，以控制数据的流动和操作。控制线还可能包括时钟信号等。也可以传输主存返回 CPU 的反馈信号。\n在IO接口中：\n数据线：可以传输IO接口中的命令字、状态字、中断类型号，在接口中的数据缓冲寄存器、内存、CPU中的寄存器之间进行数据传送。**（可双向传输）**同时接口和设备的状态信息被记录在状态寄存器中，通过数据线将状态信息送到 CPU。CPU 对外设的控制命令也通过数据线传送。 地址线：接口中的地址线用于给出要访问的 I/O 接口中的寄存器的地址，它和读/写控制信号一起被送到 I/O 接口的控制逻辑部件。(只能单向) 控制线：通过控制线传送来的读/写信号确认是读寄存器还是写寄存器，此外控制线还会传送一些仲裁信号和握手信号。（只能单向） 中断处理和子程序调用的区别 触发方式：\n中断处理：中断是由硬件或外部事件触发的。当发生了某个预定义的事件（如设备输入、时钟周期等），硬件会暂停当前程序的执行，并跳转到相应的中断处理程序中执行。\n子程序调用：子程序调用是由程序内部通过软件指令来触发的。程序会通过调用指令跳转到指定的子程序中执行，执行完后再返回到原来的程序。\n上下文切换：\n中断处理：中断处理涉及到从用户态切换到内核态，然后再返回用户态的过程。这涉及到硬件和操作系统的支持，需要保存和恢复相应的寄存器和状态，如断点（PC）、程序状态字寄存器（PSW）。（中断处理中最重要的两个寄存器）\n子程序调用：子程序调用是在同一程序执行流中完成的，没有涉及到从用户态到内核态的切换。因此，它比中断处理的上下文切换开销要小，只需要保存程序断点。\n异步性质：\n中断处理：中断是异步的，它可以随时发生并打断当前的程序执行。因此，中断处理必须能够处理不可预知的事件。\n子程序调用：子程序调用是同步的，它是由程序内部明确地发起的，执行完子程序后会继续执行后续的指令。\n权限级别：\n中断处理：中断处理通常需要在内核态执行。\n子程序调用：子程序可以在用户态或内核态中执行，具体取决于程序的权限和需要。\n物理接口各个特性的功能 机械特性：指明接口所用接线器的形状和尺寸、引脚数目和排列、固定和锁定装置等。 电气特性：指明在接口电缆的各条线上出现的电压的范围。 功能特性：指明某条线上出现的某一电平的电压表示何种意义。 过程特性：或称规程特性。指明对于不同功能的各种可能事件的出现顺序。 协议的三部分 协议由语法、语义和同步三部分组成。\n语法规定了传输数据的格式； 语义规定了所要完成的功能，即需要发出何种控制信息、完成何种动作及做出何种应答； 同步规定了执行各种操作的条件、时序关系等，即事件实现顺序的详细说明。 一个完整的协议通常应具有线路管理（建立、释放连接）、差错控制、数据转换等功能。协议并不关心具体如何实现，只要求实现什么功能。\n路由器的功能 各层协议有无连接、可不可靠？ 数据链路层：\n以太网的MAC协议提供的是无连接不可靠服务：考虑到局域网信道质量好，以太网采取了两项重要的措施以使通信更简便：采用无连接的工作方式；不对发送的数据帧进行编号，也不要求对方发回确认。因此，以太网提供的服务是不可靠的服务，即尽最大努力的交付。差错的纠正由高层完成。 无线局域网的MAC协议提供的是无连接可靠服务：并没有“握手”的过程，即传输数据之前并没有连接。 网络层：\nIP协议提供的是无连接不可靠服务：IP协议不需要在传输数据前建立连接，也不需要在传输过程中保持连接状态。每个IP数据包都是独立传输的，它们之间没有直接的关联。IP数据包的传输是不可靠的，这意味着它们可能会丢失、延迟、重复或者乱序。IP协议不提供任何机制来保证数据的可靠性，也不负责处理丢失的数据包。 传输层：\nTCP协议提供的是有连接可靠服务：通过序号、确认、重传等机制来保证数据的完整性和有序性。 UDP协议提供的是无连接不可靠服务：将数据分割成报文段，并将报文段发送到目标，无需建立连接或维护会话状态。但是可以通过在应用层实现自定义的可靠性机制，使得UDP的通信变得可靠。 IP首部各字段意义 协议A直接为协议B提供服务 协议A 协议B TCP BGP IP OSPF UDP RIP IP ICMP IP TCP IP UDP UDP DNS TCP HTTP TCP SMTP TCP POP3 IP IGMP TCP FTP 13年 最佳归并树 有n个初始归并段，需要做k路平衡归并排序，可以根据哈夫曼树的思想来优化WPL。\nRAID相关知识 RAID0方案是无冗余和无校验的磁盘阵列，而RAID1-5方案均是加入了冗余（镜像）或校验的磁盘阵列。能够提高 RAID 可靠性的措施主要是对磁盘进行镜像处理和奇偶校验。\n条带化技术是一种自动地将I/O的负载均衡到多个物理磁盘上的技术。条带化技术就是将一块连续的数据分成很多小部分并把它们分别存储到不同磁盘上去。这就能使多个进程同时访问数据的多个不同部分但不会造成磁盘冲突，而且在需要对这种数据进行顺序访问的时候可以获得最大程度上的I/O并行能力，从而获得非常好的性能。\n中断I/O方式和DMA方式的比较 中断处理方式： 在设备输入每个数据的过程中，由于无须 CPU 干预，因而可使CPU与I/O设备并行工作。仅当输完一个数据时，才需 CPU 花费极短的时间去做些中断处理，因此中断申请使用的是 CPU 处理时间； 中断响应发生的时间是在一条指令执行结束之后； 数据是在软件（中断服务程序）的控制下完成传送的。 DMA方式： 数据传输的基本单位是数据块； 每个数据块传送完毕时，都会发生DMA请求，DMA请求每次申请的是总线的使用权，所传送的数据是从设备直接送入内存的，或者相反； 仅在传送一个或多个数据块的开始和结束时，才需 CPU 干预，整块数据的传送是在硬件（DMA控制器）的控制下完成的。 IO密集型的进程和计算密集型的进程优先级 当系统中存在大量IO密集型任务时，优先处理这类任务可以减少IO等待时间，提高IO设备的利用率，同时可以充分利用CPU资源等待IO操作完成。\n操作系统的加载 操作系统最终被加载到RAM中。\n预防死锁、避免死锁的区别 预防死锁：预防死锁的方法是在设计阶段就采取措施，使得系统不会发生死锁。这种方法主要通过破坏死锁产生的四个必要条件（互斥访问、不可剥夺、请求和保持、循环等待）来实现。预防死锁是一种静态的、全局的策略，需要在系统设计和实施阶段进行考虑和实施。 避免死锁：避免死锁是在系统运行时根据进程的动态行为来避免死锁的发生。这种方法会通过对资源的合理分配和释放（如银行家算法）来避免进入死锁状态。避免死锁是一种动态的、局部的策略，根据当前系统状态来进行判断和处理。 物理层基带传输信号 图源《通信原理》（樊昌信\u0026ndash;第六版）\n(a) 单极性非归零编码\n(b) 双极性非归零编码\n(c) 单极性归零编码\n(d) 双极性归零编码\n(e) 差分编码\n图源王道《计算机网络考研复习指导》\n以太网使用的编码方式就是曼彻斯特编码\nSMTP协议 14年 指令cache与数据cache分离的主要目的 可以减少指令流水线资源冲突。如一个进程在取指令时，另一条指令可以同时取数据。\n管道通信的定义、特点 **管道是驻留在内存中的伪文件，可以使用标准文件函数对其进行访问。**与磁盘文件不同，它是临时的，且并不占用磁盘或者其他外部存储的空间，而是占用内存空间。Linux系统直接把管道实现成了一种文件系统，借助VFS给应用程序提供操作接口。所以，Linux上的管道就是一个操作方式为文件的内存缓冲区。 管道的容量大小通常为内存上的一页，它的大小并不是受磁盘容量大小的限制。 它常用于父子进程之间的通信。类似于通信中半双工信道的进程通信机制，一个管道同一个时刻只能最多有一个方向的传输，不能两个方向同时进行。若要实现父子进程双向通信，则需要定义两个管道。 一个进程可以向管道写入数据，另一个进程可以同时从管道读取数据。当管道满时，进程在写管道会被阻塞，而当管道空时，进程在读管道会被阻塞。 从管道读数据是一次性操作，数据一旦被读取，就释放空间以便写更多数据。 关于管道不是文件这一点，参考知乎文章Linux 的进程间通信：管道以及Windows应用开发\n交换区和内存映射 内存映射和交换区（Swap）都是操作系统中用于管理内存的重要机制，但它们有着不同的作用和实现方式。\n内存映射：\n作用：内存映射是一种将磁盘上的文件或设备映射到进程的地址空间中的机制。它允许程序直接访问磁盘上的文件，而无需通过常规的文件读写操作。通过内存映射，程序可以将文件的内容视为内存中的一部分，从而实现对文件的高效访问。\n实现：内存映射是通过将磁盘文件的某个区域映射到进程的虚拟地址空间中，从而让程序可以直接读写这块区域的内容。在某种程度上，内存映射可以看作是文件和内存之间的一个透明的接口。\n交换区：\n作用：交换区是一块硬盘空间，用于暂时存储在物理内存中暂时不活跃的数据和程序。当物理内存不足以容纳当前运行的程序和数据时，操作系统会将一部分数据移到交换区中，从而释放出物理内存。\n实现：交换区是一块硬盘或者固态硬盘的空间，它用于作为物理内存的扩展。当系统需要释放物理内存时，它会将部分不活动的数据和程序写入到交换区中。当需要时，可以将交换区中的数据重新读取到物理内存中。\n区别：\n作用不同：内存映射主要用于实现文件和内存之间的高效访问，而交换区用于在物理内存不足时暂存数据。\n实现方式不同：内存映射是通过将文件或设备映射到进程的地址空间中实现的，而交换区是通过将部分不活动的数据写入到硬盘空间中实现的。\n适用场景不同：内存映射适用于需要频繁访问文件内容的场景，而交换区是用于解决物理内存不足的问题。\n虚拟内存 = 物理内存 + 交换区大小 + 内存映射\n码片 UDP协议的特点 15年 卡特兰数 $\\frac{1}{n+1}C^n_{2n}$\n例如，n个不同的元素进栈，出栈元素不同排列的个数为$\\frac{1}{n+1}C^n_{2n}$\n例如，求先序序列为abcd的不同二叉树的个数也可以利用此解法：\n根据二叉树前序遍历和中序遍历的递归算法中递归工作栈的状态变化得出：前序序列和中序序列的关系相当于以前序序列为入栈次序，以中序序列为出栈次序。因为前序序列和中序序列可以唯一地确定一棵二叉树，所以题意相当于“以序列abcd为入栈次序，则出栈序列的个数为多少”，对于n个不同元素进栈，出栈序列的个数为卡特兰数。\n堆调整时的比较次数 例如，对于大根堆：\n调整乱序初始堆：从全部结点的一半处n/2，开始调整： 调整i及其子树：向下调整：需要先两个孩子进行比较，再和较大者进行交换； i\u0026ndash;：对左兄弟结点或父结点进行调整，重复上一步。 插入节点后：自底向上比较调整，每次向上调整，只需要和父节点进行比较，如果比父节点大，则上移，否则不动；而不是先和兄弟节点比较谁大，因为兄弟节点必定比父节点小。 删除节点后：自顶向下比较调整，每次上下调整，需要先两个孩子进行比较，再和较大者进行交换，因为本节点和两个孩子的大小关系、两个孩子之间的大小都未知。 浮点数溢出问题 对阶操作不会引起阶码上溢或下溢（小阶向大阶对齐，这里前提是小阶能对齐到大阶，如果大的阶数超过了小阶数的阶码所能表示的范围，那么对阶时也会发生溢出）； 左规时可能引起阶码下溢； 右规和尾数舍入（0舍1入法）都可能引起阶码上溢； 尾数溢出时，结果不一定溢出，因为尾数溢出可以通过右规操作来纠正，结果可能产生误差，但不一定会溢出。 DRAM的刷新 对于ROM，即使断电信息也不会丢失。\n对于SRAM，其存储元（区别于存储单位）是双稳态触发器（六晶体管MOS），即使信息被读出后，仍保持原状态而不需要再生（非破坏性读出）。但是断电后信息会丢失。\n对于DRAM，其存储元通常只使用一个晶体管。DRAM电容上的电荷一般只能维持1~2ms，即使电源不断电，信息也会自动消失，因此必须每隔一段时间进行刷新，称为刷新周期，常见的刷新方式有3种：\n集中刷新：指在一个刷新周期内，利用一段固定的时间，依次对存储器的所有行进行逐一再生，在此期间停止对存储器的读写操作，称为“死时间”，又称访存“死区”。优点是读写操作时不受刷新工作的影响；缺点是在集中刷新期间不能访问存储器。 分散刷新：把对每行的刷新分散到各个工作周期中。这样，一个存储器的系统工作周期分为两部分：前半部分用于正常读、写或保持；后半部分用于刷新。优点是没有死区；缺点是加长了系统的存取周期。 异步刷新：异步刷新是前两种方法的结合。具体做法是将刷新周期除以行数，得到两次刷新操作之间的时间间隔t，利用逻辑电路每隔时间t产生一次刷新请求。这样可以避免使CPU连续等待过长的时间，而且减少了刷新次数，从根本上提高了整机的工作效率。 DRAM 的刷新需要注意以下问题：\n刷新对CPU是透明的，即刷新不依赖于外部的访问，不需要CPU控制； DRAM的刷新单位是行，由芯片内部自行生成行地址； 刷新操作类似于读操作，但又有所不同。另外，刷新时不需要选片，即整个存储器中的所有芯片同时被刷新。 总线定时 **同步定时方式：**系统采用一个统一的时钟信号来协调发送和接收双方的传送定时关系。\n异步定时方式：没有统一的时钟，也没有固定的时间间隔，完全依靠传送双方相互制约的“握手”信号来实现定时控制。\n不互锁方式：主设备发出“请求”信号后，不必等到接到从设备的“回答”信号，而是经过一段时间，便撤销“请求”信号。而从设备在接到“请求”信号后，发出“回答”信号，并经过一段时间，自动撤销“回答”信号。双方不存在互锁关系。速度最快，可靠性最差 半互锁方式：主设备发出“请求”信号后，必须待接到从设备的“回答”信号后，才撤销“请求”信号，有互锁的关系。而从设备在接到“请求”信号后，发出“回答”信号，但不必等待获知主设备的“请求”信号已经撤销，而是隔一段时间后自动撤销“回答”信号，不存在互锁关系； 全互锁方式：主设备发出“请求”信号后，必须待从设备“回答”后，才撤销“请求”信号；从设备发出“回答”信号，必须待获知主设备“请求”信号已撤销后，再撤销其“回答”信号。双方存在互锁关系。速度最慢，可靠性最好 优点：总线周期长度可变，能保证两个工作速度相差很大的部件或设备之间可靠地进行信息交换，自动适应时间的配合。\n缺点：比同步控制方式稍复杂一些，速度比同步定时方式慢\n半同步定时方式：统一时钟的基础上，增加一个“等待”响应信号；\n分离式通信：$\\cdots$\nDHCP报文地址问题 ARP报文地址问题 ","permalink":"https://fireflyyh.top/posts/408/%E7%9C%9F%E9%A2%98%E6%80%BB%E7%BB%931/","summary":"10年 平衡二叉树的调整 LL调整 RR调整 RL调整 例如（原谅我图画的难看😂）：\nLR调整 二分查找的次数（成功失败）、折半查找判定树与二叉搜索树的关系 平衡二叉树是一种特殊的二叉查找树，它要求任何节点的两棵子树的高度差不超过1（同一棵树的不同节点的子树高度差可以为1、0、-1）。平衡二叉树通过在插入和删除节点时做旋转来维持树的平衡。\n折半查找判定树是一种特殊的平衡二叉树，它要求更加严格。同一棵树节点的左子树和右子树的差不能同时存在1和-1（即为统一向上取整或统一向下取整)。查找时，根据比较的结果折半排除一边的树。折半查找判定树中，只有最下面一层才可以不满。\n根据完全二叉树的高度计算公式，元素个数为n时，树高$h=\\lceil log_2(n+1)\\rceil$或$h=\\lfloor log_2(n)\\rfloor+1$。在折半查找中，\n查找成功的最小比较次数为1，最大比较次数为$h$； 查找失败的最小比较次数为：若$n=2^h-1$，则为$h$，否则为$h-1$，最大比较次数：$h$。 数据类型转换造成的精度丢失等问题 将高精度数转换为低精度数可能会引起：\n精度丢失：高精度数通常能够表示更大范围和更高精度的数字，但当将其转换为低精度数时，可能会导致小数部分被截断或丢失，从而引起精度丧失。 溢出：如果高精度数的值超出了低精度数所能表示的范围，会导致溢出。 将整型数转换为浮点数一般不会出现问题，但特殊情况下会导致精度丢失，对于非常大或非常小的整数，可能无法精确表示。如int类型数据二进制表示有32位，但是对于float类型，在IEEE 754格式下，尾数部分只有23位，可能无法完全表示某一个int类型数，造成精度的丢失。\n单精度与双精度浮点数的运算也有可能会有一些问题，例如10年真题$T_{14}$，$f=1.5678e3,d=1.5e100$，进行$(d+f)-d$运算，在$d+f$时，需要先进行对阶（小阶向大阶对齐），由于格式中的尾数限制，对阶后，$f$的尾数被舍去而变成了0，故$d+f$仍然为$d$，再减去$d$结果为0，而不是$f$。\n字扩展、位扩展与相关的芯片最低地址问题 位扩展\n位扩展是指用若干片位数较少的存储器芯片构成给定字长的存储器，容量改变，位数改变，地址单元个数不变。\n在袁春风老师的《计算机系统基础》中的一个例子如下：\n注意到8个$16M\\times8bit$的芯片扩展构成一个128M内存条。在进行扩展之前，对于单个芯片，地址位数为24bit。即地址单元个数为$16M=2^{24}$ 。每个地址单元存储8bit。\n在进行扩展之后，$128M=2^{27}$，而行列地址位数加起来一共$24bit$，$2^{24}=16M$，则说明此次扩展为位扩展。一个地址单元中的数据位数增加，但是总的地址单元个数并未改变。\n12位行地址$i$和12位列地址$j$分别送到DRAM芯片内部的行地址译码器和列地址译码器，选择行列地址交叉点$(i,j)$的8位数据同时进行读写，8个芯片就可以同时读取64bit，组合成总线所需要的64位传输宽度，再通过存储器总线进行传输。\n字扩展\n字扩展，容量改变，地址单元个数改变，即地址位数会改变，位数不会改变。\n另外，对于某一存储器，由多个DRAM经过字扩展而成，那么对于单个DRAM芯片来说，其行地址RAS位数、列地址CAS位数也不会变，但是整体存储器的总地址位数会变，会增加片选信号位数。 此时，对于一个主存地址，可以理解为芯片序号+芯片内的位置 。\n也就是说，无论是位扩展还是字扩展，对于单一的DRAM芯片，其行列地址位数均不含会改变。（14年T15）\n引起进程状态改变的一些典型事件 进程状态可以在以下情况下发生改变：\n创建新进程：当操作系统启动一个新的程序时，会创建一个新的进程，并将其状态设置为就绪状态。\n进程等待：当一个进程等待某些事件发生，例如等待用户输入、等待某个文件就绪等，它的状态会从运行状态变为阻塞状态。\n时间片用完：如果一个进程在分配给它的时间片用完之后，调度器会将其状态从运行状态变为就绪状态，降低其进程优先级，然后选择下一个要执行的进程。\nI/O操作完成：当一个进程等待的I/O操作完成后，它的状态会从阻塞状态变为就绪状态。\n进程终止：当一个进程完成了它的任务，或者由于某种原因需要被终止，它的状态会从运行状态变为终止状态。\n进程被阻塞的资源可用：当一个进程等待的资源（如锁或信号量）变为可用时，它的状态会从阻塞状态变为就绪状态。设备分配是在一个已经存在的进程中进行的，不会导致创建新进程。\n进程被唤醒：在多任务环境中，一个进程可能会被另一个进程唤醒，使得它从阻塞状态变为就绪状态。\n进程被挂起或恢复：操作系统可以将一个进程从内存中挂起（暂时移出内存）或者从挂起状态恢复（重新加载到内存中）。\n父进程等待子进程：当一个父进程等待其子进程结束时，它的状态可能会从运行状态变为阻塞状态。\n发生错误或异常：当一个进程遇到错误或异常情况时，它的状态可能会从运行状态变为终止状态或者阻塞状态（如果它在等待某些事件发生时发生了错误）。\n四种动态分区管理方式 IO系统的分层结构 最大帧长、最小帧长、数据报长度 RIP协议 碰撞域、广播域 冲突域：在同一个冲突域中，每一个结点都能收到所有其他结点发送的帧。简单地说，冲突域为同一时间内只能有一台设备发送信息的范围。 广播域：网络中能接收任意设备发出的广播帧的所有设备的集合。即，如果站点发出一个广播信号，所有能接收到这个信号的设备范围被称为一个广播域。 通常一个网段为一个冲突域，一个局域网为一个广播域。\n磁盘的调度策略 磁盘调度算法是操作系统中用于管理磁盘上的I/O请求的一种策略。以下是一些常见的磁盘调度算法：\n先来先服务（FCFS）：最简单的磁盘调度算法，按照请求的到达顺序依次执行。但可能会出现“早来的请求等待时间长”的问题。 最短寻道时间优先（SSTF）：选择当前磁头位置最近的请求进行服务，以最小化寻道时间。但可能会导致某些请求长时间等待。 SCAN算法：扫描算法，也称为电梯算法，类似于电梯的运行方式，磁头按一个方向移动，直到最后一个磁道后再改变方向。 C-SCAN算法：循环扫描算法，磁头按同一个方向移动，直到到达最后一个磁道后，立即直接返回到磁道0处，再继续扫描。 LOOK 算法：类似于扫描算法，但在到达最远的请求后不会立即返回，而是根据当前请求的方向决定下一个服务的磁道。在朝一个给定方向移动前查看是否有请求。 C-LOOK 算法：类似于 C-SCAN 算法，但在到达最远的请求后不会立即返回，而是直接返回到最远端的有请求的磁道。 注意，在做题时，若无特别说明，也可以默认SCAN算法和C-SCAN算法为LOOK和C-LOOK调度。\n磁盘块空闲状态的管理 FAT","title":"真题总结1"},{"content":"本博客使用了Hugo等技术进行搭建，使用的主题为PaperMod，并对其进行了一定的修改，在这过程也参考了其他博客的实现，如Sulv\u0026rsquo;s Blog。\n本博客主要用于记录平时学习的一些过程，比如：校园学习、编程学习、读书笔记等等。\n作者本人是一名普通的大学生，也是一名编程新手（新手中的新手），仍在不断地试错与学习。如果您能主动与我交流（日常也好，学习也好），我都会非常高兴。😊\n另外，非常感谢你能够浏览我的博客！\n你也可以通过以下途径联系我：\nGithub 邮箱 哔哩哔哩 ","permalink":"https://fireflyyh.top/about/","summary":"about","title":"About me"}]